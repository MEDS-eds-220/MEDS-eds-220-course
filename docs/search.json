[
  {
    "objectID": "book/setup.html",
    "href": "book/setup.html",
    "title": "Setup",
    "section": "",
    "text": "All the course materials use the Python programming language and git for version control. To install or make sure you have these in your computer, follow the MEDS Software Installation Guide from 4. Check for git to 9. Install VS Code.\n\n\n\nTo install the libraries needed to execute the code in these notes you should create a conda environment using the environment.yml file in the notes repository.\nTo build the environment:\n\nDownload the environment.yml file in the notes repository. Place it in the directory where you will store the notebooks associated with these notes.\nUsing the terminal, navigate to the directory where the environment.yml file is.\nRun the following command to build the environment:\n\nconda env create -f environment.yml\n\nOnce the building finishes, run the following command to check the new environment was created:\n\nconda env list\nTo activate the environment:\n\nIn your terminal, … Finish\nIf you are using VSCode, you should be able open a Python notebok and select the new environment by accessing a drop-down list by clicking on the top right corner.\n\nAdd picture\n\n\n\nYou’re ready to start coding! The course starts with a Python review in the next section.",
    "crumbs": [
      "book",
      "Setup"
    ]
  },
  {
    "objectID": "book/setup.html#software-installation",
    "href": "book/setup.html#software-installation",
    "title": "Setup",
    "section": "",
    "text": "All the course materials use the Python programming language and git for version control. To install or make sure you have these in your computer, follow the MEDS Software Installation Guide from 4. Check for git to 9. Install VS Code.",
    "crumbs": [
      "book",
      "Setup"
    ]
  },
  {
    "objectID": "book/setup.html#python-environment",
    "href": "book/setup.html#python-environment",
    "title": "Setup",
    "section": "",
    "text": "To install the libraries needed to execute the code in these notes you should create a conda environment using the environment.yml file in the notes repository.\nTo build the environment:\n\nDownload the environment.yml file in the notes repository. Place it in the directory where you will store the notebooks associated with these notes.\nUsing the terminal, navigate to the directory where the environment.yml file is.\nRun the following command to build the environment:\n\nconda env create -f environment.yml\n\nOnce the building finishes, run the following command to check the new environment was created:\n\nconda env list\nTo activate the environment:\n\nIn your terminal, … Finish\nIf you are using VSCode, you should be able open a Python notebok and select the new environment by accessing a drop-down list by clicking on the top right corner.\n\nAdd picture",
    "crumbs": [
      "book",
      "Setup"
    ]
  },
  {
    "objectID": "book/setup.html#next",
    "href": "book/setup.html#next",
    "title": "Setup",
    "section": "",
    "text": "You’re ready to start coding! The course starts with a Python review in the next section.",
    "crumbs": [
      "book",
      "Setup"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html",
    "href": "book/appendices/A-python-environments.html",
    "title": "Virtual environments",
    "section": "",
    "text": "This hands-on lesson gives a brief introduction to Python virtual environments.\n\n\nBy the end of this lesson, students will be able to:\n\n\n\nEnvironments are a way to keep the packages and Python versions you use for different projects organized.\n\n\n\nSome environments can have lots of packages and dependencies, while others can keep it simple.\n\n\nThe main reasons to create an environment for each of your projects are:\n\nTo not interfere with your computer’s pre-installed Python\nManage dependency conflicts for different projects\nReproducibility! Being able to share your code and what it needs to run it with others\n\n\n\n\n\n\n\nDependencies\n\n\n\nWhat these are.\n\n\n\n\n\nConda is an environment and package management system: it can both create and administer the environments and install compatible versions of software and their dependencies. Environments created with Conda are usually called Conda environments. A Conda environment doesn’t need to be a Python environment, Conda can manage packages for any programming language.\n\n\n\n\n\n\n\n\nConda channels are the remote locations where packages are stored. Think of them as shops for getting packages. By default, packages are downloaded to your computer and updated from the conda default channel. But there are others! Conda-forge and bioconda are two popular ones. We can choose which Conda channel to install a package from.\n\n\n\npip is a package management system only for Python. We can use it to install packages from the Python Package Index (PyPI). We can use pip inside a Conda environment when a package is not available from a Conda channel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommand\nWhat it does\n\n\n\n\nconda env list\nlist available Conda environments\n\n\nconda create --name my-env python\ncreate new Python environment called my-env\n\n\nconda remove --name my-env  --all\ndelete my-env\n\n\ncoda activate my-env\nactivate environment\n\n\ncoda deactivate\ndeactivate active environment\n\n\npython -V\ncheck which Python version is installed in active environment\n\n\nconda list\ncheck which packages are installed in active environment\n\n\nconda list numpy\ncheck if numpy is installed in active environment\n\n\nconda install numpy\ninstall numpy package in environment using environment channel priorities (generally just from defaults channel)\n\n\nconda install --channel conda-forge rioxarray\ninstall rioxarray package in environment from from conda-forge channel (after going through other environment channel prioirities)\n\n\n\n\n\n\n\n\nTo list all the Conda environments available in your computer and their location we use:\nconda env list\nThe output should look something like this:\n# conda environments:\n#\nbase                  *  /Users/galaz-garcia/opt/anaconda3\neds220-env               /Users/galaz-garcia/opt/anaconda3/envs/eds220-env\nInfo about env being a directory/files with that file path.\n\n\n\n\n\n\nWhat is my current active environment?\n\n\n\nWhen you run conda env list, the asterisk next to the environment path indicates which environment is active. In this example, I am using the base Python environment. The currently active environment also appears in the terminal in parenthesis at the beginning of each line, something like this:\n(base) my-computer:MEDS-eds-220-course galaz-garcia$\n\n\n\n\n\nTo create a new environment called test-env and, within it, install the most recent version of python we simply run:\nconda create --name test-env python\nWhen you run it it will give you information about the packages that will be installed and ask you whether to proceed or not. Type y and press enter to create the environment and install the packages.\n\n\n\n\n\n\nCheck-in\n\n\n\nCheck whether the new test-env environment is listed by Conda. Is it activated or not?\n\n\n\n\n\nTo activate the test-env environment we use the command\nconda activate test-env\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that test-env is now your current environment.\n\n\n\n\n\nTo see which packages are installed within the currently active environment we run:\nconda list\nThe output will be a long list that looks something like this:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbzip2                     1.0.8                h6c40b1e_6  \npip                       24.2            py312hecd8cb5_0  \nsqlite                    3.45.3               h6c40b1e_0  \n[...]\nThe name and version of each installed package in the environment appear in their respective columns. The ‘Build’ column shows a build string for each package. This string encodes important information about how the package was compiled, including any updates or changes made without altering the package version. It also reflects any compatibility or performance optimizations that were integrated during the build process.\nFor example, the same package with the same version might have different builds (and therefore different build strings) depending on whether it was installed on macOS, Windows, or Linux. This difference arises because the package may need to be compiled differently to optimize performance and ensure compatibility with each operating system.\nThe ‘Channel’ column shows the source from which the package was downloaded and installed. In this example the entries on this column are blank, signaling these packages were downloaded from the defeault Conda channel. We’ll see other channels appear in the next examples.\nWe can also request information about a specific package. For example, if we run\nconda list pip\nwe obtain only the information about the pip package:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\npip                       24.2            py312hecd8cb5_0  \nWe can also use this to verify whether a package is installed. For example, if we run\nconda list numpy\nwe will get empty columns:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbecause the numpy package is not intalled in this environment.\n\n\n\nLet’s say we want to install numpy in our currently active environment test-env. To do this we can simply use the command:\nconda install numpy\nSince we have not specified another channel, this command will install numpy from the default channel.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that numpy is now installed.\n\n\nNow, suppose we want to install rioxarray, this is a Python package for raster data analysis. This is a relatively new package, so it might not be available from the default Conda channels. A sensible measure would be to first look if rioxarray is available in the defaults channels, which we can do by running:\nconda search rioxarray\nThe output will look similar to\nLoading channels: done\nNo match found for: rioxarray. Search: *rioxarray*\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - rioxarray\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/osx-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/osx-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the Conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\nAs stated, rioxarray is not available on the default channels for my conda installation. Notice a couple of the channels it is seraching on are specific to macOS (my corrent operating system), and the last two are actually channels for R packages.\nIf we had tried to install rioxarray using conda install rioxarray we would have obtained an error message with similar information.\nWe may have better luck searching for rioxarray in the conda-forge channel, which we can do like this:\nconda search --channel conda-forge rioxarray\nfrom which we obtain a list of available versions and builds of this package in the conda-forge channel:\nLoading channels: done\n# Name                       Version           Build  Channel             \nrioxarray                      0.0.3            py_0  conda-forge         \nrioxarray                      0.0.4            py_0  conda-forge         \nrioxarray                      0.0.5            py_0  conda-forge     \n[...]\nrioxarray                     0.16.0    pyhd8ed1ab_0  conda-forge         \nrioxarray                     0.17.0    pyhd8ed1ab_0  conda-forge   \n\n\n\n\n\n\nCheck-in\n\n\n\nDo you see any versions of rioxarray with multiple builds?\n\n\nSince we now know that we can find rioxarray in the conda-forge channel, we can go ahead and install it from this channel using the command\nconda install --channel conda-forge rioxarray\nYou’ll see a moving bar that says Conda is solving (the) environment - this is Conda doing what the package management! It means Conda is working on finding the dependencies for the packages you are trying to install, finding versions of these dependencies that are compatible with each other, making sure these new packages are compatible with the packages already present in the environment or see it needs to upgrade, downgrade or remove anything in the environment. Overall, Conda tries to install what we need with the least disruption. Solving an environment can often take time but it is crucial so that the environment remains stable and functional.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nCheck whether pandas is installed in the environment.\nWhich channels were used to install dependencies for rioxarray?\n\n\n\n\n\n\n\nTo deactivate our current environment and return to our base environment we simply run\nconda deactivate\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify we are no longer in the test-env.\n\n\n\n\n\nSince this was a test environment, we can go ahead and delete all of it using the command:\nconda remove --name test-env  --all\nWe can run conda env list to verify the test-env does not exist anymore.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#learning-objectives",
    "href": "book/appendices/A-python-environments.html#learning-objectives",
    "title": "Virtual environments",
    "section": "",
    "text": "By the end of this lesson, students will be able to:",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#environments-what-and-why",
    "href": "book/appendices/A-python-environments.html#environments-what-and-why",
    "title": "Virtual environments",
    "section": "",
    "text": "Environments are a way to keep the packages and Python versions you use for different projects organized.\n\n\n\nSome environments can have lots of packages and dependencies, while others can keep it simple.\n\n\nThe main reasons to create an environment for each of your projects are:\n\nTo not interfere with your computer’s pre-installed Python\nManage dependency conflicts for different projects\nReproducibility! Being able to share your code and what it needs to run it with others\n\n\n\n\n\n\n\nDependencies\n\n\n\nWhat these are.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-environments",
    "href": "book/appendices/A-python-environments.html#conda-environments",
    "title": "Virtual environments",
    "section": "",
    "text": "Conda is an environment and package management system: it can both create and administer the environments and install compatible versions of software and their dependencies. Environments created with Conda are usually called Conda environments. A Conda environment doesn’t need to be a Python environment, Conda can manage packages for any programming language.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-channels",
    "href": "book/appendices/A-python-environments.html#conda-channels",
    "title": "Virtual environments",
    "section": "",
    "text": "Conda channels are the remote locations where packages are stored. Think of them as shops for getting packages. By default, packages are downloaded to your computer and updated from the conda default channel. But there are others! Conda-forge and bioconda are two popular ones. We can choose which Conda channel to install a package from.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#pip",
    "href": "book/appendices/A-python-environments.html#pip",
    "title": "Virtual environments",
    "section": "",
    "text": "pip is a package management system only for Python. We can use it to install packages from the Python Package Index (PyPI). We can use pip inside a Conda environment when a package is not available from a Conda channel.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-commands",
    "href": "book/appendices/A-python-environments.html#conda-commands",
    "title": "Virtual environments",
    "section": "",
    "text": "Command\nWhat it does\n\n\n\n\nconda env list\nlist available Conda environments\n\n\nconda create --name my-env python\ncreate new Python environment called my-env\n\n\nconda remove --name my-env  --all\ndelete my-env\n\n\ncoda activate my-env\nactivate environment\n\n\ncoda deactivate\ndeactivate active environment\n\n\npython -V\ncheck which Python version is installed in active environment\n\n\nconda list\ncheck which packages are installed in active environment\n\n\nconda list numpy\ncheck if numpy is installed in active environment\n\n\nconda install numpy\ninstall numpy package in environment using environment channel priorities (generally just from defaults channel)\n\n\nconda install --channel conda-forge rioxarray\ninstall rioxarray package in environment from from conda-forge channel (after going through other environment channel prioirities)",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#hands-on-environments",
    "href": "book/appendices/A-python-environments.html#hands-on-environments",
    "title": "Virtual environments",
    "section": "",
    "text": "To list all the Conda environments available in your computer and their location we use:\nconda env list\nThe output should look something like this:\n# conda environments:\n#\nbase                  *  /Users/galaz-garcia/opt/anaconda3\neds220-env               /Users/galaz-garcia/opt/anaconda3/envs/eds220-env\nInfo about env being a directory/files with that file path.\n\n\n\n\n\n\nWhat is my current active environment?\n\n\n\nWhen you run conda env list, the asterisk next to the environment path indicates which environment is active. In this example, I am using the base Python environment. The currently active environment also appears in the terminal in parenthesis at the beginning of each line, something like this:\n(base) my-computer:MEDS-eds-220-course galaz-garcia$\n\n\n\n\n\nTo create a new environment called test-env and, within it, install the most recent version of python we simply run:\nconda create --name test-env python\nWhen you run it it will give you information about the packages that will be installed and ask you whether to proceed or not. Type y and press enter to create the environment and install the packages.\n\n\n\n\n\n\nCheck-in\n\n\n\nCheck whether the new test-env environment is listed by Conda. Is it activated or not?\n\n\n\n\n\nTo activate the test-env environment we use the command\nconda activate test-env\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that test-env is now your current environment.\n\n\n\n\n\nTo see which packages are installed within the currently active environment we run:\nconda list\nThe output will be a long list that looks something like this:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbzip2                     1.0.8                h6c40b1e_6  \npip                       24.2            py312hecd8cb5_0  \nsqlite                    3.45.3               h6c40b1e_0  \n[...]\nThe name and version of each installed package in the environment appear in their respective columns. The ‘Build’ column shows a build string for each package. This string encodes important information about how the package was compiled, including any updates or changes made without altering the package version. It also reflects any compatibility or performance optimizations that were integrated during the build process.\nFor example, the same package with the same version might have different builds (and therefore different build strings) depending on whether it was installed on macOS, Windows, or Linux. This difference arises because the package may need to be compiled differently to optimize performance and ensure compatibility with each operating system.\nThe ‘Channel’ column shows the source from which the package was downloaded and installed. In this example the entries on this column are blank, signaling these packages were downloaded from the defeault Conda channel. We’ll see other channels appear in the next examples.\nWe can also request information about a specific package. For example, if we run\nconda list pip\nwe obtain only the information about the pip package:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\npip                       24.2            py312hecd8cb5_0  \nWe can also use this to verify whether a package is installed. For example, if we run\nconda list numpy\nwe will get empty columns:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbecause the numpy package is not intalled in this environment.\n\n\n\nLet’s say we want to install numpy in our currently active environment test-env. To do this we can simply use the command:\nconda install numpy\nSince we have not specified another channel, this command will install numpy from the default channel.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that numpy is now installed.\n\n\nNow, suppose we want to install rioxarray, this is a Python package for raster data analysis. This is a relatively new package, so it might not be available from the default Conda channels. A sensible measure would be to first look if rioxarray is available in the defaults channels, which we can do by running:\nconda search rioxarray\nThe output will look similar to\nLoading channels: done\nNo match found for: rioxarray. Search: *rioxarray*\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - rioxarray\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/osx-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/osx-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the Conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\nAs stated, rioxarray is not available on the default channels for my conda installation. Notice a couple of the channels it is seraching on are specific to macOS (my corrent operating system), and the last two are actually channels for R packages.\nIf we had tried to install rioxarray using conda install rioxarray we would have obtained an error message with similar information.\nWe may have better luck searching for rioxarray in the conda-forge channel, which we can do like this:\nconda search --channel conda-forge rioxarray\nfrom which we obtain a list of available versions and builds of this package in the conda-forge channel:\nLoading channels: done\n# Name                       Version           Build  Channel             \nrioxarray                      0.0.3            py_0  conda-forge         \nrioxarray                      0.0.4            py_0  conda-forge         \nrioxarray                      0.0.5            py_0  conda-forge     \n[...]\nrioxarray                     0.16.0    pyhd8ed1ab_0  conda-forge         \nrioxarray                     0.17.0    pyhd8ed1ab_0  conda-forge   \n\n\n\n\n\n\nCheck-in\n\n\n\nDo you see any versions of rioxarray with multiple builds?\n\n\nSince we now know that we can find rioxarray in the conda-forge channel, we can go ahead and install it from this channel using the command\nconda install --channel conda-forge rioxarray\nYou’ll see a moving bar that says Conda is solving (the) environment - this is Conda doing what the package management! It means Conda is working on finding the dependencies for the packages you are trying to install, finding versions of these dependencies that are compatible with each other, making sure these new packages are compatible with the packages already present in the environment or see it needs to upgrade, downgrade or remove anything in the environment. Overall, Conda tries to install what we need with the least disruption. Solving an environment can often take time but it is crucial so that the environment remains stable and functional.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nCheck whether pandas is installed in the environment.\nWhich channels were used to install dependencies for rioxarray?\n\n\n\n\n\n\n\nTo deactivate our current environment and return to our base environment we simply run\nconda deactivate\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify we are no longer in the test-env.\n\n\n\n\n\nSince this was a test environment, we can go ahead and delete all of it using the command:\nconda remove --name test-env  --all\nWe can run conda env list to verify the test-env does not exist anymore.",
    "crumbs": [
      "book",
      "Appendices",
      "Virtual environments"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html",
    "href": "book/chapters/lesson-2-series-dataframes.html",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "In this lesson we introduce the two core objects in the pandas library, the pandas.Series and the pandas.DataFrame. The overall goal is to gain familiarity with these two objects, understand their relation to each other, and review Python data structures such as dictionaries and lists.\n\n\nBy the end of this lesson, students will be able to:\n\nExplain the relation between pandas.Series and pandas.DataFrame\nConstruct simple pandas.Series and pandas.DataFrame from scratch using different initalization methods\nPerform simple operations on pandas.Series\nNavigate the pandas documentation to look for attributes and methods of pandas.Series and pandas.DataFrame\n\n\n\n\npandas [1] [2] is a Python package to wrangle and analyze tabular data. It is built on top of NumPy and has become the core tool for doing data analysis in Python.\nThe standard abbreviation for pandas is pd. Here we will import it together with NumPy:\n\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n\n\nConvention: importing packages\n\n\n\nAlways import all your packages in a single cell at the top of you notebook! Following the PEP 8 - Style Guide for Python Code [3], each package or library import should be in a separate line.\n\n\n\n\n\n\nThe first core object of pandas is the series. A series is a one-dimensional array of indexed data.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\nA pandas.Series having an index is the main difference between a pandas.Series and a NumPy array. Let’s see the difference:\n\n# a numpy array\narr = np.random.randn(4) # random values from std normal distribution\nprint(type(arr))\nprint(arr, \"\\n\")\n\n# a pandas series made from the previous array\ns = pd.Series(arr)\nprint(type(s))\nprint(s)\n\n&lt;class 'numpy.ndarray'&gt;\n[-0.19007242  0.74871208  0.16997246  0.59083012] \n\n&lt;class 'pandas.core.series.Series'&gt;\n0   -0.190072\n1    0.748712\n2    0.169972\n3    0.590830\ndtype: float64\n\n\nNotice the index is printed as part of the pandas.Series while, although the np.array is indexable, the index is not part of this data structure. Printing the pandas.Series also shows the values and their data type.\n\n\n\nThe basic method to create a pandas.Series is to call\ns = pd.Series(data, index=index)\nThe data parameter can be:\n\na list or NumPy array,\na Python dictionary, or\na single number, boolean (True/False), or string.\n\nThe index parameter is optional, if we wish to include it, it must be a list of list of indices of the same length as data.\n\n\nLet’s create a pandas.Series from a NumPy array. To use this method we need to pass a NumPy array (or a list of objects that can be converted to NumPy types) as data. Here, we will also include the list [2023, 2024, 2025] to be used as an index:\n\n# a series from a numpy array \npd.Series(np.arange(3), index=[2023, 2024, 2025])\n\n2023    0\n2024    1\n2025    2\ndtype: int64\n\n\n\n\n\nHere we create a pandas.Series from a list of strings. Remember that the index parameter is optional. If we don’t include it, the default is to make the index equal to [0,...,len(data)-1]. For example:\n\n# a series from a list of strings with default index\npd.Series(['EDS 220', 'EDS 222', 'EDS 223', 'EDS 242'])\n\n0    EDS 220\n1    EDS 222\n2    EDS 223\n3    EDS 242\ndtype: object\n\n\n\n\n\nRecall that a dictionary is a set of key-value pairs. If we create a pandas.Series via a dictionary the keys will become the index and the values the corresponding data.\n\n# construct dictionary\nd = {'key_0':2, 'key_1':'3', 'key_2':5}\n\n# initialize series using a dictionary\npd.Series(d)\n\nkey_0    2\nkey_1    3\nkey_2    5\ndtype: object\n\n\n\n\n\n\n\n\ndtype: object\n\n\n\nNotice that in this and the previous example the data type of the values in the series is object. This data type in pandas usually indicates that the series is made up of strings. However, we can see in this example that the object data type can also indicate a mix of strings and numbers.\n\n\n\n\n\nIf we only provide a single number, boolean, or string as the data for the series, we need to provide an index. The value will be repeated to match the length of the index. Here, we create a series from a single float number with an index given by a list of strings:\n\npd.Series(3.0, index = ['A', 'B', 'C'])\n\nA    3.0\nB    3.0\nC    3.0\ndtype: float64\n\n\n\n\n\n\nArithmetic operations work on series and so most NumPy functions. For example:\n\n# define a series\ns = pd.Series([98,73,65],index=['Andrea', 'Beth', 'Carolina'])\n\n# divide each element in series by 10\nprint(s /10, '\\n')\n\n# take the exponential of each element in series\nprint(np.exp(s), '\\n')\n\n# original series is unchanged\nprint(s)\n\nAndrea      9.8\nBeth        7.3\nCarolina    6.5\ndtype: float64 \n\nAndrea      3.637971e+42\nBeth        5.052394e+31\nCarolina    1.694889e+28\ndtype: float64 \n\nAndrea      98\nBeth        73\nCarolina    65\ndtype: int64\n\n\nWe can also produce new pandas.Series with True/False values indicating whether the elements in a series satisfy a condition or not:\n\ns &gt; 70\n\nAndrea       True\nBeth         True\nCarolina    False\ndtype: bool\n\n\nThis kind of simple conditions on pandas.Series will be key when we are selecting data from data frames.\n\n\n\nIn pandas we can represent a missing, NULL, or NA value with the float value numpy.nan, which stands for “not a number”. Let’s construct a small series with some NA values represented this way:\n\n# series with NAs in it\ns = pd.Series([1, 2, np.nan, 4, np.nan])\ns\n\n0    1.0\n1    2.0\n2    NaN\n3    4.0\n4    NaN\ndtype: float64\n\n\nNotice the data type of the values it he series is still float64.\nThe hasnans attribute for a pandas.Series returns True if there are any NA values in it and false otherwise:\n\n# check if series has NAs\ns.hasnans\n\nTrue\n\n\nAfter detecting there are Na values, we might be intersted in knowing which elements in the series are NAs. We can do this using the isna method:\n\ns.isna()\n\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n\n\nThe ouput is a pandas.Series of boolean values indicating if an element in the row at the given index is np.nan (True = is NA) or not (False = not NA).\n\n\n\n\n\n\nCheck-in\n\n\n\n\nThe integer number -999 is often used to represent missing values. Create a pandas.Series named s with four integer values, two of which are -999. The index of this series should be the the letters A through D.\n\n\n\nIn the pandas.Series documentation, look for the method mask(). Use this method to update the series s so that the -999 values are replaced by NA values. HINT: check the first example in the method’s documentation.\n\n\n\n\nThere’s much more to say about pandas.Series, but this is enough to get us going. At this point, we mainly want to know about pandas.Series because pandas.Series are the columns of a pandas.DataFrame.\n\n\n\n\n\nThe pandas.DataFrame is the most used pandas object. It represents tabular data and we can think of it as a spreadhseet. Each column of a pandas.DataFrame is a pandas.Series.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nThere are many ways of creating a pandas.DataFrame. We present one simple one in this section.\nWe already mentioned each column of a pandas.DataFrame is a pandas.Series. In fact, the pandas.DataFrame is a dictionary of pandas.Series, with each column name being the key and the column values being the key’s value. Thus, we can create a pandas.DataFrame in this way:\n\n# initialize dictionary with columns' data \nd = {'col_name_1' : pd.Series(np.arange(3)),\n     'col_name_2' : pd.Series([3.1, 3.2, 3.3]),\n     }\n\n# create data frame\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\n0\n0\n3.1\n\n\n1\n1\n3.2\n\n\n2\n2\n3.3\n\n\n\n\n\n\n\nWe can change the index by changing the index attribute in the data frame:\n\n# change index\ndf.index = ['a','b','c']\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\na\n0\n3.1\n\n\nb\n1\n3.2\n\n\nc\n2\n3.3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can access the data frame’s column names via the columns attribute. Update the column names to C1 and C2 by updating this attribute.\n\n\n\n\n\n\n\nJump to the week 1 discussion section to practice preliminary data exploration with a real world dataset. Then, continue with the next lesson on subsetting data frames.",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#learning-objectives",
    "href": "book/chapters/lesson-2-series-dataframes.html#learning-objectives",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nExplain the relation between pandas.Series and pandas.DataFrame\nConstruct simple pandas.Series and pandas.DataFrame from scratch using different initalization methods\nPerform simple operations on pandas.Series\nNavigate the pandas documentation to look for attributes and methods of pandas.Series and pandas.DataFrame",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#pandas",
    "href": "book/chapters/lesson-2-series-dataframes.html#pandas",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "pandas [1] [2] is a Python package to wrangle and analyze tabular data. It is built on top of NumPy and has become the core tool for doing data analysis in Python.\nThe standard abbreviation for pandas is pd. Here we will import it together with NumPy:\n\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n\n\nConvention: importing packages\n\n\n\nAlways import all your packages in a single cell at the top of you notebook! Following the PEP 8 - Style Guide for Python Code [3], each package or library import should be in a separate line.",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#series",
    "href": "book/chapters/lesson-2-series-dataframes.html#series",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "The first core object of pandas is the series. A series is a one-dimensional array of indexed data.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\nA pandas.Series having an index is the main difference between a pandas.Series and a NumPy array. Let’s see the difference:\n\n# a numpy array\narr = np.random.randn(4) # random values from std normal distribution\nprint(type(arr))\nprint(arr, \"\\n\")\n\n# a pandas series made from the previous array\ns = pd.Series(arr)\nprint(type(s))\nprint(s)\n\n&lt;class 'numpy.ndarray'&gt;\n[-0.19007242  0.74871208  0.16997246  0.59083012] \n\n&lt;class 'pandas.core.series.Series'&gt;\n0   -0.190072\n1    0.748712\n2    0.169972\n3    0.590830\ndtype: float64\n\n\nNotice the index is printed as part of the pandas.Series while, although the np.array is indexable, the index is not part of this data structure. Printing the pandas.Series also shows the values and their data type.\n\n\n\nThe basic method to create a pandas.Series is to call\ns = pd.Series(data, index=index)\nThe data parameter can be:\n\na list or NumPy array,\na Python dictionary, or\na single number, boolean (True/False), or string.\n\nThe index parameter is optional, if we wish to include it, it must be a list of list of indices of the same length as data.\n\n\nLet’s create a pandas.Series from a NumPy array. To use this method we need to pass a NumPy array (or a list of objects that can be converted to NumPy types) as data. Here, we will also include the list [2023, 2024, 2025] to be used as an index:\n\n# a series from a numpy array \npd.Series(np.arange(3), index=[2023, 2024, 2025])\n\n2023    0\n2024    1\n2025    2\ndtype: int64\n\n\n\n\n\nHere we create a pandas.Series from a list of strings. Remember that the index parameter is optional. If we don’t include it, the default is to make the index equal to [0,...,len(data)-1]. For example:\n\n# a series from a list of strings with default index\npd.Series(['EDS 220', 'EDS 222', 'EDS 223', 'EDS 242'])\n\n0    EDS 220\n1    EDS 222\n2    EDS 223\n3    EDS 242\ndtype: object\n\n\n\n\n\nRecall that a dictionary is a set of key-value pairs. If we create a pandas.Series via a dictionary the keys will become the index and the values the corresponding data.\n\n# construct dictionary\nd = {'key_0':2, 'key_1':'3', 'key_2':5}\n\n# initialize series using a dictionary\npd.Series(d)\n\nkey_0    2\nkey_1    3\nkey_2    5\ndtype: object\n\n\n\n\n\n\n\n\ndtype: object\n\n\n\nNotice that in this and the previous example the data type of the values in the series is object. This data type in pandas usually indicates that the series is made up of strings. However, we can see in this example that the object data type can also indicate a mix of strings and numbers.\n\n\n\n\n\nIf we only provide a single number, boolean, or string as the data for the series, we need to provide an index. The value will be repeated to match the length of the index. Here, we create a series from a single float number with an index given by a list of strings:\n\npd.Series(3.0, index = ['A', 'B', 'C'])\n\nA    3.0\nB    3.0\nC    3.0\ndtype: float64\n\n\n\n\n\n\nArithmetic operations work on series and so most NumPy functions. For example:\n\n# define a series\ns = pd.Series([98,73,65],index=['Andrea', 'Beth', 'Carolina'])\n\n# divide each element in series by 10\nprint(s /10, '\\n')\n\n# take the exponential of each element in series\nprint(np.exp(s), '\\n')\n\n# original series is unchanged\nprint(s)\n\nAndrea      9.8\nBeth        7.3\nCarolina    6.5\ndtype: float64 \n\nAndrea      3.637971e+42\nBeth        5.052394e+31\nCarolina    1.694889e+28\ndtype: float64 \n\nAndrea      98\nBeth        73\nCarolina    65\ndtype: int64\n\n\nWe can also produce new pandas.Series with True/False values indicating whether the elements in a series satisfy a condition or not:\n\ns &gt; 70\n\nAndrea       True\nBeth         True\nCarolina    False\ndtype: bool\n\n\nThis kind of simple conditions on pandas.Series will be key when we are selecting data from data frames.\n\n\n\nIn pandas we can represent a missing, NULL, or NA value with the float value numpy.nan, which stands for “not a number”. Let’s construct a small series with some NA values represented this way:\n\n# series with NAs in it\ns = pd.Series([1, 2, np.nan, 4, np.nan])\ns\n\n0    1.0\n1    2.0\n2    NaN\n3    4.0\n4    NaN\ndtype: float64\n\n\nNotice the data type of the values it he series is still float64.\nThe hasnans attribute for a pandas.Series returns True if there are any NA values in it and false otherwise:\n\n# check if series has NAs\ns.hasnans\n\nTrue\n\n\nAfter detecting there are Na values, we might be intersted in knowing which elements in the series are NAs. We can do this using the isna method:\n\ns.isna()\n\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n\n\nThe ouput is a pandas.Series of boolean values indicating if an element in the row at the given index is np.nan (True = is NA) or not (False = not NA).\n\n\n\n\n\n\nCheck-in\n\n\n\n\nThe integer number -999 is often used to represent missing values. Create a pandas.Series named s with four integer values, two of which are -999. The index of this series should be the the letters A through D.\n\n\n\nIn the pandas.Series documentation, look for the method mask(). Use this method to update the series s so that the -999 values are replaced by NA values. HINT: check the first example in the method’s documentation.\n\n\n\n\nThere’s much more to say about pandas.Series, but this is enough to get us going. At this point, we mainly want to know about pandas.Series because pandas.Series are the columns of a pandas.DataFrame.",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#data-frames",
    "href": "book/chapters/lesson-2-series-dataframes.html#data-frames",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "The pandas.DataFrame is the most used pandas object. It represents tabular data and we can think of it as a spreadhseet. Each column of a pandas.DataFrame is a pandas.Series.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nThere are many ways of creating a pandas.DataFrame. We present one simple one in this section.\nWe already mentioned each column of a pandas.DataFrame is a pandas.Series. In fact, the pandas.DataFrame is a dictionary of pandas.Series, with each column name being the key and the column values being the key’s value. Thus, we can create a pandas.DataFrame in this way:\n\n# initialize dictionary with columns' data \nd = {'col_name_1' : pd.Series(np.arange(3)),\n     'col_name_2' : pd.Series([3.1, 3.2, 3.3]),\n     }\n\n# create data frame\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\n0\n0\n3.1\n\n\n1\n1\n3.2\n\n\n2\n2\n3.3\n\n\n\n\n\n\n\nWe can change the index by changing the index attribute in the data frame:\n\n# change index\ndf.index = ['a','b','c']\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\na\n0\n3.1\n\n\nb\n1\n3.2\n\n\nc\n2\n3.3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can access the data frame’s column names via the columns attribute. Update the column names to C1 and C2 by updating this attribute.",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#next",
    "href": "book/chapters/lesson-2-series-dataframes.html#next",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "Jump to the week 1 discussion section to practice preliminary data exploration with a real world dataset. Then, continue with the next lesson on subsetting data frames.",
    "crumbs": [
      "book",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "discussion-sections/discussion-sections-listing.html",
    "href": "discussion-sections/discussion-sections-listing.html",
    "title": "Discussion sections",
    "section": "",
    "text": "Preliminary data exploration\n\n\nWeek 1 - Discussion section\n\n\n\n\n\nOct 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub setup for discussion sections\n\n\nWeek 0 - Discussion section\n\n\n\n\n\nSep 26, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html",
    "href": "discussion-sections/ds1-prelim-data-exploration.html",
    "title": "Preliminary data exploration",
    "section": "",
    "text": "This discussion section will guide you through preliminary data exploration for a real world dataset about animal observations in the California drylands. In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#setup",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#setup",
    "title": "Preliminary data exploration",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nIn the Taylor server, start a new JupyterLab session or access an active one.\nIn the terminal, use cd to navigate into the eds-220-sections directory. Use pwd to verify eds-220-sections is your current working directory.\nCreate a new Python Notebook in section-1.\nUpdate the notebook’s name to something useful like ‘exercise-data-selection.ipynb’.\nUse the terminal to stage, commit, and push this file to the remote repository. Remember:\n\ncheck git status: git status\nstage: git add file-name.ipynb\ncommit with message: git commit -m \"commit message\"\npush: git push\n\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU’VE ALL SUCCESSFULLY SET UP YOUR NOTEBOOKS BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#general-directions",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#general-directions",
    "title": "Preliminary data exploration",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments in each one of your code cells.\nInclude markdown cells in between your code cells to add titles and information to each exercise.\nIndications about when to commit and push changes are included, but you are encouraged to commit and push more often.\nYou won’t need to upload any data."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#about-the-data",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#about-the-data",
    "title": "Preliminary data exploration",
    "section": "About the data",
    "text": "About the data\n\n\n\n\n\n\nFor these exercises we will use data about prey items for endangered terrestrial vertebrate species within central California drylands[1] [2].\nThis dataset is stored in the Knowledge Network for Biocomplexity (KNB) data repository. This is an international repository intended to facilitate ecological and environmental research. It has thousands of open datasets and is hosted by the National Center for Ecological Analysis and Synthesis (NCEAS)."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#archive-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#archive-exploration",
    "title": "Preliminary data exploration",
    "section": "Archive exploration",
    "text": "Archive exploration\nFor many datasets, data exploration begins at the data repository. Take some time to look through the dataset’s description in the KNB data repository. Discuss the following questions with your team:\n\nWhat is this data about?\nIs this data collected in-situ by the authors or is it a synthesis of multiple datasets?\nDuring what time frame were the observations in the dataset collected?\nDoes this dataset come with an associated metadata file?\nDoes the dataset contain sensitive data?\n\nIn your notebook: use a markdown cell to add a brief description of the dataset, including a citation, date of access, and a link to the archive.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#metadata-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#metadata-exploration",
    "title": "Preliminary data exploration",
    "section": "Metadata exploration",
    "text": "Metadata exploration\nYou may have noticed there are two metadata files: Compiled_occurrence_records_for_prey_items_of.xml and metadata_arth_occurrences.csv. The .xml document file type is EML which stands for EML: Ecological Metadata Language. This is a machine-readable file that has metadata about the whole dataset. In this section we will only use the metadata in the csv file.\nBack in your notebook, import the pandas package using standard abbreviation in a code cell. Then follow these steps to read in the metadata csv using the pandas.read_csv() function:\n\nNavigate to the data package site and copy the URL to access the metadata_arth_occurrences csv file. To copy the URL:\n\n\nhover over the Download button –&gt; right click –&gt; “Copy Link”.\n\n\nRead in the data from the URL using the pd.read_csv() function like this:\n# look at metadata\npd.read_csv('the URL goes here')\nTake a minute to look at the descriptions for the columns.\n\nNote: Not all datasets have column descriptions in a csv file. Often they come with a doc or txt file with information."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#data-loading",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#data-loading",
    "title": "Preliminary data exploration",
    "section": "Data loading",
    "text": "Data loading\n\nFollow steps (a) and (b) from the previous exercise to read in the drylands prey data file arth_occurrences_with_env.csv using pd.read_csv(). Store the dataframe to a variable called prey like this:\n\n# read in data\nprey = pd.read_csv('the URL goes here')\n\nWhat is the type of the prey variable? Use a Python function get this information.\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; push changes\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU’VE ALL SUCCESSFULLY ACCESSED THE DATA BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#look-at-your-data",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#look-at-your-data",
    "title": "Preliminary data exploration",
    "section": "Look at your data",
    "text": "Look at your data\n\nRun prey in a cell. What do you notice in the columns section?\nTo see all the column names in the same display we need to set a pandas option. Run the following command and then look at the prey data again:\n\npd.set_option(\"display.max.columns\", None)\n\nAdd a comment explaining what pd.set_option(\"display.max.columns\", None) does.\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#pd.dataframe-preliminary-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#pd.dataframe-preliminary-exploration",
    "title": "Preliminary data exploration",
    "section": "pd.DataFrame preliminary exploration",
    "text": "pd.DataFrame preliminary exploration\nRun each of the following methods for prey in a different cell and write a brief description of what they do as a comment:\n\nhead()\ntail()\ninfo()\nnunique()\n\nFor example:\n# head()\n# returns the first five rows of the data frame\nprey.head()\nIf you’re not sure about what the method does, try looking it up in the pandas.DataFrame documentation.\n\nCheck the documentation for head(). If this function has any optional parameters, change the default value to get a different output.\n\nPrint each of the following attributes of prey in a different cell and write a brief explanation of what they are as a comment:\n\nshape\ncolumns\ndtypes\n\nIf you’re not sure about what information is the attribute showing, look it up in the pandas.DataFrame documentation.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#update-column-names",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#update-column-names",
    "title": "Preliminary data exploration",
    "section": "Update column names",
    "text": "Update column names\nChange the column names of institutionCode and datasetKey to institution_code and dataset_key, respectively. Make sure you’re actually updating the dataframe. HINT: yesterday’s class.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; push changes"
  },
  {
    "objectID": "assignments/assignments-home.html",
    "href": "assignments/assignments-home.html",
    "title": "General info about assignments",
    "section": "",
    "text": "General info about assignments"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome to the course materials for EDS 220 - Working with Environmental Datasets! In this website you will find all the materials for the Fall 2024 term. This course is part of the UCSB Masters in Environmental Data Science.\n\n\nThis hands-on course explores widely used environmental data formats and Python libraries for analyzing diverse environmental data. Students will gain experience working with popular open data repositories and cloud platforms to source and analyze real-world environmental datasets. The course will also serve as an introduction to Python programming and provide opportunities to practice effective communication of the strengths and weaknesses of students’ data products and analyses.\n\n\n\n\n\n\nCarmen Galaz García (she/her/hers)\n\nE-mail: galazgarcia@bren.ucsb.edu\nStudent hours: Wednesday 4-5 @ Bren Hall 4424\n\n\n\n\n\nE-mail:\nStudent hours:\n\n\n\n\n\n\nClick here to access the syllabus.\n\n\n\nThe following is our tentative calendar. The course content and calendar may be subject to change as the course progresses.\n\n\n\n\n📝 If you have suggestions on how to correct, improve, or expand these course materials, please feel free to email the course instructor at galazgarcia@bren.ucsb.edu or file a GitHub issue.\n🌟 If these materials have been useful to you, consider adding a star to the project’s repository!"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Welcome!",
    "section": "",
    "text": "This hands-on course explores widely used environmental data formats and Python libraries for analyzing diverse environmental data. Students will gain experience working with popular open data repositories and cloud platforms to source and analyze real-world environmental datasets. The course will also serve as an introduction to Python programming and provide opportunities to practice effective communication of the strengths and weaknesses of students’ data products and analyses."
  },
  {
    "objectID": "index.html#instruction-team",
    "href": "index.html#instruction-team",
    "title": "Welcome!",
    "section": "",
    "text": "Carmen Galaz García (she/her/hers)\n\nE-mail: galazgarcia@bren.ucsb.edu\nStudent hours: Wednesday 4-5 @ Bren Hall 4424\n\n\n\n\n\nE-mail:\nStudent hours:"
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Welcome!",
    "section": "",
    "text": "Click here to access the syllabus."
  },
  {
    "objectID": "index.html#calendar",
    "href": "index.html#calendar",
    "title": "Welcome!",
    "section": "",
    "text": "The following is our tentative calendar. The course content and calendar may be subject to change as the course progresses."
  },
  {
    "objectID": "index.html#contribute",
    "href": "index.html#contribute",
    "title": "Welcome!",
    "section": "",
    "text": "📝 If you have suggestions on how to correct, improve, or expand these course materials, please feel free to email the course instructor at galazgarcia@bren.ucsb.edu or file a GitHub issue.\n🌟 If these materials have been useful to you, consider adding a star to the project’s repository!"
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html",
    "href": "discussion-sections/ds0-sections-setup.html",
    "title": "GitHub setup for discussion sections",
    "section": "",
    "text": "Create a new repository on GitHub. Use the following settings:\n\nCall the repository eds-220-section-1.\nAdd a brief description for your new repository. For example: EDS 220 section - practice session for data selection in pandas.\nKeep the repository public.\nInitialize the repository with a README file and a Python .gitignore template.\n\nIn the Taylor server, start a new JupyterLab session or access an active one.\nUsing the terminal, clone the repository to a new directory under your eds-220 directory.\n\nTalk about setting a PAT.\n\nIf you are prompted for your credentials and need to set up a new Personal Access Token (PAT) follow steps 13-18 in this guide to set it up."
  },
  {
    "objectID": "conventions.html",
    "href": "conventions.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Any website, package, scientific article, dataset or other source should be cited. The IEEE citation style will be used. This is set up via de iee-with-url.csl file and the bibliography and csl parameters in the _quarto.yml file.\nReferences are add into one file for the whole course: references.bib."
  },
  {
    "objectID": "conventions.html#citations",
    "href": "conventions.html#citations",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Any website, package, scientific article, dataset or other source should be cited. The IEEE citation style will be used. This is set up via de iee-with-url.csl file and the bibliography and csl parameters in the _quarto.yml file.\nReferences are add into one file for the whole course: references.bib."
  },
  {
    "objectID": "conventions.html#subsection-names",
    "href": "conventions.html#subsection-names",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Subsection names",
    "text": "Subsection names\n\nOnly the first letter in subsection names should be capitalized.\nExamples should follow the format “Example: what this example is about” and should be unlisted from the table of contents using {.unlisted}."
  },
  {
    "objectID": "conventions.html#file-naming",
    "href": "conventions.html#file-naming",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "File naming",
    "text": "File naming\nAll files (except README) should be named in small caps and each work separated by -."
  },
  {
    "objectID": "conventions.html#discussion-sections",
    "href": "conventions.html#discussion-sections",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Discussion sections",
    "text": "Discussion sections\nAll discussion sections should have the following YAML heading:\n---\ntitle: Topic of discussion section\nsubtitle: Week n - Discussion section \ndate: YYYY-MM-DD\nweek: week n\nimage: images/ds-weekn.png\nsidebar: false\n---\nStructure for sections files should be:\n\nBrief intro about what the discussion section is about, followed by In ‘this discussion section, you will:’ then a list of what will happen in the section.\nSetup in a :::{.callout-tip appearance=\"minimal\"}} ::: block\nGeneral directions in a :::{.callout-tip appearance=\"minimal\"}} ::: block\nAbout the data ina a :::{.callout-note appearance=\"minimal\"}} :::\nExercises numbered"
  },
  {
    "objectID": "conventions.html#lessons",
    "href": "conventions.html#lessons",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Lessons",
    "text": "Lessons\n\nYAML\n---\ntoc-title: In this lesson\n---\n\n\nLearning objectives\nState them using “By the end of this lesson, students will be able to:”"
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html",
    "href": "book/chapters/lesson-1-python-review.html",
    "title": "Python review",
    "section": "",
    "text": "This is a short review about some core concepts in Python exemplified by objects in the NumPy library. The goal is to recall basic Python vocabulary that will be used throughout the course, rather than to serve as an introduction to Python programming.\n\n\nBy the end of this lesson, students will be able to:\n\nDefine and provide examples for basic terms in Python programming like variable, object, function, class, attribute, and method.\nRecognize optional and non-optional arguments in a function.\nUnderstand some of the basic differences in R and Python syntax.\n\n\n\n\nA library is a collection of code that we can use to perform specific tasks in our programs. It can be a single file or multiple ones. NumPy [1] is one of the core libraries for numerical computing in Python. Many of the libraries we will use in this course use NumPy’s arrays as their building blocks. Additionally, NumPy objects have been optimized for processing, so computations on them are really fast and use less memory than doing the equivalent using the core Python data structures.\nIn this lesson we will use NumPy to review some fundamental concepts in Python you should be already familiar with.\n\n\n\n\n\n\nLibrary or package?\n\n\n\nA package in Python refers to a specific way of organizing multiple files of code into a directory hierarcy, often within a large code library. The words “library” and “package” are often used interchangeably. NumPy, for example, is both a library and a package.\n\n\nLet’s start by importing the NumPy library by using the standard to abbreviation, np:\n\nimport numpy as np\n\nBy importing numpy, all the objects and functions in this library will be available for us to use in our notebook.\n\n\n\nWe can think of a variable as a name we assign to a particular object in Python. For example:\n\n# assign a small array to variable a\na = np.array([[1,1,2],[3,5,8]])\n\nWhen we run the cell, we store the variables and their value. We can view a variable’s value in two ways from within our Jupyter notebook:\n\nrunning a cell with the variable name\nusing the print function to print the value\n\n\n# show the value\na\n\narray([[1, 1, 2],\n       [3, 5, 8]])\n\n\n\n# print the value \nprint(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\n\n\n\n\n\n\nR and Python: assigning values\n\n\n\nRemember that in Python we use the equal sign = to assign values to variables in the same way the left-arrow &lt;- is used in R:\n# R: assign value 10 to variable a\na &lt;- 10\n# python: assign value 10 to variable a\na = 10\n\n\n\n\n\n\n\n\nConvention: Use snake_case for naming variables\n\n\n\nThere are many ways of constructing multi-word variable names. In this course we will name variables using snake_case, where words are all in small caps and separated by underscores (ex: raw_data, fires_2023). This is the naming convention suggested by the PEP 8 - Style Guide for Python Code [2]. Remember variable names should be both descriptive and concise!\n\n\n\n\n\nYou will often encounter the word object in Python documentation and tutorials. Informally speaking, an object is a bundle of properties and actions about something specific. For example, an object could represent a data frame with properties such as number of rows, names of columns, and date created, and actions suchs as selecting a specific row or adding a new column.\nA variable is the name we give a specific object, and the same object can be referenced by different variables. An analogy for this is the following: the Sun (object) is called “sol” in Spanish and “soleil” in French, so two different names (variables) represent the same object. You can read more technical details about the difference between objects and variables in Python here [3].\nIn practice, we can often use the word variable and object interchangeably (for example, in the next subsection!). I want to bring up what objects are so you are not caught off-guard with vocabulary you will often encounter in the documentation, StackExchange, etc.\n\n\n\nEvery object in Python has a type, the type tells us what kind of object it is. We can also call the type of an object, the class of an object, so class and type both mean what kind of object we have.\nWe can see the type/class of a variable/object by using the type function:\n\nprint(a)\ntype(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\nnumpy.ndarray\n\n\nThe numpy.ndarray is the core object/data type in the NumPy package. We can check the type of an entry in the array by indexing:\n\nprint(a[0,0])\ntype(a[0,0])\n\n1\n\n\nnumpy.int64\n\n\nNotice the type of the value 1 in the array is numpy.int64 and not just the standard Python integer type int. The NumPy type numpy.int64 is telling us 1 is an integer stored as a 64-bit number. NumPy has its own data types to deal with numbers depending on memory storage and floating point precision, click here to know see all the types.\n\n\n\n\n\n\nR and Python: indexing\n\n\n\nRemember that in Python the indexing starts from 0, while in R it starts from 1. If you learned R first, this might seem odd but it’s easy to get used to it with some practice. A way to understand this 0-indexing is that, in Python, the index indicates the displacement from the start of the collection. So ‘0 index in an array’ means ‘zero displacement from the start of the array’, in other words, the first element of the array.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nHow would you access the value 5 in the array a?\n\n\nSince “everything in Python is an object” and every object belongs to a class, we will interact with SO MANY classes in this course. Often, knowing the type of an object is the first step to finding information to code what you want!\n\n\n\nprint was our first example of a Python function. Functions take in a set of arguments, separated by commas, and use those arguments to create an output. There are several built-in funcions in Python, most of them are for interacting with the Python basic data types such as int (integers), float (decimal numbers), str (strings), and bool (boolean values).\n\n\n\n\n\n\nArgument or Parameter?\n\n\n\nWe can interchangeably say arguments or parameters. You will see argument more often in the documentation.\n\n\nWe can ask for information about what a function does function by executing ? followed by the function name:\n\n?print\n\n\nWhat we obtain is a docstring, a special type of comment that is used to document how a function (or class, or module) works. The first line in the docstring is telling us the function name followed by all of its arguments in parentheses. Then there is a short description of what the function does. And finally a list of the arguments and a brief explanation about each of them.\nYou can see there are different types of arguments inside the parenthesis. Roughly speaking, a function has two types of arguments:\n\nnon-optional arguments: arguments you need to specify for the function to do something, and\noptional arguments: arguments that are pre-filled with a default value by the function, but you can override them. Optional arguments appear inside the parenthesis () in the form optional_argument = default_value.\n\n\n\nend is an argument in print with the default value a new line. We can change this argument so that finishes the line with ^_^ instead:\n\nprint('changing the default end argument of the print function', end=' ^_^')\n\nchanging the default end argument of the print function ^_^\n\n\nNotice that before we had always used print without specifying any value for the end argument.\n\n\n\n\nAn object in Python has attributes and methods. An attribute is a property of the object, some piece of information about it. A method is a procedure associated with an object, so it is an action where the main ingredient is the object.\nFor example, these could be some attributes and methods for class cat:\n\n\n\n.\n\n\nMore formally, a method is a function that acts on the object it is part of.\nWe can access a variable’s attributes and methods by adding a period . at the end of the variable’s name. So we would write variable.variable_method() or variable.variable_attribute.\n\n\n\n\n\n\nCheck-in\n\n\n\nSuppose we have a class fish, make a diagram similar to the cat class diagram showing 3 attributes for the class and 3 methods.\n\n\n\n\nNumPy arrays have many methods and attributes. Let’s see some concrete examples.\n\n# a 3x3 array\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nT is an example of attribute, it returns the transpose of var:\n\nprint(var.T)\nprint(type(var.T))\n\n[[1 4 7]\n [2 5 8]\n [3 6 9]]\n&lt;class 'numpy.ndarray'&gt;\n\n\nshape, another attribute, tells us the shape of the array:\n\nprint(var.shape)\nprint(type(var.shape))\n\n(3, 3)\n&lt;class 'tuple'&gt;\n\n\nndim is an attribute holding the number of array dimensions\n\nprint(var.ndim)\nprint(type(var.ndim))\n\n2\n&lt;class 'int'&gt;\n\n\nNotice these attributes can have many different data types. Here we saw a tuple and an int (two of the basic Python classes) and also a NumPy array as attributes of var.\nNow some examples of methods.\nThe tolist method returns the array as a nested list of scalars:\n\nvar.tolist()\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nThe min method returns the minimum value in the array along a specified axis:\n\nvar.min(axis=0)\n\narray([1, 2, 3])\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can also call the min method without any parameters:\n\nvar.min()\n\n1\n\n\nWhat kind of parameter is axis in our previous call of the var method?\n\n\nRemember, methods are functions associated to an object. We can confirm this!\n\ntype(var.tolist)\n\nbuiltin_function_or_method\n\n\n\ntype(var.min)\n\nbuiltin_function_or_method\n\n\nYou can see a complete list of NumPy array’s methods and attributes in the documentation.\n\n\n\n\n\n\nR and Python: are there methods in R?\n\n\n\nIt is uncommon to use methods within an object in R. Rather, functions are extrinsic to the objects they are acting on. In R, for example, there would usually be two separate items: the variable var and a separate function min that gets var as a parameter:\n# this is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nmin(var)\nUsing the pipe operator %&gt;% in R’s tidyverse is closer to the dot . in Python:\n# this is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nvar %&gt;% min()\nWhat happens here is that the pipe %&gt;% is passing var to the min() function as its first argument. This is similar to what happens in Python when a function is a method of a class:\n# this is Python code\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar.min()\nWhen working in Python, remember that methods are functions that are part of an object and a method uses the object it is part of to produce some information.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#learning-objectives",
    "href": "book/chapters/lesson-1-python-review.html#learning-objectives",
    "title": "Python review",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nDefine and provide examples for basic terms in Python programming like variable, object, function, class, attribute, and method.\nRecognize optional and non-optional arguments in a function.\nUnderstand some of the basic differences in R and Python syntax.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#libraries-and-packages",
    "href": "book/chapters/lesson-1-python-review.html#libraries-and-packages",
    "title": "Python review",
    "section": "",
    "text": "A library is a collection of code that we can use to perform specific tasks in our programs. It can be a single file or multiple ones. NumPy [1] is one of the core libraries for numerical computing in Python. Many of the libraries we will use in this course use NumPy’s arrays as their building blocks. Additionally, NumPy objects have been optimized for processing, so computations on them are really fast and use less memory than doing the equivalent using the core Python data structures.\nIn this lesson we will use NumPy to review some fundamental concepts in Python you should be already familiar with.\n\n\n\n\n\n\nLibrary or package?\n\n\n\nA package in Python refers to a specific way of organizing multiple files of code into a directory hierarcy, often within a large code library. The words “library” and “package” are often used interchangeably. NumPy, for example, is both a library and a package.\n\n\nLet’s start by importing the NumPy library by using the standard to abbreviation, np:\n\nimport numpy as np\n\nBy importing numpy, all the objects and functions in this library will be available for us to use in our notebook.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#variables",
    "href": "book/chapters/lesson-1-python-review.html#variables",
    "title": "Python review",
    "section": "",
    "text": "We can think of a variable as a name we assign to a particular object in Python. For example:\n\n# assign a small array to variable a\na = np.array([[1,1,2],[3,5,8]])\n\nWhen we run the cell, we store the variables and their value. We can view a variable’s value in two ways from within our Jupyter notebook:\n\nrunning a cell with the variable name\nusing the print function to print the value\n\n\n# show the value\na\n\narray([[1, 1, 2],\n       [3, 5, 8]])\n\n\n\n# print the value \nprint(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\n\n\n\n\n\n\nR and Python: assigning values\n\n\n\nRemember that in Python we use the equal sign = to assign values to variables in the same way the left-arrow &lt;- is used in R:\n# R: assign value 10 to variable a\na &lt;- 10\n# python: assign value 10 to variable a\na = 10\n\n\n\n\n\n\n\n\nConvention: Use snake_case for naming variables\n\n\n\nThere are many ways of constructing multi-word variable names. In this course we will name variables using snake_case, where words are all in small caps and separated by underscores (ex: raw_data, fires_2023). This is the naming convention suggested by the PEP 8 - Style Guide for Python Code [2]. Remember variable names should be both descriptive and concise!",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#objects",
    "href": "book/chapters/lesson-1-python-review.html#objects",
    "title": "Python review",
    "section": "",
    "text": "You will often encounter the word object in Python documentation and tutorials. Informally speaking, an object is a bundle of properties and actions about something specific. For example, an object could represent a data frame with properties such as number of rows, names of columns, and date created, and actions suchs as selecting a specific row or adding a new column.\nA variable is the name we give a specific object, and the same object can be referenced by different variables. An analogy for this is the following: the Sun (object) is called “sol” in Spanish and “soleil” in French, so two different names (variables) represent the same object. You can read more technical details about the difference between objects and variables in Python here [3].\nIn practice, we can often use the word variable and object interchangeably (for example, in the next subsection!). I want to bring up what objects are so you are not caught off-guard with vocabulary you will often encounter in the documentation, StackExchange, etc.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#types",
    "href": "book/chapters/lesson-1-python-review.html#types",
    "title": "Python review",
    "section": "",
    "text": "Every object in Python has a type, the type tells us what kind of object it is. We can also call the type of an object, the class of an object, so class and type both mean what kind of object we have.\nWe can see the type/class of a variable/object by using the type function:\n\nprint(a)\ntype(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\nnumpy.ndarray\n\n\nThe numpy.ndarray is the core object/data type in the NumPy package. We can check the type of an entry in the array by indexing:\n\nprint(a[0,0])\ntype(a[0,0])\n\n1\n\n\nnumpy.int64\n\n\nNotice the type of the value 1 in the array is numpy.int64 and not just the standard Python integer type int. The NumPy type numpy.int64 is telling us 1 is an integer stored as a 64-bit number. NumPy has its own data types to deal with numbers depending on memory storage and floating point precision, click here to know see all the types.\n\n\n\n\n\n\nR and Python: indexing\n\n\n\nRemember that in Python the indexing starts from 0, while in R it starts from 1. If you learned R first, this might seem odd but it’s easy to get used to it with some practice. A way to understand this 0-indexing is that, in Python, the index indicates the displacement from the start of the collection. So ‘0 index in an array’ means ‘zero displacement from the start of the array’, in other words, the first element of the array.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nHow would you access the value 5 in the array a?\n\n\nSince “everything in Python is an object” and every object belongs to a class, we will interact with SO MANY classes in this course. Often, knowing the type of an object is the first step to finding information to code what you want!",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#functions",
    "href": "book/chapters/lesson-1-python-review.html#functions",
    "title": "Python review",
    "section": "",
    "text": "print was our first example of a Python function. Functions take in a set of arguments, separated by commas, and use those arguments to create an output. There are several built-in funcions in Python, most of them are for interacting with the Python basic data types such as int (integers), float (decimal numbers), str (strings), and bool (boolean values).\n\n\n\n\n\n\nArgument or Parameter?\n\n\n\nWe can interchangeably say arguments or parameters. You will see argument more often in the documentation.\n\n\nWe can ask for information about what a function does function by executing ? followed by the function name:\n\n?print\n\n\nWhat we obtain is a docstring, a special type of comment that is used to document how a function (or class, or module) works. The first line in the docstring is telling us the function name followed by all of its arguments in parentheses. Then there is a short description of what the function does. And finally a list of the arguments and a brief explanation about each of them.\nYou can see there are different types of arguments inside the parenthesis. Roughly speaking, a function has two types of arguments:\n\nnon-optional arguments: arguments you need to specify for the function to do something, and\noptional arguments: arguments that are pre-filled with a default value by the function, but you can override them. Optional arguments appear inside the parenthesis () in the form optional_argument = default_value.\n\n\n\nend is an argument in print with the default value a new line. We can change this argument so that finishes the line with ^_^ instead:\n\nprint('changing the default end argument of the print function', end=' ^_^')\n\nchanging the default end argument of the print function ^_^\n\n\nNotice that before we had always used print without specifying any value for the end argument.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#attributes-methods",
    "href": "book/chapters/lesson-1-python-review.html#attributes-methods",
    "title": "Python review",
    "section": "",
    "text": "An object in Python has attributes and methods. An attribute is a property of the object, some piece of information about it. A method is a procedure associated with an object, so it is an action where the main ingredient is the object.\nFor example, these could be some attributes and methods for class cat:\n\n\n\n.\n\n\nMore formally, a method is a function that acts on the object it is part of.\nWe can access a variable’s attributes and methods by adding a period . at the end of the variable’s name. So we would write variable.variable_method() or variable.variable_attribute.\n\n\n\n\n\n\nCheck-in\n\n\n\nSuppose we have a class fish, make a diagram similar to the cat class diagram showing 3 attributes for the class and 3 methods.\n\n\n\n\nNumPy arrays have many methods and attributes. Let’s see some concrete examples.\n\n# a 3x3 array\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nT is an example of attribute, it returns the transpose of var:\n\nprint(var.T)\nprint(type(var.T))\n\n[[1 4 7]\n [2 5 8]\n [3 6 9]]\n&lt;class 'numpy.ndarray'&gt;\n\n\nshape, another attribute, tells us the shape of the array:\n\nprint(var.shape)\nprint(type(var.shape))\n\n(3, 3)\n&lt;class 'tuple'&gt;\n\n\nndim is an attribute holding the number of array dimensions\n\nprint(var.ndim)\nprint(type(var.ndim))\n\n2\n&lt;class 'int'&gt;\n\n\nNotice these attributes can have many different data types. Here we saw a tuple and an int (two of the basic Python classes) and also a NumPy array as attributes of var.\nNow some examples of methods.\nThe tolist method returns the array as a nested list of scalars:\n\nvar.tolist()\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nThe min method returns the minimum value in the array along a specified axis:\n\nvar.min(axis=0)\n\narray([1, 2, 3])\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can also call the min method without any parameters:\n\nvar.min()\n\n1\n\n\nWhat kind of parameter is axis in our previous call of the var method?\n\n\nRemember, methods are functions associated to an object. We can confirm this!\n\ntype(var.tolist)\n\nbuiltin_function_or_method\n\n\n\ntype(var.min)\n\nbuiltin_function_or_method\n\n\nYou can see a complete list of NumPy array’s methods and attributes in the documentation.\n\n\n\n\n\n\nR and Python: are there methods in R?\n\n\n\nIt is uncommon to use methods within an object in R. Rather, functions are extrinsic to the objects they are acting on. In R, for example, there would usually be two separate items: the variable var and a separate function min that gets var as a parameter:\n# this is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nmin(var)\nUsing the pipe operator %&gt;% in R’s tidyverse is closer to the dot . in Python:\n# this is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nvar %&gt;% min()\nWhat happens here is that the pipe %&gt;% is passing var to the min() function as its first argument. This is similar to what happens in Python when a function is a method of a class:\n# this is Python code\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar.min()\nWhen working in Python, remember that methods are functions that are part of an object and a method uses the object it is part of to produce some information.",
    "crumbs": [
      "book",
      "Python review"
    ]
  },
  {
    "objectID": "book/preface.html",
    "href": "book/preface.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the ‘EDS 220 - Working with Environmental Datasets’ course notes!\nDesigned for the UCSB Masters in Environmental Data Science (MEDS), this course will guide you through widely used environmental data formats and Python libraries for analyzing diverse environmental datasets.\nThe notes are organized following the increasing dimensions of different environmental datasets, from familiar tabular data to intricate multi-dimensional arrays. Through hands-on code and activities, you’ll analyze real-world environmental datasets sourced from leading open data repositories and cloud platforms.\nWho is this course for? EDS 220 is tailored for beginner Python programmers eager to deepen their skills. If you’re familiar with the basics of Python and have experience working in Jupyter notebooks, you’re in the right place. You are also encouraged to bring along your git skills and GitHub profile, ready to practice the essential git pull - git push workflow as you progress.\nOverall, these notes are just the beginning! They offer a solid foundation but are, inevitably, a partial exposition of the incredibly vast ecosystem of data formats, repositories, and Python tools available in environmental data science. By the end of this course, you’ll have a strong grasp of the fundamentals and also the confidence to dive deeper into using Python for environmental data science and continue your MEDS journey.\n\n\nA big thanks to the creators of the open-source Python libraries, datasets, and educational materials that have helped shape this course. Your contributions have made our learning journey richer and more impactful. Attribution is included in any materials where content is adapted from other resources.\n\n\n\n📝 If you have suggestions on how to correct, improve, or expand these notes, please feel free to email Carmen Galaz García at galazgarcia@bren.ucsb.edu or file a GitHub issue.\n🌟 If course materials notes have been useful to you, consider adding a star to the project’s repository!\n\n\n\nThis work, including the course notes, discussion sections, and assignments, is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) License. For attribution, please cite these materials as:\n\nC. Galaz García, EDS 220 - Working with Environmental Datasets, Course Notes. 2024. [Online]. Available: https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html\n\nor use the bib reference:\n@misc{galaz_garcia_eds_2024,\n    title = {EDS 220 - Working with Environmental Datasets, Course Notes},\n    url = {https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html},\n    author = {Galaz García, Carmen},\n    year = {2024},\n}",
    "crumbs": [
      "book",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#acknowledgements",
    "href": "book/preface.html#acknowledgements",
    "title": "About",
    "section": "",
    "text": "A big thanks to the creators of the open-source Python libraries, datasets, and educational materials that have helped shape this course. Your contributions have made our learning journey richer and more impactful. Attribution is included in any materials where content is adapted from other resources.",
    "crumbs": [
      "book",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#contribute",
    "href": "book/preface.html#contribute",
    "title": "About",
    "section": "",
    "text": "📝 If you have suggestions on how to correct, improve, or expand these notes, please feel free to email Carmen Galaz García at galazgarcia@bren.ucsb.edu or file a GitHub issue.\n🌟 If course materials notes have been useful to you, consider adding a star to the project’s repository!",
    "crumbs": [
      "book",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#attribution",
    "href": "book/preface.html#attribution",
    "title": "About",
    "section": "",
    "text": "This work, including the course notes, discussion sections, and assignments, is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) License. For attribution, please cite these materials as:\n\nC. Galaz García, EDS 220 - Working with Environmental Datasets, Course Notes. 2024. [Online]. Available: https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html\n\nor use the bib reference:\n@misc{galaz_garcia_eds_2024,\n    title = {EDS 220 - Working with Environmental Datasets, Course Notes},\n    url = {https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html},\n    author = {Galaz García, Carmen},\n    year = {2024},\n}",
    "crumbs": [
      "book",
      "About"
    ]
  }
]