[
  {
    "objectID": "commits-guidelines.html",
    "href": "commits-guidelines.html",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Write commit messages in the imperative mood (i.e., as if you‚Äôre giving a command). This is a widely accepted convention.\nExample: - Good: Add function to process user input - Bad: Added function to process user input or Adding function to process user input\n\n\n\nThe first line of the commit message should summarize the changes in around 50 characters or less. This makes it easy to scan in logs or on GitHub.\nExample:\nFix bug in data processing pipeline\n\n\n\nIf the commit requires further explanation, add a blank line after the summary and provide a more detailed description in the body. Focus on what and why, not necessarily how.\nExample:\nAdd user authentication check before data access\n\nPreviously, users could access the data without proper authentication.\nThis commit adds a check to ensure that only authenticated users can\naccess the sensitive data.\n\n\n\nMake sure the commit message explains the reason behind the change, not just what was changed. This helps future developers (or your future self) understand the motivation.\nExample:\nRefactor database query to improve performance\n\nThe previous query was causing significant lag for larger datasets.\nThis change optimizes the query and reduces execution time by 40%.\n\n\n\nUse a consistent format for commit messages throughout the project. If your team follows a particular convention (e.g., prefixing messages with issue numbers), stick to it.\nExample:\n# Consistent format with issue tracking\n[ISSUE-123] Fix broken link in user dashboard\n\n\n\nAlways start the commit message with a capital letter to keep it professional and uniform.\nExample: - Good: Update documentation for new feature - Bad: update documentation for new feature\n\n\n\nVague or uninformative commit messages are not helpful. Avoid commit messages like ‚ÄúFixes,‚Äù ‚ÄúUpdates,‚Äù ‚ÄúMiscellaneous changes,‚Äù or ‚ÄúWIP.‚Äù\nExample:\nBad: \"Fix stuff\"\nGood: \"Fix missing validation for email input\"\n\n\n\nA commit should represent a single logical change. Avoid lumping multiple unrelated changes into a single commit. Instead, break them up into separate, focused commits.\nExample: - Good: Commit the bug fix in one commit and the new feature in another. - Bad: Combine multiple changes in one commit with a message like ‚ÄúFix bug and add new feature.‚Äù\n\n\n\nIf applicable, reference issue numbers, bug reports, or pull requests in the commit message to tie the commit to the broader project context.\nExample:\nFix typo in data validation logic (#456)\n\n\n\nEven for small changes, write clear and meaningful messages. Something like Fix typo or Update README is fine for minor commits as long as it‚Äôs clear what the change is about.\n\n\n\nEnsure the code works as expected before committing, and write a commit message that reflects the final, working state of the change.\n\n\n\nCommit messages should be professional. Avoid using emojis, abbreviations, or casual language.\nExample: - Bad: üî• Fix all the things! üöÄ - Good: Fix critical bugs in data parsing logic\n\n\n\nRefactor user input validation to reduce redundancy\n\nThe validation logic for user input was repeated in multiple places.\nThis commit refactors the validation into a separate function that\ncan be reused across different modules. This improves code maintainability\nand reduces potential errors.\n\nCloses #123"
  },
  {
    "objectID": "commits-guidelines.html#use-the-imperative-mood",
    "href": "commits-guidelines.html#use-the-imperative-mood",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Write commit messages in the imperative mood (i.e., as if you‚Äôre giving a command). This is a widely accepted convention.\nExample: - Good: Add function to process user input - Bad: Added function to process user input or Adding function to process user input"
  },
  {
    "objectID": "commits-guidelines.html#keep-the-first-line-short-and-descriptive",
    "href": "commits-guidelines.html#keep-the-first-line-short-and-descriptive",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "The first line of the commit message should summarize the changes in around 50 characters or less. This makes it easy to scan in logs or on GitHub.\nExample:\nFix bug in data processing pipeline"
  },
  {
    "objectID": "commits-guidelines.html#provide-more-detail-in-the-body-if-necessary",
    "href": "commits-guidelines.html#provide-more-detail-in-the-body-if-necessary",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "If the commit requires further explanation, add a blank line after the summary and provide a more detailed description in the body. Focus on what and why, not necessarily how.\nExample:\nAdd user authentication check before data access\n\nPreviously, users could access the data without proper authentication.\nThis commit adds a check to ensure that only authenticated users can\naccess the sensitive data."
  },
  {
    "objectID": "commits-guidelines.html#explain-the-why-and-the-impact",
    "href": "commits-guidelines.html#explain-the-why-and-the-impact",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Make sure the commit message explains the reason behind the change, not just what was changed. This helps future developers (or your future self) understand the motivation.\nExample:\nRefactor database query to improve performance\n\nThe previous query was causing significant lag for larger datasets.\nThis change optimizes the query and reduces execution time by 40%."
  },
  {
    "objectID": "commits-guidelines.html#be-consistent",
    "href": "commits-guidelines.html#be-consistent",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Use a consistent format for commit messages throughout the project. If your team follows a particular convention (e.g., prefixing messages with issue numbers), stick to it.\nExample:\n# Consistent format with issue tracking\n[ISSUE-123] Fix broken link in user dashboard"
  },
  {
    "objectID": "commits-guidelines.html#capitalize-the-first-letter-of-the-summary",
    "href": "commits-guidelines.html#capitalize-the-first-letter-of-the-summary",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Always start the commit message with a capital letter to keep it professional and uniform.\nExample: - Good: Update documentation for new feature - Bad: update documentation for new feature"
  },
  {
    "objectID": "commits-guidelines.html#avoid-commit-messages-like-fixes-or-miscellaneous",
    "href": "commits-guidelines.html#avoid-commit-messages-like-fixes-or-miscellaneous",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Vague or uninformative commit messages are not helpful. Avoid commit messages like ‚ÄúFixes,‚Äù ‚ÄúUpdates,‚Äù ‚ÄúMiscellaneous changes,‚Äù or ‚ÄúWIP.‚Äù\nExample:\nBad: \"Fix stuff\"\nGood: \"Fix missing validation for email input\""
  },
  {
    "objectID": "commits-guidelines.html#group-related-changes-together",
    "href": "commits-guidelines.html#group-related-changes-together",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "A commit should represent a single logical change. Avoid lumping multiple unrelated changes into a single commit. Instead, break them up into separate, focused commits.\nExample: - Good: Commit the bug fix in one commit and the new feature in another. - Bad: Combine multiple changes in one commit with a message like ‚ÄúFix bug and add new feature.‚Äù"
  },
  {
    "objectID": "commits-guidelines.html#reference-relevant-issues-or-pull-requests",
    "href": "commits-guidelines.html#reference-relevant-issues-or-pull-requests",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "If applicable, reference issue numbers, bug reports, or pull requests in the commit message to tie the commit to the broader project context.\nExample:\nFix typo in data validation logic (#456)"
  },
  {
    "objectID": "commits-guidelines.html#use-short-informative-messages-for-small-changes",
    "href": "commits-guidelines.html#use-short-informative-messages-for-small-changes",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Even for small changes, write clear and meaningful messages. Something like Fix typo or Update README is fine for minor commits as long as it‚Äôs clear what the change is about."
  },
  {
    "objectID": "commits-guidelines.html#test-before-committing",
    "href": "commits-guidelines.html#test-before-committing",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Ensure the code works as expected before committing, and write a commit message that reflects the final, working state of the change."
  },
  {
    "objectID": "commits-guidelines.html#avoid-emoticons-and-slang",
    "href": "commits-guidelines.html#avoid-emoticons-and-slang",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Commit messages should be professional. Avoid using emojis, abbreviations, or casual language.\nExample: - Bad: üî• Fix all the things! üöÄ - Good: Fix critical bugs in data parsing logic"
  },
  {
    "objectID": "commits-guidelines.html#example-of-a-well-structured-commit-message",
    "href": "commits-guidelines.html#example-of-a-well-structured-commit-message",
    "title": "Guidelines for Writing Good Commit Messages",
    "section": "",
    "text": "Refactor user input validation to reduce redundancy\n\nThe validation logic for user input was repeated in multiple places.\nThis commit refactors the validation into a separate function that\ncan be reused across different modules. This improves code maintainability\nand reduces potential errors.\n\nCloses #123"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-6-arctic-plot.html",
    "href": "discussion-sections-upcoming/ds-6-arctic-plot.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "import os\n#import contextily as ctx\nimport geopandas as gpd\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndf = gpd.read_file('data/arctic_communities.geojson')\ndf\n\n\n\n\n\n\n\n\nadmin\ncountry\nn_communities\ngeometry\n\n\n\n\n0\nUnited States of America\nUS\n115\nMULTIPOLYGON (((-132.74687 56.52568, -132.7576...\n\n\n1\nUnited Kingdom\nGB\n96\nMULTIPOLYGON (((-2.66768 51.62300, -2.74214 51...\n\n\n2\nSweden\nSE\n133\nMULTIPOLYGON (((19.07646 57.83594, 18.99375 57...\n\n\n3\nRussia\nRU\n774\nMULTIPOLYGON (((145.88154 43.45952, 145.89561 ...\n\n\n4\nNorway\nNO\n48\nMULTIPOLYGON (((20.62217 69.03687, 20.49199 69...\n\n\n5\nLithuania\nLT\n26\nMULTIPOLYGON (((20.95781 55.27891, 20.89980 55...\n\n\n6\nLatvia\nLV\n25\nPOLYGON ((26.59355 55.66753, 26.54287 55.67241...\n\n\n7\nIceland\nIS\n5\nPOLYGON ((-15.54312 66.22852, -15.42847 66.224...\n\n\n8\nFinland\nFI\n99\nMULTIPOLYGON (((24.15547 65.80527, 24.04902 65...\n\n\n9\nEstonia\nEE\n14\nMULTIPOLYGON (((27.35195 57.52813, 27.32656 57...\n\n\n10\nGreenland\nGL\n1\nMULTIPOLYGON (((-29.95288 83.56484, -28.99199 ...\n\n\n11\nFaroe Islands\nFO\n1\nMULTIPOLYGON (((-6.62319 61.80596, -6.64277 61...\n\n\n12\nDenmark\nDK\n72\nMULTIPOLYGON (((12.56875 55.78506, 12.57119 55...\n\n\n13\nCanada\nCA\n7\nMULTIPOLYGON (((-132.65552 54.12749, -132.5640...\n\n\n14\nBelarus\nBY\n8\nPOLYGON ((31.76338 52.10107, 31.57373 52.10811...\n\n\n\n\n\n\n\n\ndf.explode(index_parts=False)\n\n\n\n\n\n\n\n\nadmin\ncountry\nn_communities\ngeometry\n\n\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-132.74687 56.52568, -132.75762 56.5...\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-132.77988 56.24727, -132.83096 56.2...\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-134.31274 58.22891, -134.31987 58.2...\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-145.11851 60.33711, -145.15049 60.3...\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-144.56563 59.81841, -144.61357 59.8...\n\n\n...\n...\n...\n...\n...\n\n\n13\nCanada\nCA\n7\nPOLYGON ((-109.16641 67.98237, -109.05391 67.9...\n\n\n13\nCanada\nCA\n7\nPOLYGON ((-108.09272 67.00518, -107.96646 66.9...\n\n\n13\nCanada\nCA\n7\nPOLYGON ((-109.32314 67.99087, -109.36084 67.9...\n\n\n13\nCanada\nCA\n7\nPOLYGON ((-139.04312 69.57690, -139.12573 69.5...\n\n\n14\nBelarus\nBY\n8\nPOLYGON ((31.76338 52.10107, 31.57373 52.10811...\n\n\n\n\n481 rows √ó 4 columns\n\n\n\n\narctic = arctic.to_crs(epsg=3413)\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Plot your data\ndf.plot(\n    ax=ax,\n    column='n_communities',\n    legend=True,\n)        \n\n# Add title and subtitle for better context\nax.set_title('Distribution of Arctic Communities', \n             fontsize=15, \n             weight='bold', \n             pad=15\n             )\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndf = df.explode(index_parts=False).reset_index(drop=True)\ndf\n\n\n\n\n\n\n\n\nadmin\ncountry\nn_communities\ngeometry\n\n\n\n\n0\nUnited States of America\nUS\n115\nPOLYGON ((-132.74687 56.52568, -132.75762 56.5...\n\n\n1\nUnited States of America\nUS\n115\nPOLYGON ((-132.77988 56.24727, -132.83096 56.2...\n\n\n2\nUnited States of America\nUS\n115\nPOLYGON ((-134.31274 58.22891, -134.31987 58.2...\n\n\n3\nUnited States of America\nUS\n115\nPOLYGON ((-145.11851 60.33711, -145.15049 60.3...\n\n\n4\nUnited States of America\nUS\n115\nPOLYGON ((-144.56563 59.81841, -144.61357 59.8...\n\n\n...\n...\n...\n...\n...\n\n\n476\nCanada\nCA\n7\nPOLYGON ((-109.16641 67.98237, -109.05391 67.9...\n\n\n477\nCanada\nCA\n7\nPOLYGON ((-108.09272 67.00518, -107.96646 66.9...\n\n\n478\nCanada\nCA\n7\nPOLYGON ((-109.32314 67.99087, -109.36084 67.9...\n\n\n479\nCanada\nCA\n7\nPOLYGON ((-139.04312 69.57690, -139.12573 69.5...\n\n\n480\nBelarus\nBY\n8\nPOLYGON ((31.76338 52.10107, 31.57373 52.10811...\n\n\n\n\n481 rows √ó 4 columns\n\n\n\n\ndf.geom_type[0]\n\n'MultiPolygon'\n\n\n\ndef miny_bound(row):\n    return row.geometry.bounds[1]\n\n\nminy_bound(df.iloc[0])\n\n56.511035156249996\n\n\n\nrow = df.iloc[0]\nrow.geometry.bounds[1]\n\n56.511035156249996\n\n\n\nrow.geometry.bounds\n\n(-132.948046875, 56.511035156249996, -132.56796875, 56.794775390625)\n\n\n\ndf.iloc[0]\n\nadmin                                     United States of America\ncountry                                                         US\nn_communities                                                  115\ngeometry         MULTIPOLYGON (((-132.746875 56.525683593749996...\nName: 0, dtype: object\n\n\n\nrow.geometry\n\n\n\n\n\n\n\n\n\ntype(row.geometry)\n\nshapely.geometry.polygon.Polygon\n\n\n\npoly = df.iloc[[0]]\npoly.total_bounds[1]\n\n18.963916015625003\n\n\n\ndf.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\ndf['miny'] = df.apply(lambda row: row.geometry.bounds[1], axis=1)\n\n\narctic = df[df.miny &gt;=40].to_crs('epsg:3857')\n\n\narctic = arctic.to_crs(epsg=3413)\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Plot your data\narctic.plot(\n    ax=ax,\n    column='n_communities',\n    cmap='PuBuGn',\n    legend=True,\n    edgecolor=\"0.6\",\n    linewidth=0.5,\n    legend_kwds={\n        \"shrink\": 0.7,\n        \"label\": \"Number of Arctic Communities\",\n        \"orientation\": \"horizontal\",\n        \"pad\": 0.05\n    }\n)        \n\n# Add title and subtitle for better context\nax.set_title('Distribution of Arctic Communities', \n             fontsize=15, \n             weight='bold', \n             pad=15\n             )\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Ensure your GeoDataFrame is in the Web Mercator projection\narctic = arctic.to_crs(epsg=3857)\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Plot your data\narctic.plot(ax=ax, column='n_communities', alpha=0.3)\n\n# Add a basemap with a specified zoom level\nctx.add_basemap(ax, zoom=3)  # Adjust the zoom level as needed for your map extent\n\nplt.show()\n\n\n\n\n\n\n\n\n\narctic = arctic.to_crs(epsg=3413)\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Plot your data\narctic.plot(\n    ax=ax,\n    column='n_communities',\n    cmap='PuBuGn',\n    legend=True,\n    edgecolor=\"0.6\",\n    linewidth=0.5,\n    legend_kwds={\n        \"shrink\": 0.7,\n        \"label\": \"Number of Arctic Communities\",\n        \"orientation\": \"horizontal\",\n        \"pad\": 0.05\n    }\n)\n\n# Add a basemap with a specified zoom level\nctx.add_basemap(ax, \n                source=ctx.providers.CartoDB.Voyager,\n                crs=arctic.crs, \n                attribution_size=4,\n                zoom=3\n                )                  \n\n# Add title and subtitle for better context\nax.set_title('Distribution of Arctic Communities', \n             fontsize=15, \n             weight='bold', \n             pad=15\n             )\n\n\nplt.show()"
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html",
    "href": "discussion-sections-upcoming/lulc_cover.html",
    "title": "Import Thomas fire perimeter",
    "section": "",
    "text": "from matplotlib.colors import ListedColormap\nimport pystac_client\n\nimport numpy as np\nimport pandas as pd\nimport planetary_computer\nimport rasterio\n\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely import box\nfrom IPython.display import Image  # To nicely display images\nfire_perimeters = gpd.read_file('data/California_Fire_Perimeters_2017/California_Fire_Perimeters_2017.shp')\nthomas_fire = fire_perimeters[fire_perimeters['FIRE_NAME']=='THOMAS']\nthomas_fire.plot()\n# Examine CRS of boundary\nthomas_fire.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06¬∞S and 85.06¬∞N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich"
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html#retrieve-lulc-data-over-fire-perimeter",
    "href": "discussion-sections-upcoming/lulc_cover.html#retrieve-lulc-data-over-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Retrieve LULC data over fire perimeter",
    "text": "Retrieve LULC data over fire perimeter\n\n# Open MPC data catalog\ncatalog = pystac_client.Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n\n# Reproject fire perimeter to match CRS needed for search\nthomas_fire = thomas_fire.to_crs('epsg:4326')\n\n# Create bounding box for search\nbbox_of_interest = list(thomas_fire.total_bounds)\n\nsearch = catalog.search(collections=[\"io-lulc-annual-v02\"], \n                        bbox=bbox_of_interest)\n\n# Retrieve search items\nitems = search.item_collection()\nprint(f\"Returned {len(items)} Items\")\nitems\n\nReturned 7 Items\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        features[] 7 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2023\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881301473854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.964594535227064\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.713500319629\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97101902039171\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.42810114793184\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97680307284368\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262455683908\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.981946056873323\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85707961871367\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98644740692807\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57147541932304\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99030662778057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582105606586\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.993523294675935\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00012563619272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99609705345823\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.71439827502174\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.998027620675984\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42864809415019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9993147836666\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288421966272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.999958400619768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85711578033728\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.999958400619768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135190584981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9993147836666\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.28560172497826\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.998027620675984\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987436380728\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99609705345823\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71417894393414\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.993523294675935\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852458067696\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99030662778057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292038128633\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98644740692807\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85737544316092\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.981946056873323\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.57189885206816\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97680307284368\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.28649968037101\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97101902039171\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00118698526144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.964594535227064\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862363547963\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34710558574068\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97581985420587\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72958897264179\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277143512539\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204444975024\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947405000839\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447177251696\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.9359232447114\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687069795639\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211443501304\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924098457442\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804290227565\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158239229177\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.89370378892504\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389468236244\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909209373909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.406177617287256\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.86420266693608\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843096072205\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.849030205053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.1706544773805\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83356924560326\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.5528479329312\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781416150304\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501109388885\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80175915525437\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714372749926\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.78539825287305\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69924560161768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76872529754793\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08131648458072\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173394301825\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46335614507083\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73441764665404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.845364351973686\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7167696622244\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734087422758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878303233713\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60928548066479\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045058053237\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99119793984452\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99616663742734\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9998190404251\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201196706637\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758114393793\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797305605531\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.014483268973116\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94403635966702\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052454225648\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26018830547575\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02570419896978\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57641529701128\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002158303139\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.89270371742927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03347614733747\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20903993319644\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03606745396311\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.5254102977869\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03779517432345\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.84180115538794\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03865908929467\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.15819884461206\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03865908929467\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.4745897022131\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03779517432345\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096006680356\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03606745396311\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.10729628257073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03347614733747\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358470298872\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002158303139\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981169452425\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02570419896978\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596364033298\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052454225648\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37202694394469\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.014483268973116\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68798803293365\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758114393793\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383336257265\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9998190404251\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31954941946765\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99119793984452\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30121696766287\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60928548066479\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323033777559\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734087422758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558235334595\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.845364351973686\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24826605698173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46335614507083\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127470245207\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08131648458072\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.21460174712695\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69924560161768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824084474563\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714372749926\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18218583849695\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501109388885\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643075439674\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.5528479329312\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15096979494699\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.1706544773805\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.13579733306392\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843096072205\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1209079062609\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.406177617287256\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.10629621107496\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389468236244\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09195709772436\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158239229177\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07788556498696\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924098457442\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06407675528858\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687069795639\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05052594999161\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447177251696\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.0372285648746\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204444975023\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418014579413\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72958897264179\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01137636452036\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34710558574068\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881301473854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.964594535227064\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31954941946765\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.964594535227064\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045058053237\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03865908929467\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            supercell\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2024-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2023-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2023\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2023\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20230101-20240101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            92111967\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2023&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2023&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2022\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2023-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2022-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2022\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2022\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20220101-20230101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            110070485\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2022&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2022&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2021\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2022-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2021-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2021\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2021\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20210101-20220101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            110367827\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2021&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2021&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2020\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2021-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2020-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2020\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2020\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20200101-20210101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            112931678\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2020&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2020&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2019\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2020-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2019-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2019\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2019\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20190101-20200101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            116945012\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2019&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2019&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2018\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2019-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2018-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2018\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2018\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20180101-20190101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            120120808\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2018&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2018&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/file/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"11S-2017\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 85 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.7135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.4281\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.14262\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.85708\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        5[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.57148\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        6[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.28582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        7[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.00013\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        8[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.7144\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        9[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.42865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        10[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.14288\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        11[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.85712\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99996\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        12[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.57135\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99931\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        13[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.2856\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99803\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        14[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.99987\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9961\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        15[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.71418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99352\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        16[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.42852\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.99031\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        17[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.14292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98645\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        18[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.85738\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.98195\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        19[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.5719\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.9768\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        20[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.2865\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.97102\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        21[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.00119\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        22[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.98862\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        23[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.97582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        24[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.96277\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        25[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.94947\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        26[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.93592\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        27[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.92211\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        28[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.90804\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        29[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8937\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        30[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.87909\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        31[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.8642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        32[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.84903\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        33[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.83357\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        34[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.81781\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        35[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.80176\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        36[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.7854\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        37[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.76873\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        38[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.75173\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        39[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.73442\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        40[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.71677\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        41[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.69878\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        42[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        43[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -113.99617\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        44[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.31201\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        45[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.62797\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        46[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -114.94404\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        47[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.26019\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        48[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.57642\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        49[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -115.8927\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        50[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.20904\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        51[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.52541\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        52[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -116.8418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        53[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.1582\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        54[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.47459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0378\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        55[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -117.79096\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03607\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        56[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.1073\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03348\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        57[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.42358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.03002\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        58[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.73981\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.0257\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        59[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.05596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.02052\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        60[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.37203\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.01448\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        61[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.68799\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            40.00758\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        62[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.00383\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.99982\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        63[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.9912\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        64[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.30122\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.60929\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        65[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.28323\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            39.22734\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        66[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.26558\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.84536\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        67[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.24827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.46336\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        68[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.23127\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.08132\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        69[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.2146\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.69925\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        70[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.19824\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            37.31714\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        71[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.18219\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.93501\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        72[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.16643\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.55285\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        73[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.15097\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.17065\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        74[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1358\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.78843\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        75[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.12091\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.40618\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        76[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.1063\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.02389\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        77[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.09196\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.64158\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        78[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.07789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.25924\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        79[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.06408\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.87687\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        80[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.05053\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.49447\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        81[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.03723\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.11204\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        82[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.02418\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.72959\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        83[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.01138\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            32.34711\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        84[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.99881\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.31955\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            31.96459\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -113.68045\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            40.03866\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3540440.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            783420.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            32611\n        \n    \n            \n        \n            \n                \n        \n            io:tile_id\n            \"11S\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            89162\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            56684\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2018-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        proj:transform[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            216580.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -10.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            4432060.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2017-01-01T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            io:supercell_id\n            \"11S\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-lulc-annual-v02/items/11S-2017\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=io-lulc-annual-v02&item=11S-2017\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/io-lulc/io-annual-lulc-v02/11S_20170101-20180101.tif?st=2024-11-25T03%3A57%3A00Z&se=2024-11-26T04%3A42%3A00Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T00%3A06%3A23Z&ske=2024-12-03T00%3A06%3A23Z&sks=b&skv=2024-05-04&sig=R4NJ7zPHXpblgkz/gCVMYpXHJ6jFsf64WuL0DRLT7nI%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            file:size\n            120895035\n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            nodata\n            0\n        \n    \n            \n        \n            \n                \n        \n            spatial_resolution\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        file:values[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"No Data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Water\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            2\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Trees\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            4\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Flooded vegetation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            5\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Crops\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            7\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Built area\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            8\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Bare ground\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            9\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Snow/ice\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            10\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Clouds\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \n        \n            \n                \n        values[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            11\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            summary\n            \"Rangeland\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-lulc-annual-v02&item=11S-2017&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-lulc-annual-v02&item=11S-2017&assets=data&colormap_name=io-lulc-9-class&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"io-lulc-annual-v02\""
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html#explore-lulc-item-around-thomas-fire-perimeter",
    "href": "discussion-sections-upcoming/lulc_cover.html#explore-lulc-item-around-thomas-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Explore LULC item around Thomas Fire perimeter",
    "text": "Explore LULC item around Thomas Fire perimeter\n\nitem = items[0]  # Select item\n\n# Display pre-rendered image\nImage(url=item.assets['rendered_preview'].href)\n\n\n\n\n\n# Access raster data from item\nlulc23 = rioxr.open_rasterio(item.assets['data'].href)\nlulc23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 89162, x: 56684)&gt; Size: 5GB\n[5054058808 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 453kB 2.166e+05 2.166e+05 ... 7.834e+05 7.834e+05\n  * y            (y) float64 713kB 4.432e+06 4.432e+06 ... 3.54e+06 3.54e+06\n    spatial_ref  int64 8B 0\nAttributes:\n    AREA_OR_POINT:  Area\n    _FillValue:     0\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 1y: 89162x: 56684...[5054058808 values with dtype=uint8]Coordinates: (4)band(band)int641array([1])x(x)float642.166e+05 2.166e+05 ... 7.834e+05array([216585., 216595., 216605., ..., 783395., 783405., 783415.])y(y)float644.432e+06 4.432e+06 ... 3.54e+06array([4432055., 4432045., 4432035., ..., 3540465., 3540455., 3540445.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :216580.0 10.0 0.0 4432060.0 0.0 -10.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([216585.0, 216595.0, 216605.0, 216615.0, 216625.0, 216635.0, 216645.0,\n       216655.0, 216665.0, 216675.0,\n       ...\n       783325.0, 783335.0, 783345.0, 783355.0, 783365.0, 783375.0, 783385.0,\n       783395.0, 783405.0, 783415.0],\n      dtype='float64', name='x', length=56684))yPandasIndexPandasIndex(Index([4432055.0, 4432045.0, 4432035.0, 4432025.0, 4432015.0, 4432005.0,\n       4431995.0, 4431985.0, 4431975.0, 4431965.0,\n       ...\n       3540535.0, 3540525.0, 3540515.0, 3540505.0, 3540495.0, 3540485.0,\n       3540475.0, 3540465.0, 3540455.0, 3540445.0],\n      dtype='float64', name='y', length=89162))Attributes: (4)AREA_OR_POINT :Area_FillValue :0scale_factor :1.0add_offset :0.0\n\n\nLet‚Äôs visually explore the extent of the lulc23 tile relative to the CA boundary:\n\n# Create GeoDataFrame from raster bounding box\nlulc23_bbox = gpd.GeoDataFrame(geometry = [box(*lulc23.rio.bounds())],\n                 crs = lulc23.rio.crs)\nca = gpd.read_file('data/ca_state_boundary/ca_state_boundary.shp')\n\n# Plot raster boundary, fire perimeter, and CA boundary\nfig, ax = plt.subplots()\nca.plot(ax=ax, color='white', edgecolor ='black')\nlulc23_bbox.to_crs(ca.crs).plot(ax=ax, alpha=0.3)   # Reproject to match CA crs\nthomas_fire.to_crs(ca.crs).plot(ax=ax, color='red')\nplt.show()"
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html#clip-raster-to-fire-perimeter",
    "href": "discussion-sections-upcoming/lulc_cover.html#clip-raster-to-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Clip raster to fire perimeter",
    "text": "Clip raster to fire perimeter\nFirst, we need to ensure our raster and fire perimeter have the same CRS.\n\nthomas_fire = thomas_fire.to_crs(lulc23.rio.crs)\nassert thomas_fire.crs == lulc23.rio.crs\n\nClipping directly with the fire perimeter is computationally expensive. It is best to first reduce with the thomas_fire bounding box, and then clip to the actual fire perimeter.\n\nlulc23_clip = lulc23.rio.clip_box(*thomas_fire.total_bounds)\n\n\nlulc23_clip.plot()\n\n\n\n\n\n\n\n\n\nlulc_thomasfire = lulc23_clip.rio.clip(thomas_fire.geometry)\n\n\nlulc_thomasfire.plot()\n\n\n\n\n\n\n\n\nNotice the clipped areas were assigned the 0 value (instead of NA). We can check this represents no data in our raster:\n\nlulc_thomasfire.rio.nodata\n\n0"
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html#land-cover-statistics",
    "href": "discussion-sections-upcoming/lulc_cover.html#land-cover-statistics",
    "title": "Import Thomas fire perimeter",
    "section": "Land cover statistics",
    "text": "Land cover statistics\nGot class names from: https://planetarycomputer.microsoft.com/dataset/io-lulc-annual-v02#Example-Notebook\n\n# Create class_names df\nclass_names = pd.DataFrame({\n    \"category\": ['No Data', 'Water', 'Trees', 'Flooded vegetation', \n                 'Crops', 'Built area', 'Bare ground', 'Snow/ice', \n                 'Clouds', 'Rangeland'],\n    \"code\": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11]\n})\nclass_names\n\n\n\n\n\n\n\n\ncategory\ncode\n\n\n\n\n0\nNo Data\n0\n\n\n1\nWater\n1\n\n\n2\nTrees\n2\n\n\n3\nFlooded vegetation\n4\n\n\n4\nCrops\n5\n\n\n5\nBuilt area\n7\n\n\n6\nBare ground\n8\n\n\n7\nSnow/ice\n9\n\n\n8\nClouds\n10\n\n\n9\nRangeland\n11\n\n\n\n\n\n\n\n\nunique_counts = np.unique(lulc_thomasfire, return_counts=True)\npix_counts = pd.DataFrame({'code':unique_counts[0], \n                           'n_pixels':unique_counts[1]})\npix_counts\n\n\n\n\n\n\n\n\ncode\nn_pixels\n\n\n\n\n0\n0\n16395636\n\n\n1\n1\n12342\n\n\n2\n2\n1231235\n\n\n3\n5\n153723\n\n\n4\n7\n173495\n\n\n5\n8\n23274\n\n\n6\n11\n9813005\n\n\n\n\n\n\n\n\nclasses = pd.merge(left=class_names, \n                   right=pix_counts, \n                   on='code')\nclasses\n\n\n\n\n\n\n\n\ncategory\ncode\nn_pixels\n\n\n\n\n0\nNo Data\n0\n16395636\n\n\n1\nWater\n1\n12342\n\n\n2\nTrees\n2\n1231235\n\n\n3\nCrops\n5\n153723\n\n\n4\nBuilt area\n7\n173495\n\n\n5\nBare ground\n8\n23274\n\n\n6\nRangeland\n11\n9813005\n\n\n\n\n\n\n\n\nclasses['area_km2']=classes.n_pixels/1000\nclasses\n\n\n\n\n\n\n\n\ncategory\ncode\nn_pixels\narea_hectares\narea_km2\n\n\n\n\n0\nNo Data\n0\n16395636\n16395636000\n16395.636\n\n\n1\nWater\n1\n12342\n12342000\n12.342\n\n\n2\nTrees\n2\n1231235\n1231235000\n1231.235\n\n\n3\nCrops\n5\n153723\n153723000\n153.723\n\n\n4\nBuilt area\n7\n173495\n173495000\n173.495\n\n\n5\nBare ground\n8\n23274\n23274000\n23.274\n\n\n6\nRangeland\n11\n9813005\n9813005000\n9813.005"
  },
  {
    "objectID": "discussion-sections-upcoming/lulc_cover.html#workflow-for-a-single-item",
    "href": "discussion-sections-upcoming/lulc_cover.html#workflow-for-a-single-item",
    "title": "Import Thomas fire perimeter",
    "section": "Workflow for a single item",
    "text": "Workflow for a single item\n\n\nindices = [0,1,2,3,4,5]\nclasses = pd.DataFrame()\nfor i in indices:\n\n    item = items[i]\n\n    # Access raster data from item\n    lulc = rioxr.open_rasterio(item.assets['data'].href)\n\n    # Match fire perimeter and raster\n    thomas_fire = thomas_fire.to_crs(lulc.rio.crs)\n    assert thomas_fire.crs == lulc.rio.crs\n\n    # Clip to Thomas Fire perimeter\n    lulc_thomasfire = (lulc.rio.clip_box(*thomas_fire.total_bounds)\n                                .rio.clip(thomas_fire.geometry))\n\n    # Calculate number of pixels per class\n    unique_counts = np.unique(lulc_thomasfire, \n                                return_counts=True)\n                                \n    pix_counts = pd.DataFrame({'code':unique_counts[0], \n                            'n_pixels':unique_counts[1]})\n    pix_counts = pd.merge(left=class_names, \n                          right=pix_counts, \n                          on='code')  \n                                                \n    classes['area_km2_'+str(2017+i)]=pix_counts.n_pixels/1000                   \n\n\npix_counts\n\n\n\n\n\n\n\n\ncategory\ncode\nn_pixels\n\n\n\n\n0\nNo Data\n0\n16395636\n\n\n1\nWater\n1\n6992\n\n\n2\nTrees\n2\n318139\n\n\n3\nCrops\n5\n123895\n\n\n4\nBuilt area\n7\n114571\n\n\n5\nBare ground\n8\n29616\n\n\n6\nRangeland\n11\n10813861\n\n\n\n\n\n\n\n\nclasses\n\n\n\n\n\n\n\n\narea_km2_2017\narea_km2_2018\narea_km2_2019\narea_km2_2020\narea_km2_2021\narea_km2_2022\n\n\n\n\n0\n16395.636\n16395.636\n16395.636\n16395.636\n16395.636\n16395.636\n\n\n1\n12.342\n6.662\n6.676\n8.624\n9.955\n6.992\n\n\n2\n1231.235\n674.905\n459.310\n756.012\n531.156\n318.139\n\n\n3\n153.723\n133.248\n138.940\n145.422\n148.931\n123.895\n\n\n4\n173.495\n143.401\n133.352\n142.510\n134.281\n114.571\n\n\n5\n23.274\n26.591\n27.944\n27.208\n28.017\n29.616\n\n\n6\n9813.005\n10422.267\n10640.852\n10327.298\n10554.734\n10813.861\n\n\n\n\n\n\n\n\nclass_names\n\n\n\n\n\n\n\n\ncategory\ncode\n\n\n\n\n0\nNo Data\n0\n\n\n1\nWater\n1\n\n\n2\nTrees\n2\n\n\n3\nFlooded vegetation\n4\n\n\n4\nCrops\n5\n\n\n5\nBuilt area\n7\n\n\n6\nBare ground\n8\n\n\n7\nSnow/ice\n9\n\n\n8\nClouds\n10\n\n\n9\nRangeland\n11\n\n\n\n\n\n\n\n\nclass_colors = {\n    0: \"black\",        # No Data\n    1: \"blue\",         # Water\n    2: \"forestgreen\",  # Trees\n    3: \"springgreen\",  # Flooded vegetation\n    4: \"gold\",         # Crops\n    5: \"slategrey\",    # Built area\n    6: \"tan\",          # Bare ground\n    7: \"azure\",        # Snow/ice\n    8: \"pink\",         # Rangeland\n}\n\n# Create a ListedColormap for the classes\ncmap = ListedColormap([class_colors[key] for key in sorted(class_colors.keys())])\n\n\nplt.figure(figsize=(8, 6))\nplt.imshow(lulc_thomasfire.squeeze(), cmap=cmap)\nplt.colorbar(ticks=[0, 1, 2, 3, 4, 5, 6, 7, 8 ], # Add class labels to the colorbar\n             label=\"Class\")  \nplt.show()"
  },
  {
    "objectID": "discussion-sections-upcoming/homework-draft.html",
    "href": "discussion-sections-upcoming/homework-draft.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "import pandas as pd\n\npd.set_option(\"display.max.columns\", None)\n\ndf = pd.read_csv('data/Colorado River Basin Water Conflict Table.csv')\ndf.head(5)\n\n\n\n\n\n\n\n\nEvent\nSearch Source\nNewspaper\nArticle Title\nDuplicate\nReport Date\nReport Year\nEvent Date\nEvent Day\nEvent Month\nEvent Year\nConflict Present\nCrisis Present\nBasin\nHUC6\nHUC2\nPlace\nCounty\nCounty FIPS\nState\nState FIPS\nUrban or Rural\nIssue Type\nEvent Summary\nStakeholders\nIntensity Value\nComments\nRelated Observation Themes\nArticle Text Search - water quality\nArticle Text Search - invasive species\nArticle Text Search - conservation\nArticle Text Search - drought\nArticle Text Search - flood\nArticle Text Search - ground water depletion\nArticle Text Search - depletion\nArticle Text Search - infrastructure\nArticle Text Search - fish passage\nArticle Text Search - instream water rights\nArticle Text Search - water rights\nArticle Text Search - intergovernmental\nArticle Text Search - water transfers\nArticle Text Search - navigation\nArticle Text Search - fish\nArticle Text Search - invasive\nArticle Text Search - diversion\nArticle Text Search - water diversion\nArticle Text Search - instream\nArticle Text Search - aquatic\n\n\n\n\n0\n1\nUSGS1-50.docx\nThe Durango Herald (Colorado)\nTribes assert water rights on Colorado River B...\nFalse\n7-Apr-22\n2022.0\nNaN\nNaN\n4.0\n2022.0\nY\nN\nUpper San Juan\n140801\n14\nDurango, CO\nLa Plata\n8067.0\nCO\n8\nBoth\nWater rights more generally\nUte Mountain and Southern Ute representatives ...\nTribal Nations, State Government, Federal Gove...\n2.0\nThe article highlights calls for negotiation b...\nLack of tribal representation\n0\n0\n3\n7\n0\n0\n0\n1\n0\n0\n17\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n2\nUSGS1-50.docx\nJournal, The (Cortez, Dolores, Mancos, CO)\nNative American tribes assert water rights on ...\nFalse\n7-Apr-22\n2022.0\nNaN\nNaN\n4.0\n2022.0\nY\nN\nUpper San Juan\n140801\n14\nDurango, CO\nLa Plata\n8067.0\nCO\n8\nBoth\nWater rights more generally\nUte Mountain and Southern Ute representatives ...\nSouthern Ute Indian Tribe, Ute Mountain Tribe,...\n2.0\nThe article highlights calls for negotiation b...\nLack of tribal representation\n0\n0\n2\n7\n0\n0\n0\n1\n0\n0\n17\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n3\nUSGS1-50.docx\nThe Salt Lake Tribune\n'Very positive change.' New Utah law will be a...\nFalse\n17-Mar-22\n2022.0\nNaN\nNaN\n3.0\n2022.0\nN\nY\nGreat Salt Lake\n160203\n16\nGreat Salt Lake\nNaN\nNaN\nUT\n49\nBoth\nInstream water rights\nA bill is proposed in Utah that would expand t...\nState Government, Any Water Rights Holder, Agr...\n3.0\nThe event is the proposal of the bill at the s...\nDishonoring the absent\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n12\n0\n0\n0\n1\n0\n0\n0\n12\n1\n\n\n3\n4\nUSGS1-50.docx\nCasa Grande Dispatch (AZ)\nLegislation would let an Arizona tribe lease C...\nFalse\n11-Dec-21\n2021.0\nNaN\nNaN\n12.0\n2021.0\nN\nY\nLower Colorado\n150301\n15\nColorado River Indian Reservation\nNaN\nNaN\nNaN\nNaN\nRural\nWater rights more generally\nThe Colorado River Indian Tribes Water Resilie...\nColorado River Indian Tribes, State Government...\n3.0\nEvent is proposal of the bill, preliminary agr...\nNaN\n0\n0\n2\n6\n0\n0\n0\n0\n0\n0\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n5\nUSGS1-50.docx\nThe Aspen Times (Colorado)\nHistorically excluded from Colorado River poli...\nFalse\n19-Dec-21\n2021.0\nNaN\nNaN\n11.0\n2021.0\nY\nY\nUpper San Juan\n140801\n14\nSouthern Ute Indian Reservation\nNaN\nNaN\nNaN\nNaN\nRural\nIntergovernmental issues\nState and federal officials say that Tribal Na...\nSothern Ute Indian Tribe, Ute Mountain Tribe, ...\n-1.0\nInteraction between tribal nations and state/f...\nLack of tribal representation\n0\n0\n2\n6\n0\n0\n0\n7\n0\n0\n18\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n# Simplify column names\ndf.columns = df.columns.str.lower().str.replace(' ', '_')\n\n\n(df['state'].dropna()\n            .str.split(';', expand=True)\n            .stack()\n            .str.strip()\n            .value_counts())\n\nAZ    87\nCO    45\nUT    40\nNV    19\nCA    16\nNM    13\nWY     8\nOH     1\nTX     1\nName: count, dtype: int64\n\n\n\n# This is probably a mistake in the dataset\noh_row = df[df['state'].str.contains('OH', case=False, na=False)]\nprint(oh_row['state'])\noh_row.iat[0,3]\n\n11    OH; UT\nName: state, dtype: object\n\n\n'Environmentalists secure water rights for Great Salt Lake'\n\n\n\ndf.urban_or_rural.unique()\n\narray(['Both', 'Rural', 'Urban  ', nan, 'Urban ', 'Urban', 'Both '],\n      dtype=object)\n\n\n\ndf.urban_or_rural = df.urban_or_rural.str.strip()\ndf.urban_or_rural.value_counts(dropna=False)\n\nurban_or_rural\nBoth     190\nRural     45\nUrban     19\nNaN       14\nName: count, dtype: int64\n\n\n\nurban = df[df.urban_or_rural == 'Urban']\n\n\nurban\n\n\n\n\n\n\n\n\nevent\nsearch_source\nnewspaper\narticle_title\nduplicate\nreport_date\nreport_year\nevent_date\nevent_day\nevent_month\nevent_year\nconflict_present\ncrisis_present\nbasin\nhuc6\nhuc2\nplace\ncounty\ncounty_fips\nstate\nstate_fips\nurban_or_rural\nissue_type\nevent_summary\nstakeholders\nintensity_value\ncomments\nrelated_observation_themes\narticle_text_search_-_water_quality\narticle_text_search_-_invasive_species\narticle_text_search_-_conservation\narticle_text_search_-_drought\narticle_text_search_-_flood\narticle_text_search_-_ground_water_depletion\narticle_text_search_-_depletion\narticle_text_search_-_infrastructure\narticle_text_search_-_fish_passage\narticle_text_search_-_instream_water_rights\narticle_text_search_-_water_rights\narticle_text_search_-_intergovernmental\narticle_text_search_-_water_transfers\narticle_text_search_-_navigation\narticle_text_search_-_fish\narticle_text_search_-_invasive\narticle_text_search_-_diversion\narticle_text_search_-_water_diversion\narticle_text_search_-_instream\narticle_text_search_-_aquatic\n\n\n\n\n15\n16\nUSGS1-50.docx\nAssociated Press State & Local\nThe Latest: Arizona governor Colorado River dr...\nFalse\n1-Feb-19\n2019.0\n2019\nNaN\nNaN\n2019.0\nN\nY\nEntire Lower Colorado Basin\nNaN\n15\nPhoenix, AZ\nNaN\nNaN\nAZ\n4\nUrban\nIntergovernmental issues\nGov. Doug Ducey has signed a measure letting A...\nState Government, Federal Government, All Wate...\n5.0\nNaN\nNaN\n0\n0\n0\n9\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n17\n18\nUSGS1-50.docx\nJournal, The (Cortez, Dolores, Mancos, CO)\nThe tiny plant that shapes the Colorado River\nFalse\n26-Jan-18\n2018.0\n2018\nNaN\nNaN\n2018.0\nN\nN\nSouth Platte\n101900\n10\nDenver, CO; Shoshone power plant\nNaN\nNaN\nCO\n8\nUrban\nInfrastructure issues\nThat facility, the Shoshone power plant, still...\nFederal Government, Water Managers\n0.0\nMore informative - fact piece\nNaN\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n6\n0\n0\n0\n4\n0\n0\n0\n0\n0\n\n\n20\n21\nUSGS1-50.docx\nMohave Valley Daily News (Bullhead City, Arizona)\nCoalition calls for moratorium on new Colorado...\nFalse\n28-Jul-21\n2021.0\n2021\nNaN\nNaN\n2021.0\nY\nY\nEntire Colorado River Basin\nNaN\n14, 15\nLaughlin, AZ\nNaN\nNaN\nAZ\n4\nUrban\nIntergovernmental issues: Water transfers\nCommittee chairwoman Brea Chiodini and committ...\nState Government, Federal Government\n-2.0\nNaN\nNaN\n0\n0\n1\n4\n0\n0\n0\n1\n0\n0\n2\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n22\n23\nUSGS1-50.docx\nAssociated Press State & Local\nCalifornia water agencies resolve Colorado Riv...\nFalse\n20-Sep-21\n2021.0\n21-Sep\nNaN\n9.0\n2021.0\nN\nN\nEntire Colorado River Basin\nNaN\n14, 15\nCA - Imperial Irrigation District\nNaN\nNaN\nCA\n6\nUrban\nInfrastructure issues\nTwo major California water agencies have settl...\nState Government, Water Managers\n3.0\nNaN\nNaN\n0\n0\n0\n8\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n33\n34\nUSGS1-50.docx\nColorado Daily (Boulder, Colorado)\nOpinion: Steve Pomerance: Climate change and B...\nFalse\n13-May-22\n2022.0\nongoing\nNaN\nNaN\n2022.0\nY\nY\nEntire Upper Colorado Basin\nNaN\n14\nBoulder, CO\nNaN\nNaN\nCO\n8\nUrban\nDrought\nDrought in the Colorado River Basin has negati...\nAll Water Users, Federal Government, State Gov...\n0.0\nFact piece\nNaN\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n40\n41\nUSGS1-50.docx\nPost Independent (Glenwood Springs, Colorado)\nGlenwood Springs receives $300,000 grant for w...\nFalse\n25-Aug-21\n2021.0\n2021\nNaN\nNaN\n2021.0\nN\nN\nColorado Headwaters\n140100\n14\nGlenwod Springs\nNaN\nNaN\nCO\n8\nUrban\nInfrastructure issues\nGlenwood Springs has been awarded a $300,000 g...\nState Government, Conservation District\n0.0\nFact piece; an announcement of a grant award\nNaN\n1\n0\n2\n4\n0\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n44\n45\nUSGS1-50.docx\nAg Journal (La Junta, Colorado)\nColorado River crisis could have huge impact o...\nFalse\n6-Dec-19\n2019.0\n2019\nNaN\nNaN\n2019.0\nN\nY\nEntire Colorado River Basin\nNaN\n14, 15\nThe Front Range, CO/WY\nNaN\nNaN\nCO; WY\n08; 56\nUrban\nDrought\nWater sufficient for more than 1 million homes...\nWater Users, Agriculture, State Government\n-1.0\nNaN\nNaN\n0\n0\n6\n6\n0\n0\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n47\n48\nUSGS1-50.docx\nAssociated Press State & Local\nThe Latest: Vegas-area water managers advance ...\nFalse\n16-Nov-18\n2018.0\n2018\nNaN\nNaN\n2018.0\nY\nN\nEntire Upper Colorado Basin\nNaN\n14\nLas Vegas, Flagstaff, AZ\nNaN\nNaN\nNV; AZ\n04; 32\nUrban\nIntergovernmental issues: Conservation\nLas Vegas-area water managers have become the ...\nWater Managers, State Government, Federal Gove...\n3.0\nNaN\nNaN\n0\n0\n0\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n55\n56\nUSGS101-150.docx\nThe Arizona Republic (Phoenix)\nWhy cities say they won't impose water restric...\nFalse\n8-May-22\n2022.0\n2022\nNaN\nNaN\n2022.0\nY\nY\nEntire Colorado River Basin\nNaN\n14, 15\nScottsdale, Tucson, Phoenix, AZ\nNaN\nNaN\nAZ\n4\nUrban\nIntergovernmental issues\nArizona's cities should consider imposing unpr...\nState Government, Local Government, All Water ...\n-1.0\nNaN\nNaN\n1\n0\n9\n10\n1\n0\n0\n1\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n68\n69\nUSGS101-150.docx\nThe Glendale Star (Arizona)\nDrought contingency plan coming to council\nFalse\n28-Mar-19\n2019.0\n3\nNaN\n3.0\n2019.0\nN\nN\nLower Gila-Agua Fria\n150701\n15\nGlendale\nNaN\nNaN\nAZ\n4\nUrban\nConservation\nNew city drought contingency plan to be heard ...\nLocal Government\n0.0\nInteraction is just within local government.\nNaN\n1\n0\n0\n12\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n83\n84\nUSGS101-150.docx\nMohave Valley Daily News (Bullhead City, Arizona)\nFree water available for areas of Needles with...\nFalse\n22-Sep-19\n2019.0\n9\nNaN\n9.0\n2019.0\nN\nN\nLower Colorado\n150301\n15\nNeedles, CA\nNaN\nNaN\nCA\n6\nUrban\nWater rights more generally\nNeedles, CA residents are the first to sign a ...\nFederal Government, Citizens\n4.0\nNegotiations and approval between BoR and citi...\nLower level of participation\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n99\n100\nUSGS101-150.docx\nThe Arizona Republic (Phoenix)\nReservoirs almost full after wet winter\nFalse\n6-Apr-20\n2020.0\n4\nNaN\n4.0\n2020.0\nN\nY\nSalt\n150601\n15\nPheonix, AZ\nNaN\nNaN\nAZ\n4\nUrban\nDrought\nAfter a couple of wet winters, runoff from rai...\nAll Water Users, Private Utility, Recreation\n0.0\nEvent has no major effects on stakeholder inte...\nNaN\n0\n0\n0\n8\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n2\n0\n0\n0\n0\n0\n\n\n120\n121\nUSGS151-200.docx\nAssociated Press State & Local\nColorado Editorial Roundup\nFalse\n26-Jun-19\n2019.0\n6\nNaN\n6.0\n2019.0\nY\nY\nSouth Platte\n101900\n10\nDenver, CO\nNaN\nNaN\nCO\n8\nUrban\nDrought\nThe event is an editorial suggesting that Denv...\nLocal Government, Environmentalists, Private C...\n-1.0\nScored -1 because while there is some talk of ...\nExclusionary public comment\n0\n0\n7\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n193\n194\nUSGS201-250.docx\nAssociated Press State & Local\nThe Latest: Irrigation district opposes draft ...\nFalse\n27-Mar-19\n2019.0\n3\nNaN\n3.0\n2019.0\nY\nY\nEntire Colorado River Basin\nNaN\n14, 15\nEntire Colorado River Basin\nNaN\nNaN\nNaN\nNaN\nUrban\nWater rights more generally\nA California irrigation district that has the ...\nState Government\n-2.0\nNaN\nNaN\n0\n0\n1\n8\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n194\n195\nUSGS201-250.docx\nBrush News Tribune (Colorado)\nWater shortage worsening along northwest Color...\nFalse\n18-Oct-21\n2021.0\n8\nNaN\n8.0\n2021.0\nN\nY\nColorado Headwaters\n140100\n14\nState of Colorado\nNaN\nNaN\nCO\n8\nUrban\nConservation\nFacing severe droughts along Colorado's Wester...\nState Government, Federal Government, All Wate...\n-1.0\nNaN\nNaN\n1\n0\n2\n2\n0\n0\n0\n0\n0\n0\n7\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n198\n199\nUSGS201-250.docx\nLa Junta Tribune-Democrat (Colorado)\nLower Arkansas Valley Water Conservancy Distri...\nFalse\n12-Dec-13\n2013.0\n12\nNaN\n12.0\n2013.0\nN\nN\nEntire Lower Colorado Basin\nNaN\n15\nLower Arkansas Valley Water Conservancy District\nNaN\nNaN\nCO\n8\nUrban\nIntergovernmental issues\nThe budget for Lower Arkansas Valley Water Con...\nConservancy District, State Government, Federa...\n0.0\nThe article is focused on the budgetary and wa...\nNaN\n0\n0\n1\n5\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n220\n221\nUSGS251-300.docx\nAssociated Press State & Local\nAustin water supply long-term plans appear to ...\nFalse\n5-Mar-15\n2015.0\n3\nNaN\n3.0\n2015.0\nNaN\nNaN\nNaN\nNaN\nNaN\nAustin, TX\nNaN\nNaN\nTX\n48\nUrban\nNaN\nA deal struck between Austin, TX and the Lower...\nCity Government, All Water Users\n1.0\nThis article actually deals with the CO River ...\nNaN\n0\n0\n3\n2\n0\n0\n0\n1\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n224\n225\nUSGS251-300.docx\nMohave Valley Daily News (Bullhead City, Arizona)\nWater supplies, drought, and the need to conserve\nFalse\n12-Jan-15\n2015.0\n1\nNaN\n1.0\n2015.0\nN\nY\nLower Colorado\n150301\n15\nNeedles, CA\nNaN\nNaN\nCA\n6\nUrban\nConservation\n2014 shows a water use reduction of 8 percent ...\nLocal Government, State Government, All Water ...\n1.0\nEvent is between city council and water author...\nNaN\n1\n0\n5\n6\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n225\n226\nUSGS251-300.docx\nRoswell Daily Record (New Mexico)\nMayor: Mistake made with marijuana farm\nFalse\n30-May-15\n2015.0\n5\nNaN\n5.0\n2015.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nUrban\nWater quality\nRoswell, NM mayor answers questions about Rosw...\nLocal Government, Irrigation Districts, Conser...\n-1.0\nEvent is outside of the CRB.\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n12\n0\n0\n0\n0\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "book/setup.html",
    "href": "book/setup.html",
    "title": "Setup",
    "section": "",
    "text": "All the course materials use the Python programming language and git for version control. To install or make sure you have these in your computer, follow the MEDS Software Installation Guide from 4. Check for git to 9. Install VS Code.\n\n\n\nTo install the libraries needed to execute the code in these notes you should create a conda environment using the environment.yml file in the notes repository.\nTo build the environment:\n\nDownload the environment.yml file in the notes repository. Place it in the directory where you will store the notebooks associated with these notes.\nUsing the terminal, navigate to the directory where the environment.yml file is.\nRun the following command to build the environment:\n\nconda env create -f environment.yml\n\nOnce the building finishes, run the following command to check the new environment was created:\n\nconda env list\nTo activate the environment:\n\nIn your terminal, ‚Ä¶ Finish\nIf you are using VSCode, you should be able open a Python notebok and select the new environment by accessing a drop-down list by clicking on the top right corner.\n\nAdd picture\n\n\n\nYou‚Äôre ready to start coding! The course starts with a Python review in the next section."
  },
  {
    "objectID": "book/setup.html#software-installation",
    "href": "book/setup.html#software-installation",
    "title": "Setup",
    "section": "",
    "text": "All the course materials use the Python programming language and git for version control. To install or make sure you have these in your computer, follow the MEDS Software Installation Guide from 4. Check for git to 9. Install VS Code."
  },
  {
    "objectID": "book/setup.html#python-environment",
    "href": "book/setup.html#python-environment",
    "title": "Setup",
    "section": "",
    "text": "To install the libraries needed to execute the code in these notes you should create a conda environment using the environment.yml file in the notes repository.\nTo build the environment:\n\nDownload the environment.yml file in the notes repository. Place it in the directory where you will store the notebooks associated with these notes.\nUsing the terminal, navigate to the directory where the environment.yml file is.\nRun the following command to build the environment:\n\nconda env create -f environment.yml\n\nOnce the building finishes, run the following command to check the new environment was created:\n\nconda env list\nTo activate the environment:\n\nIn your terminal, ‚Ä¶ Finish\nIf you are using VSCode, you should be able open a Python notebok and select the new environment by accessing a drop-down list by clicking on the top right corner.\n\nAdd picture"
  },
  {
    "objectID": "book/setup.html#next",
    "href": "book/setup.html#next",
    "title": "Setup",
    "section": "",
    "text": "You‚Äôre ready to start coding! The course starts with a Python review in the next section."
  },
  {
    "objectID": "book/appendices/comments-guidelines.html",
    "href": "book/appendices/comments-guidelines.html",
    "title": "Commenting code",
    "section": "",
    "text": "In this section, we‚Äôll explore how to write clear and helpful comments in your code. Good comments make your code easier to understand and maintain, for both you and others. By following a few guidelines, you can write comments that are professional, consistent, and aligned with best practices.\nAs you read through this, remember: Your comments will evolve hand-in-hand with your programming. Don‚Äôt get caught up on ‚Äúwriting the perfect comments‚Äù! Start with correctly formatting your comments and thinking about their content and move on from there.\n\n\n\nComment should start with a pound sign # followed by a single space, then the text.\nThe first word in the comment should be capitalized [1].\nAlways use proper spelling.\nPeriods at the end of short comments are optional, but you should be consistent across your code.\n\n\n\nüö´ Typos, inconsistent capitalization, spacing, and punctuation\n#calculate teh average temp from dataset.\naverage_temp = sum(temperatures) / len(temperatures)\n\n    ##      Apply the TEMPERATURE correction\ncorrected_temp = average_temp + correction_factor\n‚úÖ Comments follow all the basic standards\n# Calculate average temperature from dataset\naverage_temp = sum(temperatures) / len(temperatures)\n\n# Apply temperature correction\ncorrected_temp = average_temp + correction_factor\n\n\n\n\n\n\nAs stated in the Python PEP 8 [1] guide:\n\nComments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes!\n\nOutdated comments and comments that contradict the code can cause confusion and lead to bugs.\n\n\nüö´ Comment is outdated and contradicts the code\n# Convert temperature from Fahrenheit to Celsius\ndf['temp_f'] = df['temp_c'] * 9/5 + 32\n‚úÖ Comments must be consistent with the code\n# Convert temperature from Celsius to Fahrenheit\ndf['temp_f'] = df['temp_c'] * 9/5 + 32\n\n\n\n\nMake comments concise and easy to understand. Avoid long-winded explanations. If the code is self-explanatory (which may vary by audience) then minimal commenting is needed.\n\n\nüö´ Too long and redundant\n# In this part of the code, we are filtering the DataFrame 'df' to keep only \n# the rows where the value in the 'region_type' column is equal to 'wetland'. \n# This will give us data specifically for wetland regions.\nwetland_data = df[df['region_type'] == 'wetland']\n‚úÖ Concise and clear comments\n# Filter rows where the region is a wetland\nwetland_data = df[df['region_type'] == 'wetland']\n\n\n\n\n\n\nWant a longer explanation? Use a markdown cell!\n\n\n\nKeeping comments short does not mean there‚Äôs no place for in-depth, detailed explanations while learning programming. If you are using a Jupyter notebook (or another file format that supports combining markdown with code), use a markdown cell for longer explanations instead of adding them as comments to your code.\n\n\n\n\n\n\nComments should be professional and avoid jokes, personal remarks, or irrelevant information.\n\n\nüö´ Unprofessional comment with casual remarks\n# Time to crunch some numbers and save the planet! üåç\ntotal_emissions = df['emissions'].sum()\n‚úÖ Professional and relevant comment\n# Calculate the total carbon emissions for the region\ntotal_emissions = df['emissions'].sum()\n\n\n\n\nWhile long or redundant comments can clutter our code and decrease readability, under-commenting can make our code obscure and difficult to share with others (including our future selves!)\n\n\nüö´ No comments make it unclear what the code is doing\nyear = '2017'\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\ncollection = 'io-biodiversity'\n\nsearch = catalog.search(collections=[collection], \n                        bbox=bbox,\n                        datetime=year)\n‚úÖ Comments clarify code\n# Parameters for search in cloud catalog\nyear = '2017'\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]  # Phoenix bounding box\ncollection = 'io-biodiversity'  # Biodiversity Intactness data\n\nsearch = catalog.search(collections=[collection], \n                        bbox=bbox,\n                        datetime=year)\n\n\n\n\n\n\n\nIn-line comments are comments on the same line as the code. Use in-line comments sparingly and keep them short.\n\n\nüö´ In-line comments are overused and don‚Äôt follow regular spacing and capitalization\nyears = [2000, 2005, 2010, 2015, 2020]#list of years for x-axis\nco2_levels = [370, 380, 390, 400, 410]  #CO2 levels for y-axis\n\nplt.plot(years, co2_levels) # Plot years against CO2 levels\nplt.title('CO2 Levels Over Time')  # Add a title\nplt.xlabel('Year')                 # x-axis = Year\nplt.ylabel('CO2 Levels (ppm)')# y-axis = CO2 Levels (ppm)\nplt.grid(True) # Enable grid on the plot\nplt.axhline(y=400, color='r', linestyle='--', label='400 ppm Threshold')\nplt.show()     #display the plot\n‚úÖ In-line comments are sparingly used and focused\nyears = [2000, 2005, 2010, 2015, 2020]\nco2_levels = [370, 380, 390, 400, 410]\n\n# Plot to see trend in atmospheric CO2 concentrations\nplt.plot(years, co2_levels)\n\nplt.title('CO2 Levels Over Time')\nplt.xlabel('Year')\nplt.ylabel('CO2 Levels (ppm)')\n\nplt.grid(True)  # Show grid for better readability\nplt.axhline(y=400,  # Add a threshold line for 400 ppm\n            color='r', \n            linestyle='--', \n            label='400 ppm Threshold')  \nplt.show()\n\n\n\n\nFor more complex explanations, use block comments spanning multiple lines. Each line should start with a # and be aligned with the code it describes.\n\n\nüö´ Wordy block comment with inconsistent spacing\n# In this code I: \n    # calculate the avg temp from a list of temperatures and then adjust the result.\n    # We first sum the temperatures, divide by the number of entries,\n    # and finally add the correction factor to the calculated average.\n\ntemperatures = [20.5, 21.0, 19.8, 22.3]\naverage_temp = sum(temperatures) / len(temperatures)\ncorrected_temp = average_temp + 1.2\n‚úÖ Concise block comments focusing on the code purpose\n# Calculate the average temperature from a list of temperature readings.\n# Then, apply a correction factor to account for measurement adjustments.\n\ntemperatures = [20.5, 21.0, 19.8, 22.3]\naverage_temp = sum(temperatures) / len(temperatures)\ncorrected_temp = average_temp + 1.2\n\n\n\n\n\n\nAs you advance in your programming journey and code looks more familiar, you can take next steps to improve your code via comments. Take some time too to learn about coding style and best practices, this resource by the UCSB Code Carpentries can help you!\n\n\nWhen we are learning to code, it can be super useful to comment on ‚Äòwhat‚Äô each line of code does. That‚Äôs ok! Over time, as you become more comfortable with the syntax, try to focus your comments on ‚Äòwhy‚Äô certain choices were made or when something might not be immediately obvious to others. Use comments to explain why a piece of code exists, what it‚Äôs doing at a high level, or to describe a complex algorithm. Great comments add value to the code, going beyond describing what is clear from the function and variable names.\nYour comments will become more streamlined and naturally shift from technical to conceptual as your coding skills improve!\n\n\n‚ö†Ô∏è Comment restates in plain language what the code does\n# Assign the maximum value of the array to x\nx = find_max_value(array)  \n‚úÖ Comment explains the rationale behind the code\n# Find the largest value to normalize the data\nx = find_max_value(array)  \n\n\n\n\nIt‚Äôs ok to err on over-commenting when you are beginning your coding journey. As you advance, focus on not over-commenting obvious code, as this can clutter your code and reduce readability.\n\n\n‚ö†Ô∏è Redundant comments clutter the code\ntemperatures = [20.5, 21.0, 19.8, 22.3, 24.1]  # List of temperatures\n\n# Initialize total to 0\ntotal = 0  \n\n# Loop through each temperature in the list\nfor temp in temperatures:\n    total += temp  # Add the current temperature to the total\n\n# Calculate the average by dividing the total by the number of temperatures\naverage_temp = total / len(temperatures)\n\nprint(average_temp)  # Print the average temperature\n‚úÖ Comments focus on important information\ntemperatures = [20.5, 21.0, 19.8, 22.3, 24.1]\n\n# Calculate the total and average temperature\ntotal = 0\nfor temp in temperatures:\n    total += temp\n\naverage_temp = total / len(temperatures)\nprint(average_temp)\n\n\n\n\nThe phrase ‚Äúcode smells‚Äù refers to symptoms in our code that may indicate deeper problems with its design or structure. Sometimes comments are used to explain overly-complicated, instead of making the code as self-explanatory as possible. If that happens, then comments are being used as deodorant for smelly code [2]. Avoid comments as deodorant and, instead, work on making your code simple and understandable. Of course, you will learn better techniques to improve your code with time!\n\n\n‚ö†Ô∏è Comments compensate for obscure variable names and overly-complicated code\n# List of pollutant concentrations (in ppm)\na = [50, 120, 85, 30, 95, 110, 70]  # 'a' stands for air quality measurements\n\n# Filter out pollutant readings that are greater than 100 ppm (considered outliers)\nb = []  # 'b' stands for valid pollutant readings\nfor x in a:  # 'x' is the individual pollutant reading\n    if x &lt;= 100: \n        b.append(x)  # Add valid readings to 'b'\n\nprint(b)\n‚úÖ Self-explanatory code needs less comments\n# List of pollutant concentrations (in ppm)\npollutant_readings = [50, 120, 85, 30, 95, 110, 70]\n\n# Filter out pollutant readings that are greater than 100 ppm (considered outliers)\nvalid_readings = [reading for reading in pollutant_readings if reading &lt;= 100]\n\nprint(valid_readings)\n\n\n\n\n\n\nKeep it clean and consistent: Consistently use proper capitalization, spacing, spelling, and indentation.\nKeep comments up-to-date: Make sure your comments always match what the code is doing.\nBe clear and concise: Write concise comments. Keep them focused, and avoid adding personal notes or jokes. When possible, write comments that explain why your code is doing something, not just how.\nWrite clean code first: Focus on making your code clear and easy to understand. Use comments to make things even clearer, not to explain complicated or messy code.\nCommenting is a learning process! Don‚Äôt stress about writing ‚Äúperfect comments‚Äù. Focus on the basics, and let your commenting style evolve naturally as you improve your coding skills!\n\n\n\n\nHappy Commenting image created with Dall-E 4.",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/appendices/comments-guidelines.html#the-basics",
    "href": "book/appendices/comments-guidelines.html#the-basics",
    "title": "Commenting code",
    "section": "",
    "text": "Comment should start with a pound sign # followed by a single space, then the text.\nThe first word in the comment should be capitalized [1].\nAlways use proper spelling.\nPeriods at the end of short comments are optional, but you should be consistent across your code.\n\n\n\nüö´ Typos, inconsistent capitalization, spacing, and punctuation\n#calculate teh average temp from dataset.\naverage_temp = sum(temperatures) / len(temperatures)\n\n    ##      Apply the TEMPERATURE correction\ncorrected_temp = average_temp + correction_factor\n‚úÖ Comments follow all the basic standards\n# Calculate average temperature from dataset\naverage_temp = sum(temperatures) / len(temperatures)\n\n# Apply temperature correction\ncorrected_temp = average_temp + correction_factor",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/appendices/comments-guidelines.html#content",
    "href": "book/appendices/comments-guidelines.html#content",
    "title": "Commenting code",
    "section": "",
    "text": "As stated in the Python PEP 8 [1] guide:\n\nComments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes!\n\nOutdated comments and comments that contradict the code can cause confusion and lead to bugs.\n\n\nüö´ Comment is outdated and contradicts the code\n# Convert temperature from Fahrenheit to Celsius\ndf['temp_f'] = df['temp_c'] * 9/5 + 32\n‚úÖ Comments must be consistent with the code\n# Convert temperature from Celsius to Fahrenheit\ndf['temp_f'] = df['temp_c'] * 9/5 + 32\n\n\n\n\nMake comments concise and easy to understand. Avoid long-winded explanations. If the code is self-explanatory (which may vary by audience) then minimal commenting is needed.\n\n\nüö´ Too long and redundant\n# In this part of the code, we are filtering the DataFrame 'df' to keep only \n# the rows where the value in the 'region_type' column is equal to 'wetland'. \n# This will give us data specifically for wetland regions.\nwetland_data = df[df['region_type'] == 'wetland']\n‚úÖ Concise and clear comments\n# Filter rows where the region is a wetland\nwetland_data = df[df['region_type'] == 'wetland']\n\n\n\n\n\n\nWant a longer explanation? Use a markdown cell!\n\n\n\nKeeping comments short does not mean there‚Äôs no place for in-depth, detailed explanations while learning programming. If you are using a Jupyter notebook (or another file format that supports combining markdown with code), use a markdown cell for longer explanations instead of adding them as comments to your code.\n\n\n\n\n\n\nComments should be professional and avoid jokes, personal remarks, or irrelevant information.\n\n\nüö´ Unprofessional comment with casual remarks\n# Time to crunch some numbers and save the planet! üåç\ntotal_emissions = df['emissions'].sum()\n‚úÖ Professional and relevant comment\n# Calculate the total carbon emissions for the region\ntotal_emissions = df['emissions'].sum()\n\n\n\n\nWhile long or redundant comments can clutter our code and decrease readability, under-commenting can make our code obscure and difficult to share with others (including our future selves!)\n\n\nüö´ No comments make it unclear what the code is doing\nyear = '2017'\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\ncollection = 'io-biodiversity'\n\nsearch = catalog.search(collections=[collection], \n                        bbox=bbox,\n                        datetime=year)\n‚úÖ Comments clarify code\n# Parameters for search in cloud catalog\nyear = '2017'\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]  # Phoenix bounding box\ncollection = 'io-biodiversity'  # Biodiversity Intactness data\n\nsearch = catalog.search(collections=[collection], \n                        bbox=bbox,\n                        datetime=year)",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/appendices/comments-guidelines.html#special-types-of-comments",
    "href": "book/appendices/comments-guidelines.html#special-types-of-comments",
    "title": "Commenting code",
    "section": "",
    "text": "In-line comments are comments on the same line as the code. Use in-line comments sparingly and keep them short.\n\n\nüö´ In-line comments are overused and don‚Äôt follow regular spacing and capitalization\nyears = [2000, 2005, 2010, 2015, 2020]#list of years for x-axis\nco2_levels = [370, 380, 390, 400, 410]  #CO2 levels for y-axis\n\nplt.plot(years, co2_levels) # Plot years against CO2 levels\nplt.title('CO2 Levels Over Time')  # Add a title\nplt.xlabel('Year')                 # x-axis = Year\nplt.ylabel('CO2 Levels (ppm)')# y-axis = CO2 Levels (ppm)\nplt.grid(True) # Enable grid on the plot\nplt.axhline(y=400, color='r', linestyle='--', label='400 ppm Threshold')\nplt.show()     #display the plot\n‚úÖ In-line comments are sparingly used and focused\nyears = [2000, 2005, 2010, 2015, 2020]\nco2_levels = [370, 380, 390, 400, 410]\n\n# Plot to see trend in atmospheric CO2 concentrations\nplt.plot(years, co2_levels)\n\nplt.title('CO2 Levels Over Time')\nplt.xlabel('Year')\nplt.ylabel('CO2 Levels (ppm)')\n\nplt.grid(True)  # Show grid for better readability\nplt.axhline(y=400,  # Add a threshold line for 400 ppm\n            color='r', \n            linestyle='--', \n            label='400 ppm Threshold')  \nplt.show()\n\n\n\n\nFor more complex explanations, use block comments spanning multiple lines. Each line should start with a # and be aligned with the code it describes.\n\n\nüö´ Wordy block comment with inconsistent spacing\n# In this code I: \n    # calculate the avg temp from a list of temperatures and then adjust the result.\n    # We first sum the temperatures, divide by the number of entries,\n    # and finally add the correction factor to the calculated average.\n\ntemperatures = [20.5, 21.0, 19.8, 22.3]\naverage_temp = sum(temperatures) / len(temperatures)\ncorrected_temp = average_temp + 1.2\n‚úÖ Concise block comments focusing on the code purpose\n# Calculate the average temperature from a list of temperature readings.\n# Then, apply a correction factor to account for measurement adjustments.\n\ntemperatures = [20.5, 21.0, 19.8, 22.3]\naverage_temp = sum(temperatures) / len(temperatures)\ncorrected_temp = average_temp + 1.2",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/appendices/comments-guidelines.html#next-level",
    "href": "book/appendices/comments-guidelines.html#next-level",
    "title": "Commenting code",
    "section": "",
    "text": "As you advance in your programming journey and code looks more familiar, you can take next steps to improve your code via comments. Take some time too to learn about coding style and best practices, this resource by the UCSB Code Carpentries can help you!\n\n\nWhen we are learning to code, it can be super useful to comment on ‚Äòwhat‚Äô each line of code does. That‚Äôs ok! Over time, as you become more comfortable with the syntax, try to focus your comments on ‚Äòwhy‚Äô certain choices were made or when something might not be immediately obvious to others. Use comments to explain why a piece of code exists, what it‚Äôs doing at a high level, or to describe a complex algorithm. Great comments add value to the code, going beyond describing what is clear from the function and variable names.\nYour comments will become more streamlined and naturally shift from technical to conceptual as your coding skills improve!\n\n\n‚ö†Ô∏è Comment restates in plain language what the code does\n# Assign the maximum value of the array to x\nx = find_max_value(array)  \n‚úÖ Comment explains the rationale behind the code\n# Find the largest value to normalize the data\nx = find_max_value(array)  \n\n\n\n\nIt‚Äôs ok to err on over-commenting when you are beginning your coding journey. As you advance, focus on not over-commenting obvious code, as this can clutter your code and reduce readability.\n\n\n‚ö†Ô∏è Redundant comments clutter the code\ntemperatures = [20.5, 21.0, 19.8, 22.3, 24.1]  # List of temperatures\n\n# Initialize total to 0\ntotal = 0  \n\n# Loop through each temperature in the list\nfor temp in temperatures:\n    total += temp  # Add the current temperature to the total\n\n# Calculate the average by dividing the total by the number of temperatures\naverage_temp = total / len(temperatures)\n\nprint(average_temp)  # Print the average temperature\n‚úÖ Comments focus on important information\ntemperatures = [20.5, 21.0, 19.8, 22.3, 24.1]\n\n# Calculate the total and average temperature\ntotal = 0\nfor temp in temperatures:\n    total += temp\n\naverage_temp = total / len(temperatures)\nprint(average_temp)\n\n\n\n\nThe phrase ‚Äúcode smells‚Äù refers to symptoms in our code that may indicate deeper problems with its design or structure. Sometimes comments are used to explain overly-complicated, instead of making the code as self-explanatory as possible. If that happens, then comments are being used as deodorant for smelly code [2]. Avoid comments as deodorant and, instead, work on making your code simple and understandable. Of course, you will learn better techniques to improve your code with time!\n\n\n‚ö†Ô∏è Comments compensate for obscure variable names and overly-complicated code\n# List of pollutant concentrations (in ppm)\na = [50, 120, 85, 30, 95, 110, 70]  # 'a' stands for air quality measurements\n\n# Filter out pollutant readings that are greater than 100 ppm (considered outliers)\nb = []  # 'b' stands for valid pollutant readings\nfor x in a:  # 'x' is the individual pollutant reading\n    if x &lt;= 100: \n        b.append(x)  # Add valid readings to 'b'\n\nprint(b)\n‚úÖ Self-explanatory code needs less comments\n# List of pollutant concentrations (in ppm)\npollutant_readings = [50, 120, 85, 30, 95, 110, 70]\n\n# Filter out pollutant readings that are greater than 100 ppm (considered outliers)\nvalid_readings = [reading for reading in pollutant_readings if reading &lt;= 100]\n\nprint(valid_readings)",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/appendices/comments-guidelines.html#takeaways",
    "href": "book/appendices/comments-guidelines.html#takeaways",
    "title": "Commenting code",
    "section": "",
    "text": "Keep it clean and consistent: Consistently use proper capitalization, spacing, spelling, and indentation.\nKeep comments up-to-date: Make sure your comments always match what the code is doing.\nBe clear and concise: Write concise comments. Keep them focused, and avoid adding personal notes or jokes. When possible, write comments that explain why your code is doing something, not just how.\nWrite clean code first: Focus on making your code clear and easy to understand. Use comments to make things even clearer, not to explain complicated or messy code.\nCommenting is a learning process! Don‚Äôt stress about writing ‚Äúperfect comments‚Äù. Focus on the basics, and let your commenting style evolve naturally as you improve your coding skills!\n\n\n\n\nHappy Commenting image created with Dall-E 4.",
    "crumbs": [
      "notes",
      "Appendices",
      "Commenting code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html",
    "title": "14 rioxarray",
    "section": "",
    "text": "In this lesson we will introduce rioxarray, a Python extension for xarray to manipulate xarray.DataArrays as rasters. The name rioxarray stands for raster input/output + xarray.\nWe will use the rioxarray‚Äôs rio accessor to obtain raster information from an xarray.DataArray and do some raster manipulations (calculate NDVI).",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#about-the-data",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#about-the-data",
    "title": "14 rioxarray",
    "section": "About the data",
    "text": "About the data\nThe raster files we will use today come from the US National Agriculture Imagery Program (NAIP). NAIP images are are high-resolution aerial images with four spectral bands: red (R), green (G), blue (B) and near-infrared (NIR). The raster‚Äôs we‚Äôll use today are from 2020.\nThe data used in this lesson was pre-processing from a complete NAIP scene to separate the RGB bands from the NIR band and reduce the spatial extent. The data was accessed through Microsoft‚Äôs Planetary Computer NAIP data repository.",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#import-a-tif-file",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#import-a-tif-file",
    "title": "14 rioxarray",
    "section": "Import a TIF file",
    "text": "Import a TIF file\nLet‚Äôs start by loading the libraries we will use:\n\nimport os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport geopandas as gpd\n\nimport rioxarray as rioxr\n\nThere are multiple ways of opening a TIF file using xarray or rioxarray. Using the rioxarray.open_rasterio() function to open the TIF file is a simple way to import the raster file as an xarray.DataArray and make sure all our geospatial data gets loaded correctly:\n\n# Import NIR TIF file\nfp = os.path.join('data','NAIP_SB_nir.tif')\nnir = rioxr.open_rasterio(fp)\nnir\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 3208, x: 2419)&gt;\n[7760152 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1\n  * x            (x) float64 2.512e+05 2.512e+05 ... 2.527e+05 2.527e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.811e+06 3.811e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 1y: 3208x: 2419...[7760152 values with dtype=uint8]Coordinates: (4)band(band)int641array([1])x(x)float642.512e+05 2.512e+05 ... 2.527e+05array([251219.1, 251219.7, 251220.3, ..., 252668.7, 252669.3, 252669.9])y(y)float643.813e+06 3.813e+06 ... 3.811e+06array([3812951.7, 3812951.1, 3812950.5, ..., 3811028.7, 3811028.1, 3811027.5])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :251218.8 0.6000000000000072 0.0 3812952.0 0.0 -0.600000000000058array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([251219.09999999998, 251219.69999999998,           251220.3,\n       251220.89999999997, 251221.49999999997, 251222.09999999998,\n       251222.69999999998,           251223.3, 251223.89999999997,\n       251224.49999999997,\n       ...\n                 252664.5,           252665.1, 252665.69999999998,\n                 252666.3,           252666.9,           252667.5,\n                 252668.1, 252668.69999999998,           252669.3,\n                 252669.9],\n      dtype='float64', name='x', length=2419))yPandasIndexPandasIndex(Index([         3812951.7,          3812951.1,          3812950.5,\n       3812949.9000000004, 3812949.3000000003,          3812948.7,\n                3812948.1,          3812947.5, 3812946.9000000004,\n       3812946.3000000003,\n       ...\n                3811032.9,          3811032.3,          3811031.7,\n                3811031.1,          3811030.5,          3811029.9,\n                3811029.3,          3811028.7,          3811028.1,\n                3811027.5],\n      dtype='float64', name='y', length=3208))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\nNotice we see all the components of an xarray.DataArray: its dimensions (band, y, x), the coordiantes for each dimension, and some attributes. We can also directly access some of these attribues:\n\nprint('Shape: ', nir.shape)\nprint('Data type: ', nir.dtype, '\\n')\n\nShape:  (1, 3208, 2419)\nData type:  uint8 \n\n\n\nUsing the .values attribute we can retrieve the underlying numpy.array holding the values of the variable:\n\nprint(type(nir.values))\nnir.values\n\n&lt;class 'numpy.ndarray'&gt;\n\n\narray([[[167, 164, 161, ..., 147, 152, 151],\n        [170, 170, 168, ..., 151, 149, 154],\n        [176, 177, 177, ..., 151, 151, 151],\n        ...,\n        [ 94,  88, 101, ...,  83,  88,  79],\n        [108,  95, 103, ...,  92,  91,  75],\n        [ 94,  90, 104, ...,  87,  88,  82]]], dtype=uint8)\n\n\nWe can also plot our data:\n\nnir.plot()\n\n\n\n\n\n\n\n\nNotice the coordinates on the x and y axes.\nThis map shows the light captured in the near-infrared spectrum by a sensor on a plane. Can you guess where this? If you guessed Santa Barbara downtown, you guessed right!",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#drop-a-dimension",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#drop-a-dimension",
    "title": "14 rioxarray",
    "section": "Drop a dimension",
    "text": "Drop a dimension\nNotice that our raster has an unnecessary extra dimension: band.\n\nprint(\"Sizes of dimensions:\", dict(nir.sizes))\n\nSizes of dimensions: {'band': 1, 'y': 3208, 'x': 2419}\n\n\nThis is making this xarray.DataArray three-dimensional when it is not needed. We can ‚Äúsqueeze this dimension‚Äù of length 1 by:\n\nusing the squeeze() method. If we don‚Äôt pass any parameters, then squeeze() gets rid of all dimensions with length one, and then\ngetting rid of the associated coordinates for this dimension. We can do this using the xarray.DataArray drop() method and specifying the name of the coordinates we want to remove, in this case ‚Äòband‚Äô.\n\nLet‚Äôs do this:\n\n# Original dimensions and coordinates\nprint(nir.dims, nir.coords,'\\n')\n\n# Remove length 1 dimension (band)\nnir = nir.squeeze()\nprint(nir.dims, nir.coords,'\\n')\n\n# Remove coordinates associated to band\nnir = nir.drop('band')\nprint(nir.dims, nir.coords)\n\n('band', 'y', 'x') Coordinates:\n  * band         (band) int64 1\n  * x            (x) float64 2.512e+05 2.512e+05 ... 2.527e+05 2.527e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.811e+06 3.811e+06\n    spatial_ref  int64 0 \n\n('y', 'x') Coordinates:\n    band         int64 1\n  * x            (x) float64 2.512e+05 2.512e+05 ... 2.527e+05 2.527e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.811e+06 3.811e+06\n    spatial_ref  int64 0 \n\n('y', 'x') Coordinates:\n  * x            (x) float64 2.512e+05 2.512e+05 ... 2.527e+05 2.527e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.811e+06 3.811e+06\n    spatial_ref  int64 0",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#rio-accessor",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#rio-accessor",
    "title": "14 rioxarray",
    "section": "rio accessor",
    "text": "rio accessor\nRemember an accessor in Python let‚Äôs us access a different set of properties of an object. We have previously used accesors like .str and .dt in pandas to work with strings and dates. In this lesson, we will use the .rio accessor for an xarray.DataArray to access its raster properties. For example, we can access the number of bands, height, width, spatial bounding box, and CRS:\n\n# Examine raster attributes using rio accessor\nprint('Number of bands: ', nir.rio.count)\nprint('Height: ', nir.rio.height)\nprint('Width: ', nir.rio.width, '\\n')\n\nprint('Spatial bounding box: ')\nprint(nir.rio.bounds(), '\\n')\n\nprint('CRS: ', nir.rio.crs)\n\nNumber of bands:  1\nHeight:  3208\nWidth:  2419 \n\nSpatial bounding box: \n(251218.8, 3811027.2, 252670.19999999998, 3812952.0) \n\nCRS:  EPSG:26911",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#multi-band-raster",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#multi-band-raster",
    "title": "14 rioxarray",
    "section": "Multi-band raster",
    "text": "Multi-band raster\nLet‚Äôs now import the RGB raster:\n\n# Import RGB raster\nfp = os.path.join('data','NAIP_SB_rgb.tif')\nrgb = rioxr.open_rasterio(fp)\nrgb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 3, y: 3208, x: 2419)&gt;\n[23280456 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3\n  * x            (x) float64 2.512e+05 2.512e+05 ... 2.527e+05 2.527e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.811e+06 3.811e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 3y: 3208x: 2419...[23280456 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3array([1, 2, 3])x(x)float642.512e+05 2.512e+05 ... 2.527e+05array([251219.1, 251219.7, 251220.3, ..., 252668.7, 252669.3, 252669.9])y(y)float643.813e+06 3.813e+06 ... 3.811e+06array([3812951.7, 3812951.1, 3812950.5, ..., 3811028.7, 3811028.1, 3811027.5])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :251218.8 0.6000000000000072 0.0 3812952.0 0.0 -0.600000000000058array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([251219.09999999998, 251219.69999999998,           251220.3,\n       251220.89999999997, 251221.49999999997, 251222.09999999998,\n       251222.69999999998,           251223.3, 251223.89999999997,\n       251224.49999999997,\n       ...\n                 252664.5,           252665.1, 252665.69999999998,\n                 252666.3,           252666.9,           252667.5,\n                 252668.1, 252668.69999999998,           252669.3,\n                 252669.9],\n      dtype='float64', name='x', length=2419))yPandasIndexPandasIndex(Index([         3812951.7,          3812951.1,          3812950.5,\n       3812949.9000000004, 3812949.3000000003,          3812948.7,\n                3812948.1,          3812947.5, 3812946.9000000004,\n       3812946.3000000003,\n       ...\n                3811032.9,          3811032.3,          3811031.7,\n                3811031.1,          3811030.5,          3811029.9,\n                3811029.3,          3811028.7,          3811028.1,\n                3811027.5],\n      dtype='float64', name='y', length=3208))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\nNotice this raster has three bands, instead of one. This makes sense because we know these bands correspond to the red, green and blue bands of the image.\n\n\n\n\n\n\nCheck-in\n\n\n\nObtain the following information about the RGB raster: shape, number of bands, data type of its values and CRS.\n\n\n\nFinally, let‚Äôs plot this raster. Since it has three bands, we can plot it as an image using the .plot.imshow() method, which will interpret the three bands of the object as RGB.\n\n# Plot three bands as RGB image\nrgb_aspect_ratio = rgb.rio.width / rgb.rio.height  # Raster's aspect ratio\nrgb.plot.imshow(size=6,  # Plot's height in inches\n                aspect=rgb_aspect_ratio  # Ratio of width/height\n                )",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#clip-a-raster",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#clip-a-raster",
    "title": "14 rioxarray",
    "section": "Clip a raster",
    "text": "Clip a raster\nOur area of interest (AOI) for this lesson is a smaller region that includes only a few blocks around the NCEAS building. This is outlined in a GeoJSON file:\n\nfp = os.path.join('data', 'SB_aoi.geojson')\naoi = gpd.read_file(fp)\naoi.plot()\n\n\n\n\n\n\n\n\nRemember: if two geospatial sets will interact they need to be in the same CRS. In our case, the AOI geopandas.GeoDataFrame does not have the same CRS as the rasters:\n\n# Examine CRss\nprint('aoi CRS: ', aoi.crs)\nprint('nir CRS: ', nir.rio.crs)\nprint('rgb CRS: ', rgb.rio.crs)\n\naoi CRS:  EPSG:4326\nnir CRS:  EPSG:26911\nrgb CRS:  EPSG:26911\n\n\nSo let‚Äôs reproject:\n\n# Reproject AOI to RGB CRS\naoi = aoi.to_crs(rgb.rio.crs)\nprint('Matched CRS?',  aoi.crs == rgb.rio.crs)\n\nMatched CRS? True\n\n\nAnd plot them together:\n\n# Plot of RGB raster with AOI overlay\nfig, ax = plt.subplots(figsize=(6, 6 * rgb_aspect_ratio))  # Directly set size and aspect\nrgb.plot.imshow(ax=ax)\naoi.plot(ax=ax, alpha=0.6)\nplt.show()\n\n\n\n\n\n\n\n\nTo clip the raster using the AOI polygon we use the .rio.clip_box() method:\n\n# Clip rasters to AOI\nrgb_small = rgb.rio.clip_box(*aoi.total_bounds)\nnir_small = nir.rio.clip_box(*aoi.total_bounds)\n\nNotice a few things:\n\nwe had to use the .rio accessor to access the clip_box() method\nsimilarly to the shapely.box() function we‚Äôve used previously, .rio.clip_box() usual parameters are minx, miny, maxx, maxy. We are using the * asterisk as an unpacking operator to get these from the list aoi.total_bounds.\n\nLet‚Äôs check our clipped data:\n\n# Examine clipped data \nprint('Original shape: ', nir.shape)\nprint('Clipped shape: ', nir_small.shape)\n\nnir_small.plot()\n\nOriginal shape:  (3208, 2419)\nClipped shape:  (1710, 1995)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nExamine the same updates for the RGB data.",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#raster-math",
    "href": "book/chapters/lesson-15-rioxarray/lesson-15-rioxarray.html#raster-math",
    "title": "14 rioxarray",
    "section": "Raster math",
    "text": "Raster math\nWe often want perform calculations on rasters to create a new output raster, commonly known as ‚Äúraster math‚Äù. \nIn our case, we are interested in computing the Normalized Difference Vegetation Index (NDVI) over our AOI. The NDVI is an index commonly used to check if an area has live green vegetation or not.\nAccording to the Earth Observing System\n\nThe results of the NDVI calculation range from -1 to 1. Negative values correspond to areas with water surfaces, manmade structures, rocks, clouds, snow; bare soil usually falls within 0.1-0.2 range; and plants will always have positive values between 0.2 and 1. Healthy, dense vegetation canopy should be above 0.5, and sparse vegetation will most likely fall within 0.2 to 0.5.\n\nThe NDVI is calculated using the NIR and red bands. The formula is\n\\(NDVI = \\frac{NIR - Red}{NIR + Red}.\\)\nFirst, let‚Äôs select the red band:\n\n# Select dimension by name and coordinate by label\nred = rgb_small.sel(band=1)\nred\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 1710, x: 1995)&gt;\n[3411450 values with dtype=uint8]\nCoordinates:\n    band         int64 1\n  * x            (x) float64 2.513e+05 2.513e+05 ... 2.525e+05 2.525e+05\n  * y            (y) float64 3.813e+06 3.813e+06 ... 3.812e+06 3.812e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayy: 1710x: 1995...[3411450 values with dtype=uint8]Coordinates: (4)band()int641array(1)x(x)float642.513e+05 2.513e+05 ... 2.525e+05axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([251294.1, 251294.7, 251295.3, ..., 252489.3, 252489.9, 252490.5])y(y)float643.813e+06 3.813e+06 ... 3.812e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([3812760.3, 3812759.7, 3812759.1, ..., 3811736.1, 3811735.5, 3811734.9])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :251293.8 0.6000000000000116 0.0 3812760.6 0.0 -0.600000000000218array(0)Indexes: (2)xPandasIndexPandasIndex(Index([251294.09999999998, 251294.69999999998,           251295.3,\n       251295.89999999997, 251296.49999999997, 251297.09999999998,\n       251297.69999999998,           251298.3, 251298.89999999997,\n       251299.49999999997,\n       ...\n                 252485.1, 252485.69999999998,           252486.3,\n                 252486.9,           252487.5,           252488.1,\n       252488.69999999998,           252489.3,           252489.9,\n                 252490.5],\n      dtype='float64', name='x', length=1995))yPandasIndexPandasIndex(Index([3812760.3000000003,          3812759.7,          3812759.1,\n                3812758.5, 3812757.9000000004, 3812757.3000000003,\n                3812756.7,          3812756.1,          3812755.5,\n       3812754.9000000004,\n       ...\n       3811740.3000000003,          3811739.7,          3811739.1,\n                3811738.5,          3811737.9, 3811737.3000000003,\n                3811736.7,          3811736.1,          3811735.5,\n                3811734.9],\n      dtype='float64', name='y', length=1710))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\nWe can perform raster calculations using the same arithmetic we use for numpy.arrays (because, underneath it all, that‚Äôs what they are). So our NDVI calculation is as follows:\n\nndvi = (nir - red)/(nir + red)\nndvi.plot()\n\n\n\n\n\n\n\n\nDo these results look as expected?\n\nData type issues\nThe uint8 (8-bit unsigned integer) is a very small data type that only holds integers from 0 up to 255. In particular, calculations don‚Äôt return what what we are used to when working with intgers (they‚Äôre done module 256):\n\nnp.uint8(150) + np.uint8(150)\n\n/var/folders/gm/chd1kps96_g7xdxyfw150wm80000gp/T/ipykernel_2983/1890984988.py:1: RuntimeWarning: overflow encountered in scalar add\n  np.uint8(150) + np.uint8(150)\n\n\n44\n\n\nIn the NDVI formula we have to add NIR + Red. If both NIR and Red are very close to 255, when we add them, the calculation overflows the uint8 data type and we don‚Äôt get the expected results.\n\n\n\n\n\n\nAvoid silent failures: ALWAYS verify your results!\n\n\n\nNotice that when we performed the NDVI calculation we did not get any warning, although we were overflowing the computation at every cell of our array. This is can be an example of what is referred as silent failure in programming, where we don‚Äôt get any warnings about the errors or unexpected behavior in our computation. That‚Äôs why it‚Äôs so important to double-check our results!\n\n\n\n\nUpdating data types\nTo be able to perform the calculation successfully, we will need to udpate the data type of our rasters into int16, which will be big enough to hold all the numbers that appear in the calculations:\n\n# Update data type to int16 to perform NDVI calculation\nred16 = red.astype('int16')\nnir16 = nir_small.astype('int16')\n\nprint('RED: original dtype:', rgb_small.dtype, '.... converted dtype:', red16.dtype)\nprint('NIR: original dtype:', nir.dtype, '.... converted dtype:', nir16.dtype)\n\n# Calculate NDVI\nndvi = (nir16 - red16)/(nir16+red16)\n\n# Plot\nfig, ax = plt.subplots()  # Adjust figure size\nndvi.plot(\n    ax=ax,\n    cmap=\"RdYlGn\",  # Colormap for NDVI\n    vmin=-1,  # Minimum value\n    vmax=1,   # Maximum value\n    cbar_kwargs={\"label\": \"NDVI\"}  # Label for color bar\n)\nax.set_title(\"Normalized Difference Vegetation Index\\nnear Santa Barbara Courthouse\")  # Add title\n\n# Remove axes ticks\nax.set_xticks([])  \nax.set_yticks([])  \n\n# Remove axes labels\nax.set_xlabel(\"\")  \nax.set_ylabel(\"\")  \n\nplt.show()\n\nRED: original dtype: uint8 .... converted dtype: int16\nNIR: original dtype: uint8 .... converted dtype: int16\n\n\n\n\n\n\n\n\n\nRemember that plants will always have positive NDVI values between 0.2 and 1. Can you spot the Santa Barbara Courthouse?",
    "crumbs": [
      "notes",
      "Raster data",
      "14 `rioxarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-8-crs.html",
    "href": "book/chapters/lesson-8-crs.html",
    "title": "7 Coordinate reference systems",
    "section": "",
    "text": "In this section we review what is a coordinate reference system (CRS). The materials here are meant to act as a refresher of the lesson on coordinate reference systems in week 2 of the EDS 223 - Geospatial Analysis & Remote Sensing MEDS course.\n\n\n\nSince the Earth does not have lines and numbers etched on it, us humans need to create a system to locate places on its surface. A way to solve this is to create a coordinate reference system (CRS). A CRS is, at its core, a way to represent places on the Earth as coordinates.\nTo understand what are the components of a CRS it can be useful to think of the process we would undergo to match places on the Earth to coordinates that represent them.\n\n\nThink of the Earth. Our planet is not a perfect sphere. Besides its rugged surface with high mountains and deep ocean trenches, the shape of the Earth is not round. Due to the Earth‚Äôs rotation, the planet is slightly wider at the Equator. Thus, a sphere is not the best way to model the shape of the Earth. Instead, we use an ellipsoid. Think of an ellipsoid as a sphere that has been flattened a bit, thus making it wider across one axis. This is the first step for creating a CRS: picking an ellipsoid, a.k.a picking a shape for the Earth. The ellipsoid used to represent the Earth‚Äôs shape has changed across time and it may also change depending on the application.\n\n\n\n\nThe ellipsoid is an abstract mathematical object on which we can locate points on it by using angles. The coordinate system on the ellipsoid is (angles from \\(x\\), angles from \\(y\\)).\n\n\n\nLatitude and longtide as angular coordinates on the ellipsoid. Image source: Coordinate systems and map projections - University of Twente\n\n\nThe next step to create a CRS is thus to make a decision on how to align the ellipsoid so that it‚Äôs surface corresponds to actual places on the Earth. We could think, for example, of:\n\nhow to place the ellipsoid‚Äôs center relative to Earth‚Äôs mass center (is it the same or is it off?) or\nhow to align the ellipsoid‚Äôs axes with the Earth (which meridian will be our prime meridian?).\n\nGenerally speaking, a geodetic datum, or just a datum, is how we are aligning our abstract ellipsoid to match the Earth‚Äôs surface.\n\n\n\nRegional datums to optimize location accuracy. Image source: GPS for Land Surveyors\n\n\n\n\n\n\n\n\nDatums may change across time and applications\n\n\n\nGeographers and cartographers have created and used many datums across time and applications. Sometimes datum refers both to a choice of ellipsoid and how to align it to the Earth. More importantly, different datums are used to increase the accuracy of representing different regions of Earth. At the GIS wiki you can see a list of names of different datums optimized for different regions.\n\n\n\n\n\nAt this point, we have successfully made a correspondence between the Earth‚Äôs surface of and our ellipsoid. This means we can now use the latitude,longitude (lat/lon) coordinates of the ellipsoid to locate any point on the Earth‚Äôs surface. This is called a geographic CRS. Geographic coordinate reference systems use degrees of latitude and longitude to locate points on the Earth, still thinking of it as a 3D object.\n\n\n\nWe use a geographic CRS to create angular coordiantes on the Earth (latitude and longitude) that allow us to locate any place\n\n\n\n\n\nA map is a flat (2-dimensional) representation of a region of the Earth. In a geographic CRS we use a 3-dimensional model of the Earth (the ellipsoid) to locate places on it. To transform our 3-dimensional ellipsoid to make a 2-dimensional representation we need to use a projection. A projection is a method to convert between angular coordinates (i.e.¬†lat/lon coordinates in 3D) and planar coordinates (i.e.¬†\\(x\\),\\(y\\) coordinates in 2D).\n\n\n\nImage Source: Battersby, S. (2017). Map Projections. The Geographic Information Science & Technology Body of Knowledge\n\n\n\n\n\n\n\n\nMany projections\n\n\n\nThere are many ways to project an ellipsoid into a 2-dimensional region. However, no matter what projection we use, the area, distances, or angles of the actual regions on Earth will be distorted when we project. Ultimately, the choice of projection relies on whether we want to optimze calculations involving area, angle, or distance measurements, as well as aesthetics when creating a map.\n\n\nThe following video, Vox - Why all world maps are wrong, does a great job at how projections work!\n\n\n\n\n\nWhen we project a region of the ellipsoid to represent a region of Earth on the plane we obtain a new set of planar coordinates, thus creating a projected CRS. A projected CRS must also include a unit of measure for its axes. These new coordinates are usually called eastings, when referring to the eastward-measured distance (\\(x\\)-coordinate), and northings, when referring to the northward-measured distance (\\(y\\)-coordinate).\n\n\n\nA projected CRS gives planar coordinates.",
    "crumbs": [
      "notes",
      "Vector data",
      "7 Coordinate reference systems"
    ]
  },
  {
    "objectID": "book/chapters/lesson-8-crs.html#how-to-create-a-crs",
    "href": "book/chapters/lesson-8-crs.html#how-to-create-a-crs",
    "title": "7 Coordinate reference systems",
    "section": "",
    "text": "Since the Earth does not have lines and numbers etched on it, us humans need to create a system to locate places on its surface. A way to solve this is to create a coordinate reference system (CRS). A CRS is, at its core, a way to represent places on the Earth as coordinates.\nTo understand what are the components of a CRS it can be useful to think of the process we would undergo to match places on the Earth to coordinates that represent them.\n\n\nThink of the Earth. Our planet is not a perfect sphere. Besides its rugged surface with high mountains and deep ocean trenches, the shape of the Earth is not round. Due to the Earth‚Äôs rotation, the planet is slightly wider at the Equator. Thus, a sphere is not the best way to model the shape of the Earth. Instead, we use an ellipsoid. Think of an ellipsoid as a sphere that has been flattened a bit, thus making it wider across one axis. This is the first step for creating a CRS: picking an ellipsoid, a.k.a picking a shape for the Earth. The ellipsoid used to represent the Earth‚Äôs shape has changed across time and it may also change depending on the application.\n\n\n\n\nThe ellipsoid is an abstract mathematical object on which we can locate points on it by using angles. The coordinate system on the ellipsoid is (angles from \\(x\\), angles from \\(y\\)).\n\n\n\nLatitude and longtide as angular coordinates on the ellipsoid. Image source: Coordinate systems and map projections - University of Twente\n\n\nThe next step to create a CRS is thus to make a decision on how to align the ellipsoid so that it‚Äôs surface corresponds to actual places on the Earth. We could think, for example, of:\n\nhow to place the ellipsoid‚Äôs center relative to Earth‚Äôs mass center (is it the same or is it off?) or\nhow to align the ellipsoid‚Äôs axes with the Earth (which meridian will be our prime meridian?).\n\nGenerally speaking, a geodetic datum, or just a datum, is how we are aligning our abstract ellipsoid to match the Earth‚Äôs surface.\n\n\n\nRegional datums to optimize location accuracy. Image source: GPS for Land Surveyors\n\n\n\n\n\n\n\n\nDatums may change across time and applications\n\n\n\nGeographers and cartographers have created and used many datums across time and applications. Sometimes datum refers both to a choice of ellipsoid and how to align it to the Earth. More importantly, different datums are used to increase the accuracy of representing different regions of Earth. At the GIS wiki you can see a list of names of different datums optimized for different regions.\n\n\n\n\n\nAt this point, we have successfully made a correspondence between the Earth‚Äôs surface of and our ellipsoid. This means we can now use the latitude,longitude (lat/lon) coordinates of the ellipsoid to locate any point on the Earth‚Äôs surface. This is called a geographic CRS. Geographic coordinate reference systems use degrees of latitude and longitude to locate points on the Earth, still thinking of it as a 3D object.\n\n\n\nWe use a geographic CRS to create angular coordiantes on the Earth (latitude and longitude) that allow us to locate any place\n\n\n\n\n\nA map is a flat (2-dimensional) representation of a region of the Earth. In a geographic CRS we use a 3-dimensional model of the Earth (the ellipsoid) to locate places on it. To transform our 3-dimensional ellipsoid to make a 2-dimensional representation we need to use a projection. A projection is a method to convert between angular coordinates (i.e.¬†lat/lon coordinates in 3D) and planar coordinates (i.e.¬†\\(x\\),\\(y\\) coordinates in 2D).\n\n\n\nImage Source: Battersby, S. (2017). Map Projections. The Geographic Information Science & Technology Body of Knowledge\n\n\n\n\n\n\n\n\nMany projections\n\n\n\nThere are many ways to project an ellipsoid into a 2-dimensional region. However, no matter what projection we use, the area, distances, or angles of the actual regions on Earth will be distorted when we project. Ultimately, the choice of projection relies on whether we want to optimze calculations involving area, angle, or distance measurements, as well as aesthetics when creating a map.\n\n\nThe following video, Vox - Why all world maps are wrong, does a great job at how projections work!\n\n\n\n\n\nWhen we project a region of the ellipsoid to represent a region of Earth on the plane we obtain a new set of planar coordinates, thus creating a projected CRS. A projected CRS must also include a unit of measure for its axes. These new coordinates are usually called eastings, when referring to the eastward-measured distance (\\(x\\)-coordinate), and northings, when referring to the northward-measured distance (\\(y\\)-coordinate).\n\n\n\nA projected CRS gives planar coordinates.",
    "crumbs": [
      "notes",
      "Vector data",
      "7 Coordinate reference systems"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html",
    "title": "16 Land cover statistics",
    "section": "",
    "text": "In this lesson we will use two datasets.\nThe first one is GAP/LANDFIRE National Terrestrial Ecosystems data for 2011 [1], from the US Geological Survey (USGS). This is a categorical raster with a 30 m x 30 m pixel resolution representing highly thematically detailed land cover map of the U.S. We will access this data through the Microsoft Planetary Computer (MPC) data catalog. The class names and corresponding codes have been saved to a separete CSV to simplify access in this lesson. Further information on how to access the classes directly from the data are available in the MPC catalog.\nThe second dataset is a shapefile with the perimeters for 2017 California fires. This data was extracted from the CALFIRE‚Äôs Historical Wildland Fire Perimeters.",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#about-the-data",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#about-the-data",
    "title": "16 Land cover statistics",
    "section": "",
    "text": "In this lesson we will use two datasets.\nThe first one is GAP/LANDFIRE National Terrestrial Ecosystems data for 2011 [1], from the US Geological Survey (USGS). This is a categorical raster with a 30 m x 30 m pixel resolution representing highly thematically detailed land cover map of the U.S. We will access this data through the Microsoft Planetary Computer (MPC) data catalog. The class names and corresponding codes have been saved to a separete CSV to simplify access in this lesson. Further information on how to access the classes directly from the data are available in the MPC catalog.\nThe second dataset is a shapefile with the perimeters for 2017 California fires. This data was extracted from the CALFIRE‚Äôs Historical Wildland Fire Perimeters.",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#fire-perimeter-preparation",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#fire-perimeter-preparation",
    "title": "16 Land cover statistics",
    "section": "Fire perimeter preparation",
    "text": "Fire perimeter preparation\nLet‚Äôs start by importing the necessary libraries:\n\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom shapely import box\n\nimport pystac_client\nimport planetary_computer\n\nfrom IPython.display import Image \n\nThen import and select the Thomas Fire within the fire perimeters data:\n\nfire_perimeters = gpd.read_file(os.path.join('data',\n                                             'California_Fire_Perimeters_2017',\n                                             'California_Fire_Perimeters_2017.shp')\n                                             )\nthomas_fire = fire_perimeters[fire_perimeters['FIRE_NAME']=='THOMAS']\n\n# Examin fire perimeter data\nthomas_fire.crs\nthomas_fire.plot()",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#catalog-search",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#catalog-search",
    "title": "16 Land cover statistics",
    "section": "Catalog search",
    "text": "Catalog search\nOur goal is to retrieve the National Terrestrial Ecosystems data over the fire perimeter. In the last lesson we used GeoJSON-type dictionary to do the catalog search. Here we will use a list [xmin, ymin, xmax, ymax] with the coordinate values defining the four corners of the region we want to search data over. Just as the GeoJSON, these coordinates have to be in the EPSG:4326 CRS.\nOur bounding box will come from the Thomas Fire perimeter. Notice we use method chaining to reproject and extract the bounds.\n\n# Create bounding box for search\nthomas_fire_bbox = list(thomas_fire.to_crs('epsg:4326') # Reproject for search\n                                   .total_bounds\n                                    )\nthomas_fire_bbox\n\n[-119.68162520650904,\n 34.27989979600195,\n -118.92518097019486,\n 34.63745683414112]\n\n\nNext, we connect to the Microsoft Planetary Computer data catalog and perform the search. The collection ID for the National Terrestrial Ecosystems data is gap:\n\n# Open MPC data catalog\ncatalog = pystac_client.Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n# Search MPC catalog \nsearch = catalog.search(collections=['gap'], \n                        bbox=thomas_fire_bbox)\n\n# Retrieve search items\nitems = search.item_collection()\nprint(f\"Returned {len(items)} Items\")\nitems\n\nReturned 1 Items\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        \n            features\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            \"2011-12-31T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            proj:wkt2\n            \"PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]\"\n        \n    \n            \n        \n            \n                \n        \n            label:type\n            \"raster\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            10000\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10000\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2011-12-31T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            label:classes\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"\"\n        \n    \n            \n        \n            \n                \n        \n            classes\n            [] 585 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"South Florida Bayhead Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"South Florida Cypress Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"South Florida Dwarf Cypress Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"South Florida Mangrove Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"South Florida Hardwood Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"Southeast Florida Coastal Strand and Maritime Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"Southwest Florida Coastal Strand and Maritime Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"South Florida Pine Rockland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Open Understory\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Scrub/Shrub Understory\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"Atlantic Coastal Plain Upland Longleaf Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"Atlantic Coastal Plain Xeric River Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Scrub/Shrub Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"Florida Longleaf Pine Sandhill - Scrub/Shrub Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"Florida Longleaf Pine Sandhill- Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"West Gulf Coastal Plain Upland Longleaf Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"Atlantic Coastal Plain Central Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"Atlantic Coastal Plain Southern Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"Central and South Texas Coastal Fringe Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            21\n            \"East Gulf Coastal Plain Limestone Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            22\n            \"East Gulf Coastal Plain Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            23\n            \"East Gulf Coastal Plain Southern Loess Bluff Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            24\n            \"East Gulf Coastal Plain Southern Mesic Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            25\n            \"Mississippi Delta Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            26\n            \"Southern Coastal Plain Dry Upland Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            27\n            \"Southern Coastal Plain Oak Dome and Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            28\n            \"West Gulf Coastal Plain Chenier and Upper Texas Coastal Fringe Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            29\n            \"West Gulf Coastal Plain Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            30\n            \"East-Central Texas Plains Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            31\n            \"West Gulf Coastal Plain Pine-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            32\n            \"West Gulf Coastal Plain Sandhill Oak and Shortleaf Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            33\n            \"Atlantic Coastal Plain Fall-Line Sandhills Longleaf Pine Woodland - Loblolly Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            34\n            \"Deciduous Plantations\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            35\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Loblolly Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            36\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Offsite Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            37\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Offsite Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            38\n            \"Evergreen Plantation or Managed Pine\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            39\n            \"California Central Valley Mixed Oak Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            40\n            \"California Coastal Closed-Cone Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            41\n            \"California Coastal Live Oak Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            42\n            \"California Lower Montane Blue Oak-Foothill Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            43\n            \"Central and Southern California Mixed Evergreen Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            44\n            \"Mediterranean California Lower Montane Black Oak-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            45\n            \"Southern California Oak Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            46\n            \"Madrean Encinal\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            47\n            \"Madrean Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            48\n            \"Madrean Pine-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            49\n            \"Madrean Upper Montane Conifer-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            50\n            \"Edwards Plateau Dry-Mesic Slope Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            51\n            \"Edwards Plateau Limestone Savanna and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            52\n            \"Edwards Plateau Mesic Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            53\n            \"Llano Uplift Acidic Forest, Woodland and Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            54\n            \"East Cascades Oak-Ponderosa Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            55\n            \"Mediterranean California Mixed Evergreen Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            56\n            \"Mediterranean California Mixed Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            57\n            \"North Pacific Dry Douglas-fir-(Madrone) Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            58\n            \"North Pacific Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            59\n            \"Edwards Plateau Limestone Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            60\n            \"Allegheny-Cumberland Dry Oak Forest and Woodland - Hardwood\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            61\n            \"Allegheny-Cumberland Dry Oak Forest and Woodland - Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            62\n            \"Central and Southern Appalachian Montane Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            63\n            \"Central and Southern Appalachian Northern Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            64\n            \"Central Appalachian Oak and Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            65\n            \"Crosstimbers Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            66\n            \"East Gulf Coastal Plain Black Belt Calcareous Prairie and Woodland - Woodland Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            67\n            \"East Gulf Coastal Plain Northern Dry Upland Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            68\n            \"East Gulf Coastal Plain Northern Loess Plain Oak-Hickory Upland - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            69\n            \"East Gulf Coastal Plain Northern Loess Plain Oak-Hickory Upland - Juniper Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            70\n            \"East-Central Texas Plains Post Oak Savanna and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            71\n            \"Lower Mississippi River Dune Woodland and Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            72\n            \"Mississippi River Alluvial Plain Dry-Mesic Loess Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            73\n            \"North-Central Interior Dry Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            74\n            \"North-Central Interior Dry-Mesic Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            75\n            \"Northeastern Interior Dry Oak Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            76\n            \"Northeastern Interior Dry Oak Forest - Virginia/Pitch Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            77\n            \"Northeastern Interior Dry Oak Forest-Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            78\n            \"Northeastern Interior Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            79\n            \"Northern Atlantic Coastal Plain Dry Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            80\n            \"Crowleys Ridge Sand Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            81\n            \"Ouachita Montane Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            82\n            \"Ozark-Ouachita Dry Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            83\n            \"Ozark-Ouachita Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            84\n            \"Southern and Central Appalachian Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            85\n            \"Southern and Central Appalachian Oak Forest - Xeric\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            86\n            \"Southern Interior Low Plateau Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            87\n            \"Southern Ridge and Valley Dry Calcareous Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            88\n            \"Southern Ridge and Valley Dry Calcareous Forest - Pine modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            89\n            \"East Gulf Coastal Plain Northern Dry Upland Hardwood Forest - Offsite Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            90\n            \"Managed Tree Plantation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            91\n            \"Ruderal forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            92\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Loblolly Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            93\n            \"Acadian Low-Elevation Spruce-Fir-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            94\n            \"Acadian-Appalachian Montane Spruce-Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            95\n            \"Appalachian Hemlock-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            96\n            \"Central and Southern Appalachian Spruce-Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            97\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            98\n            \"Laurentian-Acadian Northern Hardwoods Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            99\n            \"Laurentian-Acadian Northern Pine-(Oak) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            100\n            \"Laurentian-Acadian Pine-Hemlock-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            101\n            \"Paleozoic Plateau Bluff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            102\n            \"Southern Appalachian Northern Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            103\n            \"Atlantic Coastal Plain Dry and Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            104\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Offsite Hardwood\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            105\n            \"East Gulf Coastal Plain Interior Shortleaf Pine-Oak Forest - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            106\n            \"East Gulf Coastal Plain Interior Shortleaf Pine-Oak Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            107\n            \"Ozark-Ouachita Shortleaf Pine-Bluestem Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            108\n            \"Ozark-Ouachita Shortleaf Pine-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            109\n            \"Southeastern Interior Longleaf Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            110\n            \"Southern Appalachian Low Mountain Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            111\n            \"Southern Piedmont Dry Oak-(Pine) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            112\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            113\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            114\n            \"Southern Piedmont Dry Oak-Heath Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            115\n            \"Eastern Great Plains Tallgrass Aspen Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            116\n            \"Northwestern Great Plains Aspen Forest and Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            117\n            \"Northwestern Great Plains Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            118\n            \"Western Great Plains Dry Bur Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            119\n            \"Western Great Plains Wooded Draw and Ravine\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            120\n            \"Southern Atlantic Coastal Plain Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            121\n            \"East Gulf Coastal Plain Northern Loess Bluff Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            122\n            \"East Gulf Coastal Plain Northern Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            123\n            \"North-Central Interior Beech-Maple Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            124\n            \"North-Central Interior Maple-Basswood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            125\n            \"Ozark-Ouachita Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            126\n            \"South-Central Interior Mesophytic Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            127\n            \"Southern and Central Appalachian Cove Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            128\n            \"Crowleys Ridge Mesic Loess Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            129\n            \"Southern Piedmont Mesic Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            130\n            \"Appalachian Shale Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            131\n            \"Atlantic Coastal Plain Northern Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            132\n            \"Laurentian Pine-Oak Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            133\n            \"Northeastern Interior Pine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            134\n            \"Northern Atlantic Coastal Plain Pitch Pine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            135\n            \"Southern Appalachian Montane Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            136\n            \"East Cascades Mesic Montane Mixed-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            137\n            \"Middle Rocky Mountain Montane Douglas-fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            138\n            \"Northern Rocky Mountain Dry-Mesic Montane Mixed Conifer Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            139\n            \"Northern Rocky Mountain Foothill Conifer Wooded Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            140\n            \"Northern Rocky Mountain Mesic Montane Mixed Conifer Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            141\n            \"Northern Rocky Mountain Ponderosa Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            142\n            \"Northern Rocky Mountain Western Larch Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            143\n            \"Northwestern Great Plains - Black Hills Ponderosa Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            144\n            \"Rocky Mountain Foothill Limber Pine-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            145\n            \"Inter-Mountain Basins Aspen-Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            146\n            \"Inter-Mountain Basins Subalpine Limber-Bristlecone Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            147\n            \"Northern Rocky Mountain Subalpine Woodland and Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            148\n            \"Rocky Mountain Aspen Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            149\n            \"Rocky Mountain Lodgepole Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            150\n            \"Rocky Mountain Poor-Site Lodgepole Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            151\n            \"Rocky Mountain Subalpine Dry-Mesic Spruce-Fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            152\n            \"Rocky Mountain Subalpine Mesic Spruce-Fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            153\n            \"Rocky Mountain Subalpine-Montane Limber-Bristlecone Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            154\n            \"Rocky Mountain Bigtooth Maple Ravine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            155\n            \"Southern Rocky Mountain Dry-Mesic Montane Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            156\n            \"Southern Rocky Mountain Mesic Montane Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            157\n            \"Southern Rocky Mountain Ponderosa Pine Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            158\n            \"Southern Rocky Mountain Ponderosa Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            159\n            \"California Montane Jeffrey Pine-(Ponderosa Pine) Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            160\n            \"Klamath-Siskiyou Lower Montane Serpentine Mixed Conifer Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            161\n            \"Klamath-Siskiyou Upper Montane Serpentine Mixed Conifer Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            162\n            \"Mediterranean California Dry-Mesic Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            163\n            \"Mediterranean California Mesic Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            164\n            \"Sierran-Intermontane Desert Western White Pine-White Fir Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            165\n            \"California Coastal Redwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            166\n            \"North Pacific Broadleaf Landslide Forest and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            167\n            \"North Pacific Dry-Mesic Silver Fir-Western Hemlock-Douglas-fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            168\n            \"North Pacific Hypermaritime Sitka Spruce Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            169\n            \"North Pacific Hypermaritime Western Red-cedar-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            170\n            \"North Pacific Lowland Mixed Hardwood-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            171\n            \"North Pacific Maritime Dry-Mesic Douglas-fir-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            172\n            \"North Pacific Maritime Mesic-Wet Douglas-fir-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            173\n            \"North Pacific Mesic Western Hemlock-Silver Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            174\n            \"North Pacific Wooded Volcanic Flowage\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            175\n            \"Mediterranean California Red Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            176\n            \"Mediterranean California Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            177\n            \"North Pacific Maritime Mesic Subalpine Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            178\n            \"North Pacific Mountain Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            179\n            \"Northern California Mesic Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            180\n            \"Northern Pacific Mesic Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            181\n            \"Sierra Nevada Subalpine Lodgepole Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            182\n            \"Columbia Plateau Western Juniper Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            183\n            \"Great Basin Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            184\n            \"Inter-Mountain Basins Curl-leaf Mountain Mahogany Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            185\n            \"Inter-Mountain Basins Juniper Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            186\n            \"Colorado Plateau Pinyon-Juniper Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            187\n            \"Colorado Plateau Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            188\n            \"Southern Rocky Mountain Juniper Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            189\n            \"Southern Rocky Mountain Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            190\n            \"Northwestern Great Plains Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            191\n            \"Northwestern Great Plains Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            192\n            \"Western Great Plains Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            193\n            \"Western Great Plains Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            194\n            \"Western Great Plains Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            195\n            \"Central Appalachian Floodplain - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            196\n            \"Central Appalachian Riparian - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            197\n            \"Central Interior and Appalachian Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            198\n            \"Central Interior and Appalachian Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            199\n            \"Laurentian-Acadian Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            200\n            \"Ozark-Ouachita Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            201\n            \"South-Central Interior Large Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            202\n            \"South-Central Interior Large Floodplain - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            203\n            \"South-Central Interior Small Stream and Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            204\n            \"North-Central Interior and Appalachian Rich Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            205\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            206\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            207\n            \"Laurentian-Acadian Swamp Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            208\n            \"North-Central Interior Wet Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            209\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            210\n            \"South-Central Interior / Upper Coastal Plain Wet Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            211\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            212\n            \"Southern Piedmont/Ridge and Valley Upland Depression Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            213\n            \"Atlantic Coastal Plain Blackwater Stream Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            214\n            \"Atlantic Coastal Plain Brownwater Stream Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            215\n            \"Atlantic Coastal Plain Northern Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            216\n            \"Atlantic Coastal Plain Small Blackwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            217\n            \"Atlantic Coastal Plain Small Brownwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            218\n            \"Atlantic Coastal Plain Southern Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            219\n            \"East Gulf Coastal Plain Large River Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            220\n            \"East Gulf Coastal Plain Small Stream and River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            221\n            \"East Gulf Coastal Plain Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            222\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            223\n            \"Southeastern Great Plains Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            224\n            \"Southeastern Great Plains Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            225\n            \"Mississippi River Bottomland Depression\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            226\n            \"Mississippi River Floodplain and Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            227\n            \"Mississippi River Low Floodplain (Bottomland) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            228\n            \"Mississippi River Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            229\n            \"Red River Large Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            230\n            \"Southern Coastal Plain Blackwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            231\n            \"Southern Piedmont Large Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            232\n            \"Southern Piedmont Small Floodplain and Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            233\n            \"West Gulf Coastal Plain Large River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            234\n            \"West Gulf Coastal Plain Near-Coast Large River Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            235\n            \"West Gulf Coastal Plain Small Stream and River Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            236\n            \"Atlantic Coastal Plain Streamhead Seepage Swamp -  Pocosin -  and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            237\n            \"Gulf and Atlantic Coastal Plain Swamp Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            238\n            \"Southern Coastal Plain Hydric Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            239\n            \"Southern Coastal Plain Seepage Swamp and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            240\n            \"West Gulf Coastal Plain Seepage Swamp and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            241\n            \"Atlantic Coastal Plain Nonriverine Swamp and Wet Hardwood Forest  - Taxodium/Nyssa Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            242\n            \"Atlantic Coastal Plain Nonriverine Swamp and Wet Hardwood Forest - Oak Dominated Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            243\n            \"East Gulf Coastal Plain Southern Loblolly-Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            244\n            \"Lower Mississippi River Bottomland Depressions - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            245\n            \"Lower Mississippi River Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            246\n            \"Northern Atlantic Coastal Plain Basin Swamp and Wet Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            247\n            \"Southern Coastal Plain Nonriverine Basin Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            248\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Bay/Gum Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            249\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            250\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Taxodium Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            251\n            \"West Gulf Coastal Plain Nonriverine Wet Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            252\n            \"West Gulf Coastal Plain Pine-Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            253\n            \"Edwards Plateau Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            254\n            \"Atlantic Coastal Plain Clay-Based Carolina Bay Forested Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            255\n            \"Atlantic Coastal Plain Clay-Based Carolina Bay Herbaceous Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            256\n            \"Atlantic Coastal Plain Southern Wet Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            257\n            \"Central Atlantic Coastal Plain Wet Longleaf Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            258\n            \"Central Florida Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            259\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            260\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            261\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Scrub/Shrub Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            262\n            \"South Florida Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            263\n            \"Southern Coastal Plain Nonriverine Cypress Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            264\n            \"West Gulf Coastal Plain Wet Longleaf Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            265\n            \"Columbia Basin Foothill Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            266\n            \"Great Basin Foothill and Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            267\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            268\n            \"Northern Rocky Mountain Conifer Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            269\n            \"Northern Rocky Mountain Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            270\n            \"Rocky Mountain Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            271\n            \"Rocky Mountain Montane Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            272\n            \"Rocky Mountain Subalpine-Montane Riparian Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            273\n            \"North Pacific Hardwood-Conifer Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            274\n            \"North Pacific Lowland Riparian Forest and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            275\n            \"North Pacific Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            276\n            \"North Pacific Shrub Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            277\n            \"California Central Valley Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            278\n            \"Mediterranean California Foothill and Lower Montane Riparian Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            279\n            \"Mediterranean California Serpentine Foothill and Lower Montane Riparian Woodland and Seep\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            280\n            \"North American Warm Desert Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            281\n            \"North American Warm Desert Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            282\n            \"North American Warm Desert Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            283\n            \"Tamaulipan Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            284\n            \"Tamaulipan Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            285\n            \"Boreal Aspen-Birch Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            286\n            \"Boreal Jack Pine-Black Spruce Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            287\n            \"Boreal White Spruce-Fir-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            288\n            \"Boreal-Laurentian Conifer Acidic Swamp and Treed Poor Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            289\n            \"Eastern Boreal Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            290\n            \"South Florida Shell Hash Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            291\n            \"Southeast Florida Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            292\n            \"Southwest Florida Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            293\n            \"South Florida Everglades Sawgrass Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            294\n            \"South Florida Freshwater Slough and Gator Hole\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            295\n            \"South Florida Wet Marl Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            296\n            \"California Maritime Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            297\n            \"California Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            298\n            \"California Xeric Serpentine Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            299\n            \"Klamath-Siskiyou Xeromorphic Serpentine Savanna and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            300\n            \"Mediterranean California Mesic Serpentine Woodland and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            301\n            \"Northern and Central California Dry-Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            302\n            \"Southern California Dry-Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            303\n            \"Southern California Coastal Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            304\n            \"California Central Valley and Southern Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            305\n            \"California Mesic Serpentine Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            306\n            \"Columbia Basin Foothill and Canyon Dry Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            307\n            \"Columbia Basin Palouse Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            308\n            \"North Pacific Alpine and Subalpine Dry Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            309\n            \"North Pacific Montane Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            310\n            \"North Pacific Montane Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            311\n            \"Northern Rocky Mountain Lower Montane, Foothill and Valley Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            312\n            \"Northern Rocky Mountain Montane-Foothill Deciduous Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            313\n            \"Northern Rocky Mountain Subalpine Deciduous Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            314\n            \"Northern Rocky Mountain Subalpine-Upper Montane Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            315\n            \"Southern Rocky Mountain Montane-Subalpine Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            316\n            \"Rocky Mountain Gambel Oak-Mixed Montane Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            317\n            \"Rocky Mountain Lower Montane-Foothill Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            318\n            \"California Northern Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            319\n            \"North Pacific Herbaceous Bald and Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            320\n            \"North Pacific Hypermaritime Shrub and Herbaceous Headland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            321\n            \"Willamette Valley Upland Prairie and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            322\n            \"Mediterranean California Subalpine Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            323\n            \"Rocky Mountain Subalpine-Montane Mesic Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            324\n            \"Central Mixedgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            325\n            \"Northwestern Great Plains Mixedgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            326\n            \"Western Great Plains Foothill and Piedmont Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            327\n            \"Western Great Plains Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            328\n            \"Western Great Plains Sand Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            329\n            \"Western Great Plains Sandhill Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            330\n            \"Western Great Plains Mesquite Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            331\n            \"Western Great Plains Shortgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            332\n            \"Arkansas Valley Prairie and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            333\n            \"Central Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            334\n            \"North-Central Interior Oak Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            335\n            \"North-Central Interior Sand and Gravel Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            336\n            \"North-Central Oak Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            337\n            \"Northern Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            338\n            \"Southeastern Great Plains Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            339\n            \"Texas Blackland Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            340\n            \"Texas-Louisiana Coastal Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            341\n            \"Central Appalachian Pine-Oak Rocky Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            342\n            \"Southern Appalachian Grass and Shrub Bald\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            343\n            \"Southern Appalachian Grass and Shrub Bald - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            344\n            \"Southern Appalachian Grass and Shrub Bald - Shrub Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            345\n            \"Central Appalachian Alkaline Glade and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            346\n            \"Central Interior Highlands Calcareous Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            347\n            \"Central Interior Highlands Dry Acidic Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            348\n            \"Cumberland Sandstone Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            349\n            \"Great Lakes Alvar\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            350\n            \"Nashville Basin Limestone Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            351\n            \"Southern Ridge and Valley / Cumberland Dry Calcareous Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            352\n            \"Southern Piedmont Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            353\n            \"East Gulf Coastal Plain Black Belt Calcareous Prairie and Woodland - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            354\n            \"East Gulf Coastal Plain Jackson Prairie and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            355\n            \"Eastern Highland Rim Prairie and Barrens - Dry Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            356\n            \"Coahuilan Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            357\n            \"Madrean Oriental Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            358\n            \"Mogollon Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            359\n            \"Sonora-Mojave Semi-Desert Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            360\n            \"California Montane Woodland and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            361\n            \"Great Basin Semi-Desert Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            362\n            \"Florida Dry Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            363\n            \"Florida Peninsula Inland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            364\n            \"West Gulf Coastal Plain Catahoula Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            365\n            \"West Gulf Coastal Plain Nepheline Syenite Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            366\n            \"East Gulf Coastal Plain Jackson Plain Dry Flatwoods - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            367\n            \"West Gulf Coastal Plain Northern Calcareous Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            368\n            \"West Gulf Coastal Plain Southern Calcareous Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            369\n            \"Acadian-Appalachian Subalpine Woodland and Heath-Krummholz\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            370\n            \"Atlantic and Gulf Coastal Plain Interdunal Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            371\n            \"Atlantic Coastal Plain Southern Dune and Maritime Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            372\n            \"Central and Upper Texas Coast Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            373\n            \"East Gulf Coastal Plain Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            374\n            \"Great Lakes Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            375\n            \"Northern Atlantic Coastal Plain Dune and Swale\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            376\n            \"Northern Atlantic Coastal Plain Heathland and Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            377\n            \"South Texas Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            378\n            \"South Texas Sand Sheet Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            379\n            \"Southwest Florida Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            380\n            \"North Pacific Coastal Cliff and Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            381\n            \"North Pacific Maritime Coastal Sand Dune and Strand\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            382\n            \"Northern California Coastal Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            383\n            \"Mediterranean California Coastal Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            384\n            \"Mediterranean California Northern Coastal Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            385\n            \"Mediterranean California Southern Coastal Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            386\n            \"Atlantic Coastal Plain Northern Sandy Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            387\n            \"Atlantic Coastal Plain Sea Island Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            388\n            \"Atlantic Coastal Plain Southern Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            389\n            \"Florida Panhandle Beach Vegetation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            390\n            \"Louisiana Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            391\n            \"Northern Atlantic Coastal Plain Sandy Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            392\n            \"Texas Coastal Bend Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            393\n            \"Upper Texas Coast Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            394\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            395\n            \"Mediterranean California Serpentine Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            396\n            \"Mediterranean California Subalpine-Montane Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            397\n            \"North Pacific Bog and Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            398\n            \"Rocky Mountain Subalpine-Montane Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            399\n            \"Atlantic Coastal Plain Peatland Pocosin\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            400\n            \"Southern and Central Appalachian Bog and Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            401\n            \"Atlantic Coastal Plain Central Fresh-Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            402\n            \"Atlantic Coastal Plain Embayed Region Tidal Freshwater Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            403\n            \"Atlantic Coastal Plain Northern Fresh and Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            404\n            \"Florida Big Bend Fresh-Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            405\n            \"Atlantic Coastal Plain Depression Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            406\n            \"Atlantic Coastal Plain Large Natural Lakeshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            407\n            \"Central Florida Herbaceous Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            408\n            \"Central Florida Herbaceous Seep\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            409\n            \"East Gulf Coastal Plain Savanna and Wet Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            410\n            \"East Gulf Coastal Plain Depression Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            411\n            \"Floridian Highlands Freshwater Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            412\n            \"Southern Coastal Plain Herbaceous Seepage Bog\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            413\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Clethra Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            414\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Nupea Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            415\n            \"Texas-Louisiana Coastal Prairie Slough\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            416\n            \"Central Interior and Appalachian Shrub-Herbaceous Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            417\n            \"Great Lakes Coastal Marsh Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            418\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            419\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            420\n            \"Laurentian-Acadian Shrub-Herbaceous Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            421\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            422\n            \"Eastern Great Plains Wet Meadow, Prairie  and Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            423\n            \"Great Lakes Wet-Mesic Lakeplain Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            424\n            \"Great Plains Prairie Pothole\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            425\n            \"Western Great Plains Closed Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            426\n            \"Western Great Plains Depressional Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            427\n            \"Western Great Plains Open Freshwater Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            428\n            \"Cumberland Riverscour\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            429\n            \"Inter-Mountain Basins Interdunal Swale Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            430\n            \"North Pacific Avalanche Chute Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            431\n            \"North Pacific Intertidal Freshwater Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            432\n            \"Temperate Pacific Freshwater Emergent Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            433\n            \"Temperate Pacific Freshwater Mudflat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            434\n            \"Columbia Plateau Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            435\n            \"Northern California Claypan Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            436\n            \"Northern Rocky Mountain Wooded Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            437\n            \"Columbia Plateau Silver Sagebrush Seasonally Flooded Shrub-Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            438\n            \"Rocky Mountain Alpine-Montane Wet Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            439\n            \"Rocky Mountain Subalpine-Montane Riparian Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            440\n            \"Temperate Pacific Montane Wet Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            441\n            \"Willamette Valley Wet Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            442\n            \"Chihuahuan-Sonoran Desert Bottomland and Swale Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            443\n            \"North American Arid West Emergent Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            444\n            \"North American Warm Desert Riparian Mesquite Bosque\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            445\n            \"Western Great Plains Saline Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            446\n            \"Acadian Salt Marsh and Estuary Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            447\n            \"Atlantic Coastal Plain Central Salt and Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            448\n            \"Atlantic Coastal Plain Embayed Region Tidal Salt and Brackish Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            449\n            \"Atlantic Coastal Plain Indian River Lagoon Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            450\n            \"Atlantic Coastal Plain Northern Tidal Salt Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            451\n            \"Florida Big Bend Salt-Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            452\n            \"Gulf and Atlantic Coastal Plain Tidal Marsh Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            453\n            \"Mississippi Sound Salt and Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            454\n            \"Texas Saline Coastal Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            455\n            \"Temperate Pacific Tidal Salt and Brackish Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            456\n            \"Inter-Mountain Basins Alkaline Closed Depression\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            457\n            \"Inter-Mountain Basins Greasewood Flat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            458\n            \"Inter-Mountain Basins Playa\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            459\n            \"North American Warm Desert Playa\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            460\n            \"Apacherian-Chihuahuan Mesquite Upland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            461\n            \"Apacherian-Chihuahuan Semi-Desert Grassland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            462\n            \"Chihuahuan Creosotebush, Mixed Desert and Thorn Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            463\n            \"Chihuahuan Gypsophilous Grassland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            464\n            \"Chihuahuan Loamy Plains Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            465\n            \"Chihuahuan Mixed Desert and Thorn Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            466\n            \"Chihuahuan Sandy Plains Semi-Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            467\n            \"Chihuahuan Stabilized Coppice Dune and Sand Flat Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            468\n            \"Chihuahuan Succulent Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            469\n            \"Madrean Juniper Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            470\n            \"Mojave Mid-Elevation Mixed Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            471\n            \"North American Warm Desert Active and Stabilized Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            472\n            \"Sonora-Mojave Creosotebush-White Bursage Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            473\n            \"Sonoran Mid-Elevation Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            474\n            \"Sonoran Paloverde-Mixed Cacti Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            475\n            \"Chihuahuan Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            476\n            \"Sonora-Mojave Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            477\n            \"North American Warm Desert Wash\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            478\n            \"South Texas Lomas\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            479\n            \"Tamaulipan Calcareous Thornscrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            480\n            \"Tamaulipan Clay Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            481\n            \"Tamaulipan Mesquite Upland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            482\n            \"Tamaulipan Mixed Deciduous Thornscrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            483\n            \"Tamaulipan Savanna Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            484\n            \"Inter-Mountain Basins Mat Saltbush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            485\n            \"Inter-Mountain Basins Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            486\n            \"Inter-Mountain Basins Wash\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            487\n            \"Columbia Plateau Steppe and Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            488\n            \"Great Basin Xeric Mixed Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            489\n            \"Inter-Mountain Basins Big Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            490\n            \"Inter-Mountain Basins Big Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            491\n            \"Inter-Mountain Basins Montane Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            492\n            \"Colorado Plateau Mixed Low Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            493\n            \"Columbia Plateau Low Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            494\n            \"Columbia Plateau Scabland Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            495\n            \"Wyoming Basins Dwarf Sagebrush Shrubland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            496\n            \"Colorado Plateau Blackbrush-Mormon-tea Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            497\n            \"Inter-Mountain Basins Semi-Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            498\n            \"Inter-Mountain Basins Semi-Desert Shrub Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            499\n            \"Southern Colorado Plateau Sand Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            500\n            \"Acadian-Appalachian Alpine Tundra\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            501\n            \"Rocky Mountain Alpine Dwarf-Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            502\n            \"Rocky Mountain Alpine Fell-Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            503\n            \"Rocky Mountain Alpine Turf\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            504\n            \"Mediterranean California Alpine Dry Tundra\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            505\n            \"Mediterranean California Alpine Fell-Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            506\n            \"North Pacific Dry and Mesic Alpine Dwarf-Shrubland, Fell-field and Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            507\n            \"Rocky Mountain Alpine Tundra/Fell-field/Dwarf-shrub Map Unit\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            508\n            \"Temperate Pacific Intertidal Mudflat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            509\n            \"Mediterranean California Eelgrass Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            510\n            \"North Pacific Maritime Eelgrass Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            511\n            \"South-Central Interior Large Floodplain - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            512\n            \"East Gulf Coastal Plain Large River Floodplain Forest - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            513\n            \"Temperate Pacific Freshwater Aquatic Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            514\n            \"Central California Coast Ranges Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            515\n            \"Mediterranean California Serpentine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            516\n            \"Southern California Coast Ranges Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            517\n            \"Central Interior Acidic Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            518\n            \"Central Interior Calcareous Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            519\n            \"East Gulf Coastal Plain Dry Chalk Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            520\n            \"North-Central Appalachian Acidic Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            521\n            \"North-Central Appalachian Circumneutral Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            522\n            \"Southern Appalachian Montane Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            523\n            \"Southern Interior Acid Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            524\n            \"Southern Interior Calcareous Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            525\n            \"Southern Piedmont Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            526\n            \"Southern Appalachian Granitic Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            527\n            \"Southern Appalachian Rocky Summit\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            528\n            \"Southern Piedmont Granite Flatrock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            529\n            \"Rocky Mountain Cliff, Canyon and Massive Bedrock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            530\n            \"Klamath-Siskiyou Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            531\n            \"North Pacific Montane Massive Bedrock, Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            532\n            \"North Pacific Serpentine Barren\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            533\n            \"North Pacific Active Volcanic Rock and Cinder Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            534\n            \"Sierra Nevada Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            535\n            \"Western Great Plains Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            536\n            \"Southwestern Great Plains Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            537\n            \"Western Great Plains Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            538\n            \"North American Warm Desert Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            539\n            \"North American Warm Desert Bedrock Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            540\n            \"North American Warm Desert Pavement\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            541\n            \"North American Warm Desert Volcanic Rockland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            542\n            \"Colorado Plateau Mixed Bedrock Canyon and Tableland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            543\n            \"Columbia Plateau Ash and Tuff Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            544\n            \"Geysers and Hot Springs\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            545\n            \"Inter-Mountain Basins Active and Stabilized Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            546\n            \"Inter-Mountain Basins Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            547\n            \"Inter-Mountain Basins Shale Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            548\n            \"Inter-Mountain Basins Volcanic Rock and Cinder Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            549\n            \"Rocky Mountain Alpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            550\n            \"Mediterranean California Alpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            551\n            \"North Pacific Alpine and Subalpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            552\n            \"Unconsolidated Shore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            553\n            \"Undifferentiated Barren Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            554\n            \"North American Alpine Ice Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            555\n            \"Orchards Vineyards and Other High Structure Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            556\n            \"Cultivated Cropland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            557\n            \"Pasture/Hay\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            558\n            \"Introduced Upland Vegetation - Annual Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            559\n            \"Introduced Upland Vegetation - Perennial Grassland and Forbland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            560\n            \"Modified/Managed Southern Tall Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            561\n            \"Introduced Upland Vegetation - Shrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            562\n            \"Introduced Riparian and Wetland Vegetation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            563\n            \"Introduced Upland Vegetation - Treed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            564\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            565\n            \"Disturbed, Non-specific\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            566\n            \"Recently Logged Areas\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            567\n            \"Harvested Forest - Grass/Forb Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            568\n            \"Harvested Forest-Shrub Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            569\n            \"Harvested Forest - Northwestern Conifer Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            570\n            \"Recently Burned\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            571\n            \"Recently burned grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            572\n            \"Recently burned shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            573\n            \"Recently burned forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            574\n            \"Disturbed/Successional - Grass/Forb Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            575\n            \"Disturbed/Successional - Shrub Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            576\n            \"Disturbed/Successional - Recently Chained Pinyon-Juniper\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            577\n            \"Open Water (Aquaculture)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            578\n            \"Open Water (Brackish/Salt)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            579\n            \"Open Water (Fresh)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            580\n            \"Quarries, Mines, Gravel Pits and Oil Wells\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            581\n            \"Developed, Open Space\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            582\n            \"Developed, Low Intensity\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            583\n            \"Developed, Medium Intensity\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            584\n            \"Developed, High Intensity\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            30.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -2361135.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -30.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            1762215.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2010-01-01T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            label:description\n            \"USGS GAP/LANDFIRE\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -118.69342028\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.99971716\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.49405483\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.60171547\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -122.74636922\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.90181191\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -121.84549185\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.32121517\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -118.69342028\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.99971716\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap/items/gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/usgs-gap/conus/gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215.tif?st=2024-11-28T22%3A47%3A47Z&se=2024-11-29T23%3A32%3A47Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-29T17%3A40%3A37Z&ske=2024-12-06T17%3A40%3A37Z&sks=b&skv=2024-05-04&sig=mpVnNH/qGoVhVbCewZAYKXiGJ2wFKz7vyI2BlS27Cz8%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoTIFF data\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215&assets=data&tile_format=png&colormap_name=gap-lulc&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215&assets=data&tile_format=png&colormap_name=gap-lulc&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -122.74636921535789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.32121516682673\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -118.69342027702393\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            36.60171546740399\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/label/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"gap\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nThere is a single item in the search, so let‚Äôs go ahead and select it and view its pre-rendered image:\n\n# Select unique search item\nitem = items[0]  \n\n# Display pre-rendered image\nImage(url=item.assets['rendered_preview'].href, width=600)\n\n\n\n\nWe can see this is a big raster!\nAt this point, we can also import the CSV file with the class labels:\n\nlabels = pd.read_csv(os.path.join('data',\n                                  'GAP_National_Terrestrial_Ecosystems.csv')\n                                  )\nlabels.head()\n\n\n\n\n\n\n\n\nclass_label\ncode\n\n\n\n\n0\n0\n0\n\n\n1\nSouth Florida Bayhead Swamp\n1\n\n\n2\nSouth Florida Cypress Dome\n2\n\n\n3\nSouth Florida Dwarf Cypress Savanna\n3\n\n\n4\nSouth Florida Mangrove Swamp\n4\n\n\n\n\n\n\n\nNoitce that 0 is used as the no-data value for this raster. This will be relevant in a moment.",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#explore-raster",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#explore-raster",
    "title": "16 Land cover statistics",
    "section": "Explore raster",
    "text": "Explore raster\nNext, we can go ahead an open the raster:\n\n# Access raster data from item\nlulc = rioxr.open_rasterio(item.assets['data'].href)\nlulc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 10000, x: 10000)&gt;\n[100000000 values with dtype=uint16]\nCoordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -2.361e+06 -2.361e+06 ... -2.061e+06 -2.061e+06\n  * y            (y) float64 1.762e+06 1.762e+06 ... 1.462e+06 1.462e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:           Area\n    TIFFTAG_RESOLUTIONUNIT:  2 (pixels/inch)\n    TIFFTAG_SOFTWARE:        ERDAS IMAGINE\n    TIFFTAG_XRESOLUTION:     1\n    TIFFTAG_YRESOLUTION:     1\n    scale_factor:            1.0\n    add_offset:              0.0xarray.DataArrayband: 1y: 10000x: 10000...[100000000 values with dtype=uint16]Coordinates: (4)band(band)int641array([1])x(x)float64-2.361e+06 ... -2.061e+06array([-2361120., -2361090., -2361060., ..., -2061210., -2061180., -2061150.])y(y)float641.762e+06 1.762e+06 ... 1.462e+06array([1762200., 1762170., 1762140., ..., 1462290., 1462260., 1462230.])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / Conus Albersgrid_mapping_name :albers_conical_equal_areastandard_parallel :(29.5, 45.5)latitude_of_projection_origin :23.0longitude_of_central_meridian :-96.0false_easting :0.0false_northing :0.0spatial_ref :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]GeoTransform :-2361135.0 30.0 0.0 1762215.0 0.0 -30.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([-2361120.0, -2361090.0, -2361060.0, -2361030.0, -2361000.0, -2360970.0,\n       -2360940.0, -2360910.0, -2360880.0, -2360850.0,\n       ...\n       -2061420.0, -2061390.0, -2061360.0, -2061330.0, -2061300.0, -2061270.0,\n       -2061240.0, -2061210.0, -2061180.0, -2061150.0],\n      dtype='float64', name='x', length=10000))yPandasIndexPandasIndex(Index([1762200.0, 1762170.0, 1762140.0, 1762110.0, 1762080.0, 1762050.0,\n       1762020.0, 1761990.0, 1761960.0, 1761930.0,\n       ...\n       1462500.0, 1462470.0, 1462440.0, 1462410.0, 1462380.0, 1462350.0,\n       1462320.0, 1462290.0, 1462260.0, 1462230.0],\n      dtype='float64', name='y', length=10000))Attributes: (7)AREA_OR_POINT :AreaTIFFTAG_RESOLUTIONUNIT :2 (pixels/inch)TIFFTAG_SOFTWARE :ERDAS IMAGINETIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1scale_factor :1.0add_offset :0.0\n\n\nNotice that band is a dimension of length 1. We can go ahead and ‚Äúsqueeze‚Äù the raster to simplify it:\n\n# Remove length 1 dimension (band)\nlulc = lulc.squeeze().drop_vars('band')\nprint(\"Sizes of dimensions:\", dict(lulc.sizes))\n\nSizes of dimensions: {'y': 10000, 'x': 10000}\n\n\nNext, let‚Äôs look at how the raster is locatd with respect to the Thomas Fire perimeter and the CA state boundary:\n\n# Create GeoDataFrame from raster bounding box\nlulc_bbox = gpd.GeoDataFrame(geometry = [box(*lulc.rio.bounds())],\n                             crs = lulc.rio.crs)\n\nca = gpd.read_file(os.path.join('data',\n                                'ca_state_boundary',   \n                                'ca_state_boundary.shp'))\n\n# ------------------------------------------------------------------\n# Plot raster boundary, fire perimeter, and CA boundary\nfig, ax = plt.subplots()\nca.plot(ax=ax, color='white', edgecolor ='black')\n\n# Reproject lulc_bbox and fire perimeter to match CA crs\nlulc_bbox.to_crs(ca.crs).plot(ax=ax, alpha=0.3)  \nthomas_fire.to_crs(ca.crs).plot(ax=ax, color='red')\n\nplt.show()\n\n\n\n\n\n\n\n\nWe can see the raster covers a big area relative to the fire perimeter. Since we want to calculate the land coverage statistics within the fire perimeter, we will have to clip the raster to this area.",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#clip-raster-to-geometry",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#clip-raster-to-geometry",
    "title": "16 Land cover statistics",
    "section": "Clip raster to geometry",
    "text": "Clip raster to geometry\nIn our first lesson about rasters we saw how to clip a raster to a rectangular region. In our case, we want to clip the raster exactly to the fire perimeter. Clipping can be a costly operation for such a big raster relative to a detailed geometry. So we will perform the clipping in two steps:\n\nClip the raster using the fire perimeter bounding box using rio.clip_box() and then\nClip the simplified raster to the fire perimeter using rio.clip().\n\n\n# Match CRSs and verify update\nthomas_fire_match = thomas_fire.to_crs(lulc.rio.crs)\nassert thomas_fire_match.crs == lulc.rio.crs\n\n# Clip large raster to detailed geometry in two steps\nlulc_step1 = lulc.rio.clip_box(*thomas_fire_match.total_bounds)\nlulc_step2 = lulc_step1.rio.clip(thomas_fire_match.geometry)  # Produces RuntimeWarning\n\n# ------------------------------------------------------\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\n\n# Plot the first clipped raster\nlulc_step1.plot(ax=ax[0])\nax[0].set_title(\"Step 1: Clip to Bounding Box\")\nax[0].axis(\"off\")\n\n# Plot the second clipped raster\nlulc_step2.plot(ax=ax[1])\nax[1].set_title(\"Step 2: Clip to Detailed Geometry\")\nax[1].axis(\"off\")\n\nplt.show()\n\n/Users/galaz-garcia/opt/anaconda3/envs/mpc-env/lib/python3.11/site-packages/xarray/core/duck_array_ops.py:201: RuntimeWarning: invalid value encountered in cast\n  return data.astype(dtype, **kwargs)",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#raster-no-data-values",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#raster-no-data-values",
    "title": "16 Land cover statistics",
    "section": "Raster no-data values",
    "text": "Raster no-data values\nNotice a warning appeared when we clipped the raster. After some investigation, we will find that this RuntimeWarning occurs because the rio.clip() function tries to replace values outside the fire perimeter geometry with np.nan. However, as we previously saw, our raster‚Äôs data type is uint16 (16 bits unsigned integer). The cast issue appears since np.nan is a float (decimal number) and it cannot be casted as a uint16. To make sure the clipping operator fills in any pixels with the adequate no-data value, let‚Äôs manually set it:\n\nprint('Original no-data value: ', lulc.rio.nodata)\n\n# Update raster's no-data value\nlulc = lulc.rio.write_nodata(0)\nprint('Updated no-data value: ', lulc.rio.nodata)\n\nOriginal no-data value:  None\nUpdated no-data value:  0\n\n\nThis way, the rio.clip() function will know what values to assign to pixels outside the fire perimeter. Let‚Äôs try clipping again, this time using method chaining:\n\nlulc_clip = (lulc.rio.clip_box(*thomas_fire_match.total_bounds)\n                 .rio.clip(thomas_fire_match.geometry)\n                 )\n\n# Examine results\nlulc_clip.plot()                                  \n\n\n\n\n\n\n\n\nNotice no warning came up during the clipping!\n\n\n\n\n\n\nAlways pay attention to warnings!\n\n\n\nWarnings are your program‚Äôs way of saying, ‚ÄúSomething might go wrong here, take a look!‚Äù They may indicate silent failures, package compatibility issues, or potential bugs, amont other issues. Do not ignore warnings! Addressing warnings is part of writing clean, maintainable code and reflects a professional approach.\nThese are some steps to handling warnings effectively:\n\nRead and understand them: Don‚Äôt dismiss warnings without understanding their cause.\nFix or address them: Modify your code to resolve the warning if possible.\nSuppress only when necessary: Use tools to suppress warnings only when you‚Äôre sure they are irrelevant or benign.",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#land-cover-statistics",
    "href": "book/chapters/lesson-17-raster-wrangling/lesson-17-raster-wrangling.html#land-cover-statistics",
    "title": "16 Land cover statistics",
    "section": "Land cover statistics",
    "text": "Land cover statistics\nIn the rest of this lesson we will compute land cover statistics within the Thomas Fire perimeter. The following exercises will guide you through this process:\n\n\n\n\n\n\nExercises\n\n\n\n\nUse the numpy function np.unique() to get the number of pixels per class in lulc_clip. HINT: check the np.unique() documentation to see what the return_counts parameter does and read the last example.\nCreate a data frame pix_counts with two columns: column one must be the code numbers for the pixels in lulc_clip and column two must be the number of pixels corresponding to each code. HINT: check our class notes on pandas.DataFrames\n\n\n\nUse the labels data frame to add the class names to the codes in the pix_counts data frame. Store the resulting data frame as classes.\n\n\n\nWhat area within the fire perimeter (in km^2) was estimated to be developed? HINT: what is the raster‚Äôs resolution?\n\n\n\nStore the total number of pixels within the fire perimeter as a variable total_pixels.\nAdd the percentage of area covered by each class as a new column percentage to the classes data frame. Sort the data frame by percentage coverage in descending order.\n\n\n\nCreate a horizontal bar plot showing the classes with more than 1% land cover in decreasing order. For example:",
    "crumbs": [
      "notes",
      "Raster data",
      "16 Land cover statistics"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html",
    "href": "book/chapters/lesson-4-plotting-pandas.html",
    "title": "3 Basic plotting",
    "section": "",
    "text": "In this lesson we will learn to use the plot() method of a pandas.DataFrame to create simple exploratory graphs from tabular data.\n\n\nBy the end of this lesson students will be able to:\n\nObtain and interpret preliminary information about a pandas.DataFrame using methods such as info() (structure), describe() (summary statistics), nunique() (unique value counts), unique() (distinct values), and value_counts() (frequency counts)\nCreate simple exploratory plots using the plot() method for pandas.DataFrames to visualize trends and distributions\nUnderstand the concept of performing operations on a pandas.DataFrame in-place\nApply method chaining to enable concise and readable code\n\n\n\n\nIn this lesson we will reuse the annual estimates of bird species abundance in four coastal wetlands along the California coast that we used in the previous lesson on subsetting a pandas.DataFrame. This dataset was derived for education purposes for this course from the UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset [1]. The SONGS dataset was collected as part of the San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program.\nThe annual bird species abundance estimates is a CSV file with 13 columns and 14 rows. You can see the first three rows below. \n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n\n\n\n\n\nThe four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM), Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the CSM_fall column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The year column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023.\n\n\n\nLet us start by loading the data:\nimport pandas as pd\n\n# Read in file\ndf = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')\n\n# Check the first 5 rows\ndf.head()\n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\nA pandas.DataFrame has a built-in method plot() for plotting. When we call it without specifying any other parameters plot() creates one line plot for each of the columns with numeric data.\n\n# Default plot(): one line plot per column with numeric data\ndf.plot()\n\n\n\n\n\n\n\n\nAs we can see, this doesn‚Äôt make much sense! In particular, look at the x-axis. The default for plot is to use the values of the index as the x-axis values. Let‚Äôs see some examples about how to improve this situation.\n\n\n\nWe can make a line plot of one column against another by using the following the general syntax:\ndf.plot(x='x_values_column', y='y_values_column')\n\n\nIf we want to plot the bird surveys at Carpinteria Salt Marsh across years we can do:\n\n# Birds species registered during winter at CSM yearly\ndf.plot(x='year', y='CSM_winter')\n\n\n\n\n\n\n\n\nWe can do some basic customization specifying other parameters of the plot() method. Some basic ones are:\n\ntitle: title to use for the plot.\nxlabel: name to use for the x-label on x-axis\nylabel: bame to use for the y-label on y-axis\ncolor: change the color of our plot\nlegend: boolean value True or False. True (default) includes the legend, False removes the legend\n\nIn action:\n\ndf.plot(x='year', \n        y='CSM_winter',\n        title='Bird species registered during winter at Carpinteria Salt Marsh',\n        xlabel='Year',\n        ylabel='Number of bird species',\n        color='green',\n        legend=False\n        )\n\n\n\n\n\n\n\n\nYou can see all the optional parameters for the plot() function in the documentation.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nPlot a graph of the spring bird surveys at Mugu Lagoon with respect to the years. Include some basic customization.\nUse the isna() method for pandas.Series and row selection to select the rows in which Mugu Lagoon has NAs during the spring survey.\n\n\n\n\n\n\n\nWe can plot multiple line plots by updating these parameters in the plot() method:\n\ny : a list of column names that will be plotted against the x-axis\ncolor: a dictionary {'column_1' : 'color_1', 'column_2':'color_2} specifying the color of each column‚Äôs line plot\n\n\n\nLet‚Äôs say we want to compare the bird surveys at the Tijuana Estuary during spring and fall across years.\n\ndf.plot(x='year', \n        y=['TJE_spring', 'TJE_fall'],\n        title = 'Seasonal bird surveys at Tijuana Estuary',\n        xlabel='Year',\n        ylabel='Number of bird species',        \n        color = {'TJE_spring':'#F48FB1',\n                 'TJE_fall': '#AB47BC'\n                 }\n        )\n\n\n\n\n\n\n\n\n\nNotice that for specifying the colors we used a HEX code, this gives us more control over how our graph looks.\nWe can also create separate plots for each column by setting the subset to True.\n\ndf.plot(x='year', \n        y=['TJE_spring', 'TJE_fall'],\n        title = 'Seasonal bird surveys at Tijuana Estuary',\n        xlabel='Year',\n        ylabel='Number of bird species',        \n        color = {'TJE_spring':'#F48FB1',\n                 'TJE_fall': '#AB47BC'\n                 },\n        subplots=True\n        )\n\narray([&lt;Axes: xlabel='Year', ylabel='Number of bird species'&gt;,\n       &lt;Axes: xlabel='Year', ylabel='Number of bird species'&gt;],\n      dtype=object)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdating the index of our data frame to be something other than the default integers numbering the rows can be a useful operation for plotting. To update the index we use the set_index() method for a pandas.DataFrame. It‚Äôs general syntax is:\ndf = df.set_index(new_index)\nwhere new_index is:\n\nthe name of the column in the data frame df we want to use as new index\nif our new index is not a column in the data frame, an array or pandas.Series of the same length as our data frame (we need one index per row).\n\nThis operation does not happen in-place.\n\nA funciton acting in-place means that our original object (in this case a pandas.DataFrame) is modified.\nIf the function does not act in-place, a new object (in this case a pandas.DataFrame) is created and the original is not modified.\n\nIf we wanted to update our df data frame we could do an explicit assignment to reassign the output of set_index() to df:\n# Set `column_name` column in df as the new index (reassignment)\ndf = df.set_index('column_name')\nor use the optional inplace parameter:\n# Set `column_name` column in df as the new index (modify df in-place)\ndf.set_index('column_name', inplace=True)\n\n\n\n\n\n\nIn general, avoid using the inplace=True argument and favor explicit variable assignments\n\n\n\nCheck the information about the inplace parameter in the set_index() documentation. You will often see the inplace parameter in methods for pandas.DataFrames. The best practice is to avoid inplace=True for better readability and maintainable code. Explicitly assigning the result to a new variable or the same variable makes it clear that an operation has occurred.\n\n\n\n\nIn all our previous examples we used the year column as the x-axis. Since all our bird survey variables are dependent on the year, it makes sense to use the year column as the index of the data frame:\n\n# Update index to be the year column\ndf = df.set_index('year')\ndf.head()\n\n\n\n\n\n\n\n\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\nyear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n# Simple plot of Carpinteria Salt Marsh winter surveys\ndf.plot(y='CSM_winter')\n\n\n\n\n\n\n\n\nIf needed, we can reset the index to be the numbering of the rows:\n\ndf = df.reset_index()\ndf.head()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\n\nWithout running the code, give a step-by-step breakdown of what this code is doing:\n\ndf.set_index('year').loc[:,'SDW_winter':'TJE_fall'].plot()\n\nIs this code modifying the data frame df? Why or why not?\nRun the code and examine the graph. Review the data description. Do we have all the necessary information to make sure it makes sense to directly compare the surveys at these different sites? \n\n\n\n\n\n\n\nThe code used in the check-in\ndf.set_index('year').loc[:,'SDW_winter':'TJE_fall'].plot()\nis an example of method chaining. Each method in the chain returns an object (typically the same object), allowing the next method to be called directly on the result. This is a powerful technique that makes code concise and readable.\nChaining methods can result in lines of code that are too long and hard to read. We can break up chains of methods by using parenthesis:\n(df.set_index('year')\n  .loc[:,'SDW_winter':'TJE_fall']\n  .plot()\n)\n\n\n\n\n\n\nMethod chaining and the R pipe operator\n\n\n\nIf you are familiar with R, you may have noticed that the period . in the method chianing acts in the same way as the R pipe operator (%&gt;% or |&gt;). The syntax of one method per line is similar to what is used in the tidyverse, except that the pipe is used at the end of the line, while the period is used at the beginning of the line.\n\n\nAn alternative to the previous code chaining could have been:\nyear_index_df = df.set_index('year')\nsubset_df = year_index_df.loc[:,'SDW_winter':'TJE_fall']\nsubset_df.plot()\nWhile this accomplishes the same output, several variables are created along the way and it can be difficult to keep track of what is what.\n\n\n\n\n\n\nUse method chaining wisely\n\n\n\nMethod chaining is particularly useful in pandas for streamlining multiple data manipulations. However:\n\nmethod chaining should be used with care to avoid overly complex and difficult-to-debug code, and\nif you‚Äôre not familiar with the methods, it‚Äôs better to apply them individually and review the results after each step.\n\n\n\nWe will move on to another dataset for the rest of this lesson.\n\n\n\nFor the next plots we will use the Palmer Penguins dataset [2] developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica during 2007, 2008, and 2009.\n\n\n\nThe Palmer Archipelago penguins. Artwork by Dr.¬†Allison Horst.\n\n\nThe dataset has 344 rows and 8 columns. We can see it‚Äôs first three rows below:\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\nThe data is usually accessed through the palmerpenguins R data package [2]. In this lesson we will access the CSV directly into our workspace using the URL: https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\nLet‚Äôs start by reading in the data:\n\n# Read in data\nURL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\npenguins = pd.read_csv(URL)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nAnd getting some preliminary information:\n\n# Check column data types and NA values\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\n\n# Simple statistics about numeric columns\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\nWe can also subset the dataframe to get information about a particular column or groups of columns:\n\n# Count unique values in categorical columns and year\npenguins[['species', 'island', 'sex', 'year']].nunique()\n\nspecies    3\nisland     3\nsex        2\nyear       3\ndtype: int64\n\n\n\n# Get unique values in species column\npenguins['species'].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\n\n# Number of values per unique value in species column\npenguins['species'].value_counts()\n\nspecies\nAdelie       152\nGentoo       124\nChinstrap     68\nName: count, dtype: int64\n\n\n\n\n\nAt the beginning of the lesson we talked about how the plot() method creates a line plot by default. The parameter that controls this behaviour is the kind parameter. By changing the value of kind we can create different kinds of plots. Let‚Äôs look at the documentation to see what these values are:\n\n\n\nExtract from the pandas.DataFrame.plot documentation. Accessed on Sept 25,2024\n\n\nNotice the default value of kind is 'line'.\nLet‚Äôs change the kind parameter to create some different plots.\n\n\n\nSuppose we want to visualy compare the flipper length against the body mass, we can do this with a scatterplot:\n\npenguins.plot(kind='scatter',\n              x='flipper_length_mm', \n              y='body_mass_g')\n\n\n\n\n\n\n\n\nWe can update some other arguments to customize the graph:\n\npenguins.plot(kind='scatter',\n              x='flipper_length_mm', \n              y='body_mass_g',\n              title='Flipper length and body mass for Palmer penguins',\n              xlabel='Flipper length (mm)',\n              ylabel='Body mass (g)',\n              color='#ff3b01',\n              alpha=0.4  # Controls transparency\n              )\n\n\n\n\n\n\n\n\n\n\n\nWe can create bar plots of our data setting kind='bar' in the plot() method.\nFor example, let‚Äôs say we want to get data about the 10 penguins with lowest body mass. We can first select this data using the nsmallest() method for series:\n\nsmallest = penguins['body_mass_g'].nsmallest(10)\nsmallest\n\n314    2700.0\n58     2850.0\n64     2850.0\n54     2900.0\n98     2900.0\n116    2900.0\n298    2900.0\n104    2925.0\n47     2975.0\n44     3000.0\nName: body_mass_g, dtype: float64\n\n\nWe can then plot this data as a bar plot\n\nsmallest.plot(kind='bar')\n\n\n\n\n\n\n\n\nIf we wanted to look at other data for these smallest penguins we can use a different call to the nsmallest method:\n\npenguins.nsmallest(10, 'body_mass_g')\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n314\nChinstrap\nDream\n46.9\n16.6\n192.0\n2700.0\nfemale\n2008\n\n\n58\nAdelie\nBiscoe\n36.5\n16.6\n181.0\n2850.0\nfemale\n2008\n\n\n64\nAdelie\nBiscoe\n36.4\n17.1\n184.0\n2850.0\nfemale\n2008\n\n\n54\nAdelie\nBiscoe\n34.5\n18.1\n187.0\n2900.0\nfemale\n2008\n\n\n98\nAdelie\nDream\n33.1\n16.1\n178.0\n2900.0\nfemale\n2008\n\n\n116\nAdelie\nTorgersen\n38.6\n17.0\n188.0\n2900.0\nfemale\n2009\n\n\n298\nChinstrap\nDream\n43.2\n16.6\n187.0\n2900.0\nfemale\n2007\n\n\n104\nAdelie\nBiscoe\n37.9\n18.6\n193.0\n2925.0\nfemale\n2009\n\n\n47\nAdelie\nDream\n37.5\n18.9\n179.0\n2975.0\nNaN\n2007\n\n\n44\nAdelie\nDream\n37.0\n16.9\n185.0\n3000.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\nWe can create a histogram of our data setting kind='hist' in plot().\n\n# Using plot without subsetting data - a mess again\npenguins.plot(kind='hist')\n\n\n\n\n\n\n\n\nTo gain actual information, let‚Äôs subset the data before plotting it. For example, suppose we want to do a preliminary graph for the distribution of flipper length. We could do it in this way:\n\n# Distribution of flipper length measurements\n# First select data, then plot\npenguins['flipper_length_mm'].plot(kind='hist',\n                                title='Penguin flipper lengths',\n                                xlabel='Flipper length (mm)',\n                                grid=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\n\nSelect the bill_length_mm and bill_depth_mm columns in the penguins dataframe and then update the kind parameter to box to make boxplots of the bill length and bill depth. \nCreate a simple histogram of the flipper length of female gentoo penguins.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#learning-objectives",
    "href": "book/chapters/lesson-4-plotting-pandas.html#learning-objectives",
    "title": "3 Basic plotting",
    "section": "",
    "text": "By the end of this lesson students will be able to:\n\nObtain and interpret preliminary information about a pandas.DataFrame using methods such as info() (structure), describe() (summary statistics), nunique() (unique value counts), unique() (distinct values), and value_counts() (frequency counts)\nCreate simple exploratory plots using the plot() method for pandas.DataFrames to visualize trends and distributions\nUnderstand the concept of performing operations on a pandas.DataFrame in-place\nApply method chaining to enable concise and readable code",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#about-the-data",
    "href": "book/chapters/lesson-4-plotting-pandas.html#about-the-data",
    "title": "3 Basic plotting",
    "section": "",
    "text": "In this lesson we will reuse the annual estimates of bird species abundance in four coastal wetlands along the California coast that we used in the previous lesson on subsetting a pandas.DataFrame. This dataset was derived for education purposes for this course from the UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset [1]. The SONGS dataset was collected as part of the San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program.\nThe annual bird species abundance estimates is a CSV file with 13 columns and 14 rows. You can see the first three rows below. \n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n\n\n\n\n\nThe four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM), Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the CSM_fall column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The year column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#plot-method",
    "href": "book/chapters/lesson-4-plotting-pandas.html#plot-method",
    "title": "3 Basic plotting",
    "section": "",
    "text": "Let us start by loading the data:\nimport pandas as pd\n\n# Read in file\ndf = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')\n\n# Check the first 5 rows\ndf.head()\n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\nA pandas.DataFrame has a built-in method plot() for plotting. When we call it without specifying any other parameters plot() creates one line plot for each of the columns with numeric data.\n\n# Default plot(): one line plot per column with numeric data\ndf.plot()\n\n\n\n\n\n\n\n\nAs we can see, this doesn‚Äôt make much sense! In particular, look at the x-axis. The default for plot is to use the values of the index as the x-axis values. Let‚Äôs see some examples about how to improve this situation.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#line-plots",
    "href": "book/chapters/lesson-4-plotting-pandas.html#line-plots",
    "title": "3 Basic plotting",
    "section": "",
    "text": "We can make a line plot of one column against another by using the following the general syntax:\ndf.plot(x='x_values_column', y='y_values_column')\n\n\nIf we want to plot the bird surveys at Carpinteria Salt Marsh across years we can do:\n\n# Birds species registered during winter at CSM yearly\ndf.plot(x='year', y='CSM_winter')\n\n\n\n\n\n\n\n\nWe can do some basic customization specifying other parameters of the plot() method. Some basic ones are:\n\ntitle: title to use for the plot.\nxlabel: name to use for the x-label on x-axis\nylabel: bame to use for the y-label on y-axis\ncolor: change the color of our plot\nlegend: boolean value True or False. True (default) includes the legend, False removes the legend\n\nIn action:\n\ndf.plot(x='year', \n        y='CSM_winter',\n        title='Bird species registered during winter at Carpinteria Salt Marsh',\n        xlabel='Year',\n        ylabel='Number of bird species',\n        color='green',\n        legend=False\n        )\n\n\n\n\n\n\n\n\nYou can see all the optional parameters for the plot() function in the documentation.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nPlot a graph of the spring bird surveys at Mugu Lagoon with respect to the years. Include some basic customization.\nUse the isna() method for pandas.Series and row selection to select the rows in which Mugu Lagoon has NAs during the spring survey.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#multiple-line-plots",
    "href": "book/chapters/lesson-4-plotting-pandas.html#multiple-line-plots",
    "title": "3 Basic plotting",
    "section": "",
    "text": "We can plot multiple line plots by updating these parameters in the plot() method:\n\ny : a list of column names that will be plotted against the x-axis\ncolor: a dictionary {'column_1' : 'color_1', 'column_2':'color_2} specifying the color of each column‚Äôs line plot\n\n\n\nLet‚Äôs say we want to compare the bird surveys at the Tijuana Estuary during spring and fall across years.\n\ndf.plot(x='year', \n        y=['TJE_spring', 'TJE_fall'],\n        title = 'Seasonal bird surveys at Tijuana Estuary',\n        xlabel='Year',\n        ylabel='Number of bird species',        \n        color = {'TJE_spring':'#F48FB1',\n                 'TJE_fall': '#AB47BC'\n                 }\n        )\n\n\n\n\n\n\n\n\n\nNotice that for specifying the colors we used a HEX code, this gives us more control over how our graph looks.\nWe can also create separate plots for each column by setting the subset to True.\n\ndf.plot(x='year', \n        y=['TJE_spring', 'TJE_fall'],\n        title = 'Seasonal bird surveys at Tijuana Estuary',\n        xlabel='Year',\n        ylabel='Number of bird species',        \n        color = {'TJE_spring':'#F48FB1',\n                 'TJE_fall': '#AB47BC'\n                 },\n        subplots=True\n        )\n\narray([&lt;Axes: xlabel='Year', ylabel='Number of bird species'&gt;,\n       &lt;Axes: xlabel='Year', ylabel='Number of bird species'&gt;],\n      dtype=object)",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#updating-the-index",
    "href": "book/chapters/lesson-4-plotting-pandas.html#updating-the-index",
    "title": "3 Basic plotting",
    "section": "",
    "text": "Updating the index of our data frame to be something other than the default integers numbering the rows can be a useful operation for plotting. To update the index we use the set_index() method for a pandas.DataFrame. It‚Äôs general syntax is:\ndf = df.set_index(new_index)\nwhere new_index is:\n\nthe name of the column in the data frame df we want to use as new index\nif our new index is not a column in the data frame, an array or pandas.Series of the same length as our data frame (we need one index per row).\n\nThis operation does not happen in-place.\n\nA funciton acting in-place means that our original object (in this case a pandas.DataFrame) is modified.\nIf the function does not act in-place, a new object (in this case a pandas.DataFrame) is created and the original is not modified.\n\nIf we wanted to update our df data frame we could do an explicit assignment to reassign the output of set_index() to df:\n# Set `column_name` column in df as the new index (reassignment)\ndf = df.set_index('column_name')\nor use the optional inplace parameter:\n# Set `column_name` column in df as the new index (modify df in-place)\ndf.set_index('column_name', inplace=True)\n\n\n\n\n\n\nIn general, avoid using the inplace=True argument and favor explicit variable assignments\n\n\n\nCheck the information about the inplace parameter in the set_index() documentation. You will often see the inplace parameter in methods for pandas.DataFrames. The best practice is to avoid inplace=True for better readability and maintainable code. Explicitly assigning the result to a new variable or the same variable makes it clear that an operation has occurred.\n\n\n\n\nIn all our previous examples we used the year column as the x-axis. Since all our bird survey variables are dependent on the year, it makes sense to use the year column as the index of the data frame:\n\n# Update index to be the year column\ndf = df.set_index('year')\ndf.head()\n\n\n\n\n\n\n\n\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\nyear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n# Simple plot of Carpinteria Salt Marsh winter surveys\ndf.plot(y='CSM_winter')\n\n\n\n\n\n\n\n\nIf needed, we can reset the index to be the numbering of the rows:\n\ndf = df.reset_index()\ndf.head()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\n\nWithout running the code, give a step-by-step breakdown of what this code is doing:\n\ndf.set_index('year').loc[:,'SDW_winter':'TJE_fall'].plot()\n\nIs this code modifying the data frame df? Why or why not?\nRun the code and examine the graph. Review the data description. Do we have all the necessary information to make sure it makes sense to directly compare the surveys at these different sites?",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#method-chaining",
    "href": "book/chapters/lesson-4-plotting-pandas.html#method-chaining",
    "title": "3 Basic plotting",
    "section": "",
    "text": "The code used in the check-in\ndf.set_index('year').loc[:,'SDW_winter':'TJE_fall'].plot()\nis an example of method chaining. Each method in the chain returns an object (typically the same object), allowing the next method to be called directly on the result. This is a powerful technique that makes code concise and readable.\nChaining methods can result in lines of code that are too long and hard to read. We can break up chains of methods by using parenthesis:\n(df.set_index('year')\n  .loc[:,'SDW_winter':'TJE_fall']\n  .plot()\n)\n\n\n\n\n\n\nMethod chaining and the R pipe operator\n\n\n\nIf you are familiar with R, you may have noticed that the period . in the method chianing acts in the same way as the R pipe operator (%&gt;% or |&gt;). The syntax of one method per line is similar to what is used in the tidyverse, except that the pipe is used at the end of the line, while the period is used at the beginning of the line.\n\n\nAn alternative to the previous code chaining could have been:\nyear_index_df = df.set_index('year')\nsubset_df = year_index_df.loc[:,'SDW_winter':'TJE_fall']\nsubset_df.plot()\nWhile this accomplishes the same output, several variables are created along the way and it can be difficult to keep track of what is what.\n\n\n\n\n\n\nUse method chaining wisely\n\n\n\nMethod chaining is particularly useful in pandas for streamlining multiple data manipulations. However:\n\nmethod chaining should be used with care to avoid overly complex and difficult-to-debug code, and\nif you‚Äôre not familiar with the methods, it‚Äôs better to apply them individually and review the results after each step.\n\n\n\nWe will move on to another dataset for the rest of this lesson.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#about-the-data-1",
    "href": "book/chapters/lesson-4-plotting-pandas.html#about-the-data-1",
    "title": "3 Basic plotting",
    "section": "",
    "text": "For the next plots we will use the Palmer Penguins dataset [2] developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica during 2007, 2008, and 2009.\n\n\n\nThe Palmer Archipelago penguins. Artwork by Dr.¬†Allison Horst.\n\n\nThe dataset has 344 rows and 8 columns. We can see it‚Äôs first three rows below:\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#data-exploration",
    "href": "book/chapters/lesson-4-plotting-pandas.html#data-exploration",
    "title": "3 Basic plotting",
    "section": "",
    "text": "The data is usually accessed through the palmerpenguins R data package [2]. In this lesson we will access the CSV directly into our workspace using the URL: https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\nLet‚Äôs start by reading in the data:\n\n# Read in data\nURL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\npenguins = pd.read_csv(URL)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nAnd getting some preliminary information:\n\n# Check column data types and NA values\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\n\n# Simple statistics about numeric columns\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\nWe can also subset the dataframe to get information about a particular column or groups of columns:\n\n# Count unique values in categorical columns and year\npenguins[['species', 'island', 'sex', 'year']].nunique()\n\nspecies    3\nisland     3\nsex        2\nyear       3\ndtype: int64\n\n\n\n# Get unique values in species column\npenguins['species'].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\n\n# Number of values per unique value in species column\npenguins['species'].value_counts()\n\nspecies\nAdelie       152\nGentoo       124\nChinstrap     68\nName: count, dtype: int64",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#kind-argument-in-plot",
    "href": "book/chapters/lesson-4-plotting-pandas.html#kind-argument-in-plot",
    "title": "3 Basic plotting",
    "section": "",
    "text": "At the beginning of the lesson we talked about how the plot() method creates a line plot by default. The parameter that controls this behaviour is the kind parameter. By changing the value of kind we can create different kinds of plots. Let‚Äôs look at the documentation to see what these values are:\n\n\n\nExtract from the pandas.DataFrame.plot documentation. Accessed on Sept 25,2024\n\n\nNotice the default value of kind is 'line'.\nLet‚Äôs change the kind parameter to create some different plots.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#scatter-plots",
    "href": "book/chapters/lesson-4-plotting-pandas.html#scatter-plots",
    "title": "3 Basic plotting",
    "section": "",
    "text": "Suppose we want to visualy compare the flipper length against the body mass, we can do this with a scatterplot:\n\npenguins.plot(kind='scatter',\n              x='flipper_length_mm', \n              y='body_mass_g')\n\n\n\n\n\n\n\n\nWe can update some other arguments to customize the graph:\n\npenguins.plot(kind='scatter',\n              x='flipper_length_mm', \n              y='body_mass_g',\n              title='Flipper length and body mass for Palmer penguins',\n              xlabel='Flipper length (mm)',\n              ylabel='Body mass (g)',\n              color='#ff3b01',\n              alpha=0.4  # Controls transparency\n              )",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#bar-plots",
    "href": "book/chapters/lesson-4-plotting-pandas.html#bar-plots",
    "title": "3 Basic plotting",
    "section": "",
    "text": "We can create bar plots of our data setting kind='bar' in the plot() method.\nFor example, let‚Äôs say we want to get data about the 10 penguins with lowest body mass. We can first select this data using the nsmallest() method for series:\n\nsmallest = penguins['body_mass_g'].nsmallest(10)\nsmallest\n\n314    2700.0\n58     2850.0\n64     2850.0\n54     2900.0\n98     2900.0\n116    2900.0\n298    2900.0\n104    2925.0\n47     2975.0\n44     3000.0\nName: body_mass_g, dtype: float64\n\n\nWe can then plot this data as a bar plot\n\nsmallest.plot(kind='bar')\n\n\n\n\n\n\n\n\nIf we wanted to look at other data for these smallest penguins we can use a different call to the nsmallest method:\n\npenguins.nsmallest(10, 'body_mass_g')\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n314\nChinstrap\nDream\n46.9\n16.6\n192.0\n2700.0\nfemale\n2008\n\n\n58\nAdelie\nBiscoe\n36.5\n16.6\n181.0\n2850.0\nfemale\n2008\n\n\n64\nAdelie\nBiscoe\n36.4\n17.1\n184.0\n2850.0\nfemale\n2008\n\n\n54\nAdelie\nBiscoe\n34.5\n18.1\n187.0\n2900.0\nfemale\n2008\n\n\n98\nAdelie\nDream\n33.1\n16.1\n178.0\n2900.0\nfemale\n2008\n\n\n116\nAdelie\nTorgersen\n38.6\n17.0\n188.0\n2900.0\nfemale\n2009\n\n\n298\nChinstrap\nDream\n43.2\n16.6\n187.0\n2900.0\nfemale\n2007\n\n\n104\nAdelie\nBiscoe\n37.9\n18.6\n193.0\n2925.0\nfemale\n2009\n\n\n47\nAdelie\nDream\n37.5\n18.9\n179.0\n2975.0\nNaN\n2007\n\n\n44\nAdelie\nDream\n37.0\n16.9\n185.0\n3000.0\nfemale\n2007",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-4-plotting-pandas.html#histograms",
    "href": "book/chapters/lesson-4-plotting-pandas.html#histograms",
    "title": "3 Basic plotting",
    "section": "",
    "text": "We can create a histogram of our data setting kind='hist' in plot().\n\n# Using plot without subsetting data - a mess again\npenguins.plot(kind='hist')\n\n\n\n\n\n\n\n\nTo gain actual information, let‚Äôs subset the data before plotting it. For example, suppose we want to do a preliminary graph for the distribution of flipper length. We could do it in this way:\n\n# Distribution of flipper length measurements\n# First select data, then plot\npenguins['flipper_length_mm'].plot(kind='hist',\n                                title='Penguin flipper lengths',\n                                xlabel='Flipper length (mm)',\n                                grid=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\n\nSelect the bill_length_mm and bill_depth_mm columns in the penguins dataframe and then update the kind parameter to box to make boxplots of the bill length and bill depth. \nCreate a simple histogram of the flipper length of female gentoo penguins.",
    "crumbs": [
      "notes",
      "Tabular data",
      "3 Basic plotting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-5-updating-dataframes.html",
    "href": "book/chapters/lesson-5-updating-dataframes.html",
    "title": "Adding a single column‚Ä¶",
    "section": "",
    "text": "In this lesson we will introduce methods for updating a pandas.DataFrame, these include adding and removing columns and updating specific values.\n\n\n\nFor this section we will use the Palmer Penguins dataset [1] developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica during 2007, 2008, and 2009.\n\n\n\nThe Palmer Archipelago penguins. Artwork by Dr.¬†Allison Horst.\n\n\nThe dataset has 344 rows and 8 columns. We can see the head of the dataset below:\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nLet us start by importing the packages we will use in this lesson and loading the data:\n\nimport numpy as np\nimport pandas as pd\nimport random  # Used for randomly sampling integers\n\n# Set the seed\nrandom.seed(42)\n\n# Import data\nURL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\npenguins = pd.read_csv(URL)\n\n\n\n\nThe simplest syntax to add a new column to a pandas.DataFrame is\ndf['new_col_name'] = new_column_values\nwhere the new_column_values could be:\n\na pandas.Series or a numpy.array of the same length as the data frame, or\na single scalar.\n\nIf the column name exists, the existing column will be updated.\nRemember a pandas.DataFrame can be seen as a dictionary of its columns. This syntax for adding a new column to a pandas.DataFrame is the same as adding a new key-value pair to a dictionary:\n# Add a new key-value pair to a dictionary\ndict[new_key] = new_value\n\n\nWe want to create a new column where the body mass is in kilograms instead of grams, then we need to divide each value in the body_mass_g by 1000.\n\n# Add new column body_mass_kg \npenguins['body_mass_kg'] = penguins['body_mass_g']/1000\n\n# Confirm the new column is in the data frame\nprint(\"body_mass_kg is in the data frame's columns: \", 'body_mass_kg' in penguins.columns)\n\n# Look at the new column\npenguins.head()\n\nbody_mass_kg is in the data frame's columns:  True\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45\n\n\n\n\n\n\n\n\n\n\n\nWe can also create or update an existing column using the assign() method for pandas.DataFrames. The general syntax is:\ndf = df.assign(new_col_name=new_column_values)\nNotice the new column names are not strings, we declare them as if we were creating variables.\nThis way of creating a new column, unlike the dictionary-like syntax, does not modify the data frame in-place. This can be useful for chaining operations:\n\n(penguins.assign(bill_length_cm=penguins.bill_length_mm/10)\n        .plot(kind='scatter',\n              x='bill_length_cm', \n              y='body_mass_g')\n    )\n\n\n\n\n\n\n\n\n\n\n\nThe new column was added by default at the end of the data frame. If we want to create a new column and insert it at a particular position we can use the data frame method insert():\ndf.insert(loc=integer_index,  # Location of new column\n          column='new_col_name', \n          value=new_col_values)\n\n\nLet‚Äôs give each penguin observation a unique identifier as a three digit number and add this column at the beginning of the data frame.\n\n# Create random 3-digit codes\ncodes = random.sample(range(100,1000), len(penguins))  # Sampling w/o replacement\n\n# Insert codes at the front of data frame\npenguins.insert(loc=0,  # Index\n                column='id_code',\n                value=codes)\n        \npenguins.head()\n\n\n\n\n\n\n\n\nid_code\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\n\n\n\n\n0\n754\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n\n\n1\n214\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n\n\n2\n125\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n\n\n3\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\n\n\n4\n381\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also use the assign() method to create or update multiple columns in the same call. The general syntax is:\ndf = df.assign(new_col1_name=new_col1_values, \n               new_col2_name=new_col2_values)\nRemember this method does not modify the data frame, so you will need to reassign the output to the original data frame to update it.\n\n\nSuppose we want to add these new columns:\n\nflipper length converted from mm to cm, and\na code representing the observer.\n\nWe can add these columns to penguins using assign():\n\n# Create columns with observer codes and flipper length in cm\npenguins = penguins.assign(flipper_length_cm=penguins.flipper_length_mm/10, \n                           observer=random.choices(['A','B','C'],  # Sample with replacement\n                                                    k=len(penguins))\n                          )\n# Examine result\npenguins.head()\n\n\n\n\n\n\n\n\nid_code\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\n\n\n\n\n0\n754\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n18.1\nC\n\n\n1\n214\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n18.6\nA\n\n\n2\n125\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n19.5\nC\n\n\n3\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\n\n\n4\n381\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45\n19.3\nB\n\n\n\n\n\n\n\n\n\n\n\nWe can remove columns using the drop() method for pandas.Data.Frames, the syntax is:\ndf = df.drop(columns=col_names)\nwhere col_names can be a single column name (string) or a list of column names. Notice again that the drop() method does not modify the data frame in place, so you need to reassign the output.\n\n\nNow that we updated the units for flipper length and body mass, it makes sense to remove the previous columns to avoid duplicate information. We can do this using drop():\n\n# Remove duplicate length and mass measurements\npenguins = penguins.drop(columns=['flipper_length_mm','body_mass_g'])\n\n# Confirm result\nprint(penguins.columns)\n\nIndex(['id_code', 'species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'sex', 'year', 'body_mass_kg', 'flipper_length_cm', 'observer'],\n      dtype='object')\n\n\n\n\n\n\n\n\nSometimes we want to update a specific value in our data frame. We‚Äôll review some methods and best practices to do that in this section.\n\n\nWe can access a single value in a pandas.DataFrame using the locators\n\nat[] to select by labels, or\niat[] to select by position.\n\nThe syntax for at[] is:\ndf.at[single_index_value, 'column_name']\nThink of at[] as the equivalent to loc[] when trying to access a single value.\n\n\nFor this example, let‚Äôs first update the index of the data frame to be the id_code column:\n\npenguins = penguins.set_index('id_code')\npenguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n754\nAdelie\nTorgersen\n39.1\n18.7\nmale\n2007\n3.750\n18.1\nC\n\n\n214\nAdelie\nTorgersen\n39.5\n17.4\nfemale\n2007\n3.800\n18.6\nA\n\n\n125\nAdelie\nTorgersen\n40.3\n18.0\nfemale\n2007\n3.250\n19.5\nC\n\n\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\n\n\n381\nAdelie\nTorgersen\n36.7\n19.3\nfemale\n2007\n3.450\n19.3\nB\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n140\nChinstrap\nDream\n55.8\n19.8\nmale\n2009\n4.000\n20.7\nC\n\n\n183\nChinstrap\nDream\n43.5\n18.1\nfemale\n2009\n3.400\n20.2\nA\n\n\n969\nChinstrap\nDream\n49.6\n18.2\nmale\n2009\n3.775\n19.3\nC\n\n\n635\nChinstrap\nDream\n50.8\n19.0\nmale\n2009\n4.100\n21.0\nA\n\n\n883\nChinstrap\nDream\n50.2\n18.7\nfemale\n2009\n3.775\n19.8\nB\n\n\n\n\n344 rows √ó 9 columns\n\n\n\nIf we want to know what was the bill length of the penguin which has ID number 859, we can directly access that information using at[]:\n\n# Check bill length of penguin with ID 859\npenguins.at[859, 'bill_length_mm']\n\nnan\n\n\nWe get this bill length is an NA. Maybe we want to update it to 38.3 mm. We can do this with at[] too:\n\n# Correct bill length value of penguin with ID 859\npenguins.at[859,'bill_length_mm'] = 38.3\n\n# Confirm value was updated\npenguins.loc[859]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            38.3\nbill_depth_mm              NaN\nsex                        NaN\nyear                      2007\nbody_mass_kg               NaN\nflipper_length_cm          NaN\nobserver                     A\nName: 859, dtype: object\n\n\nIf we want to access or update a single value by position we use the iat[] locator. The syntax for iat[] is:\ndf.iat[index_integer_location, column_integer_location]\nThis is the same way you would index entries in a matrix. You may find it useful to think of iat[] as the equivalent of iloc[] to access a single value in the data frame.\nObtaining the location of a specific column within the column list can be prone to error if we do it ‚Äòby hand‚Äô. If we need to obtain this index, we can dynamically get the location this way:\npenguins.columns.get_loc('column_name')\n\n\n\n\n\n\nCheck-in\n\n\n\n\nObtain the location of the bill_length_mm column.\nUse iat[] to access the same bill length value for the penguin with ID 859 and revert it back to an NA. Confirm your update using iloc[].\n\n\n\n\n\n\n\n\nWhat if we want to update multiple values in a column? We‚Äôll cover two cases: with a condition on the column values and by selecting a few values to update.\n\n\nOften, we need to create a new column where the new values depend on conditions on another column.\n\n\n\nWe want to classify the Palmer penguins such that :\n\npenguins with body mass less than 3kg as small,\npenguins with body mass greater or equal than 3 kg but less than 5 kg as medium,\nand those with body mass greater or equal than 5 kg as large.\n\nOne way to add this information in a new column is using the numpy.select() function:\n\n# Create a list with the conditions\nconditions = [penguins.body_mass_kg &lt; 3, \n              (3 &lt;= penguins.body_mass_kg) & (penguins.body_mass_kg &lt; 5),\n              5 &lt;= penguins.body_mass_kg]\n\n# Create a list with the choices\nchoices = [\"small\",\n           \"medium\",\n           \"large\"]\n\n# Add the selections using np.select\npenguins['size'] = np.select(conditions, \n                             choices, \n                             default=np.nan) # Value for anything outside conditions\n\n# Display the updated data frame to confirm the new column\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\nsize\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n754\nAdelie\nTorgersen\n39.1\n18.7\nmale\n2007\n3.75\n18.1\nC\nmedium\n\n\n214\nAdelie\nTorgersen\n39.5\n17.4\nfemale\n2007\n3.80\n18.6\nA\nmedium\n\n\n125\nAdelie\nTorgersen\n40.3\n18.0\nfemale\n2007\n3.25\n19.5\nC\nmedium\n\n\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\nnan\n\n\n381\nAdelie\nTorgersen\n36.7\n19.3\nfemale\n2007\n3.45\n19.3\nB\nmedium\n\n\n\n\n\n\n\n\n\n\n\nWhen we only want to update some values in a column we can do this by selecting this data using loc (if selecting by labels) or iloc (if selecting by position). The general syntax for updating data with loc is:\ndf.loc[row_selection, column_name] = new_values\nwhere\n\nrow_selection is the rows we want to update, this can be any expression that gives us a boolean pandas.Series,\ncol_name is a single column name, and\nnew_values is the new value or values we want. If using multiple values, then new_values must be of the same length as the number of rows selected.\n\nUsing loc[] in assignment modifies the data frame directly without the need for reassignment.\n\n\n\nWe want to update the ‚Äúmale‚Äù values in the sex column to ‚ÄúM‚Äù.\n\n# Select rows with sex=male and simplify values in 'sex' column\npenguins.loc[penguins.sex=='male', 'sex'] = 'M'\n\n# Check changes in 'sex' column specifically\nprint(penguins['sex'].unique())\n\n['M' 'female' nan]\n\n\n\n\n\n\nSuppose we want to similarly update the ‚Äúfemale‚Äù values in the sex column to ‚ÄúF‚Äù. This is an example of another way we might try to do it:\n\n# Select rows where 'sex' is 'female' and then attempt to update 'sex' column values\npenguins[penguins.sex=='female']['sex'] = 'F' # This raises SettingWithCopyWarning\n\n/var/folders/gm/chd1kps96_g7xdxyfw150wm80000gp/T/ipykernel_7781/534867616.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  penguins[penguins.sex=='female']['sex'] = 'F' # This raises SettingWithCopyWarning\n\n\nWhen we select the data we want to update using chained indexing (two selection brackets [][]) instead of loc[] we get a SettingWithCopyWarning. With this warning, pandas is trying to alert us to a potential bug. In this case, the bug is that we actually did not update our data frame:\n\n# Confirm values were updated\nprint(penguins['sex'].unique())\n\n['M' 'female' nan]\n\n\n\n\n\n\n\n\nAvoid chained indexing [][] and use .loc[]\n\n\n\nThe SettingWithCopyWarning often arises from chained indexing:\ndf[df['col'] == value]['col2'] = new_value\nIn the words of the pandas documentation:\n\nassigning to the product of chained indexing has inherently unpredictable results.\n\nThe best practice is to use .loc[] instead:\ndf.loc[df['col'] == value,'col2'] = new_value\n.loc[] is generally more readable and explicitly modifies the original data frame.\nWarnings in Python are intended to be helpful and can prevent unintended data modification errors!\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nUpdate the ‚Äúfemale‚Äù values in the penguins data frame to ‚ÄúF‚Äù. Don‚Äôt use chained indexing. Confirm that the values in the column were updated.\n\n\n\nTo understand why the SettingWithCopyWarning pops up we need to understand that some pandas operations return a view to your data, while others return a copy of your data.\n\nViews are actual subsets of the original data, when we update them, we are modifying the original data frame.\nCopies are unique objects, independent of our original data frames. When we update a copy we are not modifying the original data frame.\n\n\n\nDepending on what we are trying to do we might want to modify the original data frame or we might want to modify a copy.\n\nPandas raises the SettingWithCopyWarning because it tries to balance memory efficiency with data integrity. By default, it avoids creating unnecessary copies, but sometimes it‚Äôs ambiguous whether a subset should be independent (a copy) or connected (a view).\n\n\nWe only want to use data from Biscoe island and, after doing some analyses, we want to add a new column to it:\n\n# Select penguins from Biscoe island\nbiscoe = penguins[penguins.island=='Biscoe']\n\n# ... Other analyses ...\n\n# Add a column\nbiscoe['sample_col'] = 100  # This raises SettingWithCopyWarning\n\n/var/folders/gm/chd1kps96_g7xdxyfw150wm80000gp/T/ipykernel_7781/844154415.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  biscoe['sample_col'] = 100  # This raises SettingWithCopyWarning\n\n\npandas is trying to alert you that it is unsure about whether biscoe is a view or a copy and it‚Äôs unclear whether an of our code will modify our dataset or not.\nTo fix this we can take control of the copy-view situation and explicitly ask for a copy of the dataset when subsetting the data. Use the copy() method to do this:\n\n# Make sure you get an independent data frame that won't alter the original\nbiscoe = penguins[penguins.island=='Biscoe'].copy()\n\n# Add a column, no warning\nbiscoe['sample_col'] = 100\n\nNow we are sure we did not modify our initial data, but rather the biscoe data frame:\n\n# Confirm the new column is in our subset data\nbiscoe.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\nsize\nsample_col\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n338\nAdelie\nBiscoe\n37.8\n18.3\nF\n2007\n3.40\n17.4\nA\nmedium\n100\n\n\n617\nAdelie\nBiscoe\n37.7\n18.7\nM\n2007\n3.60\n18.0\nC\nmedium\n100\n\n\n716\nAdelie\nBiscoe\n35.9\n19.2\nF\n2007\n3.80\n18.9\nC\nmedium\n100\n\n\n127\nAdelie\nBiscoe\n38.2\n18.1\nM\n2007\n3.95\n18.5\nB\nmedium\n100\n\n\n674\nAdelie\nBiscoe\n38.8\n17.2\nM\n2007\n3.80\n18.0\nC\nmedium\n100\n\n\n\n\n\n\n\n\n# Confirm that original data was not modified\nprint('sample_column' in penguins.columns)\n\nFalse\n\n\nThe SettingWithCopyWarning can be tricky, there are also false positives and false negatives. Avoiding chained indexing and making a copy of your data frame subset when needed and possible will save you from the usual pitfalls!\nTo learn more about the SettingWithCopyWarning, these are some articles that go into more depth:\nüìñ pandas Documentation - Returning a view versus a copy\nüìñ Real Python- SettingWithCopyWarning in pandas: Views vs Copies\nüìñ Dataquest - SettingwithCopyWarning: How to Fix This Warning in Pandas",
    "crumbs": [
      "notes",
      "Tabular data",
      "4 Updating data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-5-updating-dataframes.html#about-the-data",
    "href": "book/chapters/lesson-5-updating-dataframes.html#about-the-data",
    "title": "Adding a single column‚Ä¶",
    "section": "",
    "text": "For this section we will use the Palmer Penguins dataset [1] developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica during 2007, 2008, and 2009.\n\n\n\nThe Palmer Archipelago penguins. Artwork by Dr.¬†Allison Horst.\n\n\nThe dataset has 344 rows and 8 columns. We can see the head of the dataset below:\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nLet us start by importing the packages we will use in this lesson and loading the data:\n\nimport numpy as np\nimport pandas as pd\nimport random  # Used for randomly sampling integers\n\n# Set the seed\nrandom.seed(42)\n\n# Import data\nURL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\npenguins = pd.read_csv(URL)\n\n\n\n\nThe simplest syntax to add a new column to a pandas.DataFrame is\ndf['new_col_name'] = new_column_values\nwhere the new_column_values could be:\n\na pandas.Series or a numpy.array of the same length as the data frame, or\na single scalar.\n\nIf the column name exists, the existing column will be updated.\nRemember a pandas.DataFrame can be seen as a dictionary of its columns. This syntax for adding a new column to a pandas.DataFrame is the same as adding a new key-value pair to a dictionary:\n# Add a new key-value pair to a dictionary\ndict[new_key] = new_value\n\n\nWe want to create a new column where the body mass is in kilograms instead of grams, then we need to divide each value in the body_mass_g by 1000.\n\n# Add new column body_mass_kg \npenguins['body_mass_kg'] = penguins['body_mass_g']/1000\n\n# Confirm the new column is in the data frame\nprint(\"body_mass_kg is in the data frame's columns: \", 'body_mass_kg' in penguins.columns)\n\n# Look at the new column\npenguins.head()\n\nbody_mass_kg is in the data frame's columns:  True\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45\n\n\n\n\n\n\n\n\n\n\n\nWe can also create or update an existing column using the assign() method for pandas.DataFrames. The general syntax is:\ndf = df.assign(new_col_name=new_column_values)\nNotice the new column names are not strings, we declare them as if we were creating variables.\nThis way of creating a new column, unlike the dictionary-like syntax, does not modify the data frame in-place. This can be useful for chaining operations:\n\n(penguins.assign(bill_length_cm=penguins.bill_length_mm/10)\n        .plot(kind='scatter',\n              x='bill_length_cm', \n              y='body_mass_g')\n    )\n\n\n\n\n\n\n\n\n\n\n\nThe new column was added by default at the end of the data frame. If we want to create a new column and insert it at a particular position we can use the data frame method insert():\ndf.insert(loc=integer_index,  # Location of new column\n          column='new_col_name', \n          value=new_col_values)\n\n\nLet‚Äôs give each penguin observation a unique identifier as a three digit number and add this column at the beginning of the data frame.\n\n# Create random 3-digit codes\ncodes = random.sample(range(100,1000), len(penguins))  # Sampling w/o replacement\n\n# Insert codes at the front of data frame\npenguins.insert(loc=0,  # Index\n                column='id_code',\n                value=codes)\n        \npenguins.head()\n\n\n\n\n\n\n\n\nid_code\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\n\n\n\n\n0\n754\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n\n\n1\n214\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n\n\n2\n125\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n\n\n3\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\n\n\n4\n381\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45",
    "crumbs": [
      "notes",
      "Tabular data",
      "4 Updating data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-5-updating-dataframes.html#adding-multiple-columns",
    "href": "book/chapters/lesson-5-updating-dataframes.html#adding-multiple-columns",
    "title": "Adding a single column‚Ä¶",
    "section": "",
    "text": "We can also use the assign() method to create or update multiple columns in the same call. The general syntax is:\ndf = df.assign(new_col1_name=new_col1_values, \n               new_col2_name=new_col2_values)\nRemember this method does not modify the data frame, so you will need to reassign the output to the original data frame to update it.\n\n\nSuppose we want to add these new columns:\n\nflipper length converted from mm to cm, and\na code representing the observer.\n\nWe can add these columns to penguins using assign():\n\n# Create columns with observer codes and flipper length in cm\npenguins = penguins.assign(flipper_length_cm=penguins.flipper_length_mm/10, \n                           observer=random.choices(['A','B','C'],  # Sample with replacement\n                                                    k=len(penguins))\n                          )\n# Examine result\npenguins.head()\n\n\n\n\n\n\n\n\nid_code\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\n\n\n\n\n0\n754\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n3.75\n18.1\nC\n\n\n1\n214\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n3.80\n18.6\nA\n\n\n2\n125\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n3.25\n19.5\nC\n\n\n3\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\n\n\n4\n381\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n3.45\n19.3\nB",
    "crumbs": [
      "notes",
      "Tabular data",
      "4 Updating data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-5-updating-dataframes.html#removing-columns",
    "href": "book/chapters/lesson-5-updating-dataframes.html#removing-columns",
    "title": "Adding a single column‚Ä¶",
    "section": "",
    "text": "We can remove columns using the drop() method for pandas.Data.Frames, the syntax is:\ndf = df.drop(columns=col_names)\nwhere col_names can be a single column name (string) or a list of column names. Notice again that the drop() method does not modify the data frame in place, so you need to reassign the output.\n\n\nNow that we updated the units for flipper length and body mass, it makes sense to remove the previous columns to avoid duplicate information. We can do this using drop():\n\n# Remove duplicate length and mass measurements\npenguins = penguins.drop(columns=['flipper_length_mm','body_mass_g'])\n\n# Confirm result\nprint(penguins.columns)\n\nIndex(['id_code', 'species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'sex', 'year', 'body_mass_kg', 'flipper_length_cm', 'observer'],\n      dtype='object')",
    "crumbs": [
      "notes",
      "Tabular data",
      "4 Updating data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-5-updating-dataframes.html#updating-values",
    "href": "book/chapters/lesson-5-updating-dataframes.html#updating-values",
    "title": "Adding a single column‚Ä¶",
    "section": "",
    "text": "Sometimes we want to update a specific value in our data frame. We‚Äôll review some methods and best practices to do that in this section.\n\n\nWe can access a single value in a pandas.DataFrame using the locators\n\nat[] to select by labels, or\niat[] to select by position.\n\nThe syntax for at[] is:\ndf.at[single_index_value, 'column_name']\nThink of at[] as the equivalent to loc[] when trying to access a single value.\n\n\nFor this example, let‚Äôs first update the index of the data frame to be the id_code column:\n\npenguins = penguins.set_index('id_code')\npenguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n754\nAdelie\nTorgersen\n39.1\n18.7\nmale\n2007\n3.750\n18.1\nC\n\n\n214\nAdelie\nTorgersen\n39.5\n17.4\nfemale\n2007\n3.800\n18.6\nA\n\n\n125\nAdelie\nTorgersen\n40.3\n18.0\nfemale\n2007\n3.250\n19.5\nC\n\n\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\n\n\n381\nAdelie\nTorgersen\n36.7\n19.3\nfemale\n2007\n3.450\n19.3\nB\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n140\nChinstrap\nDream\n55.8\n19.8\nmale\n2009\n4.000\n20.7\nC\n\n\n183\nChinstrap\nDream\n43.5\n18.1\nfemale\n2009\n3.400\n20.2\nA\n\n\n969\nChinstrap\nDream\n49.6\n18.2\nmale\n2009\n3.775\n19.3\nC\n\n\n635\nChinstrap\nDream\n50.8\n19.0\nmale\n2009\n4.100\n21.0\nA\n\n\n883\nChinstrap\nDream\n50.2\n18.7\nfemale\n2009\n3.775\n19.8\nB\n\n\n\n\n344 rows √ó 9 columns\n\n\n\nIf we want to know what was the bill length of the penguin which has ID number 859, we can directly access that information using at[]:\n\n# Check bill length of penguin with ID 859\npenguins.at[859, 'bill_length_mm']\n\nnan\n\n\nWe get this bill length is an NA. Maybe we want to update it to 38.3 mm. We can do this with at[] too:\n\n# Correct bill length value of penguin with ID 859\npenguins.at[859,'bill_length_mm'] = 38.3\n\n# Confirm value was updated\npenguins.loc[859]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            38.3\nbill_depth_mm              NaN\nsex                        NaN\nyear                      2007\nbody_mass_kg               NaN\nflipper_length_cm          NaN\nobserver                     A\nName: 859, dtype: object\n\n\nIf we want to access or update a single value by position we use the iat[] locator. The syntax for iat[] is:\ndf.iat[index_integer_location, column_integer_location]\nThis is the same way you would index entries in a matrix. You may find it useful to think of iat[] as the equivalent of iloc[] to access a single value in the data frame.\nObtaining the location of a specific column within the column list can be prone to error if we do it ‚Äòby hand‚Äô. If we need to obtain this index, we can dynamically get the location this way:\npenguins.columns.get_loc('column_name')\n\n\n\n\n\n\nCheck-in\n\n\n\n\nObtain the location of the bill_length_mm column.\nUse iat[] to access the same bill length value for the penguin with ID 859 and revert it back to an NA. Confirm your update using iloc[].\n\n\n\n\n\n\n\n\nWhat if we want to update multiple values in a column? We‚Äôll cover two cases: with a condition on the column values and by selecting a few values to update.\n\n\nOften, we need to create a new column where the new values depend on conditions on another column.\n\n\n\nWe want to classify the Palmer penguins such that :\n\npenguins with body mass less than 3kg as small,\npenguins with body mass greater or equal than 3 kg but less than 5 kg as medium,\nand those with body mass greater or equal than 5 kg as large.\n\nOne way to add this information in a new column is using the numpy.select() function:\n\n# Create a list with the conditions\nconditions = [penguins.body_mass_kg &lt; 3, \n              (3 &lt;= penguins.body_mass_kg) & (penguins.body_mass_kg &lt; 5),\n              5 &lt;= penguins.body_mass_kg]\n\n# Create a list with the choices\nchoices = [\"small\",\n           \"medium\",\n           \"large\"]\n\n# Add the selections using np.select\npenguins['size'] = np.select(conditions, \n                             choices, \n                             default=np.nan) # Value for anything outside conditions\n\n# Display the updated data frame to confirm the new column\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\nsize\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n754\nAdelie\nTorgersen\n39.1\n18.7\nmale\n2007\n3.75\n18.1\nC\nmedium\n\n\n214\nAdelie\nTorgersen\n39.5\n17.4\nfemale\n2007\n3.80\n18.6\nA\nmedium\n\n\n125\nAdelie\nTorgersen\n40.3\n18.0\nfemale\n2007\n3.25\n19.5\nC\nmedium\n\n\n859\nAdelie\nTorgersen\nNaN\nNaN\nNaN\n2007\nNaN\nNaN\nA\nnan\n\n\n381\nAdelie\nTorgersen\n36.7\n19.3\nfemale\n2007\n3.45\n19.3\nB\nmedium\n\n\n\n\n\n\n\n\n\n\n\nWhen we only want to update some values in a column we can do this by selecting this data using loc (if selecting by labels) or iloc (if selecting by position). The general syntax for updating data with loc is:\ndf.loc[row_selection, column_name] = new_values\nwhere\n\nrow_selection is the rows we want to update, this can be any expression that gives us a boolean pandas.Series,\ncol_name is a single column name, and\nnew_values is the new value or values we want. If using multiple values, then new_values must be of the same length as the number of rows selected.\n\nUsing loc[] in assignment modifies the data frame directly without the need for reassignment.\n\n\n\nWe want to update the ‚Äúmale‚Äù values in the sex column to ‚ÄúM‚Äù.\n\n# Select rows with sex=male and simplify values in 'sex' column\npenguins.loc[penguins.sex=='male', 'sex'] = 'M'\n\n# Check changes in 'sex' column specifically\nprint(penguins['sex'].unique())\n\n['M' 'female' nan]\n\n\n\n\n\n\nSuppose we want to similarly update the ‚Äúfemale‚Äù values in the sex column to ‚ÄúF‚Äù. This is an example of another way we might try to do it:\n\n# Select rows where 'sex' is 'female' and then attempt to update 'sex' column values\npenguins[penguins.sex=='female']['sex'] = 'F' # This raises SettingWithCopyWarning\n\n/var/folders/gm/chd1kps96_g7xdxyfw150wm80000gp/T/ipykernel_7781/534867616.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  penguins[penguins.sex=='female']['sex'] = 'F' # This raises SettingWithCopyWarning\n\n\nWhen we select the data we want to update using chained indexing (two selection brackets [][]) instead of loc[] we get a SettingWithCopyWarning. With this warning, pandas is trying to alert us to a potential bug. In this case, the bug is that we actually did not update our data frame:\n\n# Confirm values were updated\nprint(penguins['sex'].unique())\n\n['M' 'female' nan]\n\n\n\n\n\n\n\n\nAvoid chained indexing [][] and use .loc[]\n\n\n\nThe SettingWithCopyWarning often arises from chained indexing:\ndf[df['col'] == value]['col2'] = new_value\nIn the words of the pandas documentation:\n\nassigning to the product of chained indexing has inherently unpredictable results.\n\nThe best practice is to use .loc[] instead:\ndf.loc[df['col'] == value,'col2'] = new_value\n.loc[] is generally more readable and explicitly modifies the original data frame.\nWarnings in Python are intended to be helpful and can prevent unintended data modification errors!\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nUpdate the ‚Äúfemale‚Äù values in the penguins data frame to ‚ÄúF‚Äù. Don‚Äôt use chained indexing. Confirm that the values in the column were updated.\n\n\n\nTo understand why the SettingWithCopyWarning pops up we need to understand that some pandas operations return a view to your data, while others return a copy of your data.\n\nViews are actual subsets of the original data, when we update them, we are modifying the original data frame.\nCopies are unique objects, independent of our original data frames. When we update a copy we are not modifying the original data frame.\n\n\n\nDepending on what we are trying to do we might want to modify the original data frame or we might want to modify a copy.\n\nPandas raises the SettingWithCopyWarning because it tries to balance memory efficiency with data integrity. By default, it avoids creating unnecessary copies, but sometimes it‚Äôs ambiguous whether a subset should be independent (a copy) or connected (a view).\n\n\nWe only want to use data from Biscoe island and, after doing some analyses, we want to add a new column to it:\n\n# Select penguins from Biscoe island\nbiscoe = penguins[penguins.island=='Biscoe']\n\n# ... Other analyses ...\n\n# Add a column\nbiscoe['sample_col'] = 100  # This raises SettingWithCopyWarning\n\n/var/folders/gm/chd1kps96_g7xdxyfw150wm80000gp/T/ipykernel_7781/844154415.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  biscoe['sample_col'] = 100  # This raises SettingWithCopyWarning\n\n\npandas is trying to alert you that it is unsure about whether biscoe is a view or a copy and it‚Äôs unclear whether an of our code will modify our dataset or not.\nTo fix this we can take control of the copy-view situation and explicitly ask for a copy of the dataset when subsetting the data. Use the copy() method to do this:\n\n# Make sure you get an independent data frame that won't alter the original\nbiscoe = penguins[penguins.island=='Biscoe'].copy()\n\n# Add a column, no warning\nbiscoe['sample_col'] = 100\n\nNow we are sure we did not modify our initial data, but rather the biscoe data frame:\n\n# Confirm the new column is in our subset data\nbiscoe.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nsex\nyear\nbody_mass_kg\nflipper_length_cm\nobserver\nsize\nsample_col\n\n\nid_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n338\nAdelie\nBiscoe\n37.8\n18.3\nF\n2007\n3.40\n17.4\nA\nmedium\n100\n\n\n617\nAdelie\nBiscoe\n37.7\n18.7\nM\n2007\n3.60\n18.0\nC\nmedium\n100\n\n\n716\nAdelie\nBiscoe\n35.9\n19.2\nF\n2007\n3.80\n18.9\nC\nmedium\n100\n\n\n127\nAdelie\nBiscoe\n38.2\n18.1\nM\n2007\n3.95\n18.5\nB\nmedium\n100\n\n\n674\nAdelie\nBiscoe\n38.8\n17.2\nM\n2007\n3.80\n18.0\nC\nmedium\n100\n\n\n\n\n\n\n\n\n# Confirm that original data was not modified\nprint('sample_column' in penguins.columns)\n\nFalse\n\n\nThe SettingWithCopyWarning can be tricky, there are also false positives and false negatives. Avoiding chained indexing and making a copy of your data frame subset when needed and possible will save you from the usual pitfalls!\nTo learn more about the SettingWithCopyWarning, these are some articles that go into more depth:\nüìñ pandas Documentation - Returning a view versus a copy\nüìñ Real Python- SettingWithCopyWarning in pandas: Views vs Copies\nüìñ Dataquest - SettingwithCopyWarning: How to Fix This Warning in Pandas",
    "crumbs": [
      "notes",
      "Tabular data",
      "4 Updating data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html",
    "href": "book/chapters/lesson-2-series-dataframes.html",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "In this lesson we introduce the two core objects in the pandas library, the pandas.Series and the pandas.DataFrame. The overall goal is to gain familiarity with these two objects, understand their relation to each other, and review Python data structures such as dictionaries and lists.\n\n\nBy the end of this lesson, students will be able to:\n\nExplain the relation between pandas.Series and pandas.DataFrame\nConstruct simple pandas.Series and pandas.DataFrame from scratch using different initalization methods\nPerform simple operations on pandas.Series\nNavigate the pandas documentation to look for attributes and methods of pandas.Series and pandas.DataFrame\n\n\n\n\npandas [1] [2] is a Python package to wrangle and analyze tabular data. It is built on top of NumPy and has become the core tool for doing data analysis in Python.\nThe standard abbreviation for pandas is pd. Here we will import it together with NumPy:\n\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n\n\nConvention: importing packages\n\n\n\nAlways import all your packages in a single cell at the top of you notebook! Following the PEP 8 - Style Guide for Python Code [3], each package or library import should be in a separate line.\n\n\n\n\n\n\nThe first core object of pandas is the series. A series is a one-dimensional array of indexed data.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\nA pandas.Series having an index is the main difference between a pandas.Series and a NumPy array. Let‚Äôs see the difference:\n\n# A numpy array\narr = np.random.randn(4) # random values from std normal distribution\nprint(type(arr))\nprint(arr, \"\\n\")\n\n# A pandas series made from the previous array\ns = pd.Series(arr)\nprint(type(s))\nprint(s)\n\n&lt;class 'numpy.ndarray'&gt;\n[-0.11699598  0.6988026  -0.02075373  0.83663288] \n\n&lt;class 'pandas.core.series.Series'&gt;\n0   -0.116996\n1    0.698803\n2   -0.020754\n3    0.836633\ndtype: float64\n\n\nNotice the index is printed as part of the pandas.Series while, although the np.array is indexable, the index is not part of this data structure. Printing the pandas.Series also shows the values and their data type.\n\n\n\nThe basic method to create a pandas.Series is to call\ns = pd.Series(data, index=index)\nThe data parameter can be:\n\na list or NumPy array,\na Python dictionary, or\na single number, boolean (True/False), or string.\n\nThe index parameter is optional, if we wish to include it, it must be a list of list of indices of the same length as data.\n\n\nLet‚Äôs create a pandas.Series from a NumPy array. To use this method we need to pass a NumPy array (or a list of objects that can be converted to NumPy types) as data. Here, we will also include the list [2023, 2024, 2025] to be used as an index:\n\n# A series from a numpy array \npd.Series(np.arange(3), index=[2023, 2024, 2025])\n\n2023    0\n2024    1\n2025    2\ndtype: int64\n\n\n\n\n\nHere we create a pandas.Series from a list of strings. Remember that the index parameter is optional. If we don‚Äôt include it, the default is to make the index equal to [0,...,len(data)-1]. For example:\n\n# A series from a list of strings with default index\npd.Series(['EDS 220', 'EDS 222', 'EDS 223', 'EDS 242'])\n\n0    EDS 220\n1    EDS 222\n2    EDS 223\n3    EDS 242\ndtype: object\n\n\n\n\n\nRecall that a dictionary is a set of key-value pairs. If we create a pandas.Series via a dictionary the keys will become the index and the values the corresponding data.\n\n# Construct dictionary\nd = {'key_0':2, 'key_1':'3', 'key_2':5}\n\n# Initialize series using a dictionary\npd.Series(d)\n\nkey_0    2\nkey_1    3\nkey_2    5\ndtype: object\n\n\n\n\n\n\n\n\ndtype: object\n\n\n\nNotice that in this and the previous example the data type of the values in the series is object. This data type in pandas usually indicates that the series is made up of strings. However, we can see in this example that the object data type can also indicate a mix of strings and numbers.\n\n\n\n\n\nIf we only provide a single number, boolean, or string as the data for the series, we need to provide an index. The value will be repeated to match the length of the index. Here, we create a series from a single float number with an index given by a list of strings:\n\npd.Series(3.0, index = ['A', 'B', 'C'])\n\nA    3.0\nB    3.0\nC    3.0\ndtype: float64\n\n\n\n\n\n\nArithmetic operations work on series and so most NumPy functions. For example:\n\n# Define a series\ns = pd.Series([98,73,65],index=['Andrea', 'Beth', 'Carolina'])\n\n# Divide each element in series by 10\nprint(s /10, '\\n')\n\n# Take the exponential of each element in series\nprint(np.exp(s), '\\n')\n\n# Original series is unchanged\nprint(s)\n\nAndrea      9.8\nBeth        7.3\nCarolina    6.5\ndtype: float64 \n\nAndrea      3.637971e+42\nBeth        5.052394e+31\nCarolina    1.694889e+28\ndtype: float64 \n\nAndrea      98\nBeth        73\nCarolina    65\ndtype: int64\n\n\nWe can also produce new pandas.Series with True/False values indicating whether the elements in a series satisfy a condition or not:\n\ns &gt; 70\n\nAndrea       True\nBeth         True\nCarolina    False\ndtype: bool\n\n\nThis kind of simple conditions on pandas.Series will be key when we are selecting data from data frames.\n\n\n\nIn pandas we can represent a missing, NULL, or NA value with the float value numpy.nan, which stands for ‚Äúnot a number‚Äù. Let‚Äôs construct a small series with some NA values represented this way:\n\n# Series with NAs in it\ns = pd.Series([1, 2, np.nan, 4, np.nan])\ns\n\n0    1.0\n1    2.0\n2    NaN\n3    4.0\n4    NaN\ndtype: float64\n\n\nNotice the data type of the values it he series is still float64.\nThe hasnans attribute for a pandas.Series returns True if there are any NA values in it and false otherwise:\n\n# Check if series has NAs\ns.hasnans\n\nTrue\n\n\nAfter detecting there are Na values, we might be intersted in knowing which elements in the series are NAs. We can do this using the isna method:\n\ns.isna()\n\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n\n\nThe ouput is a pandas.Series of boolean values indicating if an element in the row at the given index is np.nan (True = is NA) or not (False = not NA).\n\n\n\n\n\n\nCheck-in\n\n\n\n\nThe integer number -999 is often used to represent missing values. Create a pandas.Series named s with four integer values, two of which are -999. The index of this series should be the the letters A through D.\n\n\n\nIn the pandas.Series documentation, look for the method mask(). Use this method to update the series s so that the -999 values are replaced by NA values. HINT: check the first example in the method‚Äôs documentation.\n\n\n\n\nThere‚Äôs much more to say about pandas.Series, but this is enough to get us going. At this point, we mainly want to know about pandas.Series because pandas.Series are the columns of a pandas.DataFrame.\n\n\n\n\n\nThe pandas.DataFrame is the most used pandas object. It represents tabular data and we can think of it as a spreadhseet. Each column of a pandas.DataFrame is a pandas.Series.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nThere are many ways of creating a pandas.DataFrame. We present one simple one in this section.\nWe already mentioned each column of a pandas.DataFrame is a pandas.Series. In fact, the pandas.DataFrame is a dictionary of pandas.Series, with each column name being the key and the column values being the key‚Äôs value. Thus, we can create a pandas.DataFrame in this way:\n\n# Initialize dictionary with columns' data \nd = {'col_name_1' : pd.Series(np.arange(3)),\n     'col_name_2' : pd.Series([3.1, 3.2, 3.3]),\n     }\n\n# Create data frame\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\n0\n0\n3.1\n\n\n1\n1\n3.2\n\n\n2\n2\n3.3\n\n\n\n\n\n\n\nWe can change the index by changing the index attribute in the data frame:\n\n# Change index\ndf.index = ['a','b','c']\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\na\n0\n3.1\n\n\nb\n1\n3.2\n\n\nc\n2\n3.3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can access the data frame‚Äôs column names via the columns attribute. Update the column names to C1 and C2 by updating this attribute.\n\n\n\n\n\n\n\nJump to the week 1 discussion section to practice preliminary data exploration with a real world dataset. Then, continue with the next lesson on subsetting data frames.",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#learning-objectives",
    "href": "book/chapters/lesson-2-series-dataframes.html#learning-objectives",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nExplain the relation between pandas.Series and pandas.DataFrame\nConstruct simple pandas.Series and pandas.DataFrame from scratch using different initalization methods\nPerform simple operations on pandas.Series\nNavigate the pandas documentation to look for attributes and methods of pandas.Series and pandas.DataFrame",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#pandas",
    "href": "book/chapters/lesson-2-series-dataframes.html#pandas",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "pandas [1] [2] is a Python package to wrangle and analyze tabular data. It is built on top of NumPy and has become the core tool for doing data analysis in Python.\nThe standard abbreviation for pandas is pd. Here we will import it together with NumPy:\n\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n\n\nConvention: importing packages\n\n\n\nAlways import all your packages in a single cell at the top of you notebook! Following the PEP 8 - Style Guide for Python Code [3], each package or library import should be in a separate line.",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#series",
    "href": "book/chapters/lesson-2-series-dataframes.html#series",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "The first core object of pandas is the series. A series is a one-dimensional array of indexed data.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\nA pandas.Series having an index is the main difference between a pandas.Series and a NumPy array. Let‚Äôs see the difference:\n\n# A numpy array\narr = np.random.randn(4) # random values from std normal distribution\nprint(type(arr))\nprint(arr, \"\\n\")\n\n# A pandas series made from the previous array\ns = pd.Series(arr)\nprint(type(s))\nprint(s)\n\n&lt;class 'numpy.ndarray'&gt;\n[-0.11699598  0.6988026  -0.02075373  0.83663288] \n\n&lt;class 'pandas.core.series.Series'&gt;\n0   -0.116996\n1    0.698803\n2   -0.020754\n3    0.836633\ndtype: float64\n\n\nNotice the index is printed as part of the pandas.Series while, although the np.array is indexable, the index is not part of this data structure. Printing the pandas.Series also shows the values and their data type.\n\n\n\nThe basic method to create a pandas.Series is to call\ns = pd.Series(data, index=index)\nThe data parameter can be:\n\na list or NumPy array,\na Python dictionary, or\na single number, boolean (True/False), or string.\n\nThe index parameter is optional, if we wish to include it, it must be a list of list of indices of the same length as data.\n\n\nLet‚Äôs create a pandas.Series from a NumPy array. To use this method we need to pass a NumPy array (or a list of objects that can be converted to NumPy types) as data. Here, we will also include the list [2023, 2024, 2025] to be used as an index:\n\n# A series from a numpy array \npd.Series(np.arange(3), index=[2023, 2024, 2025])\n\n2023    0\n2024    1\n2025    2\ndtype: int64\n\n\n\n\n\nHere we create a pandas.Series from a list of strings. Remember that the index parameter is optional. If we don‚Äôt include it, the default is to make the index equal to [0,...,len(data)-1]. For example:\n\n# A series from a list of strings with default index\npd.Series(['EDS 220', 'EDS 222', 'EDS 223', 'EDS 242'])\n\n0    EDS 220\n1    EDS 222\n2    EDS 223\n3    EDS 242\ndtype: object\n\n\n\n\n\nRecall that a dictionary is a set of key-value pairs. If we create a pandas.Series via a dictionary the keys will become the index and the values the corresponding data.\n\n# Construct dictionary\nd = {'key_0':2, 'key_1':'3', 'key_2':5}\n\n# Initialize series using a dictionary\npd.Series(d)\n\nkey_0    2\nkey_1    3\nkey_2    5\ndtype: object\n\n\n\n\n\n\n\n\ndtype: object\n\n\n\nNotice that in this and the previous example the data type of the values in the series is object. This data type in pandas usually indicates that the series is made up of strings. However, we can see in this example that the object data type can also indicate a mix of strings and numbers.\n\n\n\n\n\nIf we only provide a single number, boolean, or string as the data for the series, we need to provide an index. The value will be repeated to match the length of the index. Here, we create a series from a single float number with an index given by a list of strings:\n\npd.Series(3.0, index = ['A', 'B', 'C'])\n\nA    3.0\nB    3.0\nC    3.0\ndtype: float64\n\n\n\n\n\n\nArithmetic operations work on series and so most NumPy functions. For example:\n\n# Define a series\ns = pd.Series([98,73,65],index=['Andrea', 'Beth', 'Carolina'])\n\n# Divide each element in series by 10\nprint(s /10, '\\n')\n\n# Take the exponential of each element in series\nprint(np.exp(s), '\\n')\n\n# Original series is unchanged\nprint(s)\n\nAndrea      9.8\nBeth        7.3\nCarolina    6.5\ndtype: float64 \n\nAndrea      3.637971e+42\nBeth        5.052394e+31\nCarolina    1.694889e+28\ndtype: float64 \n\nAndrea      98\nBeth        73\nCarolina    65\ndtype: int64\n\n\nWe can also produce new pandas.Series with True/False values indicating whether the elements in a series satisfy a condition or not:\n\ns &gt; 70\n\nAndrea       True\nBeth         True\nCarolina    False\ndtype: bool\n\n\nThis kind of simple conditions on pandas.Series will be key when we are selecting data from data frames.\n\n\n\nIn pandas we can represent a missing, NULL, or NA value with the float value numpy.nan, which stands for ‚Äúnot a number‚Äù. Let‚Äôs construct a small series with some NA values represented this way:\n\n# Series with NAs in it\ns = pd.Series([1, 2, np.nan, 4, np.nan])\ns\n\n0    1.0\n1    2.0\n2    NaN\n3    4.0\n4    NaN\ndtype: float64\n\n\nNotice the data type of the values it he series is still float64.\nThe hasnans attribute for a pandas.Series returns True if there are any NA values in it and false otherwise:\n\n# Check if series has NAs\ns.hasnans\n\nTrue\n\n\nAfter detecting there are Na values, we might be intersted in knowing which elements in the series are NAs. We can do this using the isna method:\n\ns.isna()\n\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n\n\nThe ouput is a pandas.Series of boolean values indicating if an element in the row at the given index is np.nan (True = is NA) or not (False = not NA).\n\n\n\n\n\n\nCheck-in\n\n\n\n\nThe integer number -999 is often used to represent missing values. Create a pandas.Series named s with four integer values, two of which are -999. The index of this series should be the the letters A through D.\n\n\n\nIn the pandas.Series documentation, look for the method mask(). Use this method to update the series s so that the -999 values are replaced by NA values. HINT: check the first example in the method‚Äôs documentation.\n\n\n\n\nThere‚Äôs much more to say about pandas.Series, but this is enough to get us going. At this point, we mainly want to know about pandas.Series because pandas.Series are the columns of a pandas.DataFrame.",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#data-frames",
    "href": "book/chapters/lesson-2-series-dataframes.html#data-frames",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "The pandas.DataFrame is the most used pandas object. It represents tabular data and we can think of it as a spreadhseet. Each column of a pandas.DataFrame is a pandas.Series.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nThere are many ways of creating a pandas.DataFrame. We present one simple one in this section.\nWe already mentioned each column of a pandas.DataFrame is a pandas.Series. In fact, the pandas.DataFrame is a dictionary of pandas.Series, with each column name being the key and the column values being the key‚Äôs value. Thus, we can create a pandas.DataFrame in this way:\n\n# Initialize dictionary with columns' data \nd = {'col_name_1' : pd.Series(np.arange(3)),\n     'col_name_2' : pd.Series([3.1, 3.2, 3.3]),\n     }\n\n# Create data frame\ndf = pd.DataFrame(d)\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\n0\n0\n3.1\n\n\n1\n1\n3.2\n\n\n2\n2\n3.3\n\n\n\n\n\n\n\nWe can change the index by changing the index attribute in the data frame:\n\n# Change index\ndf.index = ['a','b','c']\ndf\n\n\n\n\n\n\n\n\ncol_name_1\ncol_name_2\n\n\n\n\na\n0\n3.1\n\n\nb\n1\n3.2\n\n\nc\n2\n3.3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can access the data frame‚Äôs column names via the columns attribute. Update the column names to C1 and C2 by updating this attribute.",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-2-series-dataframes.html#next",
    "href": "book/chapters/lesson-2-series-dataframes.html#next",
    "title": "1 pandas series and data frames",
    "section": "",
    "text": "Jump to the week 1 discussion section to practice preliminary data exploration with a real world dataset. Then, continue with the next lesson on subsetting data frames.",
    "crumbs": [
      "notes",
      "Tabular data",
      "1 `pandas` series and data frames"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html",
    "title": "11 Reprojecting",
    "section": "",
    "text": "In this section we will learn how to join dataframes and will apply this to creating a choropleth map with geopandas.\n\n\nThe first dataset we will use is a list of Arctic communities and their location [1] created by the Alaska Native Tribal Health Consortium. This data comes in a GeoJSON file with the following attributes:\n\nname: name of Arctic community,\npopulation: population of Arctic community, as of 2022\ncountry: country that the Arctic community falls within (see dataset metadata for the codes)\ngeoname-id: numeric codes that uniquely identify all administrative/legal and statistical geographic areas for which the Census Bureau tabulates data\n\nThe second dataset is Natural Earth‚Äôs medium-scale cultural boundaries data for countries (1:50m). We can obtain this dataset by downloading the shapefile. Natural Earth is a public domain dataset with free, ready-to-use data for creating maps.\nThe third dataset we will use is a CSV file with the country codes and names of the Arctic countries in the Arctic communities dataset. This dataset was created for educational purposes for this lesson based on the metadata of the Arctic communities dataset and the country names in Natural Earth‚Äôs dataset. It can be accessed here.\n\n\n\nWe will first import the countries shapefile and adapt it for wrangling purposes:\n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\n# Import countries polygons\nfp = os.path.join('data', 'ne_50m_admin_0_countries', 'ne_50m_admin_0_countries.shp')\ncountries = gpd.read_file(fp)\n\n# Simplify column names\ncountries.columns = countries.columns.str.lower()\n\n# Select columns for analysis\ncountries = countries[['admin', 'type', 'geometry']]\n\ncountries.head()\n\n\n\n\n\n\n\n\nadmin\ntype\ngeometry\n\n\n\n\n0\nZimbabwe\nSovereign country\nPOLYGON ((31.28789 -22.40205, 31.19727 -22.344...\n\n\n1\nZambia\nSovereign country\nPOLYGON ((30.39609 -15.64307, 30.25068 -15.643...\n\n\n2\nYemen\nSovereign country\nMULTIPOLYGON (((53.08564 16.64839, 52.58145 16...\n\n\n3\nVietnam\nSovereign country\nMULTIPOLYGON (((104.06396 10.39082, 104.08301 ...\n\n\n4\nVenezuela\nSovereign country\nMULTIPOLYGON (((-60.82119 9.13838, -60.94141 9...\n\n\n\n\n\n\n\n\n# Quick view\ncountries.plot()\n\n\n\n\n\n\n\n\nNext, we import the Arctic communities data. Similar to how we previously used pandas.read_csv(), we can read in the Arctic communities GeoJSON data directly from the data repository using geopandas.read_file():\n\n# Import Arctic communities data\nURL = 'https://cn.dataone.org/cn/v2/resolve/urn%3Auuid%3Aed7718ae-fb0d-43dd-9270-fbfe80bfc7a4'\ncommunities = gpd.read_file(URL)\n\ncommunities.head()\n\n\n\n\n\n\n\n\nname\npopulation\ncountry\ngeoname-id\ngeometry\n\n\n\n\n0\nUdomlya\n32373\nRU\n452949\nPOINT (34.99250 57.87944)\n\n\n1\nValmiera\n26963\nLV\n453754\nPOINT (25.42751 57.54108)\n\n\n2\nVentspils\n42644\nLV\n454310\nPOINT (21.57288 57.38988)\n\n\n3\nVec-LiepƒÅja\n85260\nLV\n454432\nPOINT (21.01667 56.53333)\n\n\n4\nTukums\n18348\nLV\n454768\nPOINT (23.15528 56.96694)\n\n\n\n\n\n\n\nThe CRS of the communities is EPSG:4326. Remember all GeoJSON files are given in this CRS and all points are expressed in longitude and latitude units of decimal degrees.\n\nprint(countries.crs)\n\nEPSG:4326\n\n\nSince the CRSs of our geospatila data match, it is easy to take a quick look at our communities data by plotting it on top of the countries dataframe:\n\n# Verify CRSs match\nassert countries.crs == communities.crs\n\nfig, ax = plt.subplots()\ncountries.plot(ax=ax)\ncommunities.plot(ax=ax, color='red')\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we import the country names and codes CSV:\n\ncountry_names = pd.read_csv(os.path.join('data','country_names.csv'))\ncountry_names\n\n\n\n\n\n\n\n\ncountry\nadmin\n\n\n\n\n0\nRU\nRussia\n\n\n1\nLV\nLatvia\n\n\n2\nEE\nEstonia\n\n\n3\nLT\nLithuania\n\n\n4\nSE\nSweden\n\n\n5\nBY\nBelarus\n\n\n6\nFI\nFinland\n\n\n7\nNO\nNorway\n\n\n8\nDK\nDenmark\n\n\n9\nFO\nFaroe Islands\n\n\n10\nIS\nIceland\n\n\n11\nGB\nUnited Kingdom\n\n\n12\nAX\nAland Islands\n\n\n13\nGL\nGreenland\n\n\n14\nUS\nUnited States of America\n\n\n15\nCA\nCanada\n\n\n\n\n\n\n\n\n\n\nNext, we want to calculate the number of Arctic communities by country.\n\n# Create data frame with number of communities per country\nn_comms = (communities.groupby('country')\n                      .size()\n                      .reset_index(name='n_communities'))\n\nLet‚Äôs break this down:\n\nWe start with our communities dataframe and use groupby('country') to group by country code.\nThen we use size() as an aggregator function to calculate the size of each group.\nThe result of this operation is a pandas.Series indexed by the country values.\nBy resetting the index we transform the pandas.Series into a pandas.DataFrame, the index is now a column named country and the values of the series are named n_communities.\n\n\n# Number of Arctic communities per country\nn_comms\n\n\n\n\n\n\n\n\ncountry\nn_communities\n\n\n\n\n0\nAX\n1\n\n\n1\nBY\n8\n\n\n2\nCA\n7\n\n\n3\nDK\n72\n\n\n4\nEE\n14\n\n\n5\nFI\n98\n\n\n6\nFO\n1\n\n\n7\nGB\n96\n\n\n8\nGL\n1\n\n\n9\nIS\n5\n\n\n10\nLT\n26\n\n\n11\nLV\n25\n\n\n12\nNO\n48\n\n\n13\nRU\n774\n\n\n14\nSE\n133\n\n\n15\nUS\n115\n\n\n\n\n\n\n\n\n\n\nOur goal is to merge the n_comms and the countries data frames. To merge two data frames they need to have at least one column in common. Currently our datasets do not have any columns in common:\n\nset(countries.columns).intersection(n_comms.columns)\n\nset()\n\n\nThe output set() represents the empty set. This might not be as informative, so let‚Äôs write a different information statement:\n\ncommon_columns = set(countries.columns).intersection(n_comms.columns)\n\n# Check if there are any common columns\nif len(common_columns) != 0:\n    print(f\"Common columns: {common_columns}\")\nelse:\n    print(\"No common columns\")\n\nNo common columns\n\n\nRemember that an if-else statement is a control structure that allows code to make decisions: it checks a condition, and if that condition is true, it executes one block of code (the if block); if the condition is false, it executes a different block (the else block). This enables programs to respond differently depending on specific criteria or inputs.\n\n\n\n\n\n\nCheck-in\n\n\n\nWrap up the previous code into a function called check_common_columns that prints a message depending of whether two data frames have common columns or not. Don‚Äôt forget to include a docstring! \n\n\n\n\n\nWe can use the country_names data frame to add the names countries into the n_comms data which, in turn, will allow us to merge that data frame with the country_names data. To merge dataframes we can use the pandas.merge() function. The basic syntax for it is:\noutput_df = pd.merge(left_df,\n                     right_df, \n                     how = type_of_join, \n                     on = column_to_join)\nwhere\n\noutput_df is the dataframe resulting from the merge,\nleft_df is the dataframe we have ‚Äúon the left side‚Äù,\nright_df is the dataframe we have ‚Äúon the right side‚Äù,\nhow specifies the type of join between the left and right dataframes, (check the options here), the default is to do an inner join,\non specifies the column to join on, this column must be present in both our dataframes.\n\nWhen merging a geopandas.GeoDataFrame with a pandas.DataFrame, the geopandas.GeoDataFrame must be ‚Äúon the left‚Äù to retain the geospatial information. Otherwise, the output will be a pandas.DataFrame.\nSo, we merge the n_comms and country_names data frames using a left join:\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub [2]\n\n\n\nn_comms = pd.merge(n_comms,\n                   country_names,\n                   how='left',\n                   on='country')\nn_comms\n\n\n\n\n\n\n\n\ncountry\nn_communities\nadmin\n\n\n\n\n0\nAX\n1\nAland Islands\n\n\n1\nBY\n8\nBelarus\n\n\n2\nCA\n7\nCanada\n\n\n3\nDK\n72\nDenmark\n\n\n4\nEE\n14\nEstonia\n\n\n5\nFI\n98\nFinland\n\n\n6\nFO\n1\nFaroe Islands\n\n\n7\nGB\n96\nUnited Kingdom\n\n\n8\nGL\n1\nGreenland\n\n\n9\nIS\n5\nIceland\n\n\n10\nLT\n26\nLithuania\n\n\n11\nLV\n25\nLatvia\n\n\n12\nNO\n48\nNorway\n\n\n13\nRU\n774\nRussia\n\n\n14\nSE\n133\nSweden\n\n\n15\nUS\n115\nUnited States of America\n\n\n\n\n\n\n\nWe can reuse our function to check that n_comms and countries now have a common column on which we can merge them:\n\ncheck_common_columns(n_comms, countries)\n\nCommon columns: {'admin'}\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nCreate a new variable named arctic_countries which is the result of an inner join between our countries and n_comms dataframes. The inner joun will merge the subset of rows that have matches in both the left table and the right table.\n \n\n\n\n\n\nNotice that the row for Aland Islands is not present in the merged dataframe:\n\narctic_countries\n\n\n\n\n\n\n\n\ntype\ngeometry\ncountry\nn_communities\n\n\nadmin\n\n\n\n\n\n\n\n\nUnited States of America\nCountry\nMULTIPOLYGON (((-132.74687 56.52568, -132.7576...\nUS\n115\n\n\nUnited Kingdom\nCountry\nMULTIPOLYGON (((-2.66768 51.62300, -2.74214 51...\nGB\n96\n\n\nSweden\nSovereign country\nMULTIPOLYGON (((19.07646 57.83594, 18.99375 57...\nSE\n133\n\n\nRussia\nSovereign country\nMULTIPOLYGON (((145.88154 43.45952, 145.89561 ...\nRU\n774\n\n\nNorway\nSovereign country\nMULTIPOLYGON (((20.62217 69.03687, 20.49199 69...\nNO\n48\n\n\nLithuania\nSovereign country\nMULTIPOLYGON (((20.95781 55.27891, 20.89980 55...\nLT\n26\n\n\nLatvia\nSovereign country\nPOLYGON ((26.59355 55.66753, 26.54287 55.67241...\nLV\n25\n\n\nIceland\nSovereign country\nPOLYGON ((-15.54312 66.22852, -15.42847 66.224...\nIS\n5\n\n\nFinland\nCountry\nMULTIPOLYGON (((24.15547 65.80527, 24.04902 65...\nFI\n98\n\n\nEstonia\nSovereign country\nMULTIPOLYGON (((27.35195 57.52812, 27.32656 57...\nEE\n14\n\n\nGreenland\nCountry\nMULTIPOLYGON (((-29.95288 83.56484, -28.99199 ...\nGL\n1\n\n\nFaroe Islands\nDependency\nMULTIPOLYGON (((-6.62319 61.80596, -6.64277 61...\nFO\n1\n\n\nDenmark\nCountry\nMULTIPOLYGON (((12.56875 55.78506, 12.57119 55...\nDK\n72\n\n\nCanada\nSovereign country\nMULTIPOLYGON (((-132.65552 54.12749, -132.5640...\nCA\n7\n\n\nBelarus\nSovereign country\nPOLYGON ((31.76338 52.10107, 31.57373 52.10811...\nBY\n8\n\n\n\n\n\n\n\nThe values attribute of a data frame returns all the values in the data frame as an array. We can verify the value ‚ÄòAland Islands‚Äô was nowhere in our original countries dataframe like this:\n\n# Check Aland Islands is nowhere in data frame\n'Aland Islands' not in countries.values\n\nTrue\n\n\nThe Aland Islands is an autonomous region of Finland and there is one Arctic community registered in this region. We will directly add one to Finland to not lose this piece of data:\n\narctic_countries.at['Finland', 'n_communities'] += 1\n\n\n\n\nA choropleth map is an efficient way to visualize aggregate data per region.\nMaking a choropleth map from our polygons GeoDataFrame is easy; we just need to specify the column parameter in plot() and make it equal to the column with the values we want to plot in each country:\n\narctic_countries.plot(column='n_communities',\n                      legend=True)\n\n\n\n\n\n\n\n\n\n\n\nRemember that CRSs reflect cultural views and even biases. Any map projection involves choices about which areas to emphasize, minimize, or distort, and those choices can influence how viewers perceive different regions. In our map, using the EPSG:4326 CRS is, among other things, mapping the Arctic regions as far apart, while they are actually near each other.\nReprojecting means changing the coordinate reference system of your geospatial data. In our case, we will reproject the Alaska geo-dataframe to the CRS EPSG:3413. This CRS is a projected CRS, better suited for working with data from the Arctic region:\n\n\n\nSource: spatialreference.org\n\n\nChanging CRSs in GeoPandas is very simple using the to_crs() method for geopandas.GeoDataFrames. The general syntax is:\nupdated_geodf = geodf.to_crs(new_crs)\nwhere:\n\nupdated_geodf is the output of the method, a new geodataframe (to_crs() does not work in place),\ngeodf is the geopandas.GeoDataFrame we want to transform,\nnew_crs the CRS we want to convert to, this is an object of type CRS or string representing the CRS (ex: 'epsg:3413').\n\nIn our case:\n\n# Reproject to CRS optimized for Arctic region\narctic_countries = arctic_countries.to_crs('epsg:3413')\n\nWe can now use the reprojected data to update our map:\n\n\nCode\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Create choropleth map of communities\n# Plot with refined color and edge style\narctic_countries.plot(\n    ax=ax,\n    column='n_communities',\n    cmap='PuBuGn',\n    legend=True,\n    edgecolor=\"0.6\",\n    linewidth=0.5,\n    legend_kwds={\n        \"shrink\": 0.7,\n        \"label\": \"Number of Arctic Communities\",\n        \"orientation\": \"horizontal\",\n        \"pad\": 0.05\n    }\n)\n\n# Add title and subtitle for better context\nax.set_title('Distribution of Arctic Communities', fontsize=18, weight='bold', pad=15)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nAlthough the new projection clearly improves the presentation of the data, there are still issues with this plot! Mainly, the entire United States territory is in it, when we should only have Alaska. In our next lesson we will review startegies to clip and subset vector data and return to this plot in our discussion section.",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#about-the-data",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#about-the-data",
    "title": "11 Reprojecting",
    "section": "",
    "text": "The first dataset we will use is a list of Arctic communities and their location [1] created by the Alaska Native Tribal Health Consortium. This data comes in a GeoJSON file with the following attributes:\n\nname: name of Arctic community,\npopulation: population of Arctic community, as of 2022\ncountry: country that the Arctic community falls within (see dataset metadata for the codes)\ngeoname-id: numeric codes that uniquely identify all administrative/legal and statistical geographic areas for which the Census Bureau tabulates data\n\nThe second dataset is Natural Earth‚Äôs medium-scale cultural boundaries data for countries (1:50m). We can obtain this dataset by downloading the shapefile. Natural Earth is a public domain dataset with free, ready-to-use data for creating maps.\nThe third dataset we will use is a CSV file with the country codes and names of the Arctic countries in the Arctic communities dataset. This dataset was created for educational purposes for this lesson based on the metadata of the Arctic communities dataset and the country names in Natural Earth‚Äôs dataset. It can be accessed here.",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#import-data",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#import-data",
    "title": "11 Reprojecting",
    "section": "",
    "text": "We will first import the countries shapefile and adapt it for wrangling purposes:\n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\n# Import countries polygons\nfp = os.path.join('data', 'ne_50m_admin_0_countries', 'ne_50m_admin_0_countries.shp')\ncountries = gpd.read_file(fp)\n\n# Simplify column names\ncountries.columns = countries.columns.str.lower()\n\n# Select columns for analysis\ncountries = countries[['admin', 'type', 'geometry']]\n\ncountries.head()\n\n\n\n\n\n\n\n\nadmin\ntype\ngeometry\n\n\n\n\n0\nZimbabwe\nSovereign country\nPOLYGON ((31.28789 -22.40205, 31.19727 -22.344...\n\n\n1\nZambia\nSovereign country\nPOLYGON ((30.39609 -15.64307, 30.25068 -15.643...\n\n\n2\nYemen\nSovereign country\nMULTIPOLYGON (((53.08564 16.64839, 52.58145 16...\n\n\n3\nVietnam\nSovereign country\nMULTIPOLYGON (((104.06396 10.39082, 104.08301 ...\n\n\n4\nVenezuela\nSovereign country\nMULTIPOLYGON (((-60.82119 9.13838, -60.94141 9...\n\n\n\n\n\n\n\n\n# Quick view\ncountries.plot()\n\n\n\n\n\n\n\n\nNext, we import the Arctic communities data. Similar to how we previously used pandas.read_csv(), we can read in the Arctic communities GeoJSON data directly from the data repository using geopandas.read_file():\n\n# Import Arctic communities data\nURL = 'https://cn.dataone.org/cn/v2/resolve/urn%3Auuid%3Aed7718ae-fb0d-43dd-9270-fbfe80bfc7a4'\ncommunities = gpd.read_file(URL)\n\ncommunities.head()\n\n\n\n\n\n\n\n\nname\npopulation\ncountry\ngeoname-id\ngeometry\n\n\n\n\n0\nUdomlya\n32373\nRU\n452949\nPOINT (34.99250 57.87944)\n\n\n1\nValmiera\n26963\nLV\n453754\nPOINT (25.42751 57.54108)\n\n\n2\nVentspils\n42644\nLV\n454310\nPOINT (21.57288 57.38988)\n\n\n3\nVec-LiepƒÅja\n85260\nLV\n454432\nPOINT (21.01667 56.53333)\n\n\n4\nTukums\n18348\nLV\n454768\nPOINT (23.15528 56.96694)\n\n\n\n\n\n\n\nThe CRS of the communities is EPSG:4326. Remember all GeoJSON files are given in this CRS and all points are expressed in longitude and latitude units of decimal degrees.\n\nprint(countries.crs)\n\nEPSG:4326\n\n\nSince the CRSs of our geospatila data match, it is easy to take a quick look at our communities data by plotting it on top of the countries dataframe:\n\n# Verify CRSs match\nassert countries.crs == communities.crs\n\nfig, ax = plt.subplots()\ncountries.plot(ax=ax)\ncommunities.plot(ax=ax, color='red')\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we import the country names and codes CSV:\n\ncountry_names = pd.read_csv(os.path.join('data','country_names.csv'))\ncountry_names\n\n\n\n\n\n\n\n\ncountry\nadmin\n\n\n\n\n0\nRU\nRussia\n\n\n1\nLV\nLatvia\n\n\n2\nEE\nEstonia\n\n\n3\nLT\nLithuania\n\n\n4\nSE\nSweden\n\n\n5\nBY\nBelarus\n\n\n6\nFI\nFinland\n\n\n7\nNO\nNorway\n\n\n8\nDK\nDenmark\n\n\n9\nFO\nFaroe Islands\n\n\n10\nIS\nIceland\n\n\n11\nGB\nUnited Kingdom\n\n\n12\nAX\nAland Islands\n\n\n13\nGL\nGreenland\n\n\n14\nUS\nUnited States of America\n\n\n15\nCA\nCanada",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#arctic-communities-by-country",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#arctic-communities-by-country",
    "title": "11 Reprojecting",
    "section": "",
    "text": "Next, we want to calculate the number of Arctic communities by country.\n\n# Create data frame with number of communities per country\nn_comms = (communities.groupby('country')\n                      .size()\n                      .reset_index(name='n_communities'))\n\nLet‚Äôs break this down:\n\nWe start with our communities dataframe and use groupby('country') to group by country code.\nThen we use size() as an aggregator function to calculate the size of each group.\nThe result of this operation is a pandas.Series indexed by the country values.\nBy resetting the index we transform the pandas.Series into a pandas.DataFrame, the index is now a column named country and the values of the series are named n_communities.\n\n\n# Number of Arctic communities per country\nn_comms\n\n\n\n\n\n\n\n\ncountry\nn_communities\n\n\n\n\n0\nAX\n1\n\n\n1\nBY\n8\n\n\n2\nCA\n7\n\n\n3\nDK\n72\n\n\n4\nEE\n14\n\n\n5\nFI\n98\n\n\n6\nFO\n1\n\n\n7\nGB\n96\n\n\n8\nGL\n1\n\n\n9\nIS\n5\n\n\n10\nLT\n26\n\n\n11\nLV\n25\n\n\n12\nNO\n48\n\n\n13\nRU\n774\n\n\n14\nSE\n133\n\n\n15\nUS\n115",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#if-else-statements",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#if-else-statements",
    "title": "11 Reprojecting",
    "section": "",
    "text": "Our goal is to merge the n_comms and the countries data frames. To merge two data frames they need to have at least one column in common. Currently our datasets do not have any columns in common:\n\nset(countries.columns).intersection(n_comms.columns)\n\nset()\n\n\nThe output set() represents the empty set. This might not be as informative, so let‚Äôs write a different information statement:\n\ncommon_columns = set(countries.columns).intersection(n_comms.columns)\n\n# Check if there are any common columns\nif len(common_columns) != 0:\n    print(f\"Common columns: {common_columns}\")\nelse:\n    print(\"No common columns\")\n\nNo common columns\n\n\nRemember that an if-else statement is a control structure that allows code to make decisions: it checks a condition, and if that condition is true, it executes one block of code (the if block); if the condition is false, it executes a different block (the else block). This enables programs to respond differently depending on specific criteria or inputs.\n\n\n\n\n\n\nCheck-in\n\n\n\nWrap up the previous code into a function called check_common_columns that prints a message depending of whether two data frames have common columns or not. Don‚Äôt forget to include a docstring!",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#merging-data-frames",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#merging-data-frames",
    "title": "11 Reprojecting",
    "section": "",
    "text": "We can use the country_names data frame to add the names countries into the n_comms data which, in turn, will allow us to merge that data frame with the country_names data. To merge dataframes we can use the pandas.merge() function. The basic syntax for it is:\noutput_df = pd.merge(left_df,\n                     right_df, \n                     how = type_of_join, \n                     on = column_to_join)\nwhere\n\noutput_df is the dataframe resulting from the merge,\nleft_df is the dataframe we have ‚Äúon the left side‚Äù,\nright_df is the dataframe we have ‚Äúon the right side‚Äù,\nhow specifies the type of join between the left and right dataframes, (check the options here), the default is to do an inner join,\non specifies the column to join on, this column must be present in both our dataframes.\n\nWhen merging a geopandas.GeoDataFrame with a pandas.DataFrame, the geopandas.GeoDataFrame must be ‚Äúon the left‚Äù to retain the geospatial information. Otherwise, the output will be a pandas.DataFrame.\nSo, we merge the n_comms and country_names data frames using a left join:\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub [2]\n\n\n\nn_comms = pd.merge(n_comms,\n                   country_names,\n                   how='left',\n                   on='country')\nn_comms\n\n\n\n\n\n\n\n\ncountry\nn_communities\nadmin\n\n\n\n\n0\nAX\n1\nAland Islands\n\n\n1\nBY\n8\nBelarus\n\n\n2\nCA\n7\nCanada\n\n\n3\nDK\n72\nDenmark\n\n\n4\nEE\n14\nEstonia\n\n\n5\nFI\n98\nFinland\n\n\n6\nFO\n1\nFaroe Islands\n\n\n7\nGB\n96\nUnited Kingdom\n\n\n8\nGL\n1\nGreenland\n\n\n9\nIS\n5\nIceland\n\n\n10\nLT\n26\nLithuania\n\n\n11\nLV\n25\nLatvia\n\n\n12\nNO\n48\nNorway\n\n\n13\nRU\n774\nRussia\n\n\n14\nSE\n133\nSweden\n\n\n15\nUS\n115\nUnited States of America\n\n\n\n\n\n\n\nWe can reuse our function to check that n_comms and countries now have a common column on which we can merge them:\n\ncheck_common_columns(n_comms, countries)\n\nCommon columns: {'admin'}\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nCreate a new variable named arctic_countries which is the result of an inner join between our countries and n_comms dataframes. The inner joun will merge the subset of rows that have matches in both the left table and the right table.",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#reviewing-results",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#reviewing-results",
    "title": "11 Reprojecting",
    "section": "",
    "text": "Notice that the row for Aland Islands is not present in the merged dataframe:\n\narctic_countries\n\n\n\n\n\n\n\n\ntype\ngeometry\ncountry\nn_communities\n\n\nadmin\n\n\n\n\n\n\n\n\nUnited States of America\nCountry\nMULTIPOLYGON (((-132.74687 56.52568, -132.7576...\nUS\n115\n\n\nUnited Kingdom\nCountry\nMULTIPOLYGON (((-2.66768 51.62300, -2.74214 51...\nGB\n96\n\n\nSweden\nSovereign country\nMULTIPOLYGON (((19.07646 57.83594, 18.99375 57...\nSE\n133\n\n\nRussia\nSovereign country\nMULTIPOLYGON (((145.88154 43.45952, 145.89561 ...\nRU\n774\n\n\nNorway\nSovereign country\nMULTIPOLYGON (((20.62217 69.03687, 20.49199 69...\nNO\n48\n\n\nLithuania\nSovereign country\nMULTIPOLYGON (((20.95781 55.27891, 20.89980 55...\nLT\n26\n\n\nLatvia\nSovereign country\nPOLYGON ((26.59355 55.66753, 26.54287 55.67241...\nLV\n25\n\n\nIceland\nSovereign country\nPOLYGON ((-15.54312 66.22852, -15.42847 66.224...\nIS\n5\n\n\nFinland\nCountry\nMULTIPOLYGON (((24.15547 65.80527, 24.04902 65...\nFI\n98\n\n\nEstonia\nSovereign country\nMULTIPOLYGON (((27.35195 57.52812, 27.32656 57...\nEE\n14\n\n\nGreenland\nCountry\nMULTIPOLYGON (((-29.95288 83.56484, -28.99199 ...\nGL\n1\n\n\nFaroe Islands\nDependency\nMULTIPOLYGON (((-6.62319 61.80596, -6.64277 61...\nFO\n1\n\n\nDenmark\nCountry\nMULTIPOLYGON (((12.56875 55.78506, 12.57119 55...\nDK\n72\n\n\nCanada\nSovereign country\nMULTIPOLYGON (((-132.65552 54.12749, -132.5640...\nCA\n7\n\n\nBelarus\nSovereign country\nPOLYGON ((31.76338 52.10107, 31.57373 52.10811...\nBY\n8\n\n\n\n\n\n\n\nThe values attribute of a data frame returns all the values in the data frame as an array. We can verify the value ‚ÄòAland Islands‚Äô was nowhere in our original countries dataframe like this:\n\n# Check Aland Islands is nowhere in data frame\n'Aland Islands' not in countries.values\n\nTrue\n\n\nThe Aland Islands is an autonomous region of Finland and there is one Arctic community registered in this region. We will directly add one to Finland to not lose this piece of data:\n\narctic_countries.at['Finland', 'n_communities'] += 1",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#choropleth-map",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#choropleth-map",
    "title": "11 Reprojecting",
    "section": "",
    "text": "A choropleth map is an efficient way to visualize aggregate data per region.\nMaking a choropleth map from our polygons GeoDataFrame is easy; we just need to specify the column parameter in plot() and make it equal to the column with the values we want to plot in each country:\n\narctic_countries.plot(column='n_communities',\n                      legend=True)",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#reprojecting-1",
    "href": "book/chapters/lesson-12-merge-data/lesson-12-merge-data.html#reprojecting-1",
    "title": "11 Reprojecting",
    "section": "",
    "text": "Remember that CRSs reflect cultural views and even biases. Any map projection involves choices about which areas to emphasize, minimize, or distort, and those choices can influence how viewers perceive different regions. In our map, using the EPSG:4326 CRS is, among other things, mapping the Arctic regions as far apart, while they are actually near each other.\nReprojecting means changing the coordinate reference system of your geospatial data. In our case, we will reproject the Alaska geo-dataframe to the CRS EPSG:3413. This CRS is a projected CRS, better suited for working with data from the Arctic region:\n\n\n\nSource: spatialreference.org\n\n\nChanging CRSs in GeoPandas is very simple using the to_crs() method for geopandas.GeoDataFrames. The general syntax is:\nupdated_geodf = geodf.to_crs(new_crs)\nwhere:\n\nupdated_geodf is the output of the method, a new geodataframe (to_crs() does not work in place),\ngeodf is the geopandas.GeoDataFrame we want to transform,\nnew_crs the CRS we want to convert to, this is an object of type CRS or string representing the CRS (ex: 'epsg:3413').\n\nIn our case:\n\n# Reproject to CRS optimized for Arctic region\narctic_countries = arctic_countries.to_crs('epsg:3413')\n\nWe can now use the reprojected data to update our map:\n\n\nCode\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Create choropleth map of communities\n# Plot with refined color and edge style\narctic_countries.plot(\n    ax=ax,\n    column='n_communities',\n    cmap='PuBuGn',\n    legend=True,\n    edgecolor=\"0.6\",\n    linewidth=0.5,\n    legend_kwds={\n        \"shrink\": 0.7,\n        \"label\": \"Number of Arctic Communities\",\n        \"orientation\": \"horizontal\",\n        \"pad\": 0.05\n    }\n)\n\n# Add title and subtitle for better context\nax.set_title('Distribution of Arctic Communities', fontsize=18, weight='bold', pad=15)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nAlthough the new projection clearly improves the presentation of the data, there are still issues with this plot! Mainly, the entire United States territory is in it, when we should only have Alaska. In our next lesson we will review startegies to clip and subset vector data and return to this plot in our discussion section.",
    "crumbs": [
      "notes",
      "Vector data",
      "11 Reprojecting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-14-xarray/lesson-14-xarray.html",
    "href": "book/chapters/lesson-14-xarray/lesson-14-xarray.html",
    "title": "13 NetCDF and xarray",
    "section": "",
    "text": "In this lesson, we will get acquainted with a popuar format for working with multidimensional datasets called NetCDF and the Python package xarray [1] which is based on NetCDF.\n\nThis lesson is adapted from the NetCDF and xarray lesson Galaz Garc√≠a created for the Arctic Data Center‚Äôs course on scalable computing [2].\n\n\nEfficient and reproducible data analysis begins with choosing a proper format to store our data, particularly when working with large, complex, multi-dimensional datasets. Consider, for example, the following Earth System Data Cube from Mahecha et al. [3] , which measures nine environmental variables at high resolution across space and time. We can consider this dataset large (high-resolution means we have a big file), complex (multiple variables), and multi-dimensional (each variable is measured along three dimensions: latitude, longitude, and time). Additionally, necessary metadata must accompany the dataset to make it functional, such as units of measurement for variables, information about the authors, and processing software used.\n\n\n\nMahecha et al.¬†2020 . Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25¬∞ and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15¬∞ S to 60¬∞ N, and 10¬∞ E to 65¬∞ W.\n\n\nKeeping complex datasets in a format that facilitates access, processing, sharing, and archiving can be as important as the tools we use to analyze them.\nNetCDF (network Common Data Form) is a set of popular software libraries and self-describing, machine-independent data formats for working with multi-dimensional datasets. They are designed to support the creation, access, and sharing of array-oriented scientific data. NetCDF was initially developed at the Unidata Program Center and is supported on almost all platforms, and parsers exist for most scientific programming languages.\nThe NetCDF documentation outlines that this data format is desgined to be:\n\n\nSelf-describing: Information describing the data contents of the file is embedded within the data file itself. This means that there is a header describing the layout of the rest of the file and arbitrary file metadata.\nScalable: Small subsets of large datasets may be accessed efficiently through netCDF interfaces, even from remote servers.\nPortable: A NetCDF file is machine-independent i.e.¬†it can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\nAppendable: Data may be appended to a properly structured NetCDF file without copying the dataset or redefining its structure.\nSharable: One writer and multiple readers may simultaneously access the same NetCDF file.\nArchivable: Access to all earlier forms of NetCDF data will be supported by current and future versions of the software.\n\n\n\n\nThe NetCDF data model is the way that NetCDF organizes data. This lesson will follow the Classic NetCDF Data Model, which is at the core of all netCDF files. \nThe model consists of three key components: variables, dimensions, and attributes.\n\nVariables are N-dimensional arrays of data. We can think of these as varying/measured/dependent quantities.\nDimensions describe the axes of the data arrays. A dimension has a name and a length. We can think of these as the constant/fixed/independent quantities at which we measure the variables.\nAttributes are small notes or supplementary metadata to annotate a variable or the file as a whole.\n\n\n\n\nClassic NetCDF Data Model (NetCDF documentation)\n\n\n\n\n\nThe most commonly used metadata standard for geospatial data is the Climate and Forecast metadata standard, also called the CF conventions.\n\nThe CF conventions are specifically designed to promote the processing and sharing of files created with the NetCDF API. Principles of CF include self-describing data (no external tables needed for understanding), metadata equally readable by humans and software, minimum redundancy, and maximum simplicity. (CF conventions FAQ)\n\nThe CF conventions provide a unique standardized name and precise description of over 1,000 physical variables. To maximize the reusability of our data, it is best to include a variable‚Äôs standardized name as an attribute called standard_name. Variables should also include a units attribute. This attribute should be a string that can be recognized by UNIDATA‚Äôs UDUNITS package. In these links you can find:\n\na table with all of the CF convention‚Äôs standard names, and\na list of the units found in the UDUNITS database maintained by the North Carolina Institute for Climate Studies.\n\n\n\n\n\nxarray [1] is an open source project and Python package that augments NumPy arrays by adding labeled dimensions, coordinates, and attributes. xarray is based on the NetCDF data model, making it the appropriate tool to open, process, and create datasets in NetCDF format.\n\n\n\nxarray‚Äôs development portal\n\n\n\n\nVariables, dimensions, and attributes refer to the same components of NetCDF files we reviewed in the previous section. The following is a concrete example of variables, dimensions, and attributes that will guide the rest of the section.\n\n\nImagine the following scenario. We have a network of 25 weather stations. They are located in a square grid: starting at 30¬∞0‚Ä≤N 60¬∞0‚Ä≤E, there is a station every 10¬∞ North and every 10¬∞ East. Each station measures the air temperature at a set time for three days, starting on September 1st, 2022. On the first day, all stations record a temperature of 0¬∞C. On the second day, all temperatures are 1¬∞C, and on the third day, all temperatures are 2¬∞C. What are the variables, dimensions and attributes for this data?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVariables: There is a single variable being measured: temperature. The variable values can be represented as a 5x5x3 array, with constant values for each day.\nDimensions: This dataset has three dimensions: time, latitude, and longitude. Time indicates when the measurement happened, we can encode it as the dates 2022-09-01, 2022-09-02, and 2022-09-03. The pairs of latitude and longitude values indicate the positions of the weather stations. Latitude has values 30, 40, 50, 60, and 70, measured in degrees North. Longitude has values 60, 70, 80, 90, and 100, measured in degrees East.\n\nAttributes: Let‚Äôs divide these into attributes for the variable, the dimensions, and the whole dataset:\n\nVariable attributes:\n\nTemperature attributes:\n\nstandard_name: air_temperature\nunits: degree_C\n\n\nDimension attributes:\n\nTime attributes:\n\ndescription: date of measurement\n\nLatitude attributes:\n\nstandard_name: grid_latitude\nunits: degrees_N\n\nLongitude attributes:\n\nsatandard_name: grid_longitude\nunits: degree_E\n\n\nDataset attributes:\n\ntitle: Temperature Measurements at Weather Stations\nsummary: an example of NetCDF data format\n\n\n\n\n\nNow imagine we calculate the average temperature over time at each weather station, and we wish to incorporate this data into the same dataset. How will adding the average temperature data change the dataset‚Äôs variables, attributes, and dimensions?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVariables: Now we are measuring two variables: temperature and average temperature. The temperature data stays the same. We can represent the average temperature as a single 5x5 array with value 1 at each cell.\nDimensions: This dataset still has three dimensions: time, latitude, and longitude. The temperature variable uses all three dimensions, and the average temperature variable only uses two (latitude and longitude). This is ok! The dataset‚Äôs dimensions are the union of the dimensions of all the variables in the dataset. Variables in the same dataset may have all, some, or no dimensions in common.\n\nAttributes: To begin with, we need to keep all the previous attributes. Notice that the dataset‚Äôs title is general enough that we don‚Äôt need to update it. The only update we need to do is add the attributes for our new average temperature variable:\n\nAverage temperature attributes:\n\nstandard_name: average_air_temperature\ndescription: average temperature over three days\n\n\n\n\n\n\n\n\n\nThe xarray.DataArray is the primary data structure of the xarray package. It is an n-dimensional array with labeled dimensions. We can think of an xarray.DataArray as representing a single variable in the NetCDF data format: it holds the variable‚Äôs values, dimensions, and attributes.\nApart from variables, dimensions, and attributes, xarray introduces one more piece of information to keep track of a dataset‚Äôs content: in xarray each dimension has at least one set of coordinates. A dimension‚Äôs coordinates indicate the dimension‚Äôs values. We can think of the coordinate‚Äôs values as the tick labels along a dimension.\n\n\nIn our previous exercise about temperature measured in weather stations, latitude is a dimension, and the latitude‚Äôs coordinates are 30, 40, 50, 60, and 70 because those are the latitude values at which we are collecting temperature data. In that same exercise, time is a dimension, and its coordinates are 2022-09-1, 2022-09-02, and 2022-09-03.\n\nHere you can read more about the xarray terminology.\n\n\n\n\nWe want to create an xarray.DataArray that includes the information from our previous example about measuring temperature across three days as an xarray.DataArray. First, we import the required libraries:\n\nimport os              \nimport numpy as np\nimport pandas as pd\nimport xarray as xr   \n\n\n\nThe underlying data in the xarray.DataArray is a numpy.array that holds the variable values. So we can start by making a numpy.array with our mock temperature data:\n\n# Values of a single variable at each point of the coords \ntemp_data = np.array([np.zeros((5,5)), \n                      np.ones((5,5)), \n                      np.ones((5,5))*2]).astype(int)\ntemp_data\n\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\n\n\nWe could think this is ‚Äúall‚Äù we need to represent our data. But if we stopped at this point, we would need to\n\nremember that the numbers in this array represent the temperature in degrees Celsius (doesn‚Äôt seem too bad),\nremember that the first dimension of the array represents time, the second latitude and the third longitude (maybe ok), and\nkeep track of the range of values that time, latitude, and longitude take (not so good).\n\nKeeping track of all this information separately could quickly get messy and could make it challenging to share our data and analyses with others. This is what the netCDF data model and xarray aim to simplify. We can get data and its descriptors together in an xarray.DataArray by adding the dimensions over which the variable is being measured and including attributes that appropriately describe dimensions and variables.\n\n\n\nTo specify the dimensions of our upcoming xarray.DataArray, we must examine how we‚Äôve constructed the numpy.array holding the temperature data. The diagram below shows how the dimensions of temp_data are ordered: the first dimension is time, the second is latitude, and the third is longitude.\n\nRemember that indexing in 2-dimensional numpy.arrays starts at the top-left corner of the array, and it is done by rows first and columns second (like matrices). This is why latitude is the second dimension and longitude the third. From the diagram, we can also see that the coordinates (values of each dimension) are as follows:\n\ntime coordinates are 2022-09-01, 2022-09-02, 2022-09-03\nlatitude coordinates are 70, 60, 50, 40, 30 (notice decreasing order)\nlongitude coordinates are 60, 70, 80, 90, 100 (notice increasing order)\n\nWe add the dimensions as a tuple of strings and coordinates as a dictionary:\n\n# Names of the dimensions in the required order\ndims = ('time', 'lat', 'lon')\n\n# Create coordinates to use for indexing along each dimension \ncoords = {'time':pd.date_range(\"2022-09-01\", \"2022-09-03\"),\n          'lat':np.arange(70, 20, -10),\n          'lon':np.arange(60, 110, 10)}  \n\n\n\n\nNext, we add the attributes (metadata) for our temperature data as a dictionary:\n\n# Attributes (metadata) of the data array \nattrs = { 'title':'temperature across weather stations',\n          'standard_name':'air_temperature',\n          'units':'degree_c'}\n\n\n\n\nFinally, we put all these pieces together (data, dimensions, coordinates, and attributes) to create an xarray.DataArray:\n\n# Initialize xarray.DataArray\ntemp = xr.DataArray(data = temp_data, \n                    dims = dims,\n                    coords = coords,\n                    attrs = attrs)\ntemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt;\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\nCoordinates:\n  * time     (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_cxarray.DataArraytime: 3lat: 5lon: 50 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Coordinates: (3)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03array(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)int6470 60 50 40 30array([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100array([ 60,  70,  80,  90, 100])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (3)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_c\n\n\nWe can also update the variable‚Äôs attributes after creating the object. Notice that each of the coordinates is also an xarray.DataArray, so we can add attributes to them.\n\n# Update attributes\ntemp.attrs['description'] = 'Simple example of an xarray.DataArray'\n\n# Add attributes to coordinates \ntemp.time.attrs = {'description':'date of measurement'}\n\ntemp.lat.attrs['standard_name']= 'grid_latitude'\ntemp.lat.attrs['units'] = 'degree_N'\n\ntemp.lon.attrs['standard_name']= 'grid_longitude'\ntemp.lon.attrs['units'] = 'degree_E'\ntemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt;\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\nCoordinates:\n  * time     (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArraytime: 3lat: 5lon: 50 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Coordinates: (3)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nAt this point, since we have a single variable, the dataset attributes and the variable attributes are the same.\n\n\n\n\nTo select data from an xarray.DataArray we need to specify the subsets we want along each dimension. We can specify the data we need from each dimension either by looking up the dimension by its position or by looking up each dimension by its name.\n\nIndexing methods summary\n\n\n\n\n\n\n\n\nDimension lookup\nIndexing along dimension\nWhat to use\nExample\n\n\n\n\nBy position\nby integer\n[]\ntemp[0,3,2]\n\n\nBy position\nby label\n.loc[]\ntemp.loc['2022-09-01', 40, 80]\n\n\nBy name\nby integer\n.isel()\ntemp.isel(time=0, lat=3, lon=2)\n\n\nBy name\nby label\n.sel()\ntemp.sel(time='2022-09-01', lat=40, lon=80)\n\n\n\n\n\nWe want to know what was the temperature recorded by the weather station located at 40¬∞0‚Ä≤N 80¬∞0‚Ä≤E on September 1st, 2022.\nDimension lookup by position\nWhen we want to rely on the position of the dimensions in the xarray.DataArray, we need to remember that time is the first dimension, latitude is the second, and longitude the third.\nThen, we can then access the values along each dimension in two ways:\n\nby integer: the exact same as a numpy.array. Use the locator brackets [] and use the integer location of the data you need to retrieve it:\n\n\n# Access dimensions by position, then use integers for indexing\ntemp[0,3,2]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\nby label: same as pandas. We use the .loc[] locator to lookup a specific coordinate at each position (which represents a dimension):\n\n\n# Access dimensions by position, then use labels for indexing\ntemp.loc['2022-09-01', 40, 80]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nFor datasets with dozens of dimensions, it can be tough to remember which dimensions go where.\nDimension lookup by name\nWe can also use the dimension names to subset data, without the need to remember which dimensions goes where In this case, there are still two ways of selecting data along a dimension:\n\nby integer: we specify the integer location of the data we want along each dimension:\n\n\n# Acess dimensions by name, then use integers for indexing\ntemp.isel(time=0, lon=2, lat=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\nby label: we use the coordinate values we want to get!\n\n\n# Access dimensions by name, then use labels for indexing\ntemp.sel(time='2022-09-01', lat=40, lon=80)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nNotice that the result of this indexing is a 1x1 xarray.DataArray. This is because operations on an xarray.DataArray always return another xarray.DataArray. In particular, operations returning scalar values will also produce xarray objects, so we need to cast them as numbers manually using the xarray.DataArray item() method:\n\ntemp.sel(time='2022-09-01', lat=40, lon=80).item()\n\n0\n\n\nThe documentation is always a great place to learn more about xarray indexing.\n\n\n\n\nxarray has implemented several methods to reduce an xarray.DataArray along any number of dimensions.  For example, we can calculate the average temperature at each weather station over time and obtain a new xarray.DataArray.\n\navg_temp = temp.mean(dim = 'time') \n\navg_temp.attrs = {'title':'Average temperature over three days'}\navg_temp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (lat: 5, lon: 5)&gt;\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\nCoordinates:\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:    Average temperature over three daysxarray.DataArraylat: 5lon: 51.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0array([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])Coordinates: (2)lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])Indexes: (2)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (1)title :Average temperature over three days\n\n\nMore about xarray computations.\n\n\n\n\nAn xarray.DataSet resembles an in-memory representation of a NetCDF file and consists of multiple variables (each being an xarray.DataArray), with dimensions, coordinates, and attributes, forming a self-describing dataset. Attributes can be specific to each variable, each dimension, or they can describe the whole dataset. The variables in an xarray.DataSet can have the same dimensions, share some dimensions, or have no dimensions in common.\n\n\nFollowing our previous example, we can create an xarray.DataSet by combining the temperature data with the average temperature data. We also add some attributes that now describe the whole dataset, not only each variable.\n\n# Make dictionaries with variables and attributes\ndata_vars = {'avg_temp': avg_temp,\n             'temp': temp\n             }\n\nattrs = {'title':'Temperature data at weather stations: daily and and average',\n         'description':'Simple example of an xarray.Dataset'\n         }\n\n# Create xarray.Dataset\ntemp_dataset = xr.Dataset( data_vars = data_vars,\n                           attrs = attrs\n                           )\n\nTake some time to click through the data viewer and read through the variables and metadata in the dataset. Notice the following:\n\ntemp_dataset is a dataset with three dimensions (time, latitude, and longitude),\ntemp is a variable that uses all three dimensions in the dataset, and\naveg_temp is a variable that only uses two dimensions (latitude and longitude).\n\n\ntemp_dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:   (lat: 5, lon: 5, time: 3)\nCoordinates:\n  * lat       (lat) int64 70 60 50 40 30\n  * lon       (lon) int64 60 70 80 90 100\n  * time      (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\nData variables:\n    avg_temp  (lat, lon) float64 1.0 1.0 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0 1.0\n    temp      (time, lat, lon) int64 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2\nAttributes:\n    title:        Temperature data at weather stations: daily and and average\n    description:  Simple example of an xarray.Datasetxarray.DatasetDimensions:lat: 5lon: 5time: 3Coordinates: (3)lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')Data variables: (2)avg_temp(lat, lon)float641.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0title :Average temperature over three daysarray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])temp(time, lat, lon)int640 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArrayarray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Indexes: (3)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))Attributes: (2)title :Temperature data at weather stations: daily and and averagedescription :Simple example of an xarray.Dataset\n\n\n\n\n\nFinally, we want to save our dataset as a NetCDF file. To do this, specify the file path and use the .nc extension for the file name. Then save the dataset using the to_netcdf method with your file path. Opening NetCDF is similarly straightforward using xarray.open_dataset().\n# Save xarray.DataSet as NetCDF file\ntemp_dataset.to_netcdf('temp_dataset.nc')\n\n# Import NetCDF file\ncheck = xr.open_dataset('temp_dataset.nc')\ncheck\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:   (lat: 5, lon: 5, time: 3)\nCoordinates:\n  * lat       (lat) int32 70 60 50 40 30\n  * lon       (lon) int32 60 70 80 90 100\n  * time      (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\nData variables:\n    avg_temp  (lat, lon) float64 ...\n    temp      (time, lat, lon) int32 ...\nAttributes:\n    title:        Temperature data at weather stations: daily and and average\n    description:  Simple example of an xarray.Datasetxarray.DatasetDimensions:lat: 5lon: 5time: 3Coordinates: (3)lat(lat)int3270 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30], dtype=int32)lon(lon)int3260 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100], dtype=int32)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')Data variables: (2)avg_temp(lat, lon)float64...title :Average temperature over three days[25 values with dtype=float64]temp(time, lat, lon)int32...title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray[75 values with dtype=int32]Indexes: (3)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int32', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int32', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)title :Temperature data at weather stations: daily and and averagedescription :Simple example of an xarray.Dataset",
    "crumbs": [
      "notes",
      "Multidimensional data",
      "13 NetCDF and `xarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#netcdf",
    "href": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#netcdf",
    "title": "13 NetCDF and xarray",
    "section": "",
    "text": "Efficient and reproducible data analysis begins with choosing a proper format to store our data, particularly when working with large, complex, multi-dimensional datasets. Consider, for example, the following Earth System Data Cube from Mahecha et al. [3] , which measures nine environmental variables at high resolution across space and time. We can consider this dataset large (high-resolution means we have a big file), complex (multiple variables), and multi-dimensional (each variable is measured along three dimensions: latitude, longitude, and time). Additionally, necessary metadata must accompany the dataset to make it functional, such as units of measurement for variables, information about the authors, and processing software used.\n\n\n\nMahecha et al.¬†2020 . Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25¬∞ and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15¬∞ S to 60¬∞ N, and 10¬∞ E to 65¬∞ W.\n\n\nKeeping complex datasets in a format that facilitates access, processing, sharing, and archiving can be as important as the tools we use to analyze them.\nNetCDF (network Common Data Form) is a set of popular software libraries and self-describing, machine-independent data formats for working with multi-dimensional datasets. They are designed to support the creation, access, and sharing of array-oriented scientific data. NetCDF was initially developed at the Unidata Program Center and is supported on almost all platforms, and parsers exist for most scientific programming languages.\nThe NetCDF documentation outlines that this data format is desgined to be:\n\n\nSelf-describing: Information describing the data contents of the file is embedded within the data file itself. This means that there is a header describing the layout of the rest of the file and arbitrary file metadata.\nScalable: Small subsets of large datasets may be accessed efficiently through netCDF interfaces, even from remote servers.\nPortable: A NetCDF file is machine-independent i.e.¬†it can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\nAppendable: Data may be appended to a properly structured NetCDF file without copying the dataset or redefining its structure.\nSharable: One writer and multiple readers may simultaneously access the same NetCDF file.\nArchivable: Access to all earlier forms of NetCDF data will be supported by current and future versions of the software.\n\n\n\n\nThe NetCDF data model is the way that NetCDF organizes data. This lesson will follow the Classic NetCDF Data Model, which is at the core of all netCDF files. \nThe model consists of three key components: variables, dimensions, and attributes.\n\nVariables are N-dimensional arrays of data. We can think of these as varying/measured/dependent quantities.\nDimensions describe the axes of the data arrays. A dimension has a name and a length. We can think of these as the constant/fixed/independent quantities at which we measure the variables.\nAttributes are small notes or supplementary metadata to annotate a variable or the file as a whole.\n\n\n\n\nClassic NetCDF Data Model (NetCDF documentation)\n\n\n\n\n\nThe most commonly used metadata standard for geospatial data is the Climate and Forecast metadata standard, also called the CF conventions.\n\nThe CF conventions are specifically designed to promote the processing and sharing of files created with the NetCDF API. Principles of CF include self-describing data (no external tables needed for understanding), metadata equally readable by humans and software, minimum redundancy, and maximum simplicity. (CF conventions FAQ)\n\nThe CF conventions provide a unique standardized name and precise description of over 1,000 physical variables. To maximize the reusability of our data, it is best to include a variable‚Äôs standardized name as an attribute called standard_name. Variables should also include a units attribute. This attribute should be a string that can be recognized by UNIDATA‚Äôs UDUNITS package. In these links you can find:\n\na table with all of the CF convention‚Äôs standard names, and\na list of the units found in the UDUNITS database maintained by the North Carolina Institute for Climate Studies.",
    "crumbs": [
      "notes",
      "Multidimensional data",
      "13 NetCDF and `xarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#xarray",
    "href": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#xarray",
    "title": "13 NetCDF and xarray",
    "section": "",
    "text": "xarray [1] is an open source project and Python package that augments NumPy arrays by adding labeled dimensions, coordinates, and attributes. xarray is based on the NetCDF data model, making it the appropriate tool to open, process, and create datasets in NetCDF format.\n\n\n\nxarray‚Äôs development portal\n\n\n\n\nVariables, dimensions, and attributes refer to the same components of NetCDF files we reviewed in the previous section. The following is a concrete example of variables, dimensions, and attributes that will guide the rest of the section.\n\n\nImagine the following scenario. We have a network of 25 weather stations. They are located in a square grid: starting at 30¬∞0‚Ä≤N 60¬∞0‚Ä≤E, there is a station every 10¬∞ North and every 10¬∞ East. Each station measures the air temperature at a set time for three days, starting on September 1st, 2022. On the first day, all stations record a temperature of 0¬∞C. On the second day, all temperatures are 1¬∞C, and on the third day, all temperatures are 2¬∞C. What are the variables, dimensions and attributes for this data?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVariables: There is a single variable being measured: temperature. The variable values can be represented as a 5x5x3 array, with constant values for each day.\nDimensions: This dataset has three dimensions: time, latitude, and longitude. Time indicates when the measurement happened, we can encode it as the dates 2022-09-01, 2022-09-02, and 2022-09-03. The pairs of latitude and longitude values indicate the positions of the weather stations. Latitude has values 30, 40, 50, 60, and 70, measured in degrees North. Longitude has values 60, 70, 80, 90, and 100, measured in degrees East.\n\nAttributes: Let‚Äôs divide these into attributes for the variable, the dimensions, and the whole dataset:\n\nVariable attributes:\n\nTemperature attributes:\n\nstandard_name: air_temperature\nunits: degree_C\n\n\nDimension attributes:\n\nTime attributes:\n\ndescription: date of measurement\n\nLatitude attributes:\n\nstandard_name: grid_latitude\nunits: degrees_N\n\nLongitude attributes:\n\nsatandard_name: grid_longitude\nunits: degree_E\n\n\nDataset attributes:\n\ntitle: Temperature Measurements at Weather Stations\nsummary: an example of NetCDF data format\n\n\n\n\n\nNow imagine we calculate the average temperature over time at each weather station, and we wish to incorporate this data into the same dataset. How will adding the average temperature data change the dataset‚Äôs variables, attributes, and dimensions?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVariables: Now we are measuring two variables: temperature and average temperature. The temperature data stays the same. We can represent the average temperature as a single 5x5 array with value 1 at each cell.\nDimensions: This dataset still has three dimensions: time, latitude, and longitude. The temperature variable uses all three dimensions, and the average temperature variable only uses two (latitude and longitude). This is ok! The dataset‚Äôs dimensions are the union of the dimensions of all the variables in the dataset. Variables in the same dataset may have all, some, or no dimensions in common.\n\nAttributes: To begin with, we need to keep all the previous attributes. Notice that the dataset‚Äôs title is general enough that we don‚Äôt need to update it. The only update we need to do is add the attributes for our new average temperature variable:\n\nAverage temperature attributes:\n\nstandard_name: average_air_temperature\ndescription: average temperature over three days\n\n\n\n\n\n\n\n\n\nThe xarray.DataArray is the primary data structure of the xarray package. It is an n-dimensional array with labeled dimensions. We can think of an xarray.DataArray as representing a single variable in the NetCDF data format: it holds the variable‚Äôs values, dimensions, and attributes.\nApart from variables, dimensions, and attributes, xarray introduces one more piece of information to keep track of a dataset‚Äôs content: in xarray each dimension has at least one set of coordinates. A dimension‚Äôs coordinates indicate the dimension‚Äôs values. We can think of the coordinate‚Äôs values as the tick labels along a dimension.\n\n\nIn our previous exercise about temperature measured in weather stations, latitude is a dimension, and the latitude‚Äôs coordinates are 30, 40, 50, 60, and 70 because those are the latitude values at which we are collecting temperature data. In that same exercise, time is a dimension, and its coordinates are 2022-09-1, 2022-09-02, and 2022-09-03.\n\nHere you can read more about the xarray terminology.\n\n\n\n\nWe want to create an xarray.DataArray that includes the information from our previous example about measuring temperature across three days as an xarray.DataArray. First, we import the required libraries:\n\nimport os              \nimport numpy as np\nimport pandas as pd\nimport xarray as xr   \n\n\n\nThe underlying data in the xarray.DataArray is a numpy.array that holds the variable values. So we can start by making a numpy.array with our mock temperature data:\n\n# Values of a single variable at each point of the coords \ntemp_data = np.array([np.zeros((5,5)), \n                      np.ones((5,5)), \n                      np.ones((5,5))*2]).astype(int)\ntemp_data\n\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\n\n\nWe could think this is ‚Äúall‚Äù we need to represent our data. But if we stopped at this point, we would need to\n\nremember that the numbers in this array represent the temperature in degrees Celsius (doesn‚Äôt seem too bad),\nremember that the first dimension of the array represents time, the second latitude and the third longitude (maybe ok), and\nkeep track of the range of values that time, latitude, and longitude take (not so good).\n\nKeeping track of all this information separately could quickly get messy and could make it challenging to share our data and analyses with others. This is what the netCDF data model and xarray aim to simplify. We can get data and its descriptors together in an xarray.DataArray by adding the dimensions over which the variable is being measured and including attributes that appropriately describe dimensions and variables.\n\n\n\nTo specify the dimensions of our upcoming xarray.DataArray, we must examine how we‚Äôve constructed the numpy.array holding the temperature data. The diagram below shows how the dimensions of temp_data are ordered: the first dimension is time, the second is latitude, and the third is longitude.\n\nRemember that indexing in 2-dimensional numpy.arrays starts at the top-left corner of the array, and it is done by rows first and columns second (like matrices). This is why latitude is the second dimension and longitude the third. From the diagram, we can also see that the coordinates (values of each dimension) are as follows:\n\ntime coordinates are 2022-09-01, 2022-09-02, 2022-09-03\nlatitude coordinates are 70, 60, 50, 40, 30 (notice decreasing order)\nlongitude coordinates are 60, 70, 80, 90, 100 (notice increasing order)\n\nWe add the dimensions as a tuple of strings and coordinates as a dictionary:\n\n# Names of the dimensions in the required order\ndims = ('time', 'lat', 'lon')\n\n# Create coordinates to use for indexing along each dimension \ncoords = {'time':pd.date_range(\"2022-09-01\", \"2022-09-03\"),\n          'lat':np.arange(70, 20, -10),\n          'lon':np.arange(60, 110, 10)}  \n\n\n\n\nNext, we add the attributes (metadata) for our temperature data as a dictionary:\n\n# Attributes (metadata) of the data array \nattrs = { 'title':'temperature across weather stations',\n          'standard_name':'air_temperature',\n          'units':'degree_c'}\n\n\n\n\nFinally, we put all these pieces together (data, dimensions, coordinates, and attributes) to create an xarray.DataArray:\n\n# Initialize xarray.DataArray\ntemp = xr.DataArray(data = temp_data, \n                    dims = dims,\n                    coords = coords,\n                    attrs = attrs)\ntemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt;\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\nCoordinates:\n  * time     (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_cxarray.DataArraytime: 3lat: 5lon: 50 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Coordinates: (3)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03array(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)int6470 60 50 40 30array([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100array([ 60,  70,  80,  90, 100])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (3)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_c\n\n\nWe can also update the variable‚Äôs attributes after creating the object. Notice that each of the coordinates is also an xarray.DataArray, so we can add attributes to them.\n\n# Update attributes\ntemp.attrs['description'] = 'Simple example of an xarray.DataArray'\n\n# Add attributes to coordinates \ntemp.time.attrs = {'description':'date of measurement'}\n\ntemp.lat.attrs['standard_name']= 'grid_latitude'\ntemp.lat.attrs['units'] = 'degree_N'\n\ntemp.lon.attrs['standard_name']= 'grid_longitude'\ntemp.lon.attrs['units'] = 'degree_E'\ntemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt;\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\nCoordinates:\n  * time     (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArraytime: 3lat: 5lon: 50 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Coordinates: (3)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nAt this point, since we have a single variable, the dataset attributes and the variable attributes are the same.\n\n\n\n\nTo select data from an xarray.DataArray we need to specify the subsets we want along each dimension. We can specify the data we need from each dimension either by looking up the dimension by its position or by looking up each dimension by its name.\n\nIndexing methods summary\n\n\n\n\n\n\n\n\nDimension lookup\nIndexing along dimension\nWhat to use\nExample\n\n\n\n\nBy position\nby integer\n[]\ntemp[0,3,2]\n\n\nBy position\nby label\n.loc[]\ntemp.loc['2022-09-01', 40, 80]\n\n\nBy name\nby integer\n.isel()\ntemp.isel(time=0, lat=3, lon=2)\n\n\nBy name\nby label\n.sel()\ntemp.sel(time='2022-09-01', lat=40, lon=80)\n\n\n\n\n\nWe want to know what was the temperature recorded by the weather station located at 40¬∞0‚Ä≤N 80¬∞0‚Ä≤E on September 1st, 2022.\nDimension lookup by position\nWhen we want to rely on the position of the dimensions in the xarray.DataArray, we need to remember that time is the first dimension, latitude is the second, and longitude the third.\nThen, we can then access the values along each dimension in two ways:\n\nby integer: the exact same as a numpy.array. Use the locator brackets [] and use the integer location of the data you need to retrieve it:\n\n\n# Access dimensions by position, then use integers for indexing\ntemp[0,3,2]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\nby label: same as pandas. We use the .loc[] locator to lookup a specific coordinate at each position (which represents a dimension):\n\n\n# Access dimensions by position, then use labels for indexing\ntemp.loc['2022-09-01', 40, 80]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nFor datasets with dozens of dimensions, it can be tough to remember which dimensions go where.\nDimension lookup by name\nWe can also use the dimension names to subset data, without the need to remember which dimensions goes where In this case, there are still two ways of selecting data along a dimension:\n\nby integer: we specify the integer location of the data we want along each dimension:\n\n\n# Acess dimensions by name, then use integers for indexing\ntemp.isel(time=0, lon=2, lat=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\nby label: we use the coordinate values we want to get!\n\n\n# Access dimensions by name, then use labels for indexing\ntemp.sel(time='2022-09-01', lat=40, lon=80)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0)\nCoordinates:\n    time     datetime64[ns] 2022-09-01\n    lat      int64 40\n    lon      int64 80\nAttributes:\n    title:          temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArray0array(0)Coordinates: (3)time()datetime64[ns]2022-09-01description :date of measurementarray('2022-09-01T00:00:00.000000000', dtype='datetime64[ns]')lat()int6440standard_name :grid_latitudeunits :degree_Narray(40)lon()int6480standard_name :grid_longitudeunits :degree_Earray(80)Indexes: (0)Attributes: (4)title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\nNotice that the result of this indexing is a 1x1 xarray.DataArray. This is because operations on an xarray.DataArray always return another xarray.DataArray. In particular, operations returning scalar values will also produce xarray objects, so we need to cast them as numbers manually using the xarray.DataArray item() method:\n\ntemp.sel(time='2022-09-01', lat=40, lon=80).item()\n\n0\n\n\nThe documentation is always a great place to learn more about xarray indexing.\n\n\n\n\nxarray has implemented several methods to reduce an xarray.DataArray along any number of dimensions.  For example, we can calculate the average temperature at each weather station over time and obtain a new xarray.DataArray.\n\navg_temp = temp.mean(dim = 'time') \n\navg_temp.attrs = {'title':'Average temperature over three days'}\navg_temp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (lat: 5, lon: 5)&gt;\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\nCoordinates:\n  * lat      (lat) int64 70 60 50 40 30\n  * lon      (lon) int64 60 70 80 90 100\nAttributes:\n    title:    Average temperature over three daysxarray.DataArraylat: 5lon: 51.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0array([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])Coordinates: (2)lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])Indexes: (2)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (1)title :Average temperature over three days\n\n\nMore about xarray computations.",
    "crumbs": [
      "notes",
      "Multidimensional data",
      "13 NetCDF and `xarray`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#xarray.dataset",
    "href": "book/chapters/lesson-14-xarray/lesson-14-xarray.html#xarray.dataset",
    "title": "13 NetCDF and xarray",
    "section": "",
    "text": "An xarray.DataSet resembles an in-memory representation of a NetCDF file and consists of multiple variables (each being an xarray.DataArray), with dimensions, coordinates, and attributes, forming a self-describing dataset. Attributes can be specific to each variable, each dimension, or they can describe the whole dataset. The variables in an xarray.DataSet can have the same dimensions, share some dimensions, or have no dimensions in common.\n\n\nFollowing our previous example, we can create an xarray.DataSet by combining the temperature data with the average temperature data. We also add some attributes that now describe the whole dataset, not only each variable.\n\n# Make dictionaries with variables and attributes\ndata_vars = {'avg_temp': avg_temp,\n             'temp': temp\n             }\n\nattrs = {'title':'Temperature data at weather stations: daily and and average',\n         'description':'Simple example of an xarray.Dataset'\n         }\n\n# Create xarray.Dataset\ntemp_dataset = xr.Dataset( data_vars = data_vars,\n                           attrs = attrs\n                           )\n\nTake some time to click through the data viewer and read through the variables and metadata in the dataset. Notice the following:\n\ntemp_dataset is a dataset with three dimensions (time, latitude, and longitude),\ntemp is a variable that uses all three dimensions in the dataset, and\naveg_temp is a variable that only uses two dimensions (latitude and longitude).\n\n\ntemp_dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:   (lat: 5, lon: 5, time: 3)\nCoordinates:\n  * lat       (lat) int64 70 60 50 40 30\n  * lon       (lon) int64 60 70 80 90 100\n  * time      (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\nData variables:\n    avg_temp  (lat, lon) float64 1.0 1.0 1.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0 1.0\n    temp      (time, lat, lon) int64 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2\nAttributes:\n    title:        Temperature data at weather stations: daily and and average\n    description:  Simple example of an xarray.Datasetxarray.DatasetDimensions:lat: 5lon: 5time: 3Coordinates: (3)lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')Data variables: (2)avg_temp(lat, lon)float641.0 1.0 1.0 1.0 ... 1.0 1.0 1.0 1.0title :Average temperature over three daysarray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])temp(time, lat, lon)int640 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArrayarray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Indexes: (3)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))Attributes: (2)title :Temperature data at weather stations: daily and and averagedescription :Simple example of an xarray.Dataset\n\n\n\n\n\nFinally, we want to save our dataset as a NetCDF file. To do this, specify the file path and use the .nc extension for the file name. Then save the dataset using the to_netcdf method with your file path. Opening NetCDF is similarly straightforward using xarray.open_dataset().\n# Save xarray.DataSet as NetCDF file\ntemp_dataset.to_netcdf('temp_dataset.nc')\n\n# Import NetCDF file\ncheck = xr.open_dataset('temp_dataset.nc')\ncheck\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:   (lat: 5, lon: 5, time: 3)\nCoordinates:\n  * lat       (lat) int32 70 60 50 40 30\n  * lon       (lon) int32 60 70 80 90 100\n  * time      (time) datetime64[ns] 2022-09-01 2022-09-02 2022-09-03\nData variables:\n    avg_temp  (lat, lon) float64 ...\n    temp      (time, lat, lon) int32 ...\nAttributes:\n    title:        Temperature data at weather stations: daily and and average\n    description:  Simple example of an xarray.Datasetxarray.DatasetDimensions:lat: 5lon: 5time: 3Coordinates: (3)lat(lat)int3270 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30], dtype=int32)lon(lon)int3260 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100], dtype=int32)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')Data variables: (2)avg_temp(lat, lon)float64...title :Average temperature over three days[25 values with dtype=float64]temp(time, lat, lon)int32...title :temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray[75 values with dtype=int32]Indexes: (3)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int32', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int32', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)title :Temperature data at weather stations: daily and and averagedescription :Simple example of an xarray.Dataset",
    "crumbs": [
      "notes",
      "Multidimensional data",
      "13 NetCDF and `xarray`"
    ]
  },
  {
    "objectID": "book/chapters/merging-data.html",
    "href": "book/chapters/merging-data.html",
    "title": "Merging data",
    "section": "",
    "text": "In this lesson we will review how to join dataframes. \nThe section is based on the Data Modeling Essentials R lesson on merging data [1] from the NCEAS Learning Hub.\n\n\nFrequently, analysis of data will require merging separate data frames. There are multiple ways to merge observations. When conceptualizing merges, we think of two tables, one on the left and one on the right.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\nAn inner join is when you merge the subset of rows that have matches in both the left table and the right table.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nA left join takes all of the rows from the left table, and merges on the data from matching rows in the right table. Keys that don‚Äôt match from the left table are still provided with a missing value (na) from the right table.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nA right join is the same as a left join, except that all of the rows from the right table are included with matching data from the left, or a missing value. Notice that left and right joins can ultimately be the same depending on the positions of the tables.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nFinally, a full outer join (or just full join) includes all data from all rows in both tables, and includes missing values wherever necessary.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\nSometimes people represent joins as Venn diagrams, showing which parts of the left and right tables are included in the results for each join. This representation is useful, however, they miss part of the story related to where the missing value comes from in each result.\n\n\n\nImage source: R for Data Science, Wickham & Grolemund.\n\n\n\n\n\n\nTo merge dataframes we can use the pandas.merge() function. The basic syntax for it is:\noutput_df = pd.merge(left_df,\n                     right_df, \n                     how = type_of_join, \n                     on = column_to_join)\nwhere\n\noutput_df is the dataframe resulting from the merge,\nleft_df is the dataframe we have ‚Äúon the left side‚Äù,\nright_df is the dataframe we have ‚Äúon the right side‚Äù,\nhow specifies the type of join between the left and right dataframes, (check the options here), the default is to do an inner join,\non specifies the column to join on, this column must be present in both our dataframes.",
    "crumbs": [
      "notes",
      "Tabular data",
      "Merging data"
    ]
  },
  {
    "objectID": "book/chapters/merging-data.html#types-of-joins",
    "href": "book/chapters/merging-data.html#types-of-joins",
    "title": "Merging data",
    "section": "",
    "text": "Frequently, analysis of data will require merging separate data frames. There are multiple ways to merge observations. When conceptualizing merges, we think of two tables, one on the left and one on the right.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\nAn inner join is when you merge the subset of rows that have matches in both the left table and the right table.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nA left join takes all of the rows from the left table, and merges on the data from matching rows in the right table. Keys that don‚Äôt match from the left table are still provided with a missing value (na) from the right table.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nA right join is the same as a left join, except that all of the rows from the right table are included with matching data from the left, or a missing value. Notice that left and right joins can ultimately be the same depending on the positions of the tables.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\n\n\n\nFinally, a full outer join (or just full join) includes all data from all rows in both tables, and includes missing values wherever necessary.\n\n\n\nImage source: Data Modeling Essentials, NCEAS Learning Hub\n\n\nSometimes people represent joins as Venn diagrams, showing which parts of the left and right tables are included in the results for each join. This representation is useful, however, they miss part of the story related to where the missing value comes from in each result.\n\n\n\nImage source: R for Data Science, Wickham & Grolemund.",
    "crumbs": [
      "notes",
      "Tabular data",
      "Merging data"
    ]
  },
  {
    "objectID": "book/chapters/merging-data.html#pandas.merge",
    "href": "book/chapters/merging-data.html#pandas.merge",
    "title": "Merging data",
    "section": "",
    "text": "To merge dataframes we can use the pandas.merge() function. The basic syntax for it is:\noutput_df = pd.merge(left_df,\n                     right_df, \n                     how = type_of_join, \n                     on = column_to_join)\nwhere\n\noutput_df is the dataframe resulting from the merge,\nleft_df is the dataframe we have ‚Äúon the left side‚Äù,\nright_df is the dataframe we have ‚Äúon the right side‚Äù,\nhow specifies the type of join between the left and right dataframes, (check the options here), the default is to do an inner join,\non specifies the column to join on, this column must be present in both our dataframes.",
    "crumbs": [
      "notes",
      "Tabular data",
      "Merging data"
    ]
  },
  {
    "objectID": "book/chapters/lesson-9-vector-data.html",
    "href": "book/chapters/lesson-9-vector-data.html",
    "title": "8 Vector data formats",
    "section": "",
    "text": "Vector data is one of the two primary types of geospatial data (the other one being raster data). In this section we will review what vector data is and go over some common data formats for it.\n\n\n\nVector data represents specific features on the Earth‚Äôs surface. There are three core types of vector data:\n\nPoints: each point has a single \\(x\\),\\(y\\) location. Examples of data that can be represented as point vector data are sampling locations or animal sightings.\nLines: a line is composed of at least two points that are connected. Roads and streams are commonly depicted as line vector data.\nPolygons: polygons are sets of three or more vertices that are connected and form a closed region. Political boundaries (outlines of countries, states, cities, etc) are examples of polygon vector data.\n\nEach item in the vector data is usually referred to as a feature. So each point would be a feature, each polygon is a feature, etc.\n\n\n\nImage Source: National Ecological Observatory Network (NEON)\n\n\nBesides points, lines, and polygons, we can also encounter an additional type of vector data:\n\nMultipolygons: represent features made up of several polygons. Each polygon can be a separate, disconnected area, but together they form one feature. For example, a country with both mainland and island territories is often represented as a multi-polygon. Multi-polygons are useful for geographic entities that consist of multiple regions but need to be treated as a single unit in analysis.\n\nIn addition to the geospatial information stored, vector data can include attributes that describe each feature. For example, a vector dataset where each feature is a polygon representing the boundary of a state could have as attributes the population and area of the state.\n\n\n\nImage Source: National Ecological Observatory Network (NEON)\n\n\n\n\n\nOne of the most popular formats to store vector data is the shapefile data format. The shapefile format is developed and maintained by the Environmental Systems Research Institute (Esri).\nSo far we have been working with data that comes stored in a single file, like a CSV or .txt file for tabular data. A shapefile is actually a collection of files that interact together to create a single data file. All the files that make up a shapefile need to have the same name (with different extensions) and be in the same directory. For our shapefiles to work we need at least these three files:\n\n.shp: shape format, this file has the geometries for all features.\n.shx: shape index format, this file indexes the features\n.dbf: attribute format, this file stores the attributes for features as a table\n\nSometimes shapefiles will have additional files, including:\n\n.prj: a file containing information about the projection and coordinate reference system\n.sbn and .sbx: files that contain a spatial index of the features\n.shp.xml: geospatial metadata in XML format.\n\nCheck the Wikipedia page about shapefiles to see a more extensive list of files associated to shapefiles.\n\n\n\n\n\n\nFile management for shapefiles\n\n\n\nRemember: when working with a shapefile all the associated files must have the same name (with different extensions) and must be located in the same directory.\n\n\n\n\n\n\n\n\nA single shapefile can only have one vector type\n\n\n\nEach shapefile can only hold one type of vector data. You cannot have, for example, lines and points in the same file. Only points, only lines, or only polygons can be inside a single shapefile.\n\n\n\n\n\n\nGeoJSON, which stands for Geographic JavaScript Object Notation, is an open format for encoding vector data (points, lines, polygons, and multipolygons) and their attributes. It is a popular format for web mapping applications. The GeoJSON format uses a single file, with extension .json or .geojson.\nWhile shapefiles can be in any coordinate reference system, the GeoJSON specification requires GeoJSON files to use the World Geodetic System 1984 (EPSG:4326/WGS84) CRS and all points must be expressed in longitude and latitude units of decimal degrees.\nData in a GeoJSON is stored as attribute-value pairs (similar to Python dictionaries!) and lists. The following are examples of how points, lines, and polygons are represented as GeoJSON features:\n\n\n\nSource: Wikipedia\n\n\nThe followng is an example of a full GeoJSON file. Notice that multiple types of geometries can be mixed within the same file:\n# Source: Wikipedia\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [102.0, 0.5]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\"\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"LineString\",\n        \"coordinates\": [\n          [102.0, 0.0],\n          [103.0, 1.0],\n          [104.0, 0.0],\n          [105.0, 1.0]\n        ]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\",\n        \"prop1\": 0.0\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [100.0, 0.0],\n            [101.0, 0.0],\n            [101.0, 1.0],\n            [100.0, 1.0],\n            [100.0, 0.0]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\",\n        \"prop1\": { \"this\": \"that\" }\n      }\n    }\n  ]\n}\nThe website https://geojson.io/ is a nice tool to easily create GeoJSON files.",
    "crumbs": [
      "notes",
      "Vector data",
      "8 Vector data formats"
    ]
  },
  {
    "objectID": "book/chapters/lesson-9-vector-data.html#points-lines-and-polygons",
    "href": "book/chapters/lesson-9-vector-data.html#points-lines-and-polygons",
    "title": "8 Vector data formats",
    "section": "",
    "text": "Vector data represents specific features on the Earth‚Äôs surface. There are three core types of vector data:\n\nPoints: each point has a single \\(x\\),\\(y\\) location. Examples of data that can be represented as point vector data are sampling locations or animal sightings.\nLines: a line is composed of at least two points that are connected. Roads and streams are commonly depicted as line vector data.\nPolygons: polygons are sets of three or more vertices that are connected and form a closed region. Political boundaries (outlines of countries, states, cities, etc) are examples of polygon vector data.\n\nEach item in the vector data is usually referred to as a feature. So each point would be a feature, each polygon is a feature, etc.\n\n\n\nImage Source: National Ecological Observatory Network (NEON)\n\n\nBesides points, lines, and polygons, we can also encounter an additional type of vector data:\n\nMultipolygons: represent features made up of several polygons. Each polygon can be a separate, disconnected area, but together they form one feature. For example, a country with both mainland and island territories is often represented as a multi-polygon. Multi-polygons are useful for geographic entities that consist of multiple regions but need to be treated as a single unit in analysis.\n\nIn addition to the geospatial information stored, vector data can include attributes that describe each feature. For example, a vector dataset where each feature is a polygon representing the boundary of a state could have as attributes the population and area of the state.\n\n\n\nImage Source: National Ecological Observatory Network (NEON)",
    "crumbs": [
      "notes",
      "Vector data",
      "8 Vector data formats"
    ]
  },
  {
    "objectID": "book/chapters/lesson-9-vector-data.html#shapefiles",
    "href": "book/chapters/lesson-9-vector-data.html#shapefiles",
    "title": "8 Vector data formats",
    "section": "",
    "text": "One of the most popular formats to store vector data is the shapefile data format. The shapefile format is developed and maintained by the Environmental Systems Research Institute (Esri).\nSo far we have been working with data that comes stored in a single file, like a CSV or .txt file for tabular data. A shapefile is actually a collection of files that interact together to create a single data file. All the files that make up a shapefile need to have the same name (with different extensions) and be in the same directory. For our shapefiles to work we need at least these three files:\n\n.shp: shape format, this file has the geometries for all features.\n.shx: shape index format, this file indexes the features\n.dbf: attribute format, this file stores the attributes for features as a table\n\nSometimes shapefiles will have additional files, including:\n\n.prj: a file containing information about the projection and coordinate reference system\n.sbn and .sbx: files that contain a spatial index of the features\n.shp.xml: geospatial metadata in XML format.\n\nCheck the Wikipedia page about shapefiles to see a more extensive list of files associated to shapefiles.\n\n\n\n\n\n\nFile management for shapefiles\n\n\n\nRemember: when working with a shapefile all the associated files must have the same name (with different extensions) and must be located in the same directory.\n\n\n\n\n\n\n\n\nA single shapefile can only have one vector type\n\n\n\nEach shapefile can only hold one type of vector data. You cannot have, for example, lines and points in the same file. Only points, only lines, or only polygons can be inside a single shapefile.",
    "crumbs": [
      "notes",
      "Vector data",
      "8 Vector data formats"
    ]
  },
  {
    "objectID": "book/chapters/lesson-9-vector-data.html#geojson",
    "href": "book/chapters/lesson-9-vector-data.html#geojson",
    "title": "8 Vector data formats",
    "section": "",
    "text": "GeoJSON, which stands for Geographic JavaScript Object Notation, is an open format for encoding vector data (points, lines, polygons, and multipolygons) and their attributes. It is a popular format for web mapping applications. The GeoJSON format uses a single file, with extension .json or .geojson.\nWhile shapefiles can be in any coordinate reference system, the GeoJSON specification requires GeoJSON files to use the World Geodetic System 1984 (EPSG:4326/WGS84) CRS and all points must be expressed in longitude and latitude units of decimal degrees.\nData in a GeoJSON is stored as attribute-value pairs (similar to Python dictionaries!) and lists. The following are examples of how points, lines, and polygons are represented as GeoJSON features:\n\n\n\nSource: Wikipedia\n\n\nThe followng is an example of a full GeoJSON file. Notice that multiple types of geometries can be mixed within the same file:\n# Source: Wikipedia\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [102.0, 0.5]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\"\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"LineString\",\n        \"coordinates\": [\n          [102.0, 0.0],\n          [103.0, 1.0],\n          [104.0, 0.0],\n          [105.0, 1.0]\n        ]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\",\n        \"prop1\": 0.0\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [100.0, 0.0],\n            [101.0, 0.0],\n            [101.0, 1.0],\n            [100.0, 1.0],\n            [100.0, 0.0]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"prop0\": \"value0\",\n        \"prop1\": { \"this\": \"that\" }\n      }\n    }\n  ]\n}\nThe website https://geojson.io/ is a nice tool to easily create GeoJSON files.",
    "crumbs": [
      "notes",
      "Vector data",
      "8 Vector data formats"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-data-preparation.html",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-data-preparation.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "import pandas as pd\n\nDataset: https://portal.edirepository.org/nis/mapbrowse?packageid=edi.649.6\nMetadata: https://portal.edirepository.org/nis/metadataviewer?packageid=edi.649.6\nMore info: https://marinemitigation.msi.ucsb.edu/data?field_species_target_id=&field_data_category_target_id%5B44%5D=44\nThese data describe annual estimates of bird density collected as part of the SONGS San Dieguito Wetland Restoration mitigation monitoring program designed to evaluate compliance of the restoration project with conditions of the SONGS permit. Monitoring began in 2012 in the San Dieguito Wetlands and Tijuana Estuary in San Diego County, CA, Carpinteria Salt Marsh in Santa Barbara County, CA, and Mugu Lagoon in Ventura County, CA. The abundance of birds is determined from twenty plots spread across each wetland.\nCSM = Carpinteria Salt Marsh MUL = Mugu Lagoon SDW = San Dieguito Wetland TJE = Tijuana Estuary\n\ndf = pd.read_csv('data/wetland_ts_bird_abundance-2024-06-12_14-38-10.csv')\ndf.head()\n\n\n\n\n\n\n\n\nyear\nsurvey\ndate\nwetland_code\nmodule_code\nbird_plot_number\nstart_time\ncloud_cover\ntemperature\nwind_speed\nwind_direction\nprecipitation_code\nbird_count_visibility_code\nspecies_id\nspecies_code\ngenus_name\nspecies_name\nbird_flight_code\ncount\nbird_plot_area_acres\n\n\n\n\n0\n2010\n1\n2010-02-03\nCSM\nCSM\n1\n04:04:00\n-99999\n60\n-99999\nNOT RECORDED\nNONE\nGOOD\n9\nCOHA\nAccipiter\ncooperii\nA\n0\n3.71\n\n\n1\n2010\n1\n2010-02-03\nCSM\nCSM\n1\n04:04:00\n-99999\n60\n-99999\nNOT RECORDED\nNONE\nGOOD\n9\nCOHA\nAccipiter\ncooperii\nG\n0\n3.71\n\n\n2\n2010\n1\n2010-02-03\nCSM\nCSM\n1\n04:04:00\n-99999\n60\n-99999\nNOT RECORDED\nNONE\nGOOD\n13\nSSHA\nAccipiter\nstriatus\nA\n0\n3.71\n\n\n3\n2010\n1\n2010-02-03\nCSM\nCSM\n1\n04:04:00\n-99999\n60\n-99999\nNOT RECORDED\nNONE\nGOOD\n13\nSSHA\nAccipiter\nstriatus\nG\n0\n3.71\n\n\n4\n2010\n1\n2010-02-03\nCSM\nCSM\n1\n04:04:00\n-99999\n60\n-99999\nNOT RECORDED\nNONE\nGOOD\n20\nSPSA\nActitis\nmacularius\nA\n0\n3.71\n\n\n\n\n\n\n\n\ndef month_to_season(month):\n    \"\"\"\n    Returns the season ('winter', 'spring', 'summer', 'fall') for a given month (1-12).\n    \"\"\"    \n    if month in [12, 1, 2]:\n        return 'winter'\n    elif month in [3, 4, 5]:\n        return 'spring'\n    elif month in [6, 7, 8]:\n        return 'summer'\n    elif month in [9, 10, 11]:\n        return 'fall'\n\n# Add column with seasons\ndf['season'] = pd.to_datetime(df.date).dt.month.apply(month_to_season)\n\n# Calculate number of species registered per (year, season, wetland) combination\n# Rows where 'count' is 0 are filtered out to do this\nspecies = df[df['count']&gt;0].groupby(['year','wetland_code','season'])['species_code'].nunique().reset_index()\n\n# Pivot the DataFrame: create columns for wetland-season pairs\nspecies = species.pivot(index='year', columns=['wetland_code','season'], values='species_code')\n\n# Flatten the MultiIndex column names\nspecies.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in species.columns]\n\n# Reset the index to make 'year' a column\nspecies = species.reset_index()\n\n# Reorder column names\nspecies = species[['year', \n    'CSM_winter','CSM_spring','CSM_fall',\n    'MUL_winter','MUL_spring','MUL_fall',\n    'SDW_winter','SDW_spring','SDW_fall',\n    'TJE_winter','TJE_spring','TJE_fall' ]]\nspecies\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n5\n2015\n44.0\n42.0\n45.0\n58.0\n50.0\n51.0\n71.0\n61.0\n65.0\n73.0\n76.0\n64.0\n\n\n6\n2016\n41.0\n36.0\n47.0\n63.0\n48.0\n58.0\n67.0\n62.0\n57.0\n76.0\n76.0\n58.0\n\n\n7\n2017\n46.0\n41.0\n43.0\n57.0\n54.0\n53.0\n66.0\n45.0\n54.0\n72.0\n63.0\n57.0\n\n\n8\n2018\n48.0\n48.0\n44.0\n56.0\n54.0\n57.0\n55.0\n49.0\n51.0\n66.0\n60.0\n55.0\n\n\n9\n2019\n39.0\n39.0\n40.0\n57.0\n52.0\n53.0\n54.0\n55.0\n53.0\n63.0\n54.0\n50.0\n\n\n10\n2020\n46.0\nNaN\n47.0\n56.0\nNaN\n66.0\n57.0\nNaN\n58.0\n54.0\n40.0\n54.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\n\nspecies.to_csv('wetlands_seasonal_bird_diversity.csv',index=False)\n\n\n\n# total bird counts by year, wetland, and season\nseasonal = df.groupby(['year','wetland_code','season'])['count'].sum().reset_index()\n\n# make columns = wetland codes x season pairs\npivot = seasonal.pivot(index='year', columns=['wetland_code','season'], values='count')\n\n# flatten column names\npivot.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in pivot.columns]\npivot = pivot.reset_index()\npivot\n\n\n# check: every year,wetland,season combination has the same number of species listed\n# so all species are listed even if they have 0 counts\ndf.groupby(['year','wetland_code','season'])['species_code'].nunique().nunique()\n\n\n# get number of different species seen per season\ndf[df['count']!=0].groupby(['year','wetland_code','season'])['species_code'].nunique().reset_index()\n\n\nspecies.columns\n\n\ndf.groupby(['year','wetland_code','survey'])['count'].sum()\ndf[(df.year==2010) & (df.wetland_code == 'CSM') & (df.survey == 1)]['count'].sum()\n\nsubset = df[(df.year==2010) & (df.wetland_code == 'SDW') & (df.season == 'fall') & (df['count'] != 0)]\nprint(len(subset.bird_plot_number.unique()))\nprint(subset.groupby('bird_plot_number')['count'].sum())\nsubset.sort_values(by='count', ascending=False).head()\n\n\nabundance = pd.read_csv('wetland_ps_bird_abundance_and_richness-2024-06-12_14-47-54.csv')\nabundance.head()\n\n\nabundance.wetland_code.unique()\n\n\n# checking plot numbers are not repeated in a year\nfor year in range(2010,2024):\n plot_num = len(abundance.loc[(abundance.wetland_code == 'SDW') & (abundance.year == 2013),'bird_plot_number'].unique())\n n = len(abundance[(abundance.wetland_code == 'SDW') & (abundance.year == 2013)])\n if n != plot_num:\n    print(\"doesn't match\")"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "",
    "text": "This discussion section will guide you through exploring data about water-related conflicts at the Colorado River Basin using data from the U.S. Geological Survey (USGS). In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#setup",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#setup",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nIn the terminal, use cd to navigate into the eds-220-sections directory. Use pwd to verify eds-220-sections is your current working directory.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-2-co-basin-water-conflicts.ipynb.\nUse the terminal to stage, commit, and push this file to the remote repository. Remember:\n\ngit status : check git status\ngit add FILE-NAME : stage updated file\ngit status : check git status again to confirm\ngit commit -m \"Commit message\" : commit with message\ngit pull : check local repo is up to date (best practice)\ngit push : push changes to upstream repository\n\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY SET UP YOUR NOTEBOOKS BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#general-directions",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#general-directions",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments in each one of your code cells.\nInclude markdown cells in between your code cells to add titles and information.\nIndications about when to commit and push changes are included, but you are encouraged to commit and push more often."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#about-the-data",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#about-the-data",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "About the data",
    "text": "About the data\nFor these exercises we will use data about Water Conflict and Crisis Events in the Colorado River Basin [1]. This dataset is stored at ScienceBase, a digital repository from the U.S. Geological Survey (USGS) created to share scientific data products and USGS resources.\nThe dataset is a CSV file containing conflict or crisis around water resource management in the Colorado River Basin. The Colorado River Basin, inhabited by several Native American tribes for centuries, is a crucial water source in the southwestern United States and northern Mexico, supporting over 40 million people, extensive agricultural lands, and diverse ecosystems. Its management is vital due to the region‚Äôs arid climate and the competing demands for water, leading to significant challenges related to water allocation and conservation.\n\n\n\nColorado River Basin. U.S. Bureau of Reclamation."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#archive-exploration",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#archive-exploration",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "1. Archive exploration",
    "text": "1. Archive exploration\n\nLook through the dataset‚Äôs description in the ScienceBase repository. Find the following information:\n\nWhere was the data collected from?? \nDuring what time frame were the observations in the dataset collected? \nWhat was the author‚Äôs perceived value of this dataset? \n\nIn a markdown cell, use your answers to the previous questions to add a brief description of the dataset. Briefly discuss anything else that seems relevant to you. Include a citation, date of access, and a link to the archive.\nTake a look at the data‚Äôs metadata by clicking on the ‚ÄúView‚Äù icon of the Coded Events Colorado River Basin Water Conflict Table Metadata.xml file.\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#data-loading",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#data-loading",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "2. Data loading",
    "text": "2. Data loading\n\n\nCreate a new directory data/ inside your eds-220-sections directory.\nDownload the Colorado River Basin Water Conflict Table.csv file from the Science Base repository and upload it into the data/ folder.\nUpdate the .gitignore file of your eds-220-sections so it ignores the data/ folder. Push the changes to this file. Verify that git is ignoring the data file. Note: If you update the .gitignore file via GitHub, you need to run git pull when you go back to the server.\nLoad the data into your section-2-co-basin-water-conflicts.ipynb notebook. Name your data frame variable df."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#preliminary-data-exploration",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#preliminary-data-exploration",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "3. Preliminary data exploration",
    "text": "3. Preliminary data exploration\n\nSet pandas to display all columns in the data frame.\nUsing pandas methods, obtain preliminary information and explore this data frame in at least four different ways.\n\n\n\nCHECK IN WITH YOUR TEAM üôå\n\n\nYOU CAN SLACK THEM TO LET THEM KNOW YOU‚ÄôRE READY FOR TOMORROW OR BRING UP ANY QUESTIONS\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY LOADED THE DATA AND DONE A PRELIMINARY EXPLORATION BEFORE CONTINUING\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#location-column-descriptions",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#location-column-descriptions",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "4. Location column descriptions",
    "text": "4. Location column descriptions\nIn these exercises we will work with columns in the data frame pertaining to the location of an event. Before continuing, read the following column descriptions form the .xml metadata file:\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nPlace\nWhere the event actually occurred, but also where the event‚Äôs direct implications are felt most directly. When the researchers reviewed the articles, they were looking for mentions of specific places impacted by the events. Empty cell indicates a place was not coded for this event. NA indicates a place is not referenced in the event text.\n\n\nState\nState Name coded from Place field. Empty cell indicates a state was not coded for this event or that the article was not coded."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#string-accessor-for-pandas.series",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#string-accessor-for-pandas.series",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "5. String accessor for pandas.Series",
    "text": "5. String accessor for pandas.Series\nIn the following exercises we will work with pandas.Series whose values are strings. This is a common scenario, so pandas has special string methods for this kind of series. These methods are accessed via the str accessor. Accessors provide additional functionality for working with specific kinds of data (in this case, strings).\n\nThe code below gives a brief demonstration of the using the str accessor to use the split() method for pandas.Series. Carefully read the code and check in with your team to see if you have questions about it. We‚Äôll use it in a moment.\n\n\nimport numpy as np\nimport pandas as pd \n\n# Example series\ns = pd.Series(['California; Nevada', 'Arizona', np.nan, 'Nevada; Utah'])\ns\n\n0    California; Nevada\n1               Arizona\n2                   NaN\n3          Nevada; Utah\ndtype: object\n\n\n\n# str accessor (doesn't do anything by itself)\ns.str\n\n&lt;pandas.core.strings.accessor.StringMethods at 0x10ad43d90&gt;\n\n\n\n# Use str accessor with additional methods to perform string operations\n# .split splits strings by ';' and expands output into separate columns\ns.str.split(';', expand=True)\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\nCalifornia\nNevada\n\n\n1\nArizona\nNone\n\n\n2\nNaN\nNaN\n\n\n3\nNevada\nUtah\n\n\n\n\n\n\n\n\n# Use stack() method to flatten the data frame into a series\n# default is to drop NAs and None from result\ns.str.split(';', expand=True).stack()\n\n0  0    California\n   1        Nevada\n1  0       Arizona\n3  0        Nevada\n   1          Utah\ndtype: object"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#examine-state-codes",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#examine-state-codes",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "6. Examine state codes",
    "text": "6. Examine state codes\nOur goal today is to find which states are reported in the dataset as having a water conflicts.\n\nWhat are the unique values in the States column? What could be a challenge to writing code to find which states are listed (without repetition)? Remember to write longer answers in mardown cells, not as comments."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#brainstorm",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#brainstorm",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "7. Brainstorm",
    "text": "7. Brainstorm\n\nIndividually, write step-by-step instructions on how you would wrangle the data frame df to obtain a list (without repetition) of the state codes in which a water conflict has been reported. It‚Äôs ok if you don‚Äôt know how to code each step - it‚Äôs more important to have an idea of what you would like to do.\nDiscuss your step-by-step instructions with your team.\n\nThe next exercises will guide you through finding the unique state codes in the dataset. There are many ways of extracting this information. The one presented here might not be the same way you thought about doing it - that‚Äôs ok! This one was designed to practice using the .str accessor in a pandas.Series."
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#exploratory-wrangling",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#exploratory-wrangling",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "8. Exploratory wrangling",
    "text": "8. Exploratory wrangling\n\nPerform the following wrangling:\n\nselect the State column from the df data frame\nsplit the strings in the column by the delimeter ; into different columns\nstack the results of the resulting data frame into a single pandas.Series\nfind the unique string values in the resulting series\n\n\nYour final answer should use method chaining without creating new variables.\n\n\nCHECK IN WITH YOUR TEAM: IS EVERY STEP IN THE CHAINING CLEAR?\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds-2-water-crisis-exploration.html#find-unique-state-codes",
    "href": "discussion-sections/ds-2-water-crisis-exploration.html#find-unique-state-codes",
    "title": "Water conflicts in the Colorado River Basin",
    "section": "9. Find unique state codes",
    "text": "9. Find unique state codes\n\nDiscuss with your team: Why do some state codes seem to be repeated? What would we need to do to get the correct strings?\nUpdate your code to obtain a list of codes (without repetition) of the states mentioned in the news articles about water conflicts in the Colorado River Basin. Hint: str.strip().\n\n\n\nBonus: How many articles mention each state?\n\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/discussion-sections-listing.html",
    "href": "discussion-sections/discussion-sections-listing.html",
    "title": "Discussion sections",
    "section": "",
    "text": "week\n\n\n\ntopic\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\nRepository setup\n\n\n\n\n\n\n\n\n\n1\n\n\nPrey species in the California drylands\n\n\n\n\n\n\n\n\n\n2\n\n\nWater conflicts in the Colorado River Basin\n\n\n\n\n\n\n\n\n\n3\n\n\nSnowshoe hares at Bonanza Creek Experimental Forest\n\n\n\n\n\n\n\n\n\n4\n\n\nYucatan Peninsula Hurricanes\n\n\n\n\n\n\n\n\n\n5\n\n\nPlotting geospatial data\n\n\n\n\n\n\n\n\n\n7\n\n\nArctic regions geospatial wrangling\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html",
    "href": "discussion-sections/ds5-earthquakes.html",
    "title": "Plotting geospatial data",
    "section": "",
    "text": "In this discussion section you will wrangle data about earthquakes and practice:"
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#setup",
    "href": "discussion-sections/ds5-earthquakes.html#setup",
    "title": "Plotting geospatial data",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nAccess the workbench-1 server.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-5-earthquakes.ipynb.\nUse the terminal to push this file to your remote repository."
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#general-directions",
    "href": "discussion-sections/ds5-earthquakes.html#general-directions",
    "title": "Plotting geospatial data",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments as appropriate along your code following the course commenting standards.\nInclude markdown cells in between your code cells to add titles and information to each exercise\nCommit every time you finish a major step. Remember to write informative commits in the imperative mood."
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#about-the-data",
    "href": "discussion-sections/ds5-earthquakes.html#about-the-data",
    "title": "Plotting geospatial data",
    "section": "About the data",
    "text": "About the data\nFor this task you will use two datasets.\nThe first dataset is simplified data from the USGS Earthquakes Database. This data is in tabular format and has the following columns:\n\n\n\nColumn\nDescription\n\n\n\n\ntime\ndate and time of event (all events from 2014)\n\n\nlatitude\ndecimal degrees [-90,90]\n\n\nlongitude\ndecimal degrees [-360,360]\n\n\ndepth\ndepth of the event (km)\n\n\nmag\nmagnitude of event\n\n\nid\nevent identifier\n\n\nplace\nwhere the event took place\n\n\ntype\ntype of event\n\n\n\nThis is the same dataset you used in assginment 1. You can access the data through this link.\nFurther information about the dataset can be accessed in the ANSS Comprehensive Earthquake Catalog (ComCat) Documentation.\nThe second dataset is Natural Earth‚Äôs low resolution cultural boundaries data. These are useful to make maps of the whole world, although might not be suitable for mapping individual nations or finer geospatial analysis. You can access the ‚ÄúAdmin 0 ‚Äì Countries‚Äù dataset available in this link."
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#brainstorm",
    "href": "discussion-sections/ds5-earthquakes.html#brainstorm",
    "title": "Plotting geospatial data",
    "section": "1. Brainstorm",
    "text": "1. Brainstorm\nIn this session you will recreate the following map:\n\n\nIndividually, write down high-level steps on how you would explore and wrangle the data to produce this map. Do not code anything yet.\nDiscuss your high-level steps with your team. What do you see as potential challenges to implementing your plan?\nAs a team, select an initial plan for recreating this plot."
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#create-the-plot",
    "href": "discussion-sections/ds5-earthquakes.html#create-the-plot",
    "title": "Plotting geospatial data",
    "section": "2. Create the plot",
    "text": "2. Create the plot\nUse your plan as a starting point to recreate the plot.\n\nYou may (or not) need to look online to carry out some of the steps in your plan. It is completely fine to seek help online! Resourceful troubleshooting is a key skill in data science.\nIt‚Äôs ok if your initial plan changes as you work with the data and discuss challenges with your team! This brainstorm is to create a shared starting point.\n\n\nDon‚Äôt forget to write informative commits in the imperative every time you finish a major step."
  },
  {
    "objectID": "discussion-sections/ds5-earthquakes.html#update-your-notebook",
    "href": "discussion-sections/ds5-earthquakes.html#update-your-notebook",
    "title": "Plotting geospatial data",
    "section": "3. Update your notebook",
    "text": "3. Update your notebook\n\nnclude any takeaways from the map in a markdown cell after your plot.\nGo over your notebook and add markdown cells with appropriate titles and subtitles to guide the reader through the different steps in your workflow.\nInclude a markdown cell at the top with a title for your notebook and a description of what it is about."
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html",
    "href": "discussion-sections/ds0-sections-setup.html",
    "title": "Repository setup",
    "section": "",
    "text": "This discussion section will guide you through setting up a repository where you will collect your notebooks for the course‚Äôs discussion sections. In this session, you will:"
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#setup",
    "href": "discussion-sections/ds0-sections-setup.html#setup",
    "title": "Repository setup",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\nThere is no setup required by students for this discussion section, the instructor will guide the activities for it."
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#create-repository",
    "href": "discussion-sections/ds0-sections-setup.html#create-repository",
    "title": "Repository setup",
    "section": "1. Create repository",
    "text": "1. Create repository\n\nCreate a new repository on GitHub. Use the following settings:\n\nRepository name: eds220-2025-sections.\nDescription: Discussion sections work for the EDS 220 MEDS course.\nVisibility: Keep the repository public.\nDon‚Äôt select any template to start.\nAdd a README file.\nAdd a Python .gitignore template.\nAdd the MIT License.\n\nIn GitHub, update your repository‚Äôs README by:\n\nDeleting all the text that was automatically generated when you created the repo.\nCopy-pasting the markdown text below, do not update [YOUR NAME HERE] yet.\n\n\n# EDS 220 Discussion Sections Repository\n\nThis repository hosts all the work completed by [YOUR NAME HERE] during the discussion sections of EDS 220 - *Working with Environmental Data*.\n\n## Course Information\n\n- **Course Title:** [EDS 220 - Working with Environmental Datasets](https://bren.ucsb.edu/courses/eds-220)\n- **Term:** Fall 2025\n- **Program:** [UCSB Masters in Environmental Data Science](https://bren.ucsb.edu/masters-programs/master-environmental-data-science).\n\nTeaching Team:\n\n- **Instructor:** [Carmen Galaz Garc√≠a](https://github.com/carmengg)\n- **Co-Instructor:** [Annie Adams](https://github.com/annieradams) \n\nComplete materials for the discussion sections and additional resources can be found on the [course website](https://meds-eds-220.github.io/MEDS-eds-220-course/discussion-sections/discussion-sections-listing.html).\n3. Commit the changes.\n\nAdd the URL to your GitHub repository to this spreadhseet.\n\n\nMAKE SURE YOU‚ÄôVE SUCCESSFULLY SET UP YOUR REPOSITORY ON GITHUB BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#clone-the-repository",
    "href": "discussion-sections/ds0-sections-setup.html#clone-the-repository",
    "title": "Repository setup",
    "section": "2. Clone the repository",
    "text": "2. Clone the repository\n\nAt Bren‚Äôs workbench 1 server, start a new JupyterLab session or access an active one.\nInside your MEDS/ directory, create a new directory called EDS-220. We‚Äôll use this directory to collect all the repositories used in the course. If you do not have a MEDS directory, go ahead and create one.\nIn the terminal, navigate into the EDS-220 directory by using\n\ncd NAME-OF-DIRECTORY\n\nUsing the terminal, clone the repository into your EDS-220 directory. To do this:\n\nIn your repository‚Äôs landing page on GitHub, click on the green button that says &lt; &gt; Code. In the HTTPS tab option, copy the URL that appears there.\nGo back to the server. In the terminal, run\n\npwd\nto make sure you‚Äôre cloning into the desired location (this should be inside the EDS-220 directory). The command pwd stands for print working directory, it lets you know where you‚Äôre at within your files.\nAfter you run pwd you should get a file path that looks like this:\n/Users/c_galazgarcia/MEDS/EDS-220/\n\nIn the terminal, run\n\ngit clone YOUR-REPOS-URL\nThe repository directory should appear in the folder navigation bar to the left.\n\nNavigate into the cloned repository in the terminal:\n\ncd eds220-2025-sections\nThe eds220-2025-sections is your local repository, the copy of your repo that lives in your computer and from which you will send updates to GitHub. The remote repository is the copy of your repo that lives in GitHub."
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#configure-git-pull.rebase",
    "href": "discussion-sections/ds0-sections-setup.html#configure-git-pull.rebase",
    "title": "Repository setup",
    "section": "3. Configure git pull.rebase",
    "text": "3. Configure git pull.rebase\nWhen you do git pull, git combines the changes from your remote repo with your local repo. There are two main ways: merge and rebase. We will want to merge changes, not rebase. This can be the easier way to handle merges when starting out with git.\n\nConfigure the way git handles git pull by running in the terminal\n\ngit config pull.rebase false\n\nVerify that your configuration was succesful by running\n\ngit config --list\nThis command shows you all the settings git is using at the moment. Your ouput should look something like this:\nuser.name=carmengg\nuser.email=c_galazgarcia@ucsb.edu\ncredential.helper=cache --timeout=10000000\n[...]\npull.rebase=false\nIf you see pull.rebase=false it means the configuration was successful."
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#update-your-name-and-push-changes",
    "href": "discussion-sections/ds0-sections-setup.html#update-your-name-and-push-changes",
    "title": "Repository setup",
    "section": "4. Update your name and push changes",
    "text": "4. Update your name and push changes\n\nIn the workbench (not on GitHub!) open the README.md file and update the [YOUR NAME HERE] with your name. Save your changes.\nPush your changes to your remote repository (remember, this is how we call the copy of your repo that lives in GitHub). To do this, remember the basic git routine:\n\ngit status : check git status, shows which files are staged, modified, or untracked\ngit add FILE-NAME : stage files that have been updated, these files will be added to your next commit\ngit status : check git status again to confirm you have staged the right files\ngit commit -m \"YOUR COMMIT MESSAGE\" : create a commit with message\ngit pull : pull latest changes before pushing to ensure your local repo is up-to-date\ngit push : push your changes to remote repo\n\n\n\n\n\n\n\n\nPrompted for your username? Abort the push!\n\n\n\nThere is a chance you might be prompted to provide your GitHub username when you do git push by getting this message on the terminal:\nUsername for 'https://github.com':   \nIf this happens, abort the push by pressing Ctrl+C. You will need to set up your credentials on the server in the next step to be able to push your changes."
  },
  {
    "objectID": "discussion-sections/ds0-sections-setup.html#configure-github-credentials-if-needed",
    "href": "discussion-sections/ds0-sections-setup.html#configure-github-credentials-if-needed",
    "title": "Repository setup",
    "section": "5. Configure GitHub credentials (if needed)",
    "text": "5. Configure GitHub credentials (if needed)\nIn this step you will need to create a personal access token (PAT) and configure your GitHub credentials before trying to push your changes.\n\nFollow steps 6 and 7 in the MEDS setup guide to create a new PAT.\nOnce you have created your PAT, do git push again, enter your credentials (the PAT will be your password), and push your changes.\n\n\nMAKE SURE YOU‚ÄôVE SUCCESSFULLY PUSHED YOUR UPDATES BEFORE ENDING"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#title-slide",
    "href": "slides/syllabus-slides.knit.html#title-slide",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "EDS 220: Working with Environmental Data\nCourse logistics"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#welcome",
    "href": "slides/syllabus-slides.knit.html#welcome",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Welcome to EDS 220!\n\nThis course focuses on hands-on exploration of widely-used environmental data formats and Python libraries. Together, we‚Äôll work with real-world datasets, giving you the skills to analyze and understand the environment around us.\n\n\nBanner by NASA‚Äôs Your Name in Landsat"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#teaching-team",
    "href": "slides/syllabus-slides.knit.html#teaching-team",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "The teaching team\n\n\n\nInstructor\n\nCarmen Galaz Garc√≠a (she/her/hers)\n\nE-mail: c_galazgarcia@ucsb.edu\nStudent hours: Thursday 2-3 @ Bren Hall 4424\n\nCo-Instructor\n\nAnnie Adams (she/her/hers)\n\nE-mail: aradams@ucsb.edu\nStudent hours: Tuesday 2-3 @ Bren Hall 3418"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#about-me",
    "href": "slides/syllabus-slides.knit.html#about-me",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Carmen: About me\n\n\n\n\nAssistant Teaching Professor @ Bren\n\n\nBefore that:\n\nData Scientist @ NCEAS\nPh.D.¬†in Mathematics @ UCSB\n\n\n\nResearch:\n\nImage analysis for invasive plant species detection\n\n\n\nTeaching:\n\nDeveloping our MEDS Python curriculum!\nMEDS capstone courses\nMath and data science initiatives @ Bren"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#section",
    "href": "slides/syllabus-slides.knit.html#section",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Introductions\n\n\nIn the next few minutes, talk with a person next to you and ask them what parts of Santa Barbara have they enjoyed exploring.\n\n\nYou‚Äôll get to introduce your partner at the end."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#learning-objectives",
    "href": "slides/syllabus-slides.knit.html#learning-objectives",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Learning Objectives\n\nBy the end of this course, you will be able to:\n\nWrite Python code from scratch following best practices and adapt code others write.\n\n\n\nManipulate various types of environmental data, including tabular, vector, and raster data, using established Python libraries.\n\n\n\nFind and access datasets from major public environmental databases.\n\n\n\nProduce effective reports that combine text and code to share their data analyses with colleagues."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#schedule",
    "href": "slides/syllabus-slides.knit.html#schedule",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Tentative Schedule"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#class-snapshot-1",
    "href": "slides/syllabus-slides.knit.html#class-snapshot-1",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Class snapshot 1",
    "text": "Class snapshot 1"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#class-snapshot-2",
    "href": "slides/syllabus-slides.knit.html#class-snapshot-2",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Class snapshot 2",
    "text": "Class snapshot 2"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#code-of-conduct",
    "href": "slides/syllabus-slides.knit.html#code-of-conduct",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Code of Conduct\n\n \nWe expect all course participants (including instructors, guests, and students) to be committed to actively creating, modeling, and maintaining an inclusive climate and supportive learning environment for all.\n\n\nWe expect everyone to treat every member of our learning community with respect.\n\n\n\nEveryone is expected to read and adhere to the Bren School Code of Conduct and the UCSB Code of Conduct."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#accommodations",
    "href": "slides/syllabus-slides.knit.html#accommodations",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Access & Accommodations\n\n\nIf you have any kind of disability, whether apparent or non-apparent, learning, emotional, physical, or cognitive, you may be eligible to use formal accessibility services on campus.\n\n\nTo arrange class-related accommodations, please contact the Disabled Students Program (DSP). DSP will initiate communication about accommodations with faculty.\nBy making a plan through DSP, appropriate accommodations can be implemented without disclosing your specific condition or diagnosis to course instructors."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#attendance",
    "href": "slides/syllabus-slides.knit.html#attendance",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Attendance\n\nIn-person attendance to classes and discussion sections is crucial!\nIf you miss a class you are expected to:\n\nüì© Be proactive: Notify the instructor before it happens or within a day and provide a brief explanation.\nüîÑ Catch up: Work with the instructors to review any missed material.\nü§í Stay home when you are sick! Prioritize your wellbeing.\n\nAttendance does not count towards your grade, but it will be tracked and absences without communication will be addressed.\nUCSB courses are taught in person, so absences for two or more weeks may require a Leave of Absence.\nThere will not be no option for remote attendance to class except for the class before Thanksgiving break."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#evaluation",
    "href": "slides/syllabus-slides.knit.html#evaluation",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Evaluation & Grading\n\n\n\nGrading Breakdown:\n\nHomework: 75% (4 assignments)\nPortfolio: 20%\nParticipation: 5%\n\n\n\nGrade Cutoffs:\n\nA+ (‚â• 97%), A (‚â• 92%), A- (‚â• 90%),\nB+ (‚â• 87%) , B (‚â• 82%), B- (‚â• 80%),\nC+ (‚â• 77%), C (‚â• 72%), C-(‚â• 70%),\nD+ (‚â• 67%), D (‚â• 62%), D-(‚â• 60%),\n(60&gt;) F."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#homework",
    "href": "slides/syllabus-slides.knit.html#homework",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Homework Assignments\n\n \n\nThere will be 4 homework assignments.\nAssignments are assigned every other Friday starting on week 1 and should be submitted by 11:59 pm on next week‚Äôs Saturday.\n\n\n\nWorking together and collaborating with peers on homework is highly encouraged!\nSubmissions are individual so make sure you understand everything you are turning in."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#regrading",
    "href": "slides/syllabus-slides.knit.html#regrading",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Regrading\n\n\n\nYou can resubmit your assignments three days after they have received initial feedback.\n\nIn this second submission, you may recover up to 50% of the points not obtained during the initial submission.\n\n\n\n\nWhy regrades? Revisions, corrections, and improvements are crucial in the learning process! We greatly encourage you to resubmit your revised assignments.\n\n\nExample: You submitted your homework on time on the due date and got a 6/10 in the assignment the coming Wednesday. You may build on the feedback received to correct your work and resubmit to improve your grade up to 8/10.\nExcept for extenuating circumstances, there will be ‚Äãno extension for any assignment. Late submissions will be accepted at the resubmission date and can obtain up to 50% of the assignment points."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#four-day-extension",
    "href": "slides/syllabus-slides.knit.html#four-day-extension",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "One-time, 4-day extension\n\n\nEvery student may use one 4-day extension during the quarter, no questions asked.\nTo request it, you will need to send an e-mail to the co-instructor by the homework due date. Only requests by the due date will be accepted.\nMay be used for any homework assignment. Does not apply to any of the portfolio deadlines.\n\n\n\n\nIf you use the extension, you will still be able to submit your improved work by the resubmission due date (~1 day turnaround).\nBeyond this extension, late work will only be accepted at the resubmission deadline (worth up to 50% of the assignment points)."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#portoflio",
    "href": "slides/syllabus-slides.knit.html#portoflio",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Portfolio Project\n\nThe final assignment for the course will be creating data science materials for the students‚Äô online professional portfolio.\nFinal Assignment:\nThe 20% grade for the portfolio is divided as follows:\n\n13% Data analysis + GitHub repository: a presentation-ready GitHub repository containing a finalized Jupyter Notebook and associated files for the data analysis,\n7% blog post: a blog post in the student‚Äôs professional portfolio based on previous assignments and discussion sections\n\nBoth a submission and a revised submission addressing all the feedback from the first revision will be needed for these two tasks."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#participation",
    "href": "slides/syllabus-slides.knit.html#participation",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Participation Requirements\n\nTo obtain full participation credit:\n\nAnswer two short surveys about their course experiences, one at the beginning and one at the end of the course.\nShare coding solutions for exercises or homework during lecture or discussion sections at least once during the course.\n\nA presentation date during the discussion section has been randomly assigned to each student.\nYou can trade dates with others. Please notify the TA or instructor about any presentation updates.\nTime for presentation during class time may also be available.\n\n\n\nWhy come up to present your solutions? Many reasons! To practice public speaking, get comfortable with technical vocabulary, practice explaining a step-by-step solution, practice the material by teaching others, have a taste of live-coding, among others."
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#GenAI",
    "href": "slides/syllabus-slides.knit.html#GenAI",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Policy on Generative AI\n\nGenAI tools (such as ChatGPT) are strongly discouraged for the following reasons:\n\nbecoming proficient in core programming skills comes through practice\nbuilding your own programming proficiency will help you engage with GenAI tools more efficiently and responsibly\nwe don‚Äôt expect perfection, we expect learning and improvement through collaboration!\n\n\nPlease adhere to these guidelines:\n\n‚úÖ Cultivate understanding: You should be able to fully understand, justify, and explain all the work you submit.\nü§î Question AI outputs: The default should be to assume the answers you get from generative AI are incorrect and you must verify any information the platform generates.\nüö´ Academic integrity: Submitting work you don‚Äôt understand or can‚Äôt explain or justify will be considered plagiarism, regardless of whether you have disclosed the use of generative AI or not.\nüìÑ Document any AI use: If you do end up using generative AI in your work, you will need to complete and submit a ‚ÄúGenerative AI Use Documentation‚Äù form and include it with your assignment.\n\nIf there are concerns about AI use in your work, your instructor will ask you to meet and talk it through.\nIf understanding is clearly lacking and this is the first time this happens, you‚Äôll have the chance to revise and resubmit your work for 50% of the original maximum grade within two days.\n\n\n\nPlease read the full policy on the course syllabus"
  },
  {
    "objectID": "slides/syllabus-slides.knit.html#student-resources",
    "href": "slides/syllabus-slides.knit.html#student-resources",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Student Resources\n\n\nüçé Basic Needs Resources & Food Security: https://basicneeds.ucsb.edu/ (schedule a CalFresh Appoinment or Basic Needs Advising Session)\nüòå Counseling & Psychological Services (CAPS): http://caps.sa.ucsb.edu\nüåà Resource Center for Sexual and Gender Diversity (RCSGD): https://rcsgd.sa.ucsb.edu/\nü¶ã Undocumented Student Services (USS) Program: https://uss.sa.ucsb.edu/\nüìö Campus Learning Assistance Services (CLAS): http://clas.sa.ucsb.edu\nüåç Student Resource Building (SRB): http://www.sa.ucsb.edu/student-resource-building/home\nüé≠ Multicultural Center (MCC): http://mcc.sa.ucsb.edu/\nüíô Campus Advocacy, Resources, & Education (CARE): http://wgse.sa.ucsb.edu/care/home\nüè† Financial Crisis Response Team: financialcrisis@sa.ucsb.edu (contact)\nüå± Health and Wellness: https://wellbeing.ucsb.edu/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome to the course materials for EDS 220 - Working with Environmental Datasets! In this website you will find all the materials for the Fall 2025 term. This course is part of the UCSB Masters in Environmental Data Science.\n\n\nThis hands-on course explores widely used environmental data formats and Python libraries for analyzing diverse environmental data. Students will gain experience working with popular open data repositories and cloud platforms to source and analyze real-world environmental datasets. The course will also serve as an introduction to Python programming and provide opportunities to practice effective communication of the strengths and weaknesses of students‚Äô data products and analyses.\n\n\n\n\n\n\nCarmen Galaz Garc√≠a (she/her/hers)\n\nE-mail: c_galazgarcia@ucsb.edu\nStudent hours: Thursday 2 pm -3 pm @ Bren Hall 4424\n\n\n\n\nAnnie Adams (she/her/hers)\n\nE-mail: aradams@ucsb.edu\nStudent hours: Tuesday 2 pm - 3 pm @ Bren Hall 3418\n\n\n\n\n\n\nClick here to see the syllabus.\n\n\n\nThe following is our tentative calendar. The course content and calendar may be subject to change as the course progresses.\n\n\n\n\nüìù If you have suggestions on how to correct, improve, or expand these course materials, please feel free to email the course instructor at galazgarcia@bren.ucsb.edu or file a GitHub issue.\nüåü If these materials have been useful to you, consider adding a star to the project‚Äôs repository!"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Welcome!",
    "section": "",
    "text": "This hands-on course explores widely used environmental data formats and Python libraries for analyzing diverse environmental data. Students will gain experience working with popular open data repositories and cloud platforms to source and analyze real-world environmental datasets. The course will also serve as an introduction to Python programming and provide opportunities to practice effective communication of the strengths and weaknesses of students‚Äô data products and analyses."
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Welcome!",
    "section": "",
    "text": "Carmen Galaz Garc√≠a (she/her/hers)\n\nE-mail: c_galazgarcia@ucsb.edu\nStudent hours: Thursday 2 pm -3 pm @ Bren Hall 4424\n\n\n\n\nAnnie Adams (she/her/hers)\n\nE-mail: aradams@ucsb.edu\nStudent hours: Tuesday 2 pm - 3 pm @ Bren Hall 3418"
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Welcome!",
    "section": "",
    "text": "Click here to see the syllabus."
  },
  {
    "objectID": "index.html#calendar",
    "href": "index.html#calendar",
    "title": "Welcome!",
    "section": "",
    "text": "The following is our tentative calendar. The course content and calendar may be subject to change as the course progresses."
  },
  {
    "objectID": "index.html#contribute",
    "href": "index.html#contribute",
    "title": "Welcome!",
    "section": "",
    "text": "üìù If you have suggestions on how to correct, improve, or expand these course materials, please feel free to email the course instructor at galazgarcia@bren.ucsb.edu or file a GitHub issue.\nüåü If these materials have been useful to you, consider adding a star to the project‚Äôs repository!"
  },
  {
    "objectID": "week-by-week/week-by-week.html",
    "href": "week-by-week/week-by-week.html",
    "title": "Week by week",
    "section": "",
    "text": "You will find the course announcements and daily activities here.\nüåÄ Fall 2024 Week by week\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\nTHIS WEEK ONLY: The schedule and rooms remain the same, but Annie will lead the Thursday setup session, and Carmen will lead the full class on Friday. Everyone is expected to attend both.\n\n\n\nSetup of discussion sections repository following the repository setup instructions\ngit setup\nPython assessment. This is not graded and completion counts towards participation grade.\n\n\n\n\n\nCourse introduction slides\nSet up of GitHub repository for in-class coding sessions.\nCovered Python review up to the end of the variables section.\n\n\n\n\n\nRead the course syllabus. You will find it on the landing page for our EDS 220 course website.\nComplete the entry survey. This will help the teaching team get to know you and your expectations for the course. The survey is part of your participation grade. https://forms.gle/s6mJ3BcZR6U7a2Q97."
  },
  {
    "objectID": "week-by-week/week-by-week.html#week-0",
    "href": "week-by-week/week-by-week.html#week-0",
    "title": "Week by week",
    "section": "",
    "text": "What happened\n\n\n\n\n\nTHIS WEEK ONLY: The schedule and rooms remain the same, but Annie will lead the Thursday setup session, and Carmen will lead the full class on Friday. Everyone is expected to attend both.\n\n\n\nSetup of discussion sections repository following the repository setup instructions\ngit setup\nPython assessment. This is not graded and completion counts towards participation grade.\n\n\n\n\n\nCourse introduction slides\nSet up of GitHub repository for in-class coding sessions.\nCovered Python review up to the end of the variables section.\n\n\n\n\n\nRead the course syllabus. You will find it on the landing page for our EDS 220 course website.\nComplete the entry survey. This will help the teaching team get to know you and your expectations for the course. The survey is part of your participation grade. https://forms.gle/s6mJ3BcZR6U7a2Q97."
  },
  {
    "objectID": "assignments/assignment4.html",
    "href": "assignments/assignment4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "The total grade of the assignment will be divided in this way:\n\n20% - Task 1\n70% - Task 2, sections 2-6\n10% - Task 2, section 7\n\n\n\n\n\n\n\n\n\nThis assignment is due by 11:59 pm on Saturday, November 23. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for task 2 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebook to Gradescope, please rename your notebook so they are called\n\nhwk4-task2-fire-perimeter-YOURLASTNAME.ipynb and\nhwk4-task2-false-color-YOURLASTNAME.ipynb\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, November 22.\n\n\n\n\n\n\n\n\n\nThere is a separate gradescope assignment for task 2, section 7 (GitHub repository). For this submission, you will need to link your whole GitHub repository.\n\n\n\n\n\n\nWhen working with satellite data, it‚Äôs easy to assume that it is inherently objective and equally accessible to everyone. However, Bennett et al., in their paper The Politics of Pixels: A Review and Agenda for Critical Remote Sensing (2022 [1]), challenge this assumption, arguing that remote sensing needs a critical lens. They emphasize that various sociopolitical factors influence who collects remotely sensed data, how it‚Äôs collected, and ultimately, who benefits from its insights. This reading will encourage you to explore the biases and inequalities that can be embedded in remote sensing technologies and practices.\n\nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. This paper is a bit denser than the others we‚Äôve read, section V is worth special attention. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nReflecting on your personal or professional background, how might sociopolitical factors shape the availability and interpretation of satellite and other remotely sensed data for communities or organizations you‚Äôre familiar with?\nWhat potential ethical responsibilities arise for environmental data scientists when working with remote sensing data that may carry biases or limitations?\nIf you were tasked with implementing remote sensing for a project, what steps might you take to ensure the data collected is fair, accessible, and unbiased?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\nThe Thomas Fire, which burned over 280,000 acres in Ventura and Santa Barbara counties in December 2017, was one of California‚Äôs largest wildfires at the time. It caused widespread ecological damage, displaced communities, and left lasting environmental impacts.\nFalse color imagery, created using satellite data from instruments like Landsat, is a useful tool for monitoring wildfire impacts. By assigning infrared bands to visible colors, these images highlight vegetation health, burn severity, and the extent of fire scars. This approach helps researchers and land managers assess recovery efforts, identify high-risk areas, and plan restoration strategies.\nIn this task, you will create a false color image of the Thomas Fire using remote sensing data, highlighting the fire scar and exploring how coding and data visualization support environmental monitoring.\n\n\n\nA Kern County firefighter stands watch as the Thomas Fire starts to spread over ridge lines in Toro Canyon.\n\n\n\n\nIn this task you will use two datsets. The first is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nThe data was retrieved from the Microsof Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution. This data should be used for visualization and educational purposes only and can be accessed at this path within workbench-1:\n/courses/EDS220/data/hwk4_landsat_data landsat8-2018-01-26-sb-simplified.nc\nThe second dataset will be historical open-access data about fire perimeters in California. There are several datasets with this information online. You will need to select one from a reputable source that includes the fire perimeter of the Thomas Fire during 2017.\n\n\n\n\n\n\n\n\n\nCreate a new GitHub repository named eds220-hwk4. You will need to create two notebooks named:\n\nhwk4-task2-false-color-YOURLASTNAME.ipynb and\nhwk4-task2-fire-perimeter-YOURLASTNAME.ipynb.\n\nYour repository should have the following structure:\neds220-hwk4\n‚îÇ   README.md\n|   hwk4-task2-fire-perimeter-YOURLASTNAME.ipynb\n‚îÇ   hwk4-task2-false-color-YOURLASTNAME.ipynb\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ‚îÄdata\n    ‚îÇ   thomas-fire-boundary-file\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on it.\n\n\n\n\n\n\n\n\nRead the following resources about false color images and Landsat imagery:\n\nNASA Earth Observatory - Why is that Forest Red and that Cloud Blue? How to Interpret a False-Color Satellite Image\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\n\n\n\n\n\n\n\n\nSection 2 must be completed in the hwk4-task2-fire-perimeter-YOURLASTNAME.ipynb notebook.\n\n\n\n\n\n\n\nExplore the data and write a brief summary of the information you obtained from the preliminary information. Your summary should include the CRS of the data and whether this is projected or geographic.\nFrom your fire perimeter data, select the Thomas Fire boundary. The fire occurred in 2017.\nSave only the 2017 Thomas Fire boundary as a geospatial file in the format of your choosing. The file should go into the data/ directory in your repository.\nIn a markdown cell, briefly explain your reasoning for selecting that specific file format.\n\n\n\n\n\n\n\nSections 3, 4, and 5 must be completed in the hwk4-task2-false-color-YOURLASTNAME.ipynb notebook. In this notebook you will be using both your fire perimeter data and the simplified Landsat data landsat8-2018-01-26-sb-simplified.nc. You may need to complete data wrangling steps beyond the ones described to create the requested outputs.\n\n\n\n\n\n\n\nConstruct a file path to the Landsat data using os and import it using rioxr.open_rasterio().\nExplore the data and write a brief summary of the information you obtained from the preliminary information. Your summary should include the a description of the data‚Äôs variables and dimensions.\nDrop the band dimension of the data. HINT: squeeze() and drop_vars().\nWithout creating any new variables:\n\n\nselect the red, green, and blue variables (in that order) of the xarray.Dataset holding the Landsat data,\nconvert it to a numpy.array using the to_array() method, and then\nuse .plot.imshow() to create an RGB image with the data. There will be a warning, that‚Äôs ok.\n\n\nAdjust the scale used for plotting the bands to get a true color image. HINT: Check the robust parameter. The issue here is the clouds: their RGB values are outliers and cause the other values to be squished when plotting.\nIn a markdown cell write a brief explanation comparing the ouputs for parts (d) and (e).\n\n\n\n\nWithout creating any new variables, create a false color image by plotting the short-wave infrared (swir22), near-infrared, and red variables (in that order).\n\n\n\n\nCreate a map showing the shortwave infrared/near-infrared/red false color image together with the Thomas Fire perimeter. Customize it appropriately including, at least, an informative title and legend.\nWrite a figure description for the map including a brief explanation of how false color imagery is being used.\n\n\n\n\n\n\n\nThe rest of the sections are about updating and cleaning your notebooks and repository. This is hugely important! By maintaining clean, well-structured repositories and notebooks, you‚Äôre not only showcasing your technical skills but also building a portfolio that reflects your professionalism, attention to detail, and ability to collaborate effectively with others.\nHere is an example of an organized repository and notebook based on the oil spills task from homework 3.\n\n\n\n\n\n\nThe target audience for your notebooks is a fellow EDS 220 student who is just learning about wrangling raster data using Python.\n\nAdd enough and appropriate comments to explain your code.\nAdd enough and appropriate markdown cells to explain the procedures you are using and their output.\nFirst cell in the notebook must be a markdown cell including:\n\nTitle\nAuthor\nLink to GitHub repository containing the notebook (for grading purposes)\n\nEach notebook must include an ‚ÄúAbout‚Äù section with the following subsections:\n\nPurpose: what is this notebook about?\nHighlights: List of highlights of analysis (3 or 4 highlights). What do you consider to be the most important aspects of this coding exercise?\nAbout the data: Datasets description\nReferences: Formal references to datasets. You can use the APA style as outlined here.\n\n\nThe rest of your notebook should be organized into logical subsections (indicated through markdown headers) for the analysis and visualization you are performing. The subsections should easily guide the reader through the analysis.\n\n\n\nUpdate your repository‚Äôs README with (at least) the following (based on EDS 296):\n\nTitle. Short, but descriptive title.\n‚ÄúAbout‚Äù section. A brief explanation of the repository‚Äôs purpose. Paragraphs or a bulleted list are both acceptable options. You may include an image or logo that represents the project.\n‚ÄúRepository Structure‚Äù section. A concise description of what‚Äôs housed in the repository. This includes information about the repository structure or file organization.\n‚ÄúData‚Äù section. Details regarding data access. Any necessary information on where data lives (e.g.¬†is it housed in the repo, on a server, in a library / package etc.) and how to access it in order to run the code.\n‚ÄúReferences‚Äù section. In an appropriate, consistent format, including links, provide a reference to the course and any other sources that supported the development of the repository. Include formal references to the datasets. You can use the APA style to cite data sources as outlined here.\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment4.html#submission-instructions",
    "href": "assignments/assignment4.html#submission-instructions",
    "title": "Assignment 4",
    "section": "",
    "text": "This assignment is due by 11:59 pm on Saturday, November 23. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for task 2 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebook to Gradescope, please rename your notebook so they are called\n\nhwk4-task2-fire-perimeter-YOURLASTNAME.ipynb and\nhwk4-task2-false-color-YOURLASTNAME.ipynb\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, November 22.\n\n\n\n\n\n\n\n\n\nThere is a separate gradescope assignment for task 2, section 7 (GitHub repository). For this submission, you will need to link your whole GitHub repository."
  },
  {
    "objectID": "assignments/assignment4.html#task-1-the-politics-of-pixels-reading",
    "href": "assignments/assignment4.html#task-1-the-politics-of-pixels-reading",
    "title": "Assignment 4",
    "section": "",
    "text": "When working with satellite data, it‚Äôs easy to assume that it is inherently objective and equally accessible to everyone. However, Bennett et al., in their paper The Politics of Pixels: A Review and Agenda for Critical Remote Sensing (2022 [1]), challenge this assumption, arguing that remote sensing needs a critical lens. They emphasize that various sociopolitical factors influence who collects remotely sensed data, how it‚Äôs collected, and ultimately, who benefits from its insights. This reading will encourage you to explore the biases and inequalities that can be embedded in remote sensing technologies and practices.\n\nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. This paper is a bit denser than the others we‚Äôve read, section V is worth special attention. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nReflecting on your personal or professional background, how might sociopolitical factors shape the availability and interpretation of satellite and other remotely sensed data for communities or organizations you‚Äôre familiar with?\nWhat potential ethical responsibilities arise for environmental data scientists when working with remote sensing data that may carry biases or limitations?\nIf you were tasked with implementing remote sensing for a project, what steps might you take to ensure the data collected is fair, accessible, and unbiased?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment4.html#task-2-visualizing-fire-scars-through-false-color",
    "href": "assignments/assignment4.html#task-2-visualizing-fire-scars-through-false-color",
    "title": "Assignment 4",
    "section": "",
    "text": "The Thomas Fire, which burned over 280,000 acres in Ventura and Santa Barbara counties in December 2017, was one of California‚Äôs largest wildfires at the time. It caused widespread ecological damage, displaced communities, and left lasting environmental impacts.\nFalse color imagery, created using satellite data from instruments like Landsat, is a useful tool for monitoring wildfire impacts. By assigning infrared bands to visible colors, these images highlight vegetation health, burn severity, and the extent of fire scars. This approach helps researchers and land managers assess recovery efforts, identify high-risk areas, and plan restoration strategies.\nIn this task, you will create a false color image of the Thomas Fire using remote sensing data, highlighting the fire scar and exploring how coding and data visualization support environmental monitoring.\n\n\n\nA Kern County firefighter stands watch as the Thomas Fire starts to spread over ridge lines in Toro Canyon.\n\n\n\n\nIn this task you will use two datsets. The first is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nThe data was retrieved from the Microsof Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution. This data should be used for visualization and educational purposes only and can be accessed at this path within workbench-1:\n/courses/EDS220/data/hwk4_landsat_data landsat8-2018-01-26-sb-simplified.nc\nThe second dataset will be historical open-access data about fire perimeters in California. There are several datasets with this information online. You will need to select one from a reputable source that includes the fire perimeter of the Thomas Fire during 2017.\n\n\n\n\n\n\n\n\n\nCreate a new GitHub repository named eds220-hwk4. You will need to create two notebooks named:\n\nhwk4-task2-false-color-YOURLASTNAME.ipynb and\nhwk4-task2-fire-perimeter-YOURLASTNAME.ipynb.\n\nYour repository should have the following structure:\neds220-hwk4\n‚îÇ   README.md\n|   hwk4-task2-fire-perimeter-YOURLASTNAME.ipynb\n‚îÇ   hwk4-task2-false-color-YOURLASTNAME.ipynb\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ‚îÄdata\n    ‚îÇ   thomas-fire-boundary-file\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on it.\n\n\n\n\n\n\n\n\nRead the following resources about false color images and Landsat imagery:\n\nNASA Earth Observatory - Why is that Forest Red and that Cloud Blue? How to Interpret a False-Color Satellite Image\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\n\n\n\n\n\n\n\n\nSection 2 must be completed in the hwk4-task2-fire-perimeter-YOURLASTNAME.ipynb notebook.\n\n\n\n\n\n\n\nExplore the data and write a brief summary of the information you obtained from the preliminary information. Your summary should include the CRS of the data and whether this is projected or geographic.\nFrom your fire perimeter data, select the Thomas Fire boundary. The fire occurred in 2017.\nSave only the 2017 Thomas Fire boundary as a geospatial file in the format of your choosing. The file should go into the data/ directory in your repository.\nIn a markdown cell, briefly explain your reasoning for selecting that specific file format.\n\n\n\n\n\n\n\nSections 3, 4, and 5 must be completed in the hwk4-task2-false-color-YOURLASTNAME.ipynb notebook. In this notebook you will be using both your fire perimeter data and the simplified Landsat data landsat8-2018-01-26-sb-simplified.nc. You may need to complete data wrangling steps beyond the ones described to create the requested outputs.\n\n\n\n\n\n\n\nConstruct a file path to the Landsat data using os and import it using rioxr.open_rasterio().\nExplore the data and write a brief summary of the information you obtained from the preliminary information. Your summary should include the a description of the data‚Äôs variables and dimensions.\nDrop the band dimension of the data. HINT: squeeze() and drop_vars().\nWithout creating any new variables:\n\n\nselect the red, green, and blue variables (in that order) of the xarray.Dataset holding the Landsat data,\nconvert it to a numpy.array using the to_array() method, and then\nuse .plot.imshow() to create an RGB image with the data. There will be a warning, that‚Äôs ok.\n\n\nAdjust the scale used for plotting the bands to get a true color image. HINT: Check the robust parameter. The issue here is the clouds: their RGB values are outliers and cause the other values to be squished when plotting.\nIn a markdown cell write a brief explanation comparing the ouputs for parts (d) and (e).\n\n\n\n\nWithout creating any new variables, create a false color image by plotting the short-wave infrared (swir22), near-infrared, and red variables (in that order).\n\n\n\n\nCreate a map showing the shortwave infrared/near-infrared/red false color image together with the Thomas Fire perimeter. Customize it appropriately including, at least, an informative title and legend.\nWrite a figure description for the map including a brief explanation of how false color imagery is being used.\n\n\n\n\n\n\n\nThe rest of the sections are about updating and cleaning your notebooks and repository. This is hugely important! By maintaining clean, well-structured repositories and notebooks, you‚Äôre not only showcasing your technical skills but also building a portfolio that reflects your professionalism, attention to detail, and ability to collaborate effectively with others.\nHere is an example of an organized repository and notebook based on the oil spills task from homework 3.\n\n\n\n\n\n\nThe target audience for your notebooks is a fellow EDS 220 student who is just learning about wrangling raster data using Python.\n\nAdd enough and appropriate comments to explain your code.\nAdd enough and appropriate markdown cells to explain the procedures you are using and their output.\nFirst cell in the notebook must be a markdown cell including:\n\nTitle\nAuthor\nLink to GitHub repository containing the notebook (for grading purposes)\n\nEach notebook must include an ‚ÄúAbout‚Äù section with the following subsections:\n\nPurpose: what is this notebook about?\nHighlights: List of highlights of analysis (3 or 4 highlights). What do you consider to be the most important aspects of this coding exercise?\nAbout the data: Datasets description\nReferences: Formal references to datasets. You can use the APA style as outlined here.\n\n\nThe rest of your notebook should be organized into logical subsections (indicated through markdown headers) for the analysis and visualization you are performing. The subsections should easily guide the reader through the analysis.\n\n\n\nUpdate your repository‚Äôs README with (at least) the following (based on EDS 296):\n\nTitle. Short, but descriptive title.\n‚ÄúAbout‚Äù section. A brief explanation of the repository‚Äôs purpose. Paragraphs or a bulleted list are both acceptable options. You may include an image or logo that represents the project.\n‚ÄúRepository Structure‚Äù section. A concise description of what‚Äôs housed in the repository. This includes information about the repository structure or file organization.\n‚ÄúData‚Äù section. Details regarding data access. Any necessary information on where data lives (e.g.¬†is it housed in the repo, on a server, in a library / package etc.) and how to access it in order to run the code.\n‚ÄúReferences‚Äù section. In an appropriate, consistent format, including links, provide a reference to the course and any other sources that supported the development of the repository. Include formal references to the datasets. You can use the APA style to cite data sources as outlined here.\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment3.html",
    "href": "assignments/assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Task 1 will contribute 20% to the total grade of the assignment and task 2 will contribute 80%.\n\n\n\n\n\n\nTask 2 is, roughly, twice the length of the previous individual coding tasks. Make sure you allocate enough time to work through it.\n\n\n\n\n\n\n\n\n\n\n\nThis assignment is due by 11:59 pm on Saturday, November 9. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for task 2 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebook to Gradescope, please rename your notebook so they are called\n\nhwk3-task2-oil-spills-YOURLASTNAME.ipynb and\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, November 8.\n\n\n\n\n\n\nIn this task, you‚Äôll explore two key frameworks in data governance. The CARE principles [1] guide us in thinking ethically about Indigenous data, focusing on respect, benefit, and the right of communities to control their own data. The FAIR principles [2], on the other hand, encourage us to make data easy to find, use, and share, emphasizing machine-actionability.\n\n\n\nImage Source: Global Indigenous Data Alliance\n\n\nRead the following resources and write a one-paragraph (between 100 and 150 words) reflection about them:\n\nFAIR principles overview from the GO FAIR Initiative.\nWhat is FAIR? from the NCEAS learning hub resources [3].\nThe CARE Principles for Indigenous Data Governance\n\nReview the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nThe FAIR principles promote openness and accessibility, while the CARE principles emphasize control and ethics in Indigenous data. Can you think of an example where balancing openness with ethical considerations was or would have been important?\nThe CARE principles stress the authority of communities over their own data. In your own experience, who has typically held authority over data? How might shifting that authority impact the outcomes or perceptions of data projects you‚Äôve been involved in?\nHow do the CARE principles challenge or expand your understanding of data management? Have you encountered situations ‚Äîpersonally or professionally‚Äî where data governance might have benefited from a more community-centered approach?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\n\n\n\n\n\n\n\nFork this repository: https://github.com/MEDS-eds-220/eds220-hwk3\nYou may also work locally using the eds-220 environment or in the workbench-1 server using the EDS-220 kernel.\nUsing the terminal, clone your fork of the eds220-hwk3 repository into your eds-220 directory.\n\n\n\n\n\n\n\nIn this task you will use data from the New York State government about spills of petroleumn and other hazardous materials to visualize trends in the spatial distribution of the spills.\n\n\n\nWorkers from the Miller Environmental Group (MEG) dispose of oil particles from a 500 gallon oil spill near Jones Beach, N.Y., Friday, Nov.¬†23, 2007.\n\n\nFollow the instructions in the notebook hwk3-task2-oil-spills.ipynb to complete this task. Review the rubric for this assignment here.\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment3.html#submission-instructions",
    "href": "assignments/assignment3.html#submission-instructions",
    "title": "Assignment 3",
    "section": "",
    "text": "This assignment is due by 11:59 pm on Saturday, November 9. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for task 2 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebook to Gradescope, please rename your notebook so they are called\n\nhwk3-task2-oil-spills-YOURLASTNAME.ipynb and\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, November 8."
  },
  {
    "objectID": "assignments/assignment3.html#task-1-fair-and-care-principles-reading",
    "href": "assignments/assignment3.html#task-1-fair-and-care-principles-reading",
    "title": "Assignment 3",
    "section": "",
    "text": "In this task, you‚Äôll explore two key frameworks in data governance. The CARE principles [1] guide us in thinking ethically about Indigenous data, focusing on respect, benefit, and the right of communities to control their own data. The FAIR principles [2], on the other hand, encourage us to make data easy to find, use, and share, emphasizing machine-actionability.\n\n\n\nImage Source: Global Indigenous Data Alliance\n\n\nRead the following resources and write a one-paragraph (between 100 and 150 words) reflection about them:\n\nFAIR principles overview from the GO FAIR Initiative.\nWhat is FAIR? from the NCEAS learning hub resources [3].\nThe CARE Principles for Indigenous Data Governance\n\nReview the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nThe FAIR principles promote openness and accessibility, while the CARE principles emphasize control and ethics in Indigenous data. Can you think of an example where balancing openness with ethical considerations was or would have been important?\nThe CARE principles stress the authority of communities over their own data. In your own experience, who has typically held authority over data? How might shifting that authority impact the outcomes or perceptions of data projects you‚Äôve been involved in?\nHow do the CARE principles challenge or expand your understanding of data management? Have you encountered situations ‚Äîpersonally or professionally‚Äî where data governance might have benefited from a more community-centered approach?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment3.html#setup-for-task-2",
    "href": "assignments/assignment3.html#setup-for-task-2",
    "title": "Assignment 3",
    "section": "",
    "text": "Fork this repository: https://github.com/MEDS-eds-220/eds220-hwk3\nYou may also work locally using the eds-220 environment or in the workbench-1 server using the EDS-220 kernel.\nUsing the terminal, clone your fork of the eds220-hwk3 repository into your eds-220 directory."
  },
  {
    "objectID": "assignments/assignment3.html#task-2-visualizing-oil-spills-in-ny-state",
    "href": "assignments/assignment3.html#task-2-visualizing-oil-spills-in-ny-state",
    "title": "Assignment 3",
    "section": "",
    "text": "In this task you will use data from the New York State government about spills of petroleumn and other hazardous materials to visualize trends in the spatial distribution of the spills.\n\n\n\nWorkers from the Miller Environmental Group (MEG) dispose of oil particles from a 500 gallon oil spill near Jones Beach, N.Y., Friday, Nov.¬†23, 2007.\n\n\nFollow the instructions in the notebook hwk3-task2-oil-spills.ipynb to complete this task. Review the rubric for this assignment here.\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment1.html",
    "href": "assignments/assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "This assignment covers topics in the notes from the Python review to the plotting with pandas lesson. Task 1 will contribute 20% to the total grade of the assignment and tasks 2 and 3 will contribute 40% each.\n\n\n\n\n\n\n\n\nThis assignment is due by 11:59 pm on Saturday, September 12. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in this checklist:\n\nAnswer for task 1 must be a PDF file.\nAnswers for tasks 2 and 3 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, September 11. \n\n\n\n\n\n\n\n\n\nRename homework notebooks before uploading them to Gradescope\n\n\n\nFor your upcoming assignment submission, you‚Äôll be downloading your notebooks and then uploading them to Gradescope. Before you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk1-task2-corals-YOURLASTNAME.ipynb and\nhwk1-task3-earthquakes-YOURLASTNAME.ipynb.\n\nIt‚Äôs important to do this so we can keep track of resubmissions.\nThanks!\n\n\n\n\n\n\n\n\nUpdates to Gradescope‚Äôs autograder\n\n\n\nHere‚Äôs updates about how auto-grading will work in this first assignment:\n\nIf you want to know your autograder score at any point, you may upload your notebook to the Homework 1 Task 2 - AUTOGRADER CHECK ONLY or Homework 1 Task 3 - AUTOGRADER CHECK ONLY assignments on gradescope.\n\nOnce you submit your assignment, you will be able to see your total score for the auto-grading, not the score for individual questions.\nIf you don‚Äôt have a 20/20 score in your auto-grade questions, it means there is some mistake with your code and you should go back and review it. If you can‚Äôt figure out where the issue is, discuss it with other people (first option always!), come see Annie or Carmen during OH, or use Slack.\n\nThe AUTOGRADER CHECK ONLY assignments on gradescope are strictly for you to see how you did on the assignment. We will not be using these grades at all\nYou must still submit your final assignment to the Homework 1- Task 2 - Corals and Homework 1 - Task 3 - Earthquakes assignment\nMake sure you‚Äôre keeping up with your classmate‚Äôs questions and answers on Slack.\nWhen submitting your final notebook, please make sure to follow the instructions above regarding how to name the notebook\n\nThanks for your patience as we work through these initial Autograder kinks!\n\n\n\n\n\nSo much goes into creating a dataset, and data is more than numbers and words in a file. Without a proper understanding of the whole context where data was created, biases, omissions, and inacuracies can go undetected. The Datasheets for Datasets [1] framework advocates for transparency about the purpose and contents of datasets.\nCheck out this short interview with lead author Dr.¬†Timnit Gebru, the executive director of the Distributed Artificial Intelligence Research Institute (DAIR), on the motivation to write this article: \nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nCan you think of a dataset you have worked with or encountered in your studies that would have benefited from a datasheet? Explain why or why not, using specific details about the dataset‚Äôs context, collection methods, or biases.\nWhat do you think are the limitations of the datasheets framework? Are there any challenges or risks associated with this approach, and how might they be addressed in practical settings?\nHow does the topic of transparency in datasets relate to your understanding of ethical data science practices? Provide an example where increased transparency could have changed the outcome of a dataset you have used or read about.\nBased on your previous professional experience, if you were tasked with creating a dataset for a project, what challenges or decisions would you face when creating its datasheet? Reflect on one or two aspects of data collection or transparency that you feel are particularly important.\n\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\n\n\n\n\n\n\n\nFork this repository: https://github.com/MEDS-eds-220/eds220-hwk1\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nUsing the terminal, clone your eds220-hwk1 repository into your eds-220 directory.\nIn the terminal, use cd to navigate into the eds-220-hwk1 directory. Use pwd to verify eds-220-hwk1 is your current working directory.\n\n\n\n\n\n\n\nFor this task we are going to use data about Western Indian Ocean Coral Diversity [2] stored in the the Knowledge Network for Biocomplexity (KNB) data repository. The author for this dataset is Dr.¬†Tim McClanahan, senior conservation zoologist at Wildlife Conservation Society.\n\n\n\nDr.¬†Tim McClanahan underwater surveying coral reefs in coastal Tanzania. Photo credit: ¬©Michael Markovina. From the online article How Mount Kilimanjaro and We Can Save Corals\n\n\nFollow the instructions in the notebook hwk1-task2-corals.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\npreliminary data exploration\naccessing data using a URL from a data archive\nselecting data from a data frame\nbasic git workflow\ncommenting your code\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\nThis task is adapted from the Pandas Fundamentals with Earthquake Data assignment from the e-book Earth and Environmental Data Science [3].\nYou will use simplified data from the USGS Earthquakes Database.\nFollow the instructions in the notebook hwk1-task3-earthquakes.ipynb to complete this task.Review the rubric for this assignment here. Here you will practice:\n\naccessing data from your directory\nselecting data from a data frame\ncreating exploratory graphs\nbasic git workflow\ncommenting your code\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment1.html#submission-instructions",
    "href": "assignments/assignment1.html#submission-instructions",
    "title": "Assignment 1",
    "section": "",
    "text": "This assignment is due by 11:59 pm on Saturday, September 12. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in this checklist:\n\nAnswer for task 1 must be a PDF file.\nAnswers for tasks 2 and 3 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, September 11. \n\n\n\n\n\n\n\n\n\nRename homework notebooks before uploading them to Gradescope\n\n\n\nFor your upcoming assignment submission, you‚Äôll be downloading your notebooks and then uploading them to Gradescope. Before you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk1-task2-corals-YOURLASTNAME.ipynb and\nhwk1-task3-earthquakes-YOURLASTNAME.ipynb.\n\nIt‚Äôs important to do this so we can keep track of resubmissions.\nThanks!\n\n\n\n\n\n\n\n\nUpdates to Gradescope‚Äôs autograder\n\n\n\nHere‚Äôs updates about how auto-grading will work in this first assignment:\n\nIf you want to know your autograder score at any point, you may upload your notebook to the Homework 1 Task 2 - AUTOGRADER CHECK ONLY or Homework 1 Task 3 - AUTOGRADER CHECK ONLY assignments on gradescope.\n\nOnce you submit your assignment, you will be able to see your total score for the auto-grading, not the score for individual questions.\nIf you don‚Äôt have a 20/20 score in your auto-grade questions, it means there is some mistake with your code and you should go back and review it. If you can‚Äôt figure out where the issue is, discuss it with other people (first option always!), come see Annie or Carmen during OH, or use Slack.\n\nThe AUTOGRADER CHECK ONLY assignments on gradescope are strictly for you to see how you did on the assignment. We will not be using these grades at all\nYou must still submit your final assignment to the Homework 1- Task 2 - Corals and Homework 1 - Task 3 - Earthquakes assignment\nMake sure you‚Äôre keeping up with your classmate‚Äôs questions and answers on Slack.\nWhen submitting your final notebook, please make sure to follow the instructions above regarding how to name the notebook\n\nThanks for your patience as we work through these initial Autograder kinks!"
  },
  {
    "objectID": "assignments/assignment1.html#task-1-datasheets-for-datasets-reading",
    "href": "assignments/assignment1.html#task-1-datasheets-for-datasets-reading",
    "title": "Assignment 1",
    "section": "",
    "text": "So much goes into creating a dataset, and data is more than numbers and words in a file. Without a proper understanding of the whole context where data was created, biases, omissions, and inacuracies can go undetected. The Datasheets for Datasets [1] framework advocates for transparency about the purpose and contents of datasets.\nCheck out this short interview with lead author Dr.¬†Timnit Gebru, the executive director of the Distributed Artificial Intelligence Research Institute (DAIR), on the motivation to write this article: \nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nCan you think of a dataset you have worked with or encountered in your studies that would have benefited from a datasheet? Explain why or why not, using specific details about the dataset‚Äôs context, collection methods, or biases.\nWhat do you think are the limitations of the datasheets framework? Are there any challenges or risks associated with this approach, and how might they be addressed in practical settings?\nHow does the topic of transparency in datasets relate to your understanding of ethical data science practices? Provide an example where increased transparency could have changed the outcome of a dataset you have used or read about.\nBased on your previous professional experience, if you were tasked with creating a dataset for a project, what challenges or decisions would you face when creating its datasheet? Reflect on one or two aspects of data collection or transparency that you feel are particularly important.\n\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment1.html#setup-for-tasks-2-and-3",
    "href": "assignments/assignment1.html#setup-for-tasks-2-and-3",
    "title": "Assignment 1",
    "section": "",
    "text": "Fork this repository: https://github.com/MEDS-eds-220/eds220-hwk1\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nUsing the terminal, clone your eds220-hwk1 repository into your eds-220 directory.\nIn the terminal, use cd to navigate into the eds-220-hwk1 directory. Use pwd to verify eds-220-hwk1 is your current working directory."
  },
  {
    "objectID": "assignments/assignment1.html#task-2-exploring-coral-diversity-data",
    "href": "assignments/assignment1.html#task-2-exploring-coral-diversity-data",
    "title": "Assignment 1",
    "section": "",
    "text": "For this task we are going to use data about Western Indian Ocean Coral Diversity [2] stored in the the Knowledge Network for Biocomplexity (KNB) data repository. The author for this dataset is Dr.¬†Tim McClanahan, senior conservation zoologist at Wildlife Conservation Society.\n\n\n\nDr.¬†Tim McClanahan underwater surveying coral reefs in coastal Tanzania. Photo credit: ¬©Michael Markovina. From the online article How Mount Kilimanjaro and We Can Save Corals\n\n\nFollow the instructions in the notebook hwk1-task2-corals.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\npreliminary data exploration\naccessing data using a URL from a data archive\nselecting data from a data frame\nbasic git workflow\ncommenting your code\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment1.html#task-3-pandas-fundamentals-with-earthquake-data",
    "href": "assignments/assignment1.html#task-3-pandas-fundamentals-with-earthquake-data",
    "title": "Assignment 1",
    "section": "",
    "text": "This task is adapted from the Pandas Fundamentals with Earthquake Data assignment from the e-book Earth and Environmental Data Science [3].\nYou will use simplified data from the USGS Earthquakes Database.\nFollow the instructions in the notebook hwk1-task3-earthquakes.ipynb to complete this task.Review the rubric for this assignment here. Here you will practice:\n\naccessing data from your directory\nselecting data from a data frame\ncreating exploratory graphs\nbasic git workflow\ncommenting your code\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment2.html",
    "href": "assignments/assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "This assignment covers topics in the notes up to the time series lesson. Task 1 will contribute 20% to the total grade of the assignment and tasks 2 and 3 will contribute 40% each.\n\n\n\n\n\n\n\n\nThis assignment is due by 11:59 pm on Saturday, October 26. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for tasks 2 and 3 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk2-task2-aqi-YOURLASTNAME.ipynb and\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, October 25.\n\n\n\n\n\n\nUsing the right tools for a reproducible, efficient, and shareable workflow can be transformational. The article Our Path to Better Science in Less Time Using Open Data Science Tools [1] recounts how switching to open data science tools made it possible to transform the Ocean Health Index into an updatable and adaptable project. Although the paper focuses on using R, their learnings go well beyond this programming language and apply to anyone seeking to improve the reproducibility of their data analyses.\nWant to hear more about paths to open science with accompanyed by beautiful ilustrations? Check out this talk where Dr.¬†Allison Horst and lead author Dr.¬†Julie Lowndes share their personal journey‚Äôs towards open science and introduce the Openscapes program!\n\nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nIn your previous working experience, have you been working with reproducibility in mind? Which tools have allowed you or prevented you from making your work reproducible?\nThe paper presents different strategies for learning intentionally. Have you used any of these strategies? Could you adopt some as you progress in your courses and career?\nWhat do the authors see as the role of Git and GitHub in supporting reproducibility, transparency, and communication? Is your experience using these tools similar?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\n\n\n\n\n\n\n\nFork this repository: https://github.com/MEDS-eds-220/eds220-hwk2\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nUsing the terminal, clone your fork of the eds220-hwk2 repository into your eds-220 directory.\n\n\n\n\n\n\n\nThis exercise is based on the Cleaning and Wrangling Data in R lesson by the NCEAS Learning Hub [2].\nIn this task you will use simplified data from the Alaska Department of Fish & Game containing commercial salmon catch data from 1878 to 1997 [3]. The original data can be accessed from the KNB repository.\nFollow the instructions in the notebook hwk2-task2-salmon.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\ndetecting and wranglig messy data\nupdating column data types\nobtaining summary statistics by groups\ncreating exploratory plots\ncreating a continuous, polished workflow\nversion control with git following best practices\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!\n\n\n\n\n\n\nIn this task you will use Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire. The Thomas Fire, which burned across Santa Barbara and Ventura counties in December 2017, has been one of California‚Äôs largest wildfires, devastating over 280,000 acres of land, destroying wildlife habitats, and leading to soil erosion and increased flood risks in the region.\n\n\n\nFlames from the Thomas Fire burn down the face of the ridge above Highway 101 in the area of Seacliff, Solimar Beach and Faria Beach west of Ventura. Photo credit: ¬©Ray Ford / Noozhawk photo.\n\n\nFollow the instructions in the notebook hwk2-task3-aqi.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\ndate and string data wrangling\ncombining multiple data frames\nvisualizing time series\ncreating a continuous, polished workflow\nversion control with git following best practices\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment2.html#submission-instructions",
    "href": "assignments/assignment2.html#submission-instructions",
    "title": "Assignment 2",
    "section": "",
    "text": "This assignment is due by 11:59 pm on Saturday, October 26. All tasks for this assignment should be submitted via Gradescope. Make sure you double-check your submission to ensure it satisfies all the items in these checklists:\n\nFile formatting and uploading:\n\nAnswer for task 1 must be submitted as a PDF file.\nAnswers for tasks 2 and 3 must be submitted as .ipynb files (Jupyter Notebooks) to Gradescope, not a PDF, html or other format.\nDouble-check that each notebook or PDF is uploaded to the correct task on Gradescope.\nBefore you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk2-task2-aqi-YOURLASTNAME.ipynb and\n\n\nNotebook content checklists:\n\nEnsure your notebooks include a link to your assignment‚Äôs GitHub repository in the designated section.\nThe notebooks you submit must have your solutions to the exercises, They should not be the blank template notebooks.\nThe notebooks you submit must include your code and all required rendered plots, graphs, and printed output. Run all cells before submitting your .ipynb file and make sure all the outputs are visible.\n\n\nResubmissions after the due date due to not satisfying one of the checks above will be strictly held to the course‚Äôs 50%-regrade resubmission policy (see syllabus).\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm Friday, October 25."
  },
  {
    "objectID": "assignments/assignment2.html#task-1-better-science-in-less-time-using-open-data-science-tools-reading",
    "href": "assignments/assignment2.html#task-1-better-science-in-less-time-using-open-data-science-tools-reading",
    "title": "Assignment 2",
    "section": "",
    "text": "Using the right tools for a reproducible, efficient, and shareable workflow can be transformational. The article Our Path to Better Science in Less Time Using Open Data Science Tools [1] recounts how switching to open data science tools made it possible to transform the Ocean Health Index into an updatable and adaptable project. Although the paper focuses on using R, their learnings go well beyond this programming language and apply to anyone seeking to improve the reproducibility of their data analyses.\nWant to hear more about paths to open science with accompanyed by beautiful ilustrations? Check out this talk where Dr.¬†Allison Horst and lead author Dr.¬†Julie Lowndes share their personal journey‚Äôs towards open science and introduce the Openscapes program!\n\nRead the paper and write a one-paragraph (between 100 and 150 words) reflection about it. Review the rubric for this assignment here. Answer at least one of the following questions for your reflection:\n\nIn your previous working experience, have you been working with reproducibility in mind? Which tools have allowed you or prevented you from making your work reproducible?\nThe paper presents different strategies for learning intentionally. Have you used any of these strategies? Could you adopt some as you progress in your courses and career?\nWhat do the authors see as the role of Git and GitHub in supporting reproducibility, transparency, and communication? Is your experience using these tools similar?\n\n\n\n\n\n\n\nReady to submit your answer? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment2.html#setup-for-tasks-2-and-3",
    "href": "assignments/assignment2.html#setup-for-tasks-2-and-3",
    "title": "Assignment 2",
    "section": "",
    "text": "Fork this repository: https://github.com/MEDS-eds-220/eds220-hwk2\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nUsing the terminal, clone your fork of the eds220-hwk2 repository into your eds-220 directory."
  },
  {
    "objectID": "assignments/assignment2.html#task-2-wrangling-alaska-salmon-catch-data",
    "href": "assignments/assignment2.html#task-2-wrangling-alaska-salmon-catch-data",
    "title": "Assignment 2",
    "section": "",
    "text": "This exercise is based on the Cleaning and Wrangling Data in R lesson by the NCEAS Learning Hub [2].\nIn this task you will use simplified data from the Alaska Department of Fish & Game containing commercial salmon catch data from 1878 to 1997 [3]. The original data can be accessed from the KNB repository.\nFollow the instructions in the notebook hwk2-task2-salmon.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\ndetecting and wranglig messy data\nupdating column data types\nobtaining summary statistics by groups\ncreating exploratory plots\ncreating a continuous, polished workflow\nversion control with git following best practices\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/assignment2.html#task-3-visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "href": "assignments/assignment2.html#task-3-visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "title": "Assignment 2",
    "section": "",
    "text": "In this task you will use Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire. The Thomas Fire, which burned across Santa Barbara and Ventura counties in December 2017, has been one of California‚Äôs largest wildfires, devastating over 280,000 acres of land, destroying wildlife habitats, and leading to soil erosion and increased flood risks in the region.\n\n\n\nFlames from the Thomas Fire burn down the face of the ridge above Highway 101 in the area of Seacliff, Solimar Beach and Faria Beach west of Ventura. Photo credit: ¬©Ray Ford / Noozhawk photo.\n\n\nFollow the instructions in the notebook hwk2-task3-aqi.ipynb to complete this task. Review the rubric for this assignment here. In this task you will practice:\n\ndate and string data wrangling\ncombining multiple data frames\nvisualizing time series\ncreating a continuous, polished workflow\nversion control with git following best practices\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/final-project.html",
    "href": "assignments/final-project.html",
    "title": "Final project",
    "section": "",
    "text": "The project consists of two tasks:\n\nTask 1: add a blog post to your personal website based on one of your previous assignments and discussion sections. This task is 35% of the final project grade.\nTask 2: create a presentation-ready GitHub repository featuring geospatial analysis in Python. This task is 65% of the final project grade.\n\n\n\n\n\n\n\n\n\nDue dates:\n\nTask 1 (blog post) is due by 11:59 pm on Wednesday, December 4.\nTask 2 (GitHub repo) is due by by 11:59 pm on Saturday, December 7.\n\nFeedback for both tasks will be given to students by Tuesday December 10 and the final resubmission for both tasks is Friday, December 13 (last day of the quarter). Both a submission and a revised submission addressing all the feedback from the first revision will be needed to get a final grade for these two tasks. An assignment without a resubmission will get a 0 grade.\nAll tasks for this assignment should be submitted via Gradescope. File formatting and uploading:\n\nYour blog post (task 1) must be submitted as a PDF file.\nYour notebook with solutions for task 2 must be submitted as a .ipynb file (Jupyter Notebook).\nAdditionally, for task 2, link your whole GitHub repository on the indicated Gradescope assignment.\n\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm on the day before the due dates.\n\n\n\n\n\n\nIn this task, you will transform your presentation-ready repository from Homework 4 into a polished blog post for your personal website and compile and streamline all its supporting notebooks.\n\n\nYour blog post should showcase two out of the three data analysis exercises we did related to the Thomas Fire:\n\nLand cover statistics (November 27 exercises)\nAir Quality Index analysis (Hwk 2 - Task 3)\nFalse color image analysis (Hwk 4 - Task 2)\n\n\n\n\n\n\n\nIf you decide to include the land cover statistics (greatly encouraged!), you should start you analysis from the terrestrial ecosystems data clipper over the Thomas Fire perimeter. You can find this ready-to-use raster and the terrestrial ecosystem labels at this directory within workbench-1:\n/courses/EDS220/data/USGS_National_Terrestrial_Ecosystems_Over_Thomas_Fire_Perimeter/\n\n\n\nYour audience is a fellow Python programmer with beginner-to-intermediate geospatial wrangling experience. This is an opportunity to highlight your skills and communicate your analysis in a clear and engaging way!\nTo help you understand the desired format and text-to-code ratio, review these examples:\n\nhttps://julietcohen.github.io/posts/2021-12-24-sstsicpython/\nhttps://learning.nceas.ucsb.edu/2023-03-arctic/sections/geopandas.html.\n\nTake note of how they balance explanations, code, and visualizations to communicate their analyses effectively.\nIn addition to the blog post, the notebooks used for the data analysis should be part of your presentation-ready GitHub repository. These notebook contain work you have already completed and probably revised, so the effort should go into cleaning and streamlining them.\n\n\n\nUpdated on Dec 1 to include information about how to render the post.\n\n\n\n\n\n\nBlog post\n\n\n\nA Quarto personal website will be needed to submit the blog post. If you previously enrolled in EDS 296-1F (Data Science Tools for Building Professional Online Portfolios) then you‚Äôre all set! If you don‚Äôt have a website, this tutorial will smoothly guide you through creating one:\n\nCreating personal websites using Quarto\n\nTo add your blog post as a Quarto (.qmd) file you can follow this tutorial:\n\nAdding a blog to your existing Quarto website\n\nAlternatively, your blog post can be rendered directly from a Jupyter notebook (.ipynb). Converting a Jupyter notebook into a Quarto file and viceversa is really easy using the quarto convert command. The Quarto documentation has more information about rendering Jupyter notebooks using Quarto.\nCustomizing your website is optional. This is a tutorial to help you add customizations:\n\nCustomizing Quarto Websites using CSS & Sass\n\n\n\n\n\n\n\n\n\nNotebooks and repository\n\n\n\nIn addition to the blog post, in this task you will expand the GitHub repository you created for homework 4 by including the notebook with the other Thomas Fire data analysis into it. Follow the repository structure below:\nrepo-name  # Consider renaming, e.g., \"thomas-fire-analysis\"\n‚îÇ   README.md\n|   notebooks  # One per analysis, clean and streamlined\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ data  # If needed\n    ‚îÇ   data-files  \nImportant notes:\n\nEnsure no .DS_Store or .ipynb_checkpoints files are present in your repository.\nAll notebooks should be streamlined and will be checked using the ‚Äúnotebooks organization‚Äù rubric!\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on it.\nüí° For your first blog post submission, it‚Äôs normal to receive feedback and a ‚Äúneeds revision‚Äù rating. Implementing the requested changes during resubmission can earn you 100% of the points. However, if no revised blog post is submitted, this task will count as 0%. Revising will be a crucial part of this task!\n\n\n\n\n\n\n\n\n\n\n\n\nThis task builds on your previous work. Your first step should be to carefully review the feedback you received on your notebooks and Homework 4 repository and make the necessary updates.\nüí° If you have questions or need clarification on the feedback, don‚Äôt hesitate to ask!\n\n\n\nYour post should be streamlined, focusing on the key steps and results. Avoid lengthy print checks and intermediate outputs, favoring concise, well-explained code chunks.\nYour post should include (at least) the following:\n\nAbout section:\n\nProvide context for the analysis. Introduce the Thomas Fire, its significance, and the relevance of your analyses.\nInclude an image related to the analysis.\n\nHighlights of analysis:\n\nList of highlights of analysis (3 or 4 highlights). What do you consider to be the most important techniques used or insights from the analysis?\n\nDataset descriptions:\n\nDescribe the datasets you used and provide proper citations or references.\n\nLink to GitHub repository:\n\nInclude a link to your GitHub repository at the top of the post. The repository should be presentation-ready and contain the full, detailed analysis.\n\nOrganized data analysis sections:\n\nBreak the analysis into logical sections.\nInclude only the most relevant code.\nAim for a clean, professional layout with properly formatted code snippets and images.\n\nFinal visualizations:\n\nShowcase your main visualizations with clear captions. Follow each visualization with a short description explaining its insights and relevance.\n\n\n\n\n\n\nIn 2021, Maricopa County ‚Äîhome to the Phoenix metropolitan area‚Äî was identified as the U.S. county with the most significant increase in developed land since 2001 [1]. This rapid urban sprawl has profound implications for biodiversity and the health of surrounding natural ecosystems.\nIn this assignment, you will investigate the impacts of urban expansion by analyzing a dataset that captures values for the Biodiversity Intactness Index (BII) [2]. Your task is to examine changes in BII in the Phoenix county subdivision area between 2017 and 2020, shedding light on how urban growth affects biodiversity over time.\n\n\nIn this task you will use two datasets.\nYou will work with two datasets for this task:\n\nBiodiversity Intactness Index (BII) Time Series Access the io-biodiversity collection from the Microsoft Planetary Computer STAC catalog. Use the 2017 and 2020 rasters covering the Phoenix subdivision. For the bounding box, use the following coordinates:\n\n[-112.826843, 32.974108, -111.184387, 33.863574]\n\nPhoenix Subdivision Shapefile Download the Phoenix subdivision polygon from the Census County Subdivision shapefiles for Arizona.\n\nTo enhance your data exploration, you may use additional shapefiles or rasters to create a map situating the Phoenix subdivision within its broader geographic context.\n\n\n\n\n\n\n\n\n\nFirst, read all the instructions and rubric for this task. Then, create a new GitHub repository to house the work for this task. Choose an adequate, informative title for your repository (not EDS220-final-project). Your repository should have the following structure:\nrepo-name\n‚îÇ   README.md\n|   notebooks\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ data  # If needed\n    ‚îÇ   data-files  \nIn particular, there should be no .DS_Store or .ipynb_checkpoints files in your repository.\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on this task!\n\n\n\n\n\n\n\n\n\n\nExplore the data and write a brief summary of the information you obtained from the preliminary information.\nCreate a map showing the Phoenix subdivision within its broader geographic context. You may use any vector or raster datasets to create your map. Be sure to include citations or descriptions for these datasets at the top of your notebook too. You may also want to check out the contextily package to add a base map.\nCalculate the percentage of area of the Phoenix subdivision with a BII of at least 0.75 in 2017. Obtain the same calculation for 2020. Before you start coding, take a moment to write step-by-step instructions for yourself about how to get this result. You don‚Äôt need to include these in your notebook, but you should have a plan before starting your code.\n\n\n\n\n\n\n\nHINTS (useful or not depending on your workflow)\n\n\n\n\n\n\nLet x be an xarray.DataArray. We can select all the values greater than n by simply doing x&gt;n.\nMake sure you are calculating the percentage over the Phoenix area, and not the complete raster extent.\n\n\n\n\n\nCreate a visualization showing the area with BII&gt;=0.75 in 2017 that was lost by 2020. Here‚Äôs an example:\n\n\n\n\n\n\n\n\n\n\nHINTS (useful or not depending on your workflow)\n\n\n\n\n\n\nTo find which pixels changed value from 2017 to 2020 think about the following example. Which values in R3 represent areas that had BII&gt;=0.75 in 2017 but not in 2020?\n\n\n\n\n\nYou can plot multiple rasters in the same figure. NaN values will be transparent.\n\n\n\n\n\nUnder your BII visualization write a brief description of the results you obtianed in this task.\n\n\n\n\nThe target audience for your notebook is a fellow EDS 220 student who is just learning geospatial wrangling using Python.\n\nAdd enough and appropriate comments to explain your code.\nFirst cell in the notebook must be a markdown cell including:\n\nTitle\nAuthor\nLink to GitHub repository containing the notebook (for grading purposes)\n\nAt the top of the notebook, include an ‚ÄúAbout‚Äù section with the following subsections:\n\nPurpose: what is this notebook about?\nHighlights: List of highlights of analysis (3 or 4 highlights). What do you consider to be the most important aspects of this coding exercise?\nAbout the data: Datasets description\nReferences: Formal references to datasets. You can use the APA style as outlined here.\n\nThe rest of your notebook should have:\n\nLogical subsections (indicated through markdown headers) for the data exploration, analysis, and visualization you are performing. The subsections should easily guide the reader through the analysis.\nEnough and appropriate markdown cells to explain the procedures you are using and their output. Copy-pasting the instructions in markdown cells is not appropriate. If your code comment is getting too long, you should probably move it to markdown cell as text.\n\n\n\n\n\nSame as the instructions for assignment 4. Update your repository‚Äôs README with (at least) the following (based on EDS 296):\n\nTitle. Short, but descriptive title.\n‚ÄúAbout‚Äù section. A brief explanation of the repository‚Äôs purpose. Paragraphs or a bulleted list are both acceptable options. You may include an image or logo that represents the project.\n‚ÄúRepository Structure‚Äù section. A concise description of what‚Äôs housed in the repository. This includes information about the repository structure or file organization.\n‚ÄúData‚Äù section. Details regarding data access. Any necessary information on where data lives (e.g.¬†is it housed in the repo, on a server, in a library / package etc.) and how to access it in order to run the code.\n‚ÄúReferences‚Äù section. In an appropriate, consistent format, including links, provide a reference to the course and any other sources that supported the development of the repository. Include formal references to the datasets. You can use the APA style to cite data sources as outlined here.\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "assignments/final-project.html#submission-instructions",
    "href": "assignments/final-project.html#submission-instructions",
    "title": "Final project",
    "section": "",
    "text": "Due dates:\n\nTask 1 (blog post) is due by 11:59 pm on Wednesday, December 4.\nTask 2 (GitHub repo) is due by by 11:59 pm on Saturday, December 7.\n\nFeedback for both tasks will be given to students by Tuesday December 10 and the final resubmission for both tasks is Friday, December 13 (last day of the quarter). Both a submission and a revised submission addressing all the feedback from the first revision will be needed to get a final grade for these two tasks. An assignment without a resubmission will get a 0 grade.\nAll tasks for this assignment should be submitted via Gradescope. File formatting and uploading:\n\nYour blog post (task 1) must be submitted as a PDF file.\nYour notebook with solutions for task 2 must be submitted as a .ipynb file (Jupyter Notebook).\nAdditionally, for task 2, link your whole GitHub repository on the indicated Gradescope assignment.\n\nIf you have any questions about assignment logistics, please reach out to the TA or instructor by 5 pm on the day before the due dates."
  },
  {
    "objectID": "assignments/final-project.html#task-1-thomas-fire-analysis-blog-post-and-accompanying-analyses",
    "href": "assignments/final-project.html#task-1-thomas-fire-analysis-blog-post-and-accompanying-analyses",
    "title": "Final project",
    "section": "",
    "text": "In this task, you will transform your presentation-ready repository from Homework 4 into a polished blog post for your personal website and compile and streamline all its supporting notebooks.\n\n\nYour blog post should showcase two out of the three data analysis exercises we did related to the Thomas Fire:\n\nLand cover statistics (November 27 exercises)\nAir Quality Index analysis (Hwk 2 - Task 3)\nFalse color image analysis (Hwk 4 - Task 2)\n\n\n\n\n\n\n\nIf you decide to include the land cover statistics (greatly encouraged!), you should start you analysis from the terrestrial ecosystems data clipper over the Thomas Fire perimeter. You can find this ready-to-use raster and the terrestrial ecosystem labels at this directory within workbench-1:\n/courses/EDS220/data/USGS_National_Terrestrial_Ecosystems_Over_Thomas_Fire_Perimeter/\n\n\n\nYour audience is a fellow Python programmer with beginner-to-intermediate geospatial wrangling experience. This is an opportunity to highlight your skills and communicate your analysis in a clear and engaging way!\nTo help you understand the desired format and text-to-code ratio, review these examples:\n\nhttps://julietcohen.github.io/posts/2021-12-24-sstsicpython/\nhttps://learning.nceas.ucsb.edu/2023-03-arctic/sections/geopandas.html.\n\nTake note of how they balance explanations, code, and visualizations to communicate their analyses effectively.\nIn addition to the blog post, the notebooks used for the data analysis should be part of your presentation-ready GitHub repository. These notebook contain work you have already completed and probably revised, so the effort should go into cleaning and streamlining them.\n\n\n\nUpdated on Dec 1 to include information about how to render the post.\n\n\n\n\n\n\nBlog post\n\n\n\nA Quarto personal website will be needed to submit the blog post. If you previously enrolled in EDS 296-1F (Data Science Tools for Building Professional Online Portfolios) then you‚Äôre all set! If you don‚Äôt have a website, this tutorial will smoothly guide you through creating one:\n\nCreating personal websites using Quarto\n\nTo add your blog post as a Quarto (.qmd) file you can follow this tutorial:\n\nAdding a blog to your existing Quarto website\n\nAlternatively, your blog post can be rendered directly from a Jupyter notebook (.ipynb). Converting a Jupyter notebook into a Quarto file and viceversa is really easy using the quarto convert command. The Quarto documentation has more information about rendering Jupyter notebooks using Quarto.\nCustomizing your website is optional. This is a tutorial to help you add customizations:\n\nCustomizing Quarto Websites using CSS & Sass\n\n\n\n\n\n\n\n\n\nNotebooks and repository\n\n\n\nIn addition to the blog post, in this task you will expand the GitHub repository you created for homework 4 by including the notebook with the other Thomas Fire data analysis into it. Follow the repository structure below:\nrepo-name  # Consider renaming, e.g., \"thomas-fire-analysis\"\n‚îÇ   README.md\n|   notebooks  # One per analysis, clean and streamlined\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ data  # If needed\n    ‚îÇ   data-files  \nImportant notes:\n\nEnsure no .DS_Store or .ipynb_checkpoints files are present in your repository.\nAll notebooks should be streamlined and will be checked using the ‚Äúnotebooks organization‚Äù rubric!\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on it.\nüí° For your first blog post submission, it‚Äôs normal to receive feedback and a ‚Äúneeds revision‚Äù rating. Implementing the requested changes during resubmission can earn you 100% of the points. However, if no revised blog post is submitted, this task will count as 0%. Revising will be a crucial part of this task!\n\n\n\n\n\n\n\n\n\n\n\n\nThis task builds on your previous work. Your first step should be to carefully review the feedback you received on your notebooks and Homework 4 repository and make the necessary updates.\nüí° If you have questions or need clarification on the feedback, don‚Äôt hesitate to ask!\n\n\n\nYour post should be streamlined, focusing on the key steps and results. Avoid lengthy print checks and intermediate outputs, favoring concise, well-explained code chunks.\nYour post should include (at least) the following:\n\nAbout section:\n\nProvide context for the analysis. Introduce the Thomas Fire, its significance, and the relevance of your analyses.\nInclude an image related to the analysis.\n\nHighlights of analysis:\n\nList of highlights of analysis (3 or 4 highlights). What do you consider to be the most important techniques used or insights from the analysis?\n\nDataset descriptions:\n\nDescribe the datasets you used and provide proper citations or references.\n\nLink to GitHub repository:\n\nInclude a link to your GitHub repository at the top of the post. The repository should be presentation-ready and contain the full, detailed analysis.\n\nOrganized data analysis sections:\n\nBreak the analysis into logical sections.\nInclude only the most relevant code.\nAim for a clean, professional layout with properly formatted code snippets and images.\n\nFinal visualizations:\n\nShowcase your main visualizations with clear captions. Follow each visualization with a short description explaining its insights and relevance."
  },
  {
    "objectID": "assignments/final-project.html#task-2-biodiversity-intactness-index-change-in-phoenix-az",
    "href": "assignments/final-project.html#task-2-biodiversity-intactness-index-change-in-phoenix-az",
    "title": "Final project",
    "section": "",
    "text": "In 2021, Maricopa County ‚Äîhome to the Phoenix metropolitan area‚Äî was identified as the U.S. county with the most significant increase in developed land since 2001 [1]. This rapid urban sprawl has profound implications for biodiversity and the health of surrounding natural ecosystems.\nIn this assignment, you will investigate the impacts of urban expansion by analyzing a dataset that captures values for the Biodiversity Intactness Index (BII) [2]. Your task is to examine changes in BII in the Phoenix county subdivision area between 2017 and 2020, shedding light on how urban growth affects biodiversity over time.\n\n\nIn this task you will use two datasets.\nYou will work with two datasets for this task:\n\nBiodiversity Intactness Index (BII) Time Series Access the io-biodiversity collection from the Microsoft Planetary Computer STAC catalog. Use the 2017 and 2020 rasters covering the Phoenix subdivision. For the bounding box, use the following coordinates:\n\n[-112.826843, 32.974108, -111.184387, 33.863574]\n\nPhoenix Subdivision Shapefile Download the Phoenix subdivision polygon from the Census County Subdivision shapefiles for Arizona.\n\nTo enhance your data exploration, you may use additional shapefiles or rasters to create a map situating the Phoenix subdivision within its broader geographic context.\n\n\n\n\n\n\n\n\n\nFirst, read all the instructions and rubric for this task. Then, create a new GitHub repository to house the work for this task. Choose an adequate, informative title for your repository (not EDS220-final-project). Your repository should have the following structure:\nrepo-name\n‚îÇ   README.md\n|   notebooks\n|   .gitignore\n‚îÇ\n‚îî‚îÄ‚îÄ data  # If needed\n    ‚îÇ   data-files  \nIn particular, there should be no .DS_Store or .ipynb_checkpoints files in your repository.\n\n\n\n\n\n\n\n\n\nüìã Don‚Äôt forget to read the rubric for this task before you start working on this task!"
  },
  {
    "objectID": "assignments/final-project.html#instructions",
    "href": "assignments/final-project.html#instructions",
    "title": "Final project",
    "section": "",
    "text": "Explore the data and write a brief summary of the information you obtained from the preliminary information.\nCreate a map showing the Phoenix subdivision within its broader geographic context. You may use any vector or raster datasets to create your map. Be sure to include citations or descriptions for these datasets at the top of your notebook too. You may also want to check out the contextily package to add a base map.\nCalculate the percentage of area of the Phoenix subdivision with a BII of at least 0.75 in 2017. Obtain the same calculation for 2020. Before you start coding, take a moment to write step-by-step instructions for yourself about how to get this result. You don‚Äôt need to include these in your notebook, but you should have a plan before starting your code.\n\n\n\n\n\n\n\nHINTS (useful or not depending on your workflow)\n\n\n\n\n\n\nLet x be an xarray.DataArray. We can select all the values greater than n by simply doing x&gt;n.\nMake sure you are calculating the percentage over the Phoenix area, and not the complete raster extent.\n\n\n\n\n\nCreate a visualization showing the area with BII&gt;=0.75 in 2017 that was lost by 2020. Here‚Äôs an example:\n\n\n\n\n\n\n\n\n\n\nHINTS (useful or not depending on your workflow)\n\n\n\n\n\n\nTo find which pixels changed value from 2017 to 2020 think about the following example. Which values in R3 represent areas that had BII&gt;=0.75 in 2017 but not in 2020?\n\n\n\n\n\nYou can plot multiple rasters in the same figure. NaN values will be transparent.\n\n\n\n\n\nUnder your BII visualization write a brief description of the results you obtianed in this task.\n\n\n\n\nThe target audience for your notebook is a fellow EDS 220 student who is just learning geospatial wrangling using Python.\n\nAdd enough and appropriate comments to explain your code.\nFirst cell in the notebook must be a markdown cell including:\n\nTitle\nAuthor\nLink to GitHub repository containing the notebook (for grading purposes)\n\nAt the top of the notebook, include an ‚ÄúAbout‚Äù section with the following subsections:\n\nPurpose: what is this notebook about?\nHighlights: List of highlights of analysis (3 or 4 highlights). What do you consider to be the most important aspects of this coding exercise?\nAbout the data: Datasets description\nReferences: Formal references to datasets. You can use the APA style as outlined here.\n\nThe rest of your notebook should have:\n\nLogical subsections (indicated through markdown headers) for the data exploration, analysis, and visualization you are performing. The subsections should easily guide the reader through the analysis.\nEnough and appropriate markdown cells to explain the procedures you are using and their output. Copy-pasting the instructions in markdown cells is not appropriate. If your code comment is getting too long, you should probably move it to markdown cell as text.\n\n\n\n\n\nSame as the instructions for assignment 4. Update your repository‚Äôs README with (at least) the following (based on EDS 296):\n\nTitle. Short, but descriptive title.\n‚ÄúAbout‚Äù section. A brief explanation of the repository‚Äôs purpose. Paragraphs or a bulleted list are both acceptable options. You may include an image or logo that represents the project.\n‚ÄúRepository Structure‚Äù section. A concise description of what‚Äôs housed in the repository. This includes information about the repository structure or file organization.\n‚ÄúData‚Äù section. Details regarding data access. Any necessary information on where data lives (e.g.¬†is it housed in the repo, on a server, in a library / package etc.) and how to access it in order to run the code.\n‚ÄúReferences‚Äù section. In an appropriate, consistent format, including links, provide a reference to the course and any other sources that supported the development of the repository. Include formal references to the datasets. You can use the APA style to cite data sources as outlined here.\n\n\n\n\n\n\n\nReady to submit your answers? Make sure your submission follows the checklist at the top of the assginment!"
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html",
    "href": "week-by-week/week-by-week-2024.html",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "THIS IS LAST YEAR‚ÄôS WEEK BY WEEK- IT IS FOR INSTRUCTOR REFERENCE ONLY\n\nYou will find the course announcements and daily activities here.\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nCourse introduction slides\nSet up of GitHub repository for in-class coding sessions. \nCovered Python review up to the end of the variables section.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 2)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week1-pandas-series.ipynb.\nRead the notes chapter on pandas series data frames and follow along with the code.\nSolve the check-in exercises. We‚Äôll present these during class.\nMake a summary of the lesson. What are the most important concepts or ideas?\n\n\n\n\n\n\n\nFinished Python review.\nStudent presentations of pandas.Series and pandas.DataFrames exercises\n\n\n\n\nThere‚Äôs no setup for this week‚Äôs discussion section. We‚Äôll follow the materials in Discussion Section 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nCompleted the following activity to add the data/ directory to the .gitignore file of the EDS-220/in-class-notebooks/ directory.\n\n\n\n\n\n\n\nEdit .gitignore file through terminal\n\n\n\n\n\n\n\n\nDownload the CSV file wetlands_seasonal_bird_diversity.csv from our shared drive.\nIn the workbench 1 server, inside your EDS-220/in-class-notebooks/ directory, create a new directory called data.\nUsing the file navigation panel, upload the wetlands_seasonal_bird_diversity.csv file to the data/ directory.\n\n\n\n\n\nVerify you are in the in-class-notebooks/ directory by using pwd. Your output should look like this:\n\n/Users/your-username/MEDS/EDS-220/in-class-notebooks\n\nRun git status. At the end of the output you‚Äôll see:\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\nThis means git knows the data/ directory exists and we have the risk of adding it to a commit.\n\nRun ls to see the files in the directory. Your output will look like this, notice the .gitiginore file is not listed:\n\nREADME.md  week1-lesson1-python-review.ipynb\ndata       week1-lesson3-pandas-subsetting.ipynb\n\nRun ls -a to see all files in the directory, including hidden files (those that start with a period .). At this point, your output will look like this:\n\n.                   README.md\n..                  data\n.git                week1-lesson1-python-review.ipynb\n.gitignore          week1-lesson3-pandas-subsetting.ipynb\n.ipynb_checkpoints\n\nRun nano .gitignore. This will open the .gitignore file in the nano editor.\nAdd the data/ folder to the .gitignore file by adding this text at the top of the file:\n\n# Ignore the 'data' directory\ndata/\n\nOnce you have made your changes, save the file:\n\n\nIn nano, press CTRL + O (the letter O, not zero) to save.\nPress Enter to confirm the file name (.gitignore).\n\n\nExit the editor by pressing CTRL + X.\nRun less .gitignore to scroll through the .gitignore file and verify the changes are there.\n\n\nUse the arrow keys or Page Up/Page Down to scroll through the file.\nPress q to exit.\n\n\nRun git status and check the output. The data/ directroy will no longer be listed!\nCommit and push your changes to the .gitignore.\n\n\n\n\n\n\nCovered pandas subsetting notes up to selecting rows using a condition.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 9)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week2-basic-plotting.ipynb.\nRead the notes on basic plotting up to and including the ‚Äúupdating the index‚Äù section and follow along with the code.\nSolve the check-in exercises. We‚Äôll present these during class.\nMake a summary of this part of the lesson. What are the most important concepts or ideas?\n\n\n\n\n\n\n\nFinished pandas subsetting notes.\nStudent presentations of basic plotting exercises\nCovered basic plotting up to scatter plots. The last two sections, about bar plots and histograms were assigned as reading.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nComplete steps 1,2 and 3 of the second discussion section to load the data before the discussion section. You‚Äôll be working on exercises 4-9 during section, so it is important that you have the data ready to go tomorrow.\nCheck-in with your discussion section teams via Slack just to make sure you‚Äôre all ready! :raised_hands:\n\n\n\n\n\n\n\n\n\n\n\nRename homework notebooks before uploading them to Gradescope\n\n\n\nFor your upcoming assignment submission, you‚Äôll be downloading your notebooks and then uploading them to Gradescope. Before you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk1-task2-corals-YOURLASTNAME.ipynb and\nhwk1-task3-earthquakes-YOURLASTNAME.ipynb.\n\nIt‚Äôs important to do this so we can keep track of resubmissions.\nThanks!\n\n\n\n\n\n\n\n\nUpdates to Gradescope‚Äôs autograder\n\n\n\nHere‚Äôs updates about how auto-grading will work in this first assignment:\n\nIf you want to know your autograder score at any point, you may upload your notebook to the Homework 1 Task 2 - AUTOGRADER CHECK ONLY or Homework 1 Task 3 - AUTOGRADER CHECK ONLY assignments on gradescope.\n\nOnce you submit your assignment, you will be able to see your total score for the auto-grading, not the score for individual questions.\nIf you don‚Äôt have a 20/20 score in your auto-grade questions, it means there is some mistake with your code and you should go back and review it. If you can‚Äôt figure out where the issue is, discuss it with other people (first option always!), come see Annie or Carmen during OH, or use Slack.\n\nThe AUTOGRADER CHECK ONLY assignments on gradescope are strictly for you to see how you did on the assignment. We will not be using these grades at all\nYou must still submit your final assignment to the Homework 1- Task 2 - Corals and Homework 1 - Task 3 - Earthquakes assignment\nMake sure you‚Äôre keeping up with your classmate‚Äôs questions and answers on Slack.\nWhen submitting your final notebook, please make sure to follow the instructions above regarding how to name the notebook\n\nThanks for your patience as we work through these initial Autograder kinks!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nCovered updating dataframes up to first example of SettingWithCopyWarning.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 16)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week3-groupby.ipynb.\nRead the notes chapter on grouping and follow along with the code.\nSummarize the lesson and solve the check-in exercise. We‚Äôll present these during class.\n\n\n\n\n\n\n\nFinished updating dataframes notes.\nWent over how to update the message in the last commit when it hasn‚Äôt been pushed yet using\n\ngit commit --amend -m \"NEW MESSAGE\"\n\nDiscussion of grouping notes by students.\nCovered conda environments notes up to exercise 7.\n\n\n\n\n\n\n\n\n\n\nLoad data before section\n\n\n\nComplete steps 1,2 and 3 of the third discussion section to load the data before the discussion section. You‚Äôll be working on exercises 4-8 during section, so it is important that you have the data ready to go tomorrow.\nCheck-in with your discussion section teams via Slack just to make sure you‚Äôre all ready!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nBuilt conda environment for the course.\n\n\n\n\n\n\n\nHow to build the conda environment for the course in your computer\n\n\n\n\n\n\nOpen VSCode on your computer.\nClone your eds220-2024-in-class GitHub repository. You can do it using the command palette.\nDownload the following YAML file and move it to the top of your eds220-2024-in-class local directory: https://github.com/MEDS-eds-220/MEDS-eds-220-course/blob/main/eds-220-env.yml\nOpen a terminal inside VSCode and in it:\n\n\nVerify you are in the eds220-2024-in-class directory.\nVerify that the eds-220-env.yml file is in the directory.\nRun the following conda command to build the environment used for the course:\n\nconda env create --name eds220-env --file eds-220-env.yml\nIt will take about 10 minutes to build the environment. Once conda has finished, verify that the environment is listed. Inside VSCode, you‚Äôll be able to select the eds220-env kernel to run your notebooks.\n\n\n\n\nCovered time series notes.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 23)\n\n\n\nRead the notes on coordinate reference systems and vector data formats. Most of it should be reciew from EDS 223. We will have some questions to test your understanding of key concepts at the start of the next class.\n\n\n\n\n\nCovered geopandas notes.\n\n\n\nNo work to do ahead of the discussion section.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nDeleted previous eds220-env conda environment in your local computer.\nCreated a new one using this YAML file, name it eds220-env (that‚Äôs why you shoul delete the old one).\nLoaded data to cover notes on for loops\n\n\n\n\n\nCovered notes on streamlining your code up to creating the power sources map.\n\n\n\n\n\n\n\nOffice hour update\n\n\n\nCarmen‚Äôs office hour today will be 3-4 at her office. Thank you!\n\n\n\n\n\n\n\n\nPreparation for Monday class (November 4)\n\n\n\nRead notes on data merging\n\n\n\n\n\nNo work to do ahead of the discussion section.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nFinished notes on streamlining your code up to creating the power sources map.\n\n\n\n\n\n\n\nPreparation for Wednesday class (November 6)\n\n\n\nFinish reading functions notes and prepare exercie at the end of section.\n\n\n\n\n\n\nCovered the reprojecting notes.\n\nWe started from a pre-filled notebook that students transferred to their in-class coding directory via the terminal. The pre-filled notebook is in this location in workbench-1:\n/courses/EDS220/student_notebooks/week-6-reprojecting-STUDENTS.ipynb\nThe general bash command to copy a file is:\ncp /path/to/source/file /path/to/destination/\n\n\n\n\nFirst activity will be solving the short exercise at the end of Monday‚Äôs lesson (green box).\nThe rest of the discussion section will be used to work on assignment 3 with your teams. Please come in with the data loaded into your notebooks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\n\n\n\nThere‚Äôs no class on Monday, November 11\n\n\n\nIt‚Äôs Veteran‚Äôs day. Enjoy the long weekend!\n\n\n\n\n\nCovered the clipping notes.\n\nWe started from a pre-filled notebook that students transferred to their in-class coding directory via the terminal. The pre-filled notebook is in this path in workbench-1:\n/courses/EDS220/student_notebooks/week-7-clipping-STUDENTS.ipynb\nThe general bash command to copy a file is:\ncp /path/to/source/file /path/to/destination/\nSo to copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-7-clipping-STUDENTS.ipynb week-7-clipping-STUDENTS.ipynb\n\n\n\nNo work to do ahead of the discussion section.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\n\n\n\nCovered the xarray notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-8-xarray-STUDENTS.ipynb week-8-xarray-STUDENTS.ipynb\n\n\n\n\nCovered the rioxarray notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-8-rioxarray-STUDENTS.ipynb week-8-rioxarray-STUDENTS.ipynb\n\n\n\nThis discussion section will be used to work on assignment 4 with your teams. Please come in with the data loaded into your notebooks.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened\n\n\n\n\n\nWe had hybrid lectures this week.\n\n\n\nCovered the STAC notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-9-STAC-STUDENTS.ipynb week-9-STAC-STUDENTS.ipynb\n\n\n\n\nCovered the land cover statistics notes\n\nWe started from a pre-filled notebook at this location in workbench-1:\n/courses/EDS220/student_notebooks/week-9-land-cover-stats-STUDENTS.ipynb \nThe exercises at the end of the lesson can be included in the final project blog post (greatly encouraged!).\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first draft for the final project‚Äôs blog post is due this Wednesday."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-1-sept-30---oct-6",
    "href": "week-by-week/week-by-week-2024.html#week-1-sept-30---oct-6",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nCourse introduction slides\nSet up of GitHub repository for in-class coding sessions. \nCovered Python review up to the end of the variables section.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 2)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week1-pandas-series.ipynb.\nRead the notes chapter on pandas series data frames and follow along with the code.\nSolve the check-in exercises. We‚Äôll present these during class.\nMake a summary of the lesson. What are the most important concepts or ideas?\n\n\n\n\n\n\n\nFinished Python review.\nStudent presentations of pandas.Series and pandas.DataFrames exercises\n\n\n\n\nThere‚Äôs no setup for this week‚Äôs discussion section. We‚Äôll follow the materials in Discussion Section 1."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-2-oct-7---oct-13",
    "href": "week-by-week/week-by-week-2024.html#week-2-oct-7---oct-13",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nCompleted the following activity to add the data/ directory to the .gitignore file of the EDS-220/in-class-notebooks/ directory.\n\n\n\n\n\n\n\nEdit .gitignore file through terminal\n\n\n\n\n\n\n\n\nDownload the CSV file wetlands_seasonal_bird_diversity.csv from our shared drive.\nIn the workbench 1 server, inside your EDS-220/in-class-notebooks/ directory, create a new directory called data.\nUsing the file navigation panel, upload the wetlands_seasonal_bird_diversity.csv file to the data/ directory.\n\n\n\n\n\nVerify you are in the in-class-notebooks/ directory by using pwd. Your output should look like this:\n\n/Users/your-username/MEDS/EDS-220/in-class-notebooks\n\nRun git status. At the end of the output you‚Äôll see:\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\nThis means git knows the data/ directory exists and we have the risk of adding it to a commit.\n\nRun ls to see the files in the directory. Your output will look like this, notice the .gitiginore file is not listed:\n\nREADME.md  week1-lesson1-python-review.ipynb\ndata       week1-lesson3-pandas-subsetting.ipynb\n\nRun ls -a to see all files in the directory, including hidden files (those that start with a period .). At this point, your output will look like this:\n\n.                   README.md\n..                  data\n.git                week1-lesson1-python-review.ipynb\n.gitignore          week1-lesson3-pandas-subsetting.ipynb\n.ipynb_checkpoints\n\nRun nano .gitignore. This will open the .gitignore file in the nano editor.\nAdd the data/ folder to the .gitignore file by adding this text at the top of the file:\n\n# Ignore the 'data' directory\ndata/\n\nOnce you have made your changes, save the file:\n\n\nIn nano, press CTRL + O (the letter O, not zero) to save.\nPress Enter to confirm the file name (.gitignore).\n\n\nExit the editor by pressing CTRL + X.\nRun less .gitignore to scroll through the .gitignore file and verify the changes are there.\n\n\nUse the arrow keys or Page Up/Page Down to scroll through the file.\nPress q to exit.\n\n\nRun git status and check the output. The data/ directroy will no longer be listed!\nCommit and push your changes to the .gitignore.\n\n\n\n\n\n\nCovered pandas subsetting notes up to selecting rows using a condition.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 9)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week2-basic-plotting.ipynb.\nRead the notes on basic plotting up to and including the ‚Äúupdating the index‚Äù section and follow along with the code.\nSolve the check-in exercises. We‚Äôll present these during class.\nMake a summary of this part of the lesson. What are the most important concepts or ideas?\n\n\n\n\n\n\n\nFinished pandas subsetting notes.\nStudent presentations of basic plotting exercises\nCovered basic plotting up to scatter plots. The last two sections, about bar plots and histograms were assigned as reading.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nComplete steps 1,2 and 3 of the second discussion section to load the data before the discussion section. You‚Äôll be working on exercises 4-9 during section, so it is important that you have the data ready to go tomorrow.\nCheck-in with your discussion section teams via Slack just to make sure you‚Äôre all ready! :raised_hands:\n\n\n\n\n\n\n\n\n\n\n\nRename homework notebooks before uploading them to Gradescope\n\n\n\nFor your upcoming assignment submission, you‚Äôll be downloading your notebooks and then uploading them to Gradescope. Before you upload your finished notebooks to Gradescope, please rename your notebooks so they are called\n\nhwk1-task2-corals-YOURLASTNAME.ipynb and\nhwk1-task3-earthquakes-YOURLASTNAME.ipynb.\n\nIt‚Äôs important to do this so we can keep track of resubmissions.\nThanks!\n\n\n\n\n\n\n\n\nUpdates to Gradescope‚Äôs autograder\n\n\n\nHere‚Äôs updates about how auto-grading will work in this first assignment:\n\nIf you want to know your autograder score at any point, you may upload your notebook to the Homework 1 Task 2 - AUTOGRADER CHECK ONLY or Homework 1 Task 3 - AUTOGRADER CHECK ONLY assignments on gradescope.\n\nOnce you submit your assignment, you will be able to see your total score for the auto-grading, not the score for individual questions.\nIf you don‚Äôt have a 20/20 score in your auto-grade questions, it means there is some mistake with your code and you should go back and review it. If you can‚Äôt figure out where the issue is, discuss it with other people (first option always!), come see Annie or Carmen during OH, or use Slack.\n\nThe AUTOGRADER CHECK ONLY assignments on gradescope are strictly for you to see how you did on the assignment. We will not be using these grades at all\nYou must still submit your final assignment to the Homework 1- Task 2 - Corals and Homework 1 - Task 3 - Earthquakes assignment\nMake sure you‚Äôre keeping up with your classmate‚Äôs questions and answers on Slack.\nWhen submitting your final notebook, please make sure to follow the instructions above regarding how to name the notebook\n\nThanks for your patience as we work through these initial Autograder kinks!"
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#setup",
    "href": "week-by-week/week-by-week-2024.html#setup",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "Download the CSV file wetlands_seasonal_bird_diversity.csv from our shared drive.\nIn the workbench 1 server, inside your EDS-220/in-class-notebooks/ directory, create a new directory called data.\nUsing the file navigation panel, upload the wetlands_seasonal_bird_diversity.csv file to the data/ directory."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#in-the-terminal",
    "href": "week-by-week/week-by-week-2024.html#in-the-terminal",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "Verify you are in the in-class-notebooks/ directory by using pwd. Your output should look like this:\n\n/Users/your-username/MEDS/EDS-220/in-class-notebooks\n\nRun git status. At the end of the output you‚Äôll see:\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\nThis means git knows the data/ directory exists and we have the risk of adding it to a commit.\n\nRun ls to see the files in the directory. Your output will look like this, notice the .gitiginore file is not listed:\n\nREADME.md  week1-lesson1-python-review.ipynb\ndata       week1-lesson3-pandas-subsetting.ipynb\n\nRun ls -a to see all files in the directory, including hidden files (those that start with a period .). At this point, your output will look like this:\n\n.                   README.md\n..                  data\n.git                week1-lesson1-python-review.ipynb\n.gitignore          week1-lesson3-pandas-subsetting.ipynb\n.ipynb_checkpoints\n\nRun nano .gitignore. This will open the .gitignore file in the nano editor.\nAdd the data/ folder to the .gitignore file by adding this text at the top of the file:\n\n# Ignore the 'data' directory\ndata/\n\nOnce you have made your changes, save the file:\n\n\nIn nano, press CTRL + O (the letter O, not zero) to save.\nPress Enter to confirm the file name (.gitignore).\n\n\nExit the editor by pressing CTRL + X.\nRun less .gitignore to scroll through the .gitignore file and verify the changes are there.\n\n\nUse the arrow keys or Page Up/Page Down to scroll through the file.\nPress q to exit.\n\n\nRun git status and check the output. The data/ directroy will no longer be listed!\nCommit and push your changes to the .gitignore."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-3-oct-14---oct-20",
    "href": "week-by-week/week-by-week-2024.html#week-3-oct-14---oct-20",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nCovered updating dataframes up to first example of SettingWithCopyWarning.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 16)\n\n\n\n\nIn your EDS-220/eds220-2024-in-class directory, create a new Python notebook called week3-groupby.ipynb.\nRead the notes chapter on grouping and follow along with the code.\nSummarize the lesson and solve the check-in exercise. We‚Äôll present these during class.\n\n\n\n\n\n\n\nFinished updating dataframes notes.\nWent over how to update the message in the last commit when it hasn‚Äôt been pushed yet using\n\ngit commit --amend -m \"NEW MESSAGE\"\n\nDiscussion of grouping notes by students.\nCovered conda environments notes up to exercise 7.\n\n\n\n\n\n\n\n\n\n\nLoad data before section\n\n\n\nComplete steps 1,2 and 3 of the third discussion section to load the data before the discussion section. You‚Äôll be working on exercises 4-8 during section, so it is important that you have the data ready to go tomorrow.\nCheck-in with your discussion section teams via Slack just to make sure you‚Äôre all ready!"
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-4-oct-21---oct-27",
    "href": "week-by-week/week-by-week-2024.html#week-4-oct-21---oct-27",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nBuilt conda environment for the course.\n\n\n\n\n\n\n\nHow to build the conda environment for the course in your computer\n\n\n\n\n\n\nOpen VSCode on your computer.\nClone your eds220-2024-in-class GitHub repository. You can do it using the command palette.\nDownload the following YAML file and move it to the top of your eds220-2024-in-class local directory: https://github.com/MEDS-eds-220/MEDS-eds-220-course/blob/main/eds-220-env.yml\nOpen a terminal inside VSCode and in it:\n\n\nVerify you are in the eds220-2024-in-class directory.\nVerify that the eds-220-env.yml file is in the directory.\nRun the following conda command to build the environment used for the course:\n\nconda env create --name eds220-env --file eds-220-env.yml\nIt will take about 10 minutes to build the environment. Once conda has finished, verify that the environment is listed. Inside VSCode, you‚Äôll be able to select the eds220-env kernel to run your notebooks.\n\n\n\n\nCovered time series notes.\n\n\n\n\n\n\n\nPreparation for Wednesday class (October 23)\n\n\n\nRead the notes on coordinate reference systems and vector data formats. Most of it should be reciew from EDS 223. We will have some questions to test your understanding of key concepts at the start of the next class.\n\n\n\n\n\nCovered geopandas notes.\n\n\n\nNo work to do ahead of the discussion section."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-5-oct-28---nov-3",
    "href": "week-by-week/week-by-week-2024.html#week-5-oct-28---nov-3",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nDeleted previous eds220-env conda environment in your local computer.\nCreated a new one using this YAML file, name it eds220-env (that‚Äôs why you shoul delete the old one).\nLoaded data to cover notes on for loops\n\n\n\n\n\nCovered notes on streamlining your code up to creating the power sources map.\n\n\n\n\n\n\n\nOffice hour update\n\n\n\nCarmen‚Äôs office hour today will be 3-4 at her office. Thank you!\n\n\n\n\n\n\n\n\nPreparation for Monday class (November 4)\n\n\n\nRead notes on data merging\n\n\n\n\n\nNo work to do ahead of the discussion section."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-6-nov-4---nov-10",
    "href": "week-by-week/week-by-week-2024.html#week-6-nov-4---nov-10",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nFinished notes on streamlining your code up to creating the power sources map.\n\n\n\n\n\n\n\nPreparation for Wednesday class (November 6)\n\n\n\nFinish reading functions notes and prepare exercie at the end of section.\n\n\n\n\n\n\nCovered the reprojecting notes.\n\nWe started from a pre-filled notebook that students transferred to their in-class coding directory via the terminal. The pre-filled notebook is in this location in workbench-1:\n/courses/EDS220/student_notebooks/week-6-reprojecting-STUDENTS.ipynb\nThe general bash command to copy a file is:\ncp /path/to/source/file /path/to/destination/\n\n\n\n\nFirst activity will be solving the short exercise at the end of Monday‚Äôs lesson (green box).\nThe rest of the discussion section will be used to work on assignment 3 with your teams. Please come in with the data loaded into your notebooks."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-7-nov-11---nov-17",
    "href": "week-by-week/week-by-week-2024.html#week-7-nov-11---nov-17",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\n\n\n\nThere‚Äôs no class on Monday, November 11\n\n\n\nIt‚Äôs Veteran‚Äôs day. Enjoy the long weekend!\n\n\n\n\n\nCovered the clipping notes.\n\nWe started from a pre-filled notebook that students transferred to their in-class coding directory via the terminal. The pre-filled notebook is in this path in workbench-1:\n/courses/EDS220/student_notebooks/week-7-clipping-STUDENTS.ipynb\nThe general bash command to copy a file is:\ncp /path/to/source/file /path/to/destination/\nSo to copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-7-clipping-STUDENTS.ipynb week-7-clipping-STUDENTS.ipynb\n\n\n\nNo work to do ahead of the discussion section."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-8-nov-18---nov-24",
    "href": "week-by-week/week-by-week-2024.html#week-8-nov-18---nov-24",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\n\n\n\nCovered the xarray notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-8-xarray-STUDENTS.ipynb week-8-xarray-STUDENTS.ipynb\n\n\n\n\nCovered the rioxarray notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-8-rioxarray-STUDENTS.ipynb week-8-rioxarray-STUDENTS.ipynb\n\n\n\nThis discussion section will be used to work on assignment 4 with your teams. Please come in with the data loaded into your notebooks."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-9-nov-25---nov-31",
    "href": "week-by-week/week-by-week-2024.html#week-9-nov-25---nov-31",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "What happened\n\n\n\n\n\nWe had hybrid lectures this week.\n\n\n\nCovered the STAC notes.\n\nWe started from a pre-filled notebook that students transferred into their in-class coding directory via the terminal. To copy the file into your current working directory use the command:\ncp /courses/EDS220/student_notebooks/week-9-STAC-STUDENTS.ipynb week-9-STAC-STUDENTS.ipynb\n\n\n\n\nCovered the land cover statistics notes\n\nWe started from a pre-filled notebook at this location in workbench-1:\n/courses/EDS220/student_notebooks/week-9-land-cover-stats-STUDENTS.ipynb \nThe exercises at the end of the lesson can be included in the final project blog post (greatly encouraged!)."
  },
  {
    "objectID": "week-by-week/week-by-week-2024.html#week-10-dec-1---dec-8",
    "href": "week-by-week/week-by-week-2024.html#week-10-dec-1---dec-8",
    "title": "Week by week for Fall 2024",
    "section": "",
    "text": "The first draft for the final project‚Äôs blog post is due this Wednesday."
  },
  {
    "objectID": "slides/syllabus-slides.html#title-slide",
    "href": "slides/syllabus-slides.html#title-slide",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "EDS 220: Working with Environmental Data\nCourse logistics"
  },
  {
    "objectID": "slides/syllabus-slides.html#welcome",
    "href": "slides/syllabus-slides.html#welcome",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Welcome to EDS 220!\n\nThis course focuses on hands-on exploration of widely-used environmental data formats and Python libraries. Together, we‚Äôll work with real-world datasets, giving you the skills to analyze and understand the environment around us.\n\n\nBanner by NASA‚Äôs Your Name in Landsat"
  },
  {
    "objectID": "slides/syllabus-slides.html#teaching-team",
    "href": "slides/syllabus-slides.html#teaching-team",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "The teaching team\n\n\n\nInstructor\n\nCarmen Galaz Garc√≠a (she/her/hers)\n\nE-mail: c_galazgarcia@ucsb.edu\nStudent hours: Thursday 2-3 @ Bren Hall 4424\n\nCo-Instructor\n\nAnnie Adams (she/her/hers)\n\nE-mail: aradams@ucsb.edu\nStudent hours: Tuesday 2-3 @ Bren Hall 3418"
  },
  {
    "objectID": "slides/syllabus-slides.html#about-me",
    "href": "slides/syllabus-slides.html#about-me",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Carmen: About me\n\n\n\n\nAssistant Teaching Professor @ Bren\n\n\nBefore that:\n\nData Scientist @ NCEAS\nPh.D.¬†in Mathematics @ UCSB\n\n\n\nResearch:\n\nImage analysis for invasive plant species detection\n\n\n\nTeaching:\n\nDeveloping our MEDS Python curriculum!\nMEDS capstone courses\nMath and data science initiatives @ Bren"
  },
  {
    "objectID": "slides/syllabus-slides.html#section",
    "href": "slides/syllabus-slides.html#section",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Introductions\n\n\nIn the next few minutes, talk with a person next to you and ask them what parts of Santa Barbara have they enjoyed exploring.\n\n\nYou‚Äôll get to introduce your partner at the end."
  },
  {
    "objectID": "slides/syllabus-slides.html#learning-objectives",
    "href": "slides/syllabus-slides.html#learning-objectives",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Learning Objectives\n\nBy the end of this course, you will be able to:\n\nWrite Python code from scratch following best practices and adapt code others write.\n\n\n\nManipulate various types of environmental data, including tabular, vector, and raster data, using established Python libraries.\n\n\n\nFind and access datasets from major public environmental databases.\n\n\n\nProduce effective reports that combine text and code to share their data analyses with colleagues."
  },
  {
    "objectID": "slides/syllabus-slides.html#schedule",
    "href": "slides/syllabus-slides.html#schedule",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Tentative Schedule"
  },
  {
    "objectID": "slides/syllabus-slides.html#class-snapshot-1",
    "href": "slides/syllabus-slides.html#class-snapshot-1",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Class snapshot 1",
    "text": "Class snapshot 1"
  },
  {
    "objectID": "slides/syllabus-slides.html#class-snapshot-2",
    "href": "slides/syllabus-slides.html#class-snapshot-2",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Class snapshot 2",
    "text": "Class snapshot 2"
  },
  {
    "objectID": "slides/syllabus-slides.html#code-of-conduct",
    "href": "slides/syllabus-slides.html#code-of-conduct",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Code of Conduct\n\n \nWe expect all course participants (including instructors, guests, and students) to be committed to actively creating, modeling, and maintaining an inclusive climate and supportive learning environment for all.\n\n\nWe expect everyone to treat every member of our learning community with respect.\n\n\n\nEveryone is expected to read and adhere to the Bren School Code of Conduct and the UCSB Code of Conduct."
  },
  {
    "objectID": "slides/syllabus-slides.html#accommodations",
    "href": "slides/syllabus-slides.html#accommodations",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Access & Accommodations\n\n\nIf you have any kind of disability, whether apparent or non-apparent, learning, emotional, physical, or cognitive, you may be eligible to use formal accessibility services on campus.\n\n\nTo arrange class-related accommodations, please contact the Disabled Students Program (DSP). DSP will initiate communication about accommodations with faculty.\nBy making a plan through DSP, appropriate accommodations can be implemented without disclosing your specific condition or diagnosis to course instructors."
  },
  {
    "objectID": "slides/syllabus-slides.html#attendance",
    "href": "slides/syllabus-slides.html#attendance",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Attendance\n\nIn-person attendance to classes and discussion sections is crucial!\nIf you miss a class you are expected to:\n\nüì© Be proactive: Notify the instructor before it happens or within a day and provide a brief explanation.\nüîÑ Catch up: Work with the instructors to review any missed material.\nü§í Stay home when you are sick! Prioritize your wellbeing.\n\nAttendance does not count towards your grade, but it will be tracked and absences without communication will be addressed.\nUCSB courses are taught in person, so absences for two or more weeks may require a Leave of Absence.\nThere will not be no option for remote attendance to class except for the class before Thanksgiving break."
  },
  {
    "objectID": "slides/syllabus-slides.html#evaluation",
    "href": "slides/syllabus-slides.html#evaluation",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Evaluation & Grading\n\n\n\nGrading Breakdown:\n\nHomework: 75% (4 assignments)\nPortfolio: 20%\nParticipation: 5%\n\n\n\nGrade Cutoffs:\n\nA+ (‚â• 97%), A (‚â• 92%), A- (‚â• 90%),\nB+ (‚â• 87%) , B (‚â• 82%), B- (‚â• 80%),\nC+ (‚â• 77%), C (‚â• 72%), C-(‚â• 70%),\nD+ (‚â• 67%), D (‚â• 62%), D-(‚â• 60%),\n(60&gt;) F."
  },
  {
    "objectID": "slides/syllabus-slides.html#homework",
    "href": "slides/syllabus-slides.html#homework",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Homework Assignments\n\n \n\nThere will be 4 homework assignments.\nAssignments are assigned every other Friday starting on week 1 and should be submitted by 11:59 pm on next week‚Äôs Saturday.\n\n\n\nWorking together and collaborating with peers on homework is highly encouraged!\nSubmissions are individual so make sure you understand everything you are turning in."
  },
  {
    "objectID": "slides/syllabus-slides.html#regrading",
    "href": "slides/syllabus-slides.html#regrading",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Regrading\n\n\n\nYou can resubmit your assignments three days after they have received initial feedback.\n\nIn this second submission, you may recover up to 50% of the points not obtained during the initial submission.\n\n\n\n\nWhy regrades? Revisions, corrections, and improvements are crucial in the learning process! We greatly encourage you to resubmit your revised assignments.\n\n\nExample: You submitted your homework on time on the due date and got a 6/10 in the assignment the coming Wednesday. You may build on the feedback received to correct your work and resubmit to improve your grade up to 8/10.\nExcept for extenuating circumstances, there will be ‚Äãno extension for any assignment. Late submissions will be accepted at the resubmission date and can obtain up to 50% of the assignment points."
  },
  {
    "objectID": "slides/syllabus-slides.html#four-day-extension",
    "href": "slides/syllabus-slides.html#four-day-extension",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "One-time, 4-day extension\n\n\nEvery student may use one 4-day extension during the quarter, no questions asked.\nTo request it, you will need to send an e-mail to the co-instructor by the homework due date. Only requests by the due date will be accepted.\nMay be used for any homework assignment. Does not apply to any of the portfolio deadlines.\n\n\n\n\nIf you use the extension, you will still be able to submit your improved work by the resubmission due date (~1 day turnaround).\nBeyond this extension, late work will only be accepted at the resubmission deadline (worth up to 50% of the assignment points)."
  },
  {
    "objectID": "slides/syllabus-slides.html#portoflio",
    "href": "slides/syllabus-slides.html#portoflio",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Portfolio Project\n\nThe final assignment for the course will be creating data science materials for the students‚Äô online professional portfolio.\nFinal Assignment:\nThe 20% grade for the portfolio is divided as follows:\n\n13% Data analysis + GitHub repository: a presentation-ready GitHub repository containing a finalized Jupyter Notebook and associated files for the data analysis,\n7% blog post: a blog post in the student‚Äôs professional portfolio based on previous assignments and discussion sections\n\nBoth a submission and a revised submission addressing all the feedback from the first revision will be needed for these two tasks."
  },
  {
    "objectID": "slides/syllabus-slides.html#participation",
    "href": "slides/syllabus-slides.html#participation",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Participation Requirements\n\nTo obtain full participation credit:\n\nAnswer two short surveys about their course experiences, one at the beginning and one at the end of the course.\nShare coding solutions for exercises or homework during lecture or discussion sections at least once during the course.\n\nA presentation date during the discussion section has been randomly assigned to each student.\nYou can trade dates with others. Please notify the TA or instructor about any presentation updates.\nTime for presentation during class time may also be available.\n\n\n\nWhy come up to present your solutions? Many reasons! To practice public speaking, get comfortable with technical vocabulary, practice explaining a step-by-step solution, practice the material by teaching others, have a taste of live-coding, among others."
  },
  {
    "objectID": "slides/syllabus-slides.html#GenAI",
    "href": "slides/syllabus-slides.html#GenAI",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Policy on Generative AI\n\nGenAI tools (such as ChatGPT) are strongly discouraged for the following reasons:\n\nbecoming proficient in core programming skills comes through practice\nbuilding your own programming proficiency will help you engage with GenAI tools more efficiently and responsibly\nwe don‚Äôt expect perfection, we expect learning and improvement through collaboration!\n\n\nPlease adhere to these guidelines:\n\n‚úÖ Cultivate understanding: You should be able to fully understand, justify, and explain all the work you submit.\nü§î Question AI outputs: The default should be to assume the answers you get from generative AI are incorrect and you must verify any information the platform generates.\nüö´ Academic integrity: Submitting work you don‚Äôt understand or can‚Äôt explain or justify will be considered plagiarism, regardless of whether you have disclosed the use of generative AI or not.\nüìÑ Document any AI use: If you do end up using generative AI in your work, you will need to complete and submit a ‚ÄúGenerative AI Use Documentation‚Äù form and include it with your assignment.\n\nIf there are concerns about AI use in your work, your instructor will ask you to meet and talk it through.\nIf understanding is clearly lacking and this is the first time this happens, you‚Äôll have the chance to revise and resubmit your work for 50% of the original maximum grade within two days.\n\n\n\nPlease read the full policy on the course syllabus"
  },
  {
    "objectID": "slides/syllabus-slides.html#student-resources",
    "href": "slides/syllabus-slides.html#student-resources",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Student Resources\n\n\nüçé Basic Needs Resources & Food Security: https://basicneeds.ucsb.edu/ (schedule a CalFresh Appoinment or Basic Needs Advising Session)\nüòå Counseling & Psychological Services (CAPS): http://caps.sa.ucsb.edu\nüåà Resource Center for Sexual and Gender Diversity (RCSGD): https://rcsgd.sa.ucsb.edu/\nü¶ã Undocumented Student Services (USS) Program: https://uss.sa.ucsb.edu/\nüìö Campus Learning Assistance Services (CLAS): http://clas.sa.ucsb.edu\nüåç Student Resource Building (SRB): http://www.sa.ucsb.edu/student-resource-building/home\nüé≠ Multicultural Center (MCC): http://mcc.sa.ucsb.edu/\nüíô Campus Advocacy, Resources, & Education (CARE): http://wgse.sa.ucsb.edu/care/home\nüè† Financial Crisis Response Team: financialcrisis@sa.ucsb.edu (contact)\nüå± Health and Wellness: https://wellbeing.ucsb.edu/"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html",
    "href": "discussion-sections/ds1-prelim-data-exploration.html",
    "title": "Prey species in the California drylands",
    "section": "",
    "text": "This discussion section will guide you through preliminary data exploration for a real world dataset about animal observations in the California drylands. In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#setup",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#setup",
    "title": "Prey species in the California drylands",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nIn the workbench-1 server, start a new JupyterLab session or access an active one.\nIn the terminal, use cd to navigate into the eds-220-sections directory. Use pwd to verify eds-220-sections is your current working directory.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-1-data-selection-drylands.ipynb.\nUse the terminal to stage, commit, and push this file to the remote repository. Remember:\n\ngit status : check git status\ngit add FILE-NAME : stage updated file\ngit status : check git status again to confirm\ngit commit -m \"Commit message\" : commit with message\ngit pull : check local repo is up to date (best practice)\ngit push : push changes to upstream repository\n\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY SET UP YOUR NOTEBOOKS BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#general-directions",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#general-directions",
    "title": "Prey species in the California drylands",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments in each one of your code cells.\nOn each exercise, include markdown cells in between your code cells to add titles and information.\nIndications about when to commit and push changes are included, but you are encouraged to commit and push more often.\nYou won‚Äôt need to upload any data."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#about-the-data",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#about-the-data",
    "title": "Prey species in the California drylands",
    "section": "About the data",
    "text": "About the data\nFor these exercises we will use data about prey items for endangered terrestrial vertebrate species within central California drylands[1] [2].\nThis dataset is stored in the Knowledge Network for Biocomplexity (KNB) data repository. This is an international repository intended to facilitate ecological and environmental research. It has thousands of open datasets and is hosted by the National Center for Ecological Analysis and Synthesis (NCEAS).\n\n\n\nData collection plot at Mojave Desert near Tecopa. Photo courtesy of Dr.¬†Rachel King."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#archive-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#archive-exploration",
    "title": "Prey species in the California drylands",
    "section": "1. Archive exploration",
    "text": "1. Archive exploration\nWhen possible, data exploration should start at the data repository. Take some time to look through the dataset‚Äôs description in the KNB data repository. Discuss the following questions with your team:\n\nWhat is this data about?\nIs this data collected in-situ by the authors or is it a synthesis of multiple datasets?\nDuring what time frame were the observations in the dataset collected?\nDoes this dataset come with an associated metadata file?\nDoes the dataset contain sensitive data?\n\nIn your notebook: use a markdown cell to add a brief description of the dataset, including a citation, date of access, and a link to the archive.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#metadata-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#metadata-exploration",
    "title": "Prey species in the California drylands",
    "section": "2. Metadata exploration",
    "text": "2. Metadata exploration\nYou may have noticed there are two metadata files: Compiled_occurrence_records_for_prey_items_of.xml and metadata_arth_occurrences.csv. The .xml document file type is EML which stands for EML: Ecological Metadata Language. This is a machine-readable file that has metadata about the whole dataset. In this section we will only use the metadata in the CSV file.\nBack in your notebook, import the pandas package using standard abbreviation in a code cell. Then follow these steps to read in the metadata CSV using the pandas.read_csv() function:\n\nNavigate to the data package site and copy the URL to access the metadata_arth_occurrences CSV file. To copy the URL:\n\n\nhover over the Download button ‚Äì&gt; right click ‚Äì&gt; ‚ÄúCopy Link‚Äù.\n\n\nRead in the data from the URL using the pd.read_csv() function like this:\n# Access metadata from repository\npd.read_csv('the URL goes here')\nTake a minute to look at the descriptions for the columns.\n\nNote: Not all datasets have column descriptions in a CSV file. Often they come with a .doc or .txt file with information."
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#data-loading",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#data-loading",
    "title": "Prey species in the California drylands",
    "section": "3. Data loading",
    "text": "3. Data loading\n\nFollow steps (a) and (b) from the previous exercise to read in the drylands prey data file arth_occurrences_with_env.csv using pd.read_csv(). Store the dataframe to a variable called prey like this:\n\n# Load data\nprey = pd.read_csv('the URL goes here')\n\nWhat is the type of the prey variable? Use a Python function get this information.\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY ACCESSED THE DATA BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#look-at-your-data",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#look-at-your-data",
    "title": "Prey species in the California drylands",
    "section": "4. Look at your data",
    "text": "4. Look at your data\n\nRun prey in a cell. What do you notice in the columns section?\nTo see all the column names in the same display we need to set a pandas option. Run the following command and then look at the prey data again:\n\npd.set_option(\"display.max.columns\", None)\n\nAdd a comment explaining what pd.set_option(\"display.max.columns\", None) does.\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#pd.dataframe-preliminary-exploration",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#pd.dataframe-preliminary-exploration",
    "title": "Prey species in the California drylands",
    "section": "5. pd.DataFrame preliminary exploration",
    "text": "5. pd.DataFrame preliminary exploration\nRun each of the following methods for prey in a different cell and write a brief description of what they do as a comment:\n\nhead()\ntail()\ninfo()\nnunique()\n\nFor example:\n# head()\n# returns the first five rows of the data frame\nprey.head()\nIf you‚Äôre not sure about what the method does, try looking it up in the pandas.DataFrame documentation.\n\nCheck the documentation for head(). If this function has any optional parameters, change the default value to get a different output.\n\nPrint each of the following attributes of prey in a different cell and write a brief explanation of what they are as a comment:\n\nshape\ncolumns\ndtypes\n\nIf you‚Äôre not sure about what information is the attribute showing, look it up in the pandas.DataFrame documentation.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds1-prelim-data-exploration.html#update-column-names",
    "href": "discussion-sections/ds1-prelim-data-exploration.html#update-column-names",
    "title": "Prey species in the California drylands",
    "section": "6. Update column names",
    "text": "6. Update column names\nChange the column names of institutionCode and datasetKey to institution_code and dataset_key, respectively. Make sure you‚Äôre actually updating the dataframe. HINT: look for the documentation on the rename method for pandas.DataFrames.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "",
    "text": "In this discussion section you will wrangle historical data about hurricanes at the Yucatan Peninsula in Mexico. In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#setup",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#setup",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nAccess the workbench-1 server.\nNavigate to theeds-220-sections directory in the file navigation panel and the terminal.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-4-yucatan-hurricanes.ipynb.\nUse the terminal to push this file to your remote repository."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#general-directions",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#general-directions",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments as appropriate along your code following the course commenting standards.\nInclude markdown cells in between your code cells to add titles and information to each exercise\nCommit every time you finish a major step. Remember to write your commits in the imperative mood."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#about-the-data",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#about-the-data",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "About the data",
    "text": "About the data\nIn this discussion section we will use historical data about hurricanes in the Yucatan Peninsula [1].\nThe Yucatan Peninsula, located in southeastern Mexico and bordered by the Gulf of Mexico and the Caribbean Sea, is a region highly susceptible to hurricanes due to its geographic location. These intense storms bring strong winds, heavy rainfall, and storm surges that significantly impact both terrestrial and coastal ecosystems. Hurricanes can cause widespread deforestation, alter habitats, and disrupt biodiversity, affecting, among other habitats, mangroves and coral reefs.\n\n\n\nHurricane Mitch (Category 5 on the Saffir-Simpson Hurricane Wind Scale) impacted the Yucatan Peninsula in late October 1998, with its effects felt most strongly around October 28-29. The Yucatan experienced heavy rains and flooding as Mitch passed near the region. Image source: NOAA\n\n\nThis dataset includes information about the Saffir-Simpson hurricane category for each hurricane. The Saffir-Simpson scale is a widely used classification system that categorizes hurricanes based on their sustained wind speeds and potential for damage. Ranging from Category 1 to Category 5, the scale assesses the intensity of hurricanes, with Category 1 being the least severe and Category 5 representing catastrophic storms. Categories 3 and above are considered major hurricanes, capable of causing significant structural damage, flooding, and long-lasting environmental impacts."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#archive-exploration",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#archive-exploration",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "1. Archive exploration",
    "text": "1. Archive exploration\n\nTake some time to mindfully look through the dataset‚Äôs description and metadata.\nIn your notebook: use a markdown cell to add a brief description of the dataset, including a citation, date of access, and a link to the archive."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#data-loading-and-preliminary-exploration",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#data-loading-and-preliminary-exploration",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "2. Data loading and preliminary exploration",
    "text": "2. Data loading and preliminary exploration\n\nWe will be using the hf071-01-hurricanes.csv file. Agree with your team on how you will import this file to your notebook and store it in a variable named df.\n\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY ACCESSED THE DATA BEFORE CONTINUING\n\n\nObtain preliminary information and explore this data frame using pandas methods."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#brainstorm",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#brainstorm",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "3. Brainstorm",
    "text": "3. Brainstorm\nIn this session we want to answer the following question:\n\nHow many hurricanes with Saffir-Simpson category 5 have been registered and what was their duration?\n\n\nIndividually, write down step-by-step instructions on how you would wrangle the df data frame to answer the question. Do not code anything yet. Remember: It‚Äôs okay if you don‚Äôt know how to code each step. The important thing is to have an idea of what you‚Äôd like to do.\nDiscuss your step-by-step instructions with your team. What do you see as potential challenges to implementing your plan?\nAs a team, select an initial data wrangling plan for answering the question."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#data-wrangling",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#data-wrangling",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "4. Data wrangling",
    "text": "4. Data wrangling\nUse your plan as a starting point to answer the question.\n\nYou may (or not) need to look online to carry out some of the steps in your plan. It is completely fine to seek help online! Resourceful troubleshooting is a key skill in data science.\nIt‚Äôs ok if your initial plan changes as you work with the data and discuss challenges with your team! This brainstorm is to create a shared starting point."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#collect-your-code-and-explain-your-results",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#collect-your-code-and-explain-your-results",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "5. Collect your code and explain your results",
    "text": "5. Collect your code and explain your results\n\nIn a new code cell, collect all the relevant code to create a streamlined workflow to obtain the final data to answer the question. Your code cell should:\n\n\nOnly print the final results.\nNot include output from intermediate variables or checks.\nNot include methods or functions that do not directly contribute to the analysis (even if they don‚Äôt print anything ex: df.head()).\nIf appropriate, combine methods using code chaining instead of creating intermediate variables.\nComment your code following our class comments guidelines.\nUse appropriate line breaks and indentation to make code readable.\n\n\nWrite a full sentence explaining your answer to the question in (3). Don‚Äôt forget to include units. You may also want to include any insights about the rest of the data for the Category 5 hurricanes."
  },
  {
    "objectID": "discussion-sections/ds4-yucatan-hurricanes.html#bonus-visualize-saffir-simpson-categories-across-time",
    "href": "discussion-sections/ds4-yucatan-hurricanes.html#bonus-visualize-saffir-simpson-categories-across-time",
    "title": "Yucatan Peninsula Hurricanes",
    "section": "BONUS: Visualize Saffir-Simpson categories across time",
    "text": "BONUS: Visualize Saffir-Simpson categories across time\n\nCreate a scatter plot of the start date of the hurricanes against the Saffir-Simpson scale. Use matplotlib to customize your graph, including updating the tick labels to be only 1, 2, 3, 4, and 5 since the Saffir-Simpsn scale does not take decimal values.\nAnalyze your plot and write (in full sentences!) any trends that you observe.\n\n\nDon‚Äôt forget to commit, pull, and push."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html",
    "href": "discussion-sections/ds6-arctic-communities.html",
    "title": "Arctic regions geospatial wrangling",
    "section": "",
    "text": "In this discussion section you will wrangle geospatial data about Arctic communities"
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#setup",
    "href": "discussion-sections/ds6-arctic-communities.html#setup",
    "title": "Arctic regions geospatial wrangling",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nAccess the workbench-1 server.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-7-arctic-communities.ipynb.\nUse the terminal to push this file to your remote repository."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#general-directions",
    "href": "discussion-sections/ds6-arctic-communities.html#general-directions",
    "title": "Arctic regions geospatial wrangling",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments as appropriate along your code following the course commenting standards.\nInclude markdown cells in between your code cells to add titles and information to each exercise\nCommit every time you finish a major step. Remember to write informative commits in the imperative mood."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#about-the-data",
    "href": "discussion-sections/ds6-arctic-communities.html#about-the-data",
    "title": "Arctic regions geospatial wrangling",
    "section": "About the data",
    "text": "About the data\nArctic communities hold immense value in traditional knowledge and environmental stewardship, offering unique insights into sustainable practices and ecosystem management in one of the planet‚Äôs most extreme environments. For this section you will use a dataset derived from the list of Arctic communities and their location [1] created by the Alaska Native Tribal Health Consortium and Natural Earth‚Äôs medium-scale cultural boundaries data for countries (1:50m) following the procedure in the Reprojecting notes.\n\n\n\nImage Source: Arctic Communities WWF. ¬©Staffan Widstrand/WWF.\n\n\nThe data is in the arctic_communities.geojson file located in the data/ directory for the EDS 220 class within workbench-1. Each geospatial feature in the data represents an Arctic territory with the following attributes:\n\n\n\nAttribute\nDescription\n\n\n\n\nadmin\nname of the territory\n\n\ncountry\ntwo-letter code\n\n\nn_communities\nnumber of Arctic communities in the territory"
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#data-loading-and-exploration",
    "href": "discussion-sections/ds6-arctic-communities.html#data-loading-and-exploration",
    "title": "Arctic regions geospatial wrangling",
    "section": "1. Data loading and exploration",
    "text": "1. Data loading and exploration\nRead in the data into a variable named df and examine it with your team."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#brainstorm",
    "href": "discussion-sections/ds6-arctic-communities.html#brainstorm",
    "title": "Arctic regions geospatial wrangling",
    "section": "2. Brainstorm",
    "text": "2. Brainstorm\nThe goal of these exercises is to refine the Arctic communities choropleth map created in the Reprojecting lesson to restrict the plotting to the Arctic relevant regions:\n\n\nIndividually, write down high-level steps on how you would explore and wrangle the data to produce the updated map. Do not code anything yet.\nDiscuss your high-level steps with your team. What do you see as potential challenges to implementing your plan?\n\nThe next exercises will guide you through selecting relevant Arctic regions. There are many ways of doing this. The one presented here might not be the same way you thought about doing it - that‚Äôs ok! This one was designed to practice creating functions."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#check-geometry-types",
    "href": "discussion-sections/ds6-arctic-communities.html#check-geometry-types",
    "title": "Arctic regions geospatial wrangling",
    "section": "2. Check geometry types",
    "text": "2. Check geometry types\n\nRun df.geom_type. Write a brief explanation about the output in a markdown cell.\nCreate an if-else statement that:\n\nprints ‚ÄúAll features are polygons.‚Äù if all the features in the df are polygons and\nprints ‚ÄúMultiple feature types:‚Äù followed by the unique geometry types (no repetition) in the geodataframe if not all the features are polygons.\n\nWrap up your code into a function named check_polygons that receives a single geodataframe as its parameter and prints out a message stating whether all the geometry types are polygons or not."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#explode-polygons",
    "href": "discussion-sections/ds6-arctic-communities.html#explode-polygons",
    "title": "Arctic regions geospatial wrangling",
    "section": "3. Explode polygons",
    "text": "3. Explode polygons\n\nOverwrite the df geodataframe with the output from the explode method with the index_parts parameter set to False. Read the documentation for the method and use a markdown cell to write a brief explanation of what is being done.\nReset the index of df.\nUse your check_polygons function to verify that df only has features of type polygon.\n\n\nDon‚Äôt forget to write informative commits in the imperative every time you finish a major step."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#compute-minimum-y-coordinate-for-polygons",
    "href": "discussion-sections/ds6-arctic-communities.html#compute-minimum-y-coordinate-for-polygons",
    "title": "Arctic regions geospatial wrangling",
    "section": "4. Compute minimum y-coordinate for polygons",
    "text": "4. Compute minimum y-coordinate for polygons\nAt this point, every row in your df should be a single polygon.\n\nSelect the first row of df using iloc. What kind of Python object is this?\nSelect the geometry of the first row of df. What kind of Python object is this?\nUse the bounds attribute for shapely Polygons to select the southern-most bound of the first polygon in df.\nCreate a function min_y that receives a single row of a geodataframe as its parameter and returns the minimum y-coordinate of its bounding box.\nUse the min_y function and the apply method for data frames to create a new column miny in df which has the minimum y coordinate."
  },
  {
    "objectID": "discussion-sections/ds6-arctic-communities.html#filter-update-crs-and-reproduce-map",
    "href": "discussion-sections/ds6-arctic-communities.html#filter-update-crs-and-reproduce-map",
    "title": "Arctic regions geospatial wrangling",
    "section": "6. Filter, update CRS, and reproduce map",
    "text": "6. Filter, update CRS, and reproduce map\n\nSelect the polygons with a bounding box at or above 40 degrees of latitude into a new variable named arctic.\nReproduce the Arctic communities map by updating the CRS to EPSG:3413."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html",
    "href": "discussion-sections/ds3-hares.html",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "",
    "text": "This discussion section will guide you through exploring data about snowshoe hares in the (Lepus americanus) in the Bonanza Creek Experimental Forest located in Alaska, USA. In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#setup",
    "href": "discussion-sections/ds3-hares.html#setup",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nAccess the workbench-1 server.\nNavigate to theeds-220-sections directory in the file navigation panel and the terminal.\nCreate a new Python notebook inside your eds-220-sections directory and rename it to section-3-snowshoe-hares.ipynb.\nUse the terminal to push this file to you remote repository."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#general-directions",
    "href": "discussion-sections/ds3-hares.html#general-directions",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments as appropriate along your code.\nInclude markdown cells in between your code cells to add titles and information to each exercise\nYou won‚Äôt need to upload any data.\nIndications about when to commit and push changes are included. Commit every time you finish a major step! Remember to write your commits in the imperative mood."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#about-the-data",
    "href": "discussion-sections/ds3-hares.html#about-the-data",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "About the data",
    "text": "About the data\nFor these exercises we will use data about Snowshoe hares (Lepus americanus) in the Bonanza Creek Experimental Forest [1].\nThis dataset is stored in the Environmental Data Initiative (EDI) data repository. This is a huge data repository committed to make data Findable, Accessible, Interoperable, and Reusable (FAIR). It is the main repository for all the data associated to the Long Term Ecological Research Network (LTER)."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#archive-exploration",
    "href": "discussion-sections/ds3-hares.html#archive-exploration",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "1. Archive exploration",
    "text": "1. Archive exploration\n\nTake some time to look through the dataset‚Äôs description in EDI and click around. Discuss the following questions with your team:\n\nWhat is this data about?\nDuring what time frame were the observations in the dataset collected?\nDoes the dataset contain sensitive data?\nIs there a publication associated with this dataset?\n\nIn your notebook: use a markdown cell to add a brief description of the dataset, including a citation, date of access, and a link to the archive.\nBack in the EDI repository, click on View Full Metadata to access more information if you haven‚Äôt done so already. Go to the ‚ÄúDetailed Metadata‚Äù section and click on ‚ÄúData Entities‚Äù. Take some time to look at the descriptions for the dataset‚Äôs columns."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#adding-an-image",
    "href": "discussion-sections/ds3-hares.html#adding-an-image",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "2. Adding an image",
    "text": "2. Adding an image\nBack in your notebook, follow these steps to add an image of a hare using a URL:\n\nGo to this link.\nGet the URL of the hare image. To do this:\n\n\nhover over the image ‚Äì&gt; right click ‚Äì&gt; ‚ÄúCopy Image Address‚Äù.\n\n\nAt the end of the markdown cell with the dataset description, use markdown sytanx to add the image from its URL:\n\n![image description](URL-goes-here)\n\nDo you need to add an attribution in the image description? Check the license at the bottom of wikimedia page.\n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#data-loading-and-preliminary-exploration",
    "href": "discussion-sections/ds3-hares.html#data-loading-and-preliminary-exploration",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "3. Data loading and preliminary exploration",
    "text": "3. Data loading and preliminary exploration\n\nBack in your notebook, import the 55_Hare_Data_2012.txt file from its URL using the pandas.read_csv() function. Store it in a variable named hares.\n\n\n\nUsing pandas methods, obtain preliminary information and explore this data frame. Consider answering some of these questions:\n\n\nWhat are the dimensions of the dataframe and what are the data types of the columns? Do the data types match what you would expect from each column?\nAre there any columns that have a significant number of NA values?\nWhat are the minimum and maximum values for the weight and hind feet measurements?\nWhat are the unique values for some of the categorical columns?\nAn explroatory question about the data frame you come up with!\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY ACCESSED THE DATA BEFORE CONTINUING\n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#detecting-messy-values",
    "href": "discussion-sections/ds3-hares.html#detecting-messy-values",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "4. Detecting messy values",
    "text": "4. Detecting messy values\n\nIn the metadata section of the EDI repository, find which are the allowed values for the hares‚Äô sex. Create a small table in a markdown cell showing the values and their definitions.\n\n\n\nGet the number of times each unique sex non-NA value appears.\n\n\n\nCheck the documentation of value_counts(). What is the purpose of the dropna parameter and what is its default value? Repeat step (a), this time adding the dropna=False parameter to value_counts(). \nDiscuss with your team the output of the unique value counts. In particular:\n\nDo the values in the sex column correspond to the values declared in the metadata?\nWhat could have been potential causes for multiple codes?\nAre there seemingly repated values? If so, what could be the cause?\n\nWrite code to confirm your suspicions about c-iii.\n\n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#brainstorm",
    "href": "discussion-sections/ds3-hares.html#brainstorm",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "5. Brainstorm",
    "text": "5. Brainstorm\n\nIndividually, write step-by-step instructions on how you would wrangle the hares data frame to clean the values in the sex column to have only two classes female and male. Which codes would you assign to each new class? Remember: It‚Äôs ok if you don‚Äôt know how to code each step - it‚Äôs more important to have an idea of what you would like to do.\nDiscuss your step-by-step instructions with your team.\n\nThe next exercise will guide you through cleaning the sex codes. There are many ways of doing this. The one presented here might not be the same way you thought about doing it - that‚Äôs ok! This one was designed to practice using the numpy.select() function."
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#clean-values",
    "href": "discussion-sections/ds3-hares.html#clean-values",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "6. Clean values",
    "text": "6. Clean values\n\nCreate a new column called sex_simple using the numpy.select() function so that\n\n\n‚ÄòF‚Äô, ‚Äòf‚Äô, and ‚Äòf_‚Äô in the sex column get assigned to ‚Äòfemale‚Äô,\n‚ÄòM‚Äô, ‚Äòm‚Äô, and ‚Äòm_‚Äô get assigned to ‚Äòmale‚Äô, and\nanything else gets assigned np.nan\n\n\n\nCheck the counts of unique values (including NAs) in the new sex_simple column. \n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#calculate-mean-weight",
    "href": "discussion-sections/ds3-hares.html#calculate-mean-weight",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "7. Calculate mean weight",
    "text": "7. Calculate mean weight\n\nUse groupby() to calculate the mean weight by sex using the new column.\n\n\n\nWrite a full sentence explaining the results you obtained. Don‚Äôt forget to include units.\n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "discussion-sections/ds3-hares.html#collect-your-code-and-explain-your-results",
    "href": "discussion-sections/ds3-hares.html#collect-your-code-and-explain-your-results",
    "title": "Snowshoe hares at Bonanza Creek Experimental Forest",
    "section": "8. Collect your code and explain your results",
    "text": "8. Collect your code and explain your results\nIn a new code cell, collect all the relevant code to create a streamlined workflow to obtain the final result from exercise 7 starting from importing the data. Your code cell should:\n\nOnly print the final results for mean weight by sex_simple.\nNot include output from intermediate variables or checks.\nNot include methods or functions that do not directly contribute to the analysis (even if they don‚Äôt print anything ex: df.head()).\nIf appropriate, combine methods using code chaining instead of creating intermediate variables.\nComment your code following our class comments guidelines.\nUse appropriate line breaks and indentation to make code readable.\n\n\n\n\ncommit, pull, and push changes"
  },
  {
    "objectID": "conventions.html",
    "href": "conventions.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Any website, package, scientific article, dataset or other source should be cited. The IEEE citation style will be used. This is set up via de iee-with-url.csl file and the bibliography and csl parameters in the _quarto.yml file.\nReferences are add into one file for the whole course: references.bib."
  },
  {
    "objectID": "conventions.html#citations",
    "href": "conventions.html#citations",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "Any website, package, scientific article, dataset or other source should be cited. The IEEE citation style will be used. This is set up via de iee-with-url.csl file and the bibliography and csl parameters in the _quarto.yml file.\nReferences are add into one file for the whole course: references.bib."
  },
  {
    "objectID": "conventions.html#subsection-names",
    "href": "conventions.html#subsection-names",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Subsection names",
    "text": "Subsection names\n\nOnly the first letter in subsection names should be capitalized.\nExamples should follow the format ‚ÄúExample: what this example is about‚Äù and should be unlisted from the table of contents using {.unlisted}."
  },
  {
    "objectID": "conventions.html#file-naming",
    "href": "conventions.html#file-naming",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "File naming",
    "text": "File naming\nAll files (except README) should be named in small caps and each work separated by -."
  },
  {
    "objectID": "conventions.html#discussion-sections",
    "href": "conventions.html#discussion-sections",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Discussion sections",
    "text": "Discussion sections\nAll discussion sections should have the following YAML heading:\n---\ntitle: Topic of discussion section\nsubtitle: Week n - Discussion section \ndate: YYYY-MM-DD\nweek: week n\nimage: images/ds-weekn.png\nsidebar: false\n---\nStructure for sections files should be:\n\nBrief intro about what the discussion section is about, followed by In ‚Äòthis discussion section, you will:‚Äô then a list of what will happen in the section.\nSetup in a :::{.callout-tip appearance=\"minimal\"}} ::: block\nGeneral directions in a :::{.callout-tip appearance=\"minimal\"}} ::: block\nAbout the data ina a :::{.callout-note appearance=\"minimal\"}} :::\nExercises numbered"
  },
  {
    "objectID": "conventions.html#lessons",
    "href": "conventions.html#lessons",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "Lessons",
    "text": "Lessons\n\nYAML\n---\ntoc-title: In this lesson\n---\n\n\nLearning objectives\nState them using ‚ÄúBy the end of this lesson, students will be able to:‚Äù"
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html",
    "title": "2 Subsetting",
    "section": "",
    "text": "In this lesson we will learn different methods to select data from a pandas.DataFrame. Like it‚Äôs often the case when working with the pandas package, there are many ways in which we can subset a data frame. Here we will review the core methods to do this.\nA summary of the methods covered in this lesson can be found in Figure¬†1.\n\n\nBy the end of this lesson, students will be able to:\n\nChoose appropriate methods for selecting rows and columns from a pandas.DataFrame\nConstruct conditions to subset rows\nDescribe the difference between label-based subsetting and position-based subsetting\nApply best practies when using iloc and loc selection\n\n\n\n\nIn this lesson we will use annual estimates of bird species abundance in four coastal wetlands along the California coast. This dataset was derived for education purposes for this course from the UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset [1]. The SONGS dataset was collected as part of the San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program.\n\n\n\nSan Onofre Nuclear Generating Station in San Diego County, California. Source: Southern California Edison\n\n\nThe annual bird species abundance estimates is a CSV file with 13 columns and 14 rows. You can see the first three rows below.\n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n\n\n\n\n\nThe four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM), Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the CSM_fall column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The year column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023.\n\n\n\nMugu Lagoon in Ventura County, California, seen from the Mugu Peak Trail. Source: USA National Park Service\n\n\n\n\n\nA CSV (Comma-Separated Values) file is an open, simple text format for storing tabular data, with rows separated by line breaks and columns by commas. It‚Äôs widely used in environmental science for sharing datasets like species counts and environmental monitoring data because it‚Äôs easy to create, read, and process in different platforms, without the need of proprietary software.\nTo read in a CSV file into our Python workspace as pandas.DataFrame we use the pandas.read_csv function:\n\nimport pandas as pd\n\n# Read in file, argument is the file path\ndf = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')\n\nNext, we obtain some high-level information about this data frame:\n\n# Print data frame's first five rows \ndf.head()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n# Print data frame's last five rows \ndf.tail()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n9\n2019\n39.0\n39.0\n40.0\n57.0\n52.0\n53.0\n54.0\n55.0\n53.0\n63.0\n54.0\n50.0\n\n\n10\n2020\n46.0\nNaN\n47.0\n56.0\nNaN\n66.0\n57.0\nNaN\n58.0\n54.0\n40.0\n54.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\n\n# Print data frame's column names\ndf.columns\n\nIndex(['year', 'CSM_winter', 'CSM_spring', 'CSM_fall', 'MUL_winter',\n       'MUL_spring', 'MUL_fall', 'SDW_winter', 'SDW_spring', 'SDW_fall',\n       'TJE_winter', 'TJE_spring', 'TJE_fall'],\n      dtype='object')\n\n\n\n# List the data types of each column\ndf.dtypes\n\nyear            int64\nCSM_winter    float64\nCSM_spring    float64\nCSM_fall      float64\nMUL_winter    float64\nMUL_spring    float64\nMUL_fall      float64\nSDW_winter    float64\nSDW_spring    float64\nSDW_fall      float64\nTJE_winter    float64\nTJE_spring    float64\nTJE_fall      float64\ndtype: object\n\n\n\n# Print data frame's shape: output is a tuple (# rows, # columns)\ndf.shape\n\n(14, 13)\n\n\n\n\n\nSelecting a single column by column name is the simplest case for selecting data in a data frame. The genereal syntax to do this is:\ndf['column_name']\nNotice the column name is given as string inside the square brackets. This is an example of label-based subsetting, which means we want to select data from our data frame using the names of the columns, not their position. When we select rows or column using their position, we are doing position-based subsetting. We‚Äôll see some methods to do this when we move into selecting rows.\n\n\nSuppose we are interested in the number of bird species observed at the Mugu Lagoon in spring. We can access that single column in this way:\n\n# Select a single column by using square brackets []\nmul_spring = df['MUL_spring']\n\n# Print first five elements in this column\nmul_spring.head()\n\n0     NaN\n1    52.0\n2    58.0\n3    58.0\n4    52.0\nName: MUL_spring, dtype: float64\n\n\nSince we only selected a single column, mul_spring is a pandas.Series:\n\n# Check the type of the ouput\nprint(type(mul_spring))\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\n\n\npd.DataFrame = dictionary of columns\n\n\n\nRemember we can think of a pandas.DataFrame as a dictionary of its columns? Then we can access a single column using the column name as the key, just like we would do in a dictionary. That is the we just used: df['column_name'].\n\n\nWe can also do label-based subsetting of a single column using attribute syntax:\ndf.column_name\nFor example, to see the head of the MUL_spring column we would do:\n\ndf.MUL_spring.head()\n\n0     NaN\n1    52.0\n2    58.0\n3    58.0\n4    52.0\nName: MUL_spring, dtype: float64\n\n\n\n\n\n\n\n\nFavor df['column_name'] instead of df.column_name\n\n\n\nIn general, it is better to use the df['column_name'] syntax. A couple reasons why are:\n\ndf['column_name'] can take in any column name, while df.column_name only works if the column name has no spaces or special characters\ndf['column_name'] avoids conflicts with pd.DataFrame methods and attributes. For example, if df has a column named count, it‚Äôs ambiguous whether pd.count is referring to the count() method or the count column.\n\n\n\n\n\n\n\n\n\nWe can select multiple columns in a single call by passing a list with the column names to the square brackets []:\ndf[['column_1', 'column_10', 'column_245']]\nNotice there are double square brackets. This is because we are passing the list of names ['column_1', 'column_10', 'column_245'] to the selection brackets [].\n\n\n\n\n\n\nCheck-in\n\n\n\nIs this an example of label-based selection or location-based selection?\n\n\n\n\nIf we want to look at the species in the Tijuana Estuary during winter and fall, then we can select these columns like this:\n\n# Select columns with names \"TJE_winter\" and \"TJE_fall\"\ntje_wf = df[['TJE_winter','TJE_fall']]\n\nNotice there are double square brackets. This is because we are passing the list of names ['TJE_winter','TJE_fall'] to the selection brakcets [].\n\n\n\n\n\n\nCheck-in\n\n\n\nWhat is the type and shape of the tje_wf output? Verify your answer.\n\n\n\n\n\n\nTo select a slice of the columns we will use a special case of loc selection (we‚Äôll cover the general one by the end of the lesson). The syntax will be\ndf.loc[ : , 'column_start':'column_end']\nwhere column_start and column_end are, respectively, the starting point and endpoint of the column slice we want to subset from the data frame.\nNotice two things:\n\nthe first value passed to loc is used for selecting rows, using a colon : as the row-selection parameter means ‚Äúselect all the rows‚Äù\nthe slice of the data frame we‚Äôll obtain includes both endpoints of the slice 'column_start':'column_end'. In other words, we‚Äôll get the column_start column and the column_end column. This is different from how slicing works in base Python and NumPy, where the endpoint is not included.\n\n\n\nLet‚Äôs select the slice of columns that covers all data from Carpinteria Salt Marsh and Mugu Lagoon. This corresponds to all columns between CSM_winter and MUL_fall.\n\n# Select columns between 'CSM_winter' and 'MUL_fall'\ncsm_mul = df.loc[:,'CSM_winter':'MUL_fall']\ncsm_mul.head()\n\n\n\n\n\n\n\n\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\n\n\n\n\n0\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\n\n\n1\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n\n\n2\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n\n\n3\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n\n\n4\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow that we are familiar with some methods for selecting columns, let‚Äôs move on to selecting rows.\n\n\nSelecting rows that satisfy a particular condition is one of the most usual kinds of row subsetting. The general syntax for this type of selection is\ndf[condition_on_rows]\nThat condition_of_rows can be a myriad things, let‚Äôs see some usual scenarios.\n\n\nSuppose we are intersted in all data after 2020. We can select these rows in this way:\n\n# Select all rows with year &gt; 2020\npost_2020 = df[df['year']&gt;2020]\npost_2020\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\nLet‚Äôs break down what is happening here. The condition for our rows is df['year']&gt;2020, this is a pandas.Series with boolean values (True or False) indicating which rows satisfy the condition year&gt;2020:\n\n# Check the type of df['year']&gt;1996\nprint(type(df['year']&gt;2020))\n\n# Print the boolean series\ndf['year']&gt;2020\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n0     False\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11     True\n12     True\n13     True\nName: year, dtype: bool\n\n\nWhen we pass such a series of boolean values to the selection brackets [] we keep only the rows that correspond to a True value.\n\n\n\n\n\n\n\nCheck-in\n\n\n\nGet the subset of the data frame on which the San Dieguito Wetland has at least 75 species recorded during spring.\n\n\n\n\n\nSuppose we want to look at data from years 2012 to 2015 (including both years). One way of doing this is to use the between operator in our condition:\n\nsubset = df[df['year'].between(2012, 2015)]\nsubset\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n5\n2015\n44.0\n42.0\n45.0\n58.0\n50.0\n51.0\n71.0\n61.0\n65.0\n73.0\n76.0\n64.0\n\n\n\n\n\n\n\nLet‚Äôs break down this code:\n\ndf['year'] is the column with the year values, a pandas.Series\nin df['year'].between(), we have that between is a method for the pandas.Series and we are calling it using the dot .\n(2012, 2015) are the parameters for the between() method, from the pandas documentation we can see this method will subset including both endpoints\ndf['year'].between(2012, 2015) is then a pandas.Series of boolean values indicating which rows have year equal to 2012, 2013, 2014, or 2015.\nwhen we put df['year'].between(2012, 2015) inside the selection brackets [] we obtain the rows of the data frame with year equal to 2012, ‚Ä¶, 2015.\n\n\n\n\n\n\n\nAvoid using loc for selecting only rows\n\n\n\nIt is equivalent to write\n# Select rows with year&lt;2015\ndf[df['year']&lt;2015]\nand\n# Select rows with year&lt;2015 using loc\ndf.loc[ df['year']&lt;2015 , :]\nIn the second one:\n\nwe are using the df.loc[ row-selection , column-selection] syntax\nthe row-selection parameter is the condition df['year']&lt;2015\nthe column-selection parameter is a colon :, which indicates we want all columns for the rows we are selecting.\n\nWe prefer the first syntax when we are selecting rows and not columns since it is simpler.\n\n\n\n\n\n\nWe can combine multipe conditions to select rows by surrounding each one in parenthesis () and using the or operator | and the and operator &.\n\n\nLet‚Äôs select rows in which the Carpinteria Salt Marsh has more than 50 species registered in winter or fall:\n\ndf[ (df['CSM_winter']&gt;50) | (df['CSM_fall']&gt;50)]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs select rows in which both the Carpinteria Salt Marsh and the San Dieguito Wetland have more than 60 reported bird species during spring:\n\ndf[ (df['CSM_spring']&gt;60) & (df['SDW_spring']&gt;60)]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n\n\n\n\n\nAn empty data frame! That‚Äôs ok, it just means there are no rows that satisfy the given condition.\n\n\n\n\nAll the selections we have done so far have been using labels. Sometimes we may want to select certain rows depending on their actual position in the data frame. In other words, using position-based subsetting. To do this, we use iloc selection with the syntax\n df.iloc[row-indices]\niloc stands for integer-location based indexing.\n\n\n\n# Select the fifth row (index=4)\ndf.iloc[4]\n\nyear          2014.0\nCSM_winter      38.0\nCSM_spring      43.0\nCSM_fall        45.0\nMUL_winter      49.0\nMUL_spring      52.0\nMUL_fall        57.0\nSDW_winter      61.0\nSDW_spring      78.0\nSDW_fall        71.0\nTJE_winter      60.0\nTJE_spring      81.0\nTJE_fall        62.0\nName: 4, dtype: float64\n\n\n\n# Select rows 9 through 13, inclduing 13\ndf.iloc[9:14]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n9\n2019\n39.0\n39.0\n40.0\n57.0\n52.0\n53.0\n54.0\n55.0\n53.0\n63.0\n54.0\n50.0\n\n\n10\n2020\n46.0\nNaN\n47.0\n56.0\nNaN\n66.0\n57.0\nNaN\n58.0\n54.0\n40.0\n54.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\nNotice that, since we are back to indexing by position, the right endpoint of the slice is not included in the ouput.\n\n\n\n\n\nSelecting rows and columns simultaneously can be done using loc (labels) or iloc (positions).\n\n\nWhen we want to select rows and columns simultaneously by labels (including using conditions) we can use loc selection with the syntax\ndf.loc[ row-selection , column-selection]\nspecifying both paratmers: row-selection and column-selection. These parameters can be a condition or a subset of labels from the index or the column names.\n\n\nLet‚Äôs select the winter surveys for Mugu Lagoon and the Tijuana Estuary after 2020:\n\ndf.loc[df['year']&gt;2020, ['MUL_winter','TJE_winter']]\n\n\n\n\n\n\n\n\nMUL_winter\nTJE_winter\n\n\n\n\n11\n54.0\n53.0\n\n\n12\n60.0\n60.0\n\n\n13\n72.0\n60.0\n\n\n\n\n\n\n\nLet‚Äôs break down this code:\n\nwe are using the df.loc[ row-selection , column-selection] syntax\nthe row-selection parameter is the condition df['year']&gt;2020, which is a boolean array saying which years are greater than 2020\nthe column-selection parameter is ['MUL_winter','TJE_winter'], which is a list with the names of the two columns we are interested in.\n\n\n\n\n\nWhen we want to select rows and columns simultaneously by position we use iloc selection with the syntax:\ndf.iloc[ row-indices , column-indices]\n\n\nSuppose we want to select rows 3-7 (including 7) and columns 3 and 4:\n\ndf.iloc[3:8, [3,4]]\n\n\n\n\n\n\n\n\nCSM_fall\nMUL_winter\n\n\n\n\n3\n38.0\n60.0\n\n\n4\n45.0\n49.0\n\n\n5\n45.0\n58.0\n\n\n6\n47.0\n63.0\n\n\n7\n43.0\n57.0\n\n\n\n\n\n\n\nLet‚Äôs break it down:\n\nwe are using the df.iloc[ row-indices , column-indices] syntax to select by position\nthe row-indices parameter is the slice of integer indices 3:8. Remember the right endpoint (8) won‚Äôt be included.\nthe column-indices parameter is the list of integer indices 3 and 4. This means we are selecting the fourth and fifth column.\n\n\n\n\n\n\n\n\n\n\n\n\niloc vs.¬†loc: which one does what?\n\n\n\nAt the beginning, the difference between iloc and loc can be confusing. Remember the i in iloc stands for integer location, this reminds us iloc only uses integer indexing to retrieve information from the data frames in the same way as indexing for Python lists.\nIf you want to dive deeper, this is a great discussion about the difference between iloc and loc: Stackoverflow - How are iloc and loc different?\nAnd, as always, the documentation will provide you with more information: pandas.DataFrame.loc and pandas.DataFrame.iloc.\n\n\n\n\n\n\n\n\niloc for column selection? Avoid it!\n\n\n\nWe can also access columns by position using iloc - but it is best not to if possible.\nSuppose we want to access the 9th column in the data frame - then we want to select a column by position. In this case, the 9th column is the data at San Dieguito Wetland during spring and the 9th position corresponds to the index 8. We can select this column by position using the iloc selection:\n\n# Select column by position using iloc\n# The syntax is iloc[row-indices, column-indices]\n# [:,8] means \"select all rows from the 8th column\"\nsdw_spring = df.iloc[:,8]\nsdw_spring.head()\n\n0    75.0\n1    74.0\n2    72.0\n3    70.0\n4    78.0\nName: SDW_spring, dtype: float64\n\n\nUnless you are really looking for information about the 9th column, do not access a column by position. This is bound to break in many ways:\n\nit relies on a person correctly counting the position of a column. Even with a small dataset this can be prone to error.\nit is not explicit: if we want information about San Dieguito Wetland during spring, df.SDW_spring or df['SDW_spring'] are explicitely telling us we are accessing that information. df.iloc[:,8] is obscure and uninformative.\ndatastets can get updated. Maybe a new column was added before SDW_spring, this would change the position of the column, which would make any code depending on df.iloc[:,8] invalid.\n\nAccessing columns by labels helps reproducibility!\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Flow diagram for selecting core methods to subset a pandas.DataFrame.\n\n\n\n\n\n\n\nWhat is presented in this section is not an exhaustive list of methods to select data in pandas.DataFrames. There are so many ways to subset data to get the same result. Some of the content from this lesson is adapted from the following resources and I encourage you to read them to learn more!\nüìñ Pandas getting started tutorials - How to I select a subset of a DataFrame\nüìñ Pandas documentation - User Guide - Indexing and Selecting Data\nüìñ Python for Data Analysis, 3E - Getting started with pandas",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#learning-objectives",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#learning-objectives",
    "title": "2 Subsetting",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nChoose appropriate methods for selecting rows and columns from a pandas.DataFrame\nConstruct conditions to subset rows\nDescribe the difference between label-based subsetting and position-based subsetting\nApply best practies when using iloc and loc selection",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#about-the-data",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#about-the-data",
    "title": "2 Subsetting",
    "section": "",
    "text": "In this lesson we will use annual estimates of bird species abundance in four coastal wetlands along the California coast. This dataset was derived for education purposes for this course from the UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset [1]. The SONGS dataset was collected as part of the San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program.\n\n\n\nSan Onofre Nuclear Generating Station in San Diego County, California. Source: Southern California Edison\n\n\nThe annual bird species abundance estimates is a CSV file with 13 columns and 14 rows. You can see the first three rows below.\n\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n\n\n\n\n\nThe four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM), Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the CSM_fall column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The year column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023.\n\n\n\nMugu Lagoon in Ventura County, California, seen from the Mugu Peak Trail. Source: USA National Park Service",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#csv-files",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#csv-files",
    "title": "2 Subsetting",
    "section": "",
    "text": "A CSV (Comma-Separated Values) file is an open, simple text format for storing tabular data, with rows separated by line breaks and columns by commas. It‚Äôs widely used in environmental science for sharing datasets like species counts and environmental monitoring data because it‚Äôs easy to create, read, and process in different platforms, without the need of proprietary software.\nTo read in a CSV file into our Python workspace as pandas.DataFrame we use the pandas.read_csv function:\n\nimport pandas as pd\n\n# Read in file, argument is the file path\ndf = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')\n\nNext, we obtain some high-level information about this data frame:\n\n# Print data frame's first five rows \ndf.head()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n0\n2010\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\nNaN\n75.0\n85.0\nNaN\nNaN\n81.0\n\n\n1\n2011\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n78.0\n74.0\nNaN\n67.0\n70.0\nNaN\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n\n\n\n\n\n\n# Print data frame's last five rows \ndf.tail()\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n9\n2019\n39.0\n39.0\n40.0\n57.0\n52.0\n53.0\n54.0\n55.0\n53.0\n63.0\n54.0\n50.0\n\n\n10\n2020\n46.0\nNaN\n47.0\n56.0\nNaN\n66.0\n57.0\nNaN\n58.0\n54.0\n40.0\n54.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\n\n# Print data frame's column names\ndf.columns\n\nIndex(['year', 'CSM_winter', 'CSM_spring', 'CSM_fall', 'MUL_winter',\n       'MUL_spring', 'MUL_fall', 'SDW_winter', 'SDW_spring', 'SDW_fall',\n       'TJE_winter', 'TJE_spring', 'TJE_fall'],\n      dtype='object')\n\n\n\n# List the data types of each column\ndf.dtypes\n\nyear            int64\nCSM_winter    float64\nCSM_spring    float64\nCSM_fall      float64\nMUL_winter    float64\nMUL_spring    float64\nMUL_fall      float64\nSDW_winter    float64\nSDW_spring    float64\nSDW_fall      float64\nTJE_winter    float64\nTJE_spring    float64\nTJE_fall      float64\ndtype: object\n\n\n\n# Print data frame's shape: output is a tuple (# rows, # columns)\ndf.shape\n\n(14, 13)",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-a-single-column",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-a-single-column",
    "title": "2 Subsetting",
    "section": "",
    "text": "Selecting a single column by column name is the simplest case for selecting data in a data frame. The genereal syntax to do this is:\ndf['column_name']\nNotice the column name is given as string inside the square brackets. This is an example of label-based subsetting, which means we want to select data from our data frame using the names of the columns, not their position. When we select rows or column using their position, we are doing position-based subsetting. We‚Äôll see some methods to do this when we move into selecting rows.\n\n\nSuppose we are interested in the number of bird species observed at the Mugu Lagoon in spring. We can access that single column in this way:\n\n# Select a single column by using square brackets []\nmul_spring = df['MUL_spring']\n\n# Print first five elements in this column\nmul_spring.head()\n\n0     NaN\n1    52.0\n2    58.0\n3    58.0\n4    52.0\nName: MUL_spring, dtype: float64\n\n\nSince we only selected a single column, mul_spring is a pandas.Series:\n\n# Check the type of the ouput\nprint(type(mul_spring))\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\n\n\npd.DataFrame = dictionary of columns\n\n\n\nRemember we can think of a pandas.DataFrame as a dictionary of its columns? Then we can access a single column using the column name as the key, just like we would do in a dictionary. That is the we just used: df['column_name'].\n\n\nWe can also do label-based subsetting of a single column using attribute syntax:\ndf.column_name\nFor example, to see the head of the MUL_spring column we would do:\n\ndf.MUL_spring.head()\n\n0     NaN\n1    52.0\n2    58.0\n3    58.0\n4    52.0\nName: MUL_spring, dtype: float64\n\n\n\n\n\n\n\n\nFavor df['column_name'] instead of df.column_name\n\n\n\nIn general, it is better to use the df['column_name'] syntax. A couple reasons why are:\n\ndf['column_name'] can take in any column name, while df.column_name only works if the column name has no spaces or special characters\ndf['column_name'] avoids conflicts with pd.DataFrame methods and attributes. For example, if df has a column named count, it‚Äôs ambiguous whether pd.count is referring to the count() method or the count column.",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-multiple-columns",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-multiple-columns",
    "title": "2 Subsetting",
    "section": "",
    "text": "We can select multiple columns in a single call by passing a list with the column names to the square brackets []:\ndf[['column_1', 'column_10', 'column_245']]\nNotice there are double square brackets. This is because we are passing the list of names ['column_1', 'column_10', 'column_245'] to the selection brackets [].\n\n\n\n\n\n\nCheck-in\n\n\n\nIs this an example of label-based selection or location-based selection?\n\n\n\n\nIf we want to look at the species in the Tijuana Estuary during winter and fall, then we can select these columns like this:\n\n# Select columns with names \"TJE_winter\" and \"TJE_fall\"\ntje_wf = df[['TJE_winter','TJE_fall']]\n\nNotice there are double square brackets. This is because we are passing the list of names ['TJE_winter','TJE_fall'] to the selection brakcets [].\n\n\n\n\n\n\nCheck-in\n\n\n\nWhat is the type and shape of the tje_wf output? Verify your answer.\n\n\n\n\n\n\nTo select a slice of the columns we will use a special case of loc selection (we‚Äôll cover the general one by the end of the lesson). The syntax will be\ndf.loc[ : , 'column_start':'column_end']\nwhere column_start and column_end are, respectively, the starting point and endpoint of the column slice we want to subset from the data frame.\nNotice two things:\n\nthe first value passed to loc is used for selecting rows, using a colon : as the row-selection parameter means ‚Äúselect all the rows‚Äù\nthe slice of the data frame we‚Äôll obtain includes both endpoints of the slice 'column_start':'column_end'. In other words, we‚Äôll get the column_start column and the column_end column. This is different from how slicing works in base Python and NumPy, where the endpoint is not included.\n\n\n\nLet‚Äôs select the slice of columns that covers all data from Carpinteria Salt Marsh and Mugu Lagoon. This corresponds to all columns between CSM_winter and MUL_fall.\n\n# Select columns between 'CSM_winter' and 'MUL_fall'\ncsm_mul = df.loc[:,'CSM_winter':'MUL_fall']\ncsm_mul.head()\n\n\n\n\n\n\n\n\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\n\n\n\n\n0\n39.0\n40.0\n50.0\n45.0\nNaN\n61.0\n\n\n1\n48.0\n44.0\nNaN\n58.0\n52.0\nNaN\n\n\n2\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n\n\n3\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n\n\n4\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-rows",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-rows",
    "title": "2 Subsetting",
    "section": "",
    "text": "Now that we are familiar with some methods for selecting columns, let‚Äôs move on to selecting rows.\n\n\nSelecting rows that satisfy a particular condition is one of the most usual kinds of row subsetting. The general syntax for this type of selection is\ndf[condition_on_rows]\nThat condition_of_rows can be a myriad things, let‚Äôs see some usual scenarios.\n\n\nSuppose we are intersted in all data after 2020. We can select these rows in this way:\n\n# Select all rows with year &gt; 2020\npost_2020 = df[df['year']&gt;2020]\npost_2020\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\nLet‚Äôs break down what is happening here. The condition for our rows is df['year']&gt;2020, this is a pandas.Series with boolean values (True or False) indicating which rows satisfy the condition year&gt;2020:\n\n# Check the type of df['year']&gt;1996\nprint(type(df['year']&gt;2020))\n\n# Print the boolean series\ndf['year']&gt;2020\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n0     False\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11     True\n12     True\n13     True\nName: year, dtype: bool\n\n\nWhen we pass such a series of boolean values to the selection brackets [] we keep only the rows that correspond to a True value.\n\n\n\n\n\n\n\nCheck-in\n\n\n\nGet the subset of the data frame on which the San Dieguito Wetland has at least 75 species recorded during spring.\n\n\n\n\n\nSuppose we want to look at data from years 2012 to 2015 (including both years). One way of doing this is to use the between operator in our condition:\n\nsubset = df[df['year'].between(2012, 2015)]\nsubset\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n3\n2013\n42.0\n46.0\n38.0\n60.0\n58.0\n62.0\n69.0\n70.0\n70.0\n69.0\n74.0\n64.0\n\n\n4\n2014\n38.0\n43.0\n45.0\n49.0\n52.0\n57.0\n61.0\n78.0\n71.0\n60.0\n81.0\n62.0\n\n\n5\n2015\n44.0\n42.0\n45.0\n58.0\n50.0\n51.0\n71.0\n61.0\n65.0\n73.0\n76.0\n64.0\n\n\n\n\n\n\n\nLet‚Äôs break down this code:\n\ndf['year'] is the column with the year values, a pandas.Series\nin df['year'].between(), we have that between is a method for the pandas.Series and we are calling it using the dot .\n(2012, 2015) are the parameters for the between() method, from the pandas documentation we can see this method will subset including both endpoints\ndf['year'].between(2012, 2015) is then a pandas.Series of boolean values indicating which rows have year equal to 2012, 2013, 2014, or 2015.\nwhen we put df['year'].between(2012, 2015) inside the selection brackets [] we obtain the rows of the data frame with year equal to 2012, ‚Ä¶, 2015.\n\n\n\n\n\n\n\nAvoid using loc for selecting only rows\n\n\n\nIt is equivalent to write\n# Select rows with year&lt;2015\ndf[df['year']&lt;2015]\nand\n# Select rows with year&lt;2015 using loc\ndf.loc[ df['year']&lt;2015 , :]\nIn the second one:\n\nwe are using the df.loc[ row-selection , column-selection] syntax\nthe row-selection parameter is the condition df['year']&lt;2015\nthe column-selection parameter is a colon :, which indicates we want all columns for the rows we are selecting.\n\nWe prefer the first syntax when we are selecting rows and not columns since it is simpler.\n\n\n\n\n\n\nWe can combine multipe conditions to select rows by surrounding each one in parenthesis () and using the or operator | and the and operator &.\n\n\nLet‚Äôs select rows in which the Carpinteria Salt Marsh has more than 50 species registered in winter or fall:\n\ndf[ (df['CSM_winter']&gt;50) | (df['CSM_fall']&gt;50)]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n2\n2012\n51.0\n43.0\n49.0\n57.0\n58.0\n53.0\n71.0\n72.0\n73.0\n70.0\n63.0\n69.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs select rows in which both the Carpinteria Salt Marsh and the San Dieguito Wetland have more than 60 reported bird species during spring:\n\ndf[ (df['CSM_spring']&gt;60) & (df['SDW_spring']&gt;60)]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n\n\n\n\n\nAn empty data frame! That‚Äôs ok, it just means there are no rows that satisfy the given condition.\n\n\n\n\nAll the selections we have done so far have been using labels. Sometimes we may want to select certain rows depending on their actual position in the data frame. In other words, using position-based subsetting. To do this, we use iloc selection with the syntax\n df.iloc[row-indices]\niloc stands for integer-location based indexing.\n\n\n\n# Select the fifth row (index=4)\ndf.iloc[4]\n\nyear          2014.0\nCSM_winter      38.0\nCSM_spring      43.0\nCSM_fall        45.0\nMUL_winter      49.0\nMUL_spring      52.0\nMUL_fall        57.0\nSDW_winter      61.0\nSDW_spring      78.0\nSDW_fall        71.0\nTJE_winter      60.0\nTJE_spring      81.0\nTJE_fall        62.0\nName: 4, dtype: float64\n\n\n\n# Select rows 9 through 13, inclduing 13\ndf.iloc[9:14]\n\n\n\n\n\n\n\n\nyear\nCSM_winter\nCSM_spring\nCSM_fall\nMUL_winter\nMUL_spring\nMUL_fall\nSDW_winter\nSDW_spring\nSDW_fall\nTJE_winter\nTJE_spring\nTJE_fall\n\n\n\n\n9\n2019\n39.0\n39.0\n40.0\n57.0\n52.0\n53.0\n54.0\n55.0\n53.0\n63.0\n54.0\n50.0\n\n\n10\n2020\n46.0\nNaN\n47.0\n56.0\nNaN\n66.0\n57.0\nNaN\n58.0\n54.0\n40.0\n54.0\n\n\n11\n2021\n47.0\n44.0\n53.0\n54.0\n55.0\n60.0\n57.0\n58.0\n57.0\n53.0\n68.0\n51.0\n\n\n12\n2022\n40.0\n46.0\n49.0\n60.0\n55.0\n65.0\n57.0\n60.0\n57.0\n60.0\n61.0\n60.0\n\n\n13\n2023\n56.0\n43.0\n36.0\n72.0\n59.0\n53.0\n64.0\n63.0\n33.0\n60.0\n56.0\n38.0\n\n\n\n\n\n\n\nNotice that, since we are back to indexing by position, the right endpoint of the slice is not included in the ouput.",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-rows-and-columns-simultaneously",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#selecting-rows-and-columns-simultaneously",
    "title": "2 Subsetting",
    "section": "",
    "text": "Selecting rows and columns simultaneously can be done using loc (labels) or iloc (positions).\n\n\nWhen we want to select rows and columns simultaneously by labels (including using conditions) we can use loc selection with the syntax\ndf.loc[ row-selection , column-selection]\nspecifying both paratmers: row-selection and column-selection. These parameters can be a condition or a subset of labels from the index or the column names.\n\n\nLet‚Äôs select the winter surveys for Mugu Lagoon and the Tijuana Estuary after 2020:\n\ndf.loc[df['year']&gt;2020, ['MUL_winter','TJE_winter']]\n\n\n\n\n\n\n\n\nMUL_winter\nTJE_winter\n\n\n\n\n11\n54.0\n53.0\n\n\n12\n60.0\n60.0\n\n\n13\n72.0\n60.0\n\n\n\n\n\n\n\nLet‚Äôs break down this code:\n\nwe are using the df.loc[ row-selection , column-selection] syntax\nthe row-selection parameter is the condition df['year']&gt;2020, which is a boolean array saying which years are greater than 2020\nthe column-selection parameter is ['MUL_winter','TJE_winter'], which is a list with the names of the two columns we are interested in.\n\n\n\n\n\nWhen we want to select rows and columns simultaneously by position we use iloc selection with the syntax:\ndf.iloc[ row-indices , column-indices]\n\n\nSuppose we want to select rows 3-7 (including 7) and columns 3 and 4:\n\ndf.iloc[3:8, [3,4]]\n\n\n\n\n\n\n\n\nCSM_fall\nMUL_winter\n\n\n\n\n3\n38.0\n60.0\n\n\n4\n45.0\n49.0\n\n\n5\n45.0\n58.0\n\n\n6\n47.0\n63.0\n\n\n7\n43.0\n57.0\n\n\n\n\n\n\n\nLet‚Äôs break it down:\n\nwe are using the df.iloc[ row-indices , column-indices] syntax to select by position\nthe row-indices parameter is the slice of integer indices 3:8. Remember the right endpoint (8) won‚Äôt be included.\nthe column-indices parameter is the list of integer indices 3 and 4. This means we are selecting the fourth and fifth column.",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#notes-about-loc-and-iloc",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#notes-about-loc-and-iloc",
    "title": "2 Subsetting",
    "section": "",
    "text": "iloc vs.¬†loc: which one does what?\n\n\n\nAt the beginning, the difference between iloc and loc can be confusing. Remember the i in iloc stands for integer location, this reminds us iloc only uses integer indexing to retrieve information from the data frames in the same way as indexing for Python lists.\nIf you want to dive deeper, this is a great discussion about the difference between iloc and loc: Stackoverflow - How are iloc and loc different?\nAnd, as always, the documentation will provide you with more information: pandas.DataFrame.loc and pandas.DataFrame.iloc.\n\n\n\n\n\n\n\n\niloc for column selection? Avoid it!\n\n\n\nWe can also access columns by position using iloc - but it is best not to if possible.\nSuppose we want to access the 9th column in the data frame - then we want to select a column by position. In this case, the 9th column is the data at San Dieguito Wetland during spring and the 9th position corresponds to the index 8. We can select this column by position using the iloc selection:\n\n# Select column by position using iloc\n# The syntax is iloc[row-indices, column-indices]\n# [:,8] means \"select all rows from the 8th column\"\nsdw_spring = df.iloc[:,8]\nsdw_spring.head()\n\n0    75.0\n1    74.0\n2    72.0\n3    70.0\n4    78.0\nName: SDW_spring, dtype: float64\n\n\nUnless you are really looking for information about the 9th column, do not access a column by position. This is bound to break in many ways:\n\nit relies on a person correctly counting the position of a column. Even with a small dataset this can be prone to error.\nit is not explicit: if we want information about San Dieguito Wetland during spring, df.SDW_spring or df['SDW_spring'] are explicitely telling us we are accessing that information. df.iloc[:,8] is obscure and uninformative.\ndatastets can get updated. Maybe a new column was added before SDW_spring, this would change the position of the column, which would make any code depending on df.iloc[:,8] invalid.\n\nAccessing columns by labels helps reproducibility!",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#summary",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#summary",
    "title": "2 Subsetting",
    "section": "",
    "text": "Figure¬†1: Flow diagram for selecting core methods to subset a pandas.DataFrame.",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#resources",
    "href": "book/chapters/lesson-3-pandas-subsetting/lesson-3-pandas-subsetting.html#resources",
    "title": "2 Subsetting",
    "section": "",
    "text": "What is presented in this section is not an exhaustive list of methods to select data in pandas.DataFrames. There are so many ways to subset data to get the same result. Some of the content from this lesson is adapted from the following resources and I encourage you to read them to learn more!\nüìñ Pandas getting started tutorials - How to I select a subset of a DataFrame\nüìñ Pandas documentation - User Guide - Indexing and Selecting Data\nüìñ Python for Data Analysis, 3E - Getting started with pandas",
    "crumbs": [
      "notes",
      "Tabular data",
      "2 Subsetting"
    ]
  },
  {
    "objectID": "book/chapters/lesson-6-groupby.html",
    "href": "book/chapters/lesson-6-groupby.html",
    "title": "5 Grouping",
    "section": "",
    "text": "In this section we will go over the split-apply-combine strategy and the groupby() function.\nThis lesson is based on the R lesson on summary statistics using group-by and summarize [1] co-developed at the NCEAS Learning Hub.",
    "crumbs": [
      "notes",
      "Tabular data",
      "5 Grouping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-6-groupby.html#learning-objectives",
    "href": "book/chapters/lesson-6-groupby.html#learning-objectives",
    "title": "5 Grouping",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this lesson students will be able to:\n\nUnderstand and apply the Split-Apply-Combine strategy to analyze grouped data.\nUse groupby() to split a pandas.DataFrame by one or more columns.\nCalculate summary statistics for groups in a pandas.DataFrame.\nUse method chaining for efficient data analysis.",
    "crumbs": [
      "notes",
      "Tabular data",
      "5 Grouping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-6-groupby.html#about-the-data",
    "href": "book/chapters/lesson-6-groupby.html#about-the-data",
    "title": "5 Grouping",
    "section": "About the data",
    "text": "About the data\nFor this section we will use the Palmer Penguins dataset [2] developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica during 2007, 2008, and 2009.\n\n\n\nThe Palmer Archipelago penguins. Artwork by Dr.¬†Allison Horst.\n\n\nThe dataset has 344 rows and 8 columns. Let‚Äôs start by loading the data:\n\nimport numpy as np\nimport pandas as pd\n\n# Load Palmer penguins data\nURL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\npenguins = pd.read_csv(URL)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007",
    "crumbs": [
      "notes",
      "Tabular data",
      "5 Grouping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-6-groupby.html#summary-statistics",
    "href": "book/chapters/lesson-6-groupby.html#summary-statistics",
    "title": "5 Grouping",
    "section": "Summary statistics",
    "text": "Summary statistics\nIt is easy to get summary statistics for each column in a pandas.DataFrame by using methods such as\n\nsum(): sum values in each column,\ncount(): count non-NA values in each column,\nmin() and max(): get the minimum and maximum value in each column,\n\nmean() and median(): get the mean and median value in each column,\nstd() and var(): get the standard deviation and variance in each column.\n\n\nExample\n\n# Get the number of non-NA values in each column \npenguins.count()\n\nspecies              344\nisland               344\nbill_length_mm       342\nbill_depth_mm        342\nflipper_length_mm    342\nbody_mass_g          342\nsex                  333\nyear                 344\ndtype: int64\n\n\n\n# Get minimum value in each column with numerical values\npenguins.select_dtypes('number').min()\n\nbill_length_mm         32.1\nbill_depth_mm          13.1\nflipper_length_mm     172.0\nbody_mass_g          2700.0\nyear                 2007.0\ndtype: float64",
    "crumbs": [
      "notes",
      "Tabular data",
      "5 Grouping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-6-groupby.html#grouping",
    "href": "book/chapters/lesson-6-groupby.html#grouping",
    "title": "5 Grouping",
    "section": "Grouping",
    "text": "Grouping\nOur penguins data is naturally split into different groups: there are three different species, two sexes, and three islands. Often, we want to calculate a certain statistic for each group. For example, suppose we want to calculate the average flipper length per species. How would we do this ‚Äúby hand‚Äù?\n\nWe start with our data and notice there are multiple species in the species column.\nWe split our original table to group all observations from the same species together.\nWe calculate the average flipper length for each of the groups we formed.\nThen we combine the values for average flipper length per species into a single table.\n\nThis is known as the Split-Apply-Combine strategy. This strategy follows the three steps we explained above:\n\nSplit: Split the data into logical groups (e.g.¬†species, sex, island, etc.)\nApply: Calculate some summary statistic on each group (e.g.¬†average flipper length by species, number of individuals per island, body mass by sex, etc.)\nCombine: Combine the statistic calculated on each group back together.\n\n\n\n\n\nSplit-apply-combine to calculate mean flipper length\n\n\n\nFor a pandas.DataFrame or pandas.Series, we can use the groupby() method to split (i.e.¬†group) the data into different categories.\nThe general syntax for groupby() is\ndf.groupby(columns_to_group_by).summary_method()\nMost often, we will have that columns_to_group_by will be a single column name (a string) or a list of column names. The unique values of the column (or columns) will be used as the groups of the data frame.\n\nExample\nIf we don‚Äôt use groupby() and directly apply the mean() method to our flipper length column, we obtain the average of all the values in the column:\n\npenguins['flipper_length_mm'].mean()\n\n200.91520467836258\n\n\nTo get the mean flipper length by species we first group our dataset by the species column‚Äôs values. However, if we just use the groupby() method without specifying what we wish to calculate on each group, not much happens up front:\n\npenguins.groupby('species')['flipper_length_mm']\n\n&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x149eda550&gt;\n\n\nWe get a GroupBy object, which is like an intermediate step. It doesn‚Äôt perform the actual calculations until we specify an operation:\n\n# Average flipper length per species\npenguins.groupby('species')['flipper_length_mm'].mean()\n\nspecies\nAdelie       189.953642\nChinstrap    195.823529\nGentoo       217.186992\nName: flipper_length_mm, dtype: float64\n\n\nLet‚Äôs recap what went on in that line (remember the . can be read as ‚Äúand then‚Ä¶‚Äù):\n\nstart with the penguins data frame, and then‚Ä¶\nuse groupby() to group the data frame by species values, and then‚Ä¶\nselect the 'flipper_length_mm' column, and then‚Ä¶\ncalculate the mean() of this column with respect to the groups.\n\nNotice that the name of the series is the same as the column on which we calculated the summary statistc. We can easily update this using the rename() method:\n\n# Average flipper length per species\navg_flipper = (penguins.groupby(\"species\")\n                        .flipper_length_mm\n                        .mean()\n                        .rename('mean_flipper_length')\n                        .sort_values(ascending=False)\n                        )\navg_flipper\n\nspecies\nGentoo       217.186992\nChinstrap    195.823529\nAdelie       189.953642\nName: mean_flipper_length, dtype: float64\n\n\nWe can also group by combinations of columns.\n\n\nExample\nWe want to know what was the number of penguins surveyed in each island on different years. We can use the count() method to count the number of non-NA values in each column like this:\n\npenguins.count()\n\nspecies              344\nisland               344\nbill_length_mm       342\nbill_depth_mm        342\nflipper_length_mm    342\nbody_mass_g          342\nsex                  333\nyear                 344\ndtype: int64\n\n\nWhen we group by island and year we get the count of non-NA values for each column across each combination of island and year:\n\npenguins.groupby(['island','year']).count()\n\n\n\n\n\n\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\nisland\nyear\n\n\n\n\n\n\n\n\n\n\nBiscoe\n2007\n44\n44\n44\n44\n44\n43\n\n\n2008\n64\n64\n64\n64\n64\n63\n\n\n2009\n60\n59\n59\n59\n59\n57\n\n\nDream\n2007\n46\n46\n46\n46\n46\n45\n\n\n2008\n34\n34\n34\n34\n34\n34\n\n\n2009\n44\n44\n44\n44\n44\n44\n\n\nTorgersen\n2007\n20\n19\n19\n19\n19\n15\n\n\n2008\n16\n16\n16\n16\n16\n16\n\n\n2009\n16\n16\n16\n16\n16\n16\n\n\n\n\n\n\n\nLet‚Äôs say we want to plot the surveyed population per year and island. We could then use method chaining to do this:\n\n(penguins.groupby(['island','year'])\n         .count()\n         .species\n         .sort_values()\n         .plot(kind='barh',\n                title='Penguins surveyed at the Palmer Archipelago',\n                ylabel=('Island, Year'))\n         )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\n\nUse the max() method for pandas.DataFrames to calculate the maximum value of a penguin‚Äôs body mass by year and species.\n\n\n\nUse (1) to display the highest body masses per year and species as a bar plot in descending order.",
    "crumbs": [
      "notes",
      "Tabular data",
      "5 Grouping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html",
    "href": "book/chapters/lesson-16-STAC.html",
    "title": "15 STAC specification",
    "section": "",
    "text": "So far in our course we have obtained data in two ways: by downloading it directly from the data provider or by obtaining a URL from a data repository. This can be a convenient way to access targeted datasets, often usign graphical user interfaces (GUIs) for data discovery and filtering. However, relying on clicking and copy-pasting addresses and file names can make our workflows more error-prone and less reproducible. In particular, satellites around the world produce terabytes of new data daily and manually browsing through data repositories can it make difficult to access this data. Moreover, it can be inconvenient to learn a new way to access data from every single big data provider. This is where STAC comes in.\nThe SpatioTemporal Asset Catalog (STAC) is an emerging open standard for geospatial data that aims to increase the interoperability of geospatial data, particularly satellite imagery. Many major data archives now follow the STAC specification.\nIn the next classes we‚Äôll be working with the Microsoft‚Äôs Planetary Computer (MPC) STAC API. In this lesson we will learn about the main components of a STAC catalog and how to search for data using the MPC‚Äôs STAC API.",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#item-collection-and-catalog",
    "href": "book/chapters/lesson-16-STAC.html#item-collection-and-catalog",
    "title": "15 STAC specification",
    "section": "Item, collection, and catalog",
    "text": "Item, collection, and catalog\nThe STAC item (or just item) is the building block of a STAC. An item is a GeoJSON feature with additional fields that make it easier to find it as we look for data across catalogs.\nAn item holds two types of information:\n\nMetadata: The metadata for a STAC item includes core identifying information (such as ID, geometry, bounding box, and date), and additional properties (for example, place of collection).\nAssets: Assets are links to the actual data of the item (for example, links to the spectral bands of a satellite image.)\n\nSTAC items can be grouped into STAC collections. For example, while a single satellite scene (at a single time and location) would constitue an item, scenes across time and location from the same satellite can be orgnanized in a collection. Finally, multiple collections can be organized into a single STAC catalog.\nFor example, we‚Äôll be accessing the MPC STAC catalog. Two of its collections are the National Agriculture Imagery Program (NAIP) colelction and the Copernicus Digital Elevation Model (DEM) colleciton. Each of these collections has multiple items, with item cotaining properties (metadata) and assets (links to the data).",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#application-programming-interface-api",
    "href": "book/chapters/lesson-16-STAC.html#application-programming-interface-api",
    "title": "15 STAC specification",
    "section": "Application Programming Interface (API)",
    "text": "Application Programming Interface (API)\nTo request data from a catalog following the STAC standard we use an Application Programming Interface (API). We can think of an API as an intermediary tasked with sending our request for data to the data catalog and getting the response from the catalog back to us. The following diagram nicely explains what an API does using a real-life analogy of a restaurant:\n\n\n\nImage Source: Geeks for geeks - What is an API?\n\n\nThe Python package to access APIs for STAC catalogs is pystac_client. Our goal in this lesson is to retrieve NAIP data from the MPC‚Äôs data catalog via its STAC API.",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#mpc-catalog",
    "href": "book/chapters/lesson-16-STAC.html#mpc-catalog",
    "title": "15 STAC specification",
    "section": "MPC Catalog",
    "text": "MPC Catalog\n\nFirst, load the necessary packages:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\n\nfrom pystac_client import Client  # To access STAC catalogs\n\nimport planetary_computer  # To sign items from the MPC STAC catalog \n\nfrom IPython.display import Image  # To nicely display images\n\n\nAccess\nWe use the Client function from the pystac_client package to access the catalog:\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\nThe modifier parameter is needed to access the data in the MPC catalog.\n\n\nCatalog Exploration\nLet‚Äôs check out some of the catalog‚Äôs metadata:\n\n# Explore catalog metadata\nprint('Title:', catalog.title)\nprint('Description:', catalog.description)\n\nTitle: Microsoft Planetary Computer STAC API\nDescription: Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\nWe can access its collections by using the get_collections() method:\n\ncatalog.get_collections()\n\n&lt;generator object Client.get_collections at 0x1494fc590&gt;\n\n\nNotice the output of get_collections() is a generator. This is a special kind of lazy object in Python over which you can loop over like a list. Unlike a list, the items in a generator do not exist in memory until you explicitely iterate over them or convert them to a list. This can allow for more efficient memory allcoation. Once the generator is exhausted (i.e.¬†iterated over completely), it cannot be reused unless it is recreated.\nLet‚Äôs try getting the collections from the catalog again:\n\n# Get collections and print their names\ncollections = list(catalog.get_collections())  # Turn generator into list\n\nprint('Number of collections:', len(collections))\n\nprint(\"Collections IDs (first 10):\")\nfor i in range(10):\n    print('-', collections[i].id)\n\nNumber of collections: 125\nCollections IDs (first 10):\n- daymet-annual-pr\n- daymet-daily-hi\n- 3dep-seamless\n- 3dep-lidar-dsm\n- fia\n- sentinel-1-rtc\n- gridmet\n- daymet-annual-na\n- daymet-monthly-na\n- daymet-annual-hi",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#collection",
    "href": "book/chapters/lesson-16-STAC.html#collection",
    "title": "15 STAC specification",
    "section": "Collection",
    "text": "Collection\nThe NAIP catalog‚Äôs ID is 'naip'. We can select a single collection for exploration using the get_child() method for the catalog and the collection ID as the parameter:\n\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) \nprovides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR). \nNAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) \nwithin the [US Department of Agriculture](https://www.usda.gov/) (USDA). \nData are captured at least once every three years for each state. \nThis dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\nYou can visualize the coverage of current and past collections [here](https://naip-usdaonline.hub.arcgis.com/). \n\"\n        \n    \n                \n            \n                \n                    \n        \n            links\n            [] 6 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"license\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://www.fsa.usda.gov/help/policies-and-links/\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Public Domain\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"describedby\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/dataset/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Human readable dataset overview and reference\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            item_assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            msft:region\n            \"westeurope\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:container\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:storage_account\n            \"naipeuwest\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:short_description\n            \"NAIP provides US-wide, high-resolution aerial imagery.  This dataset includes NAIP images from 2010 to the present.\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"NAIP: National Agriculture Imagery Program\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -124.784\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            24.744\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -66.951\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            49.346\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -156.003\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            19.059\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -154.809\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            20.127\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -67.316\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            17.871\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -65.596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            18.565\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -64.94\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            17.622\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -64.56\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            17.814\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        \n            interval\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"2010-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2022-12-31T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        \n            keywords\n            [] 7 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"NAIP\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"Aerial\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"Imagery\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"USDA\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"AFPO\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"United States\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            providers\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Esri\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.esri.com/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Microsoft\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://planetarycomputer.microsoft.com\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        \n            gsd\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.3\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"NAIP thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geoparquet-items\n            \n        \n            \n                \n        \n            href\n            \"abfs://items/naip.parquet\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/x-parquet\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoParquet STAC items\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Snapshot of the collection's STAC items exported to GeoParquet format.\"\n        \n    \n            \n        \n            \n                \n        \n            msft:partition_info\n            \n        \n            \n                \n        \n            is_partitioned\n            True\n        \n    \n            \n        \n            \n                \n        \n            partition_frequency\n            \"AS\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            table:storage_options\n            \n        \n            \n                \n        \n            account_name\n            \"pcstacitems\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"stac-items\"",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#catalog-search",
    "href": "book/chapters/lesson-16-STAC.html#catalog-search",
    "title": "15 STAC specification",
    "section": "Catalog search",
    "text": "Catalog search\nWe can narrow down the search within the catalog by specifying a time range, an area of interest, and the collection name. The simplest ways to define the area of interest to look for data in the catalog are:\n\na GeoJSON-type dictionary with the coordinates of the bounding box,\nas a list [xmin, ymin, xmax, ymax] with the coordinate values defining the four corners of the bounding box.\n\nIn this lesson we will look for the NAIP scenes over Santa Barbara from 2018 to 2023. We‚Äôll use the GeoJSON method to define the area of interest:\n\n# Temporal range of interest\ntime_range = \"2018-01-01/2023-01-01\"\n\n# NCEAS bounding box (as a GeoJSON)\nbbox = {\n    \"type\": \"Polygon\",\n    \"coordinates\":[\n        [\n            [-119.70608227128903, 34.426300194372274],\n            [-119.70608227128903, 34.42041139020533],\n            [-119.6967885126002, 34.42041139020533],\n            [-119.6967885126002, 34.426300194372274],\n            [-119.70608227128903, 34.426300194372274]\n        ]\n    ],\n}\n\n# Catalog search\nsearch = catalog.search(\n    collections = ['naip'],\n    intersects = bbox,\n    datetime = time_range)\nsearch\n\n&lt;pystac_client.item_search.ItemSearch at 0x149619210&gt;\n\n\nTo get the items found in the search (or check if there were any matches in the search) we use the item_collection() method:\n\n# Retrieve search items\nitems = search.item_collection()\nlen(items)\n\n3\n\n\nThis output tells us there were three items in the catalog that matched our search!\n\nitems\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        \n            features\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20220513\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2022-05-13T16:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2022\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806808.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253260.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814296.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            providers\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12480\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10550\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:centroid\n            \n        \n            \n                \n        \n            lat\n            34.40624\n        \n    \n            \n        \n            \n                \n        \n            lon\n            -119.71877\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814296.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685448\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.439192\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.752061\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20220513\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20220513\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2022/ca_060cm_2022/34119/m_3411935_sw_11_060_20220513.tif?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2022/ca_060cm_2022/34119/m_3411935_sw_11_060_20220513.200.jpg?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20220513&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20220513&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2020-05-21T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2020\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806808.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253260.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814296.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12480\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10550\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814296.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685448\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.439192\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.752061\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2018-07-24T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2018\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806856.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253212.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814248.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12320\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10390\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814248.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685956\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.438772\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.751554\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.tif?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_fgdc_2018/34119/m_3411935_sw_11_060_20180724.txt?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.200.jpg?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\"",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#item",
    "href": "book/chapters/lesson-16-STAC.html#item",
    "title": "15 STAC specification",
    "section": "Item",
    "text": "Item\n\nLet‚Äôs get the first item in the search:\n\n# Get first item in the catalog search\nitem = items[0]\ntype(item)\n\npystac.item.Item\n\n\nRemember the STAC item is the core object in a STAC catalog. The item does not contain the data itself, but rather metadata and assets that contain links to access the actual data. Some of the metadata:\n\n# Print item ID and properties\nprint('ID:' , item.id)\nitem.properties\n\nID: ca_m_3411935_sw_11_060_20220513\n\n\n{'gsd': 0.6,\n 'datetime': '2022-05-13T16:00:00Z',\n 'naip:year': '2022',\n 'proj:bbox': [246930.0, 3806808.0, 253260.0, 3814296.0],\n 'proj:epsg': 26911,\n 'providers': [{'url': 'https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/',\n   'name': 'USDA Farm Service Agency',\n   'roles': ['producer', 'licensor']}],\n 'naip:state': 'ca',\n 'proj:shape': [12480, 10550],\n 'proj:centroid': {'lat': 34.40624, 'lon': -119.71877},\n 'proj:transform': [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]}\n\n\nJust as the item properties, the item assets are given in a dictionary, with each value being a pystac.asset Let‚Äôs check the assets in the item:\n\nitem.assets\n\n{'image': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2022/ca_060cm_2022/34119/m_3411935_sw_11_060_20220513.tif?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D&gt;,\n 'thumbnail': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2022/ca_060cm_2022/34119/m_3411935_sw_11_060_20220513.200.jpg?st=2024-11-25T22%3A06%3A49Z&se=2024-11-26T22%3A51%3A49Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-11-26T15%3A06%3A26Z&ske=2024-12-03T15%3A06%3A26Z&sks=b&skv=2024-05-04&sig=FDtjYiXqRfXkOsqqBYOJNvO4ozwvXKxaZEkS42czSWA%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20220513&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20220513&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;}\n\n\n\nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\nimage -- RGBIR COG tile\nthumbnail -- Thumbnail\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\nNotice each asset has an href, which is a link to the data. For example, we can use the URL for the 'rendered_preview' asset to plot it:\n\n# Plot rendered preview\nImage(url=item.assets['rendered_preview'].href, width=500)",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#load-data",
    "href": "book/chapters/lesson-16-STAC.html#load-data",
    "title": "15 STAC specification",
    "section": "Load data",
    "text": "Load data\nThe raster data in our current item is in the image asset. Again, we access this data via its URL. This time, we open it using rioxr.open_rasterio() directly:\n\nsb = rioxr.open_rasterio(item.assets['image'].href)\nsb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12480, x: 10550)&gt;\n[526656000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3 4\n  * x            (x) float64 2.469e+05 2.469e+05 ... 2.533e+05 2.533e+05\n  * y            (y) float64 3.814e+06 3.814e+06 ... 3.807e+06 3.807e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:             Area\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12480x: 10550...[526656000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.469e+05 2.469e+05 ... 2.533e+05array([246930.3, 246930.9, 246931.5, ..., 253258.5, 253259.1, 253259.7])y(y)float643.814e+06 3.814e+06 ... 3.807e+06array([3814295.7, 3814295.1, 3814294.5, ..., 3806809.5, 3806808.9, 3806808.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :246930.0 0.6 0.0 3814296.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          246930.3,           246930.9,           246931.5,\n       246932.09999999998, 246932.69999999998,           246933.3,\n                 246933.9,           246934.5, 246935.09999999998,\n       246935.69999999998,\n       ...\n                 253254.3,           253254.9,           253255.5,\n       253256.09999999998, 253256.69999999998,           253257.3,\n                 253257.9,           253258.5, 253259.09999999998,\n       253259.69999999998],\n      dtype='float64', name='x', length=10550))yPandasIndexPandasIndex(Index([         3814295.7,          3814295.1,          3814294.5,\n       3814293.9000000004, 3814293.3000000003,          3814292.7,\n                3814292.1,          3814291.5, 3814290.9000000004,\n       3814290.3000000003,\n       ...\n                3806813.7,          3806813.1,          3806812.5,\n       3806811.9000000004, 3806811.3000000003,          3806810.7,\n                3806810.1,          3806809.5, 3806808.9000000004,\n       3806808.3000000003],\n      dtype='float64', name='y', length=12480))Attributes: (8)AREA_OR_POINT :AreaTIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1scale_factor :1.0add_offset :0.0\n\n\nNotice this raster has four bands (red, green, blue, nir), so we cannot use the .plot.imshow() method directly (as this function only works when we have three bands). Thus we need select the bands we want to plot (RGB) before plotting:\n\n# Plot raster with correct ratio\nsize = 6  \naspect = sb.rio.width / sb.rio.height \n# Select R,G,B bands and plot\nsb.sel(band=[1,2,3]).plot.imshow(size=size, aspect=aspect)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe 'cop-dem-glo-90' collection contains the Copernicus Digital Elevation Model (DEM) at 90m resolution data.\n\nReuse the bbox for Santa Barbara to look for items in this collection.\nGet the first item in the search and examine its assets.\nCheck the item‚Äôs rendered preview asset by clicking on it‚Äôs URL.\nOpen and plot the item‚Äôs data using rioxarray.\nObtain the maximum and minimum elevation on the scene as numbers.\nPrint the maximum and minimum elevation rounded to two decimal points using f-strings.",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-16-STAC.html#references",
    "href": "book/chapters/lesson-16-STAC.html#references",
    "title": "15 STAC specification",
    "section": "References",
    "text": "References\nSTAC Documentation:\n\nThe STAC Specification\nRead a STAC Catalog Using PySTAC\n\nMicrosoft Planetary Computer Documentation - Reading Data from the STAC API",
    "crumbs": [
      "notes",
      "Raster data",
      "15 STAC specification"
    ]
  },
  {
    "objectID": "book/chapters/lesson-14-xarray/xarray.html",
    "href": "book/chapters/lesson-14-xarray/xarray.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "import os              \nimport numpy as np\nimport pandas as pd\n\nimport xarray as xr  \n\n\n# Values of a single variable at each point of the coords \ntemp_data = np.array([np.zeros((5,5)), \n                      np.ones((5,5)), \n                      np.ones((5,5))*2]).astype(int)\n\n# Names of the dimensions in the required order\ndims = ('time', 'lat', 'lon')\n\n# Create coordinates to use for indexing along each dimension \ncoords = {'time' : pd.date_range(\"2022-09-01\", \"2022-09-03\"),\n          'lat' : np.arange(70, 20, -10),\n          'lon' : np.arange(60, 110, 10)\n          }  \n\n# Attributes (metadata) of the data array \nattrs = { 'title' : 'Temperature across weather stations',\n          'standard_name' : 'air_temperature',\n          'units' : 'degree_c',\n          'description' : 'Simple example of an xarray.DataArray' \n          }\n\n# Initialize xarray.DataArray\ntemp = xr.DataArray(data = temp_data, \n                    dims = dims,\n                    coords = coords,\n                    attrs = attrs\n                    )\n\n# Add attributes to coordinates \ntemp.time.attrs = {'description':'date of measurement'}\n\ntemp.lat.attrs['standard_name']= 'grid_latitude'\ntemp.lat.attrs['units'] = 'degree_N'\n\ntemp.lon.attrs['standard_name']= 'grid_longitude'\ntemp.lon.attrs['units'] = 'degree_E'\n\ntemp          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt; Size: 600B\narray([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])\nCoordinates:\n  * time     (time) datetime64[ns] 24B 2022-09-01 2022-09-02 2022-09-03\n  * lat      (lat) int64 40B 70 60 50 40 30\n  * lon      (lon) int64 40B 60 70 80 90 100\nAttributes:\n    title:          Temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArraytime: 3lat: 5lon: 50 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]],\n\n       [[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2]]])Coordinates: (3)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)int6470 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30])lon(lon)int6460 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq='D'))latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int64', name='lon'))Attributes: (4)title :Temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\n#temp.to_netcdf('example_temperature_data.nc')\n\n\ndf = xr.open_dataarray('data/example_temperature_data.nc')\ndf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 3, lat: 5, lon: 5)&gt; Size: 300B\n[75 values with dtype=int32]\nCoordinates:\n  * lat      (lat) int32 20B 70 60 50 40 30\n  * lon      (lon) int32 20B 60 70 80 90 100\n  * time     (time) datetime64[ns] 24B 2022-09-01 2022-09-02 2022-09-03\nAttributes:\n    title:          Temperature across weather stations\n    standard_name:  air_temperature\n    units:          degree_c\n    description:    Simple example of an xarray.DataArrayxarray.DataArraytime: 3lat: 5lon: 5...[75 values with dtype=int32]Coordinates: (3)lat(lat)int3270 60 50 40 30standard_name :grid_latitudeunits :degree_Narray([70, 60, 50, 40, 30], dtype=int32)lon(lon)int3260 70 80 90 100standard_name :grid_longitudeunits :degree_Earray([ 60,  70,  80,  90, 100], dtype=int32)time(time)datetime64[ns]2022-09-01 2022-09-02 2022-09-03description :date of measurementarray(['2022-09-01T00:00:00.000000000', '2022-09-02T00:00:00.000000000',\n       '2022-09-03T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (3)latPandasIndexPandasIndex(Index([70, 60, 50, 40, 30], dtype='int32', name='lat'))lonPandasIndexPandasIndex(Index([60, 70, 80, 90, 100], dtype='int32', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2022-09-01', '2022-09-02', '2022-09-03'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (4)title :Temperature across weather stationsstandard_name :air_temperatureunits :degree_cdescription :Simple example of an xarray.DataArray\n\n\n\ntemp.sel(time='2022-09-01', lat=40, lon=80).item()\n\n0"
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html",
    "title": "9 geopandas",
    "section": "",
    "text": "GeoPandas is a Python library that extends the pandas library by adding support for geospatial data. In this lesson we will introduce the geopandas library to work with vector data. We will also make our first map.\n\n\n\nWild pigs (Sus scrofa) are a destructive invasive species in California, causing significant environmental and agricultural damage. Introduced to the region in the 1700s, they have since spread across the state, impacting native ecosystems through habitat destruction, soil disturbance due to their rooting behavior, and competition with native wildlife for food [1]. This widespread damage has made managing wild pig populations a critical issue for conservation and agricultural communities in California.\n\n\n\nWild boar in Santa Teresa Park, CA. Photo by Don DeBold\n\n\nIn this lesson we will use simplified point data about wild pig sightings in California from the Global Biodiversity Information Facility (GBIF). GBIF is an international network and data platform that provides open access to biodiversity data from around the world. By aggregating data from multiple sources, including museums, research institutions, and citizen science initiatives, GBIF enables scientists, policymakers, and the public to explore and analyze species distribution and environmental trends.\nThe data we will use today has been simplified from the complete Sus scrofa occurrencies data [2] accessed through the GBIF website.\n\n\n\n\n\nIn this lesson we will introduce three Python packages:\n\ngeopandas [3]: a package that extends pandas to work with geospatial data. This is the main package we will be working with in the next few lessons.\nos: a package that provides functions for interacting with the operating system, allowing us to perform tasks like file manipulation in a platform-independent way.\nmatplotlib [4]: one of the most popular and widely used Python libraries for data visualization.\n\nLet‚Äôs start by importing these packages:\n\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nTo import our data we will first use the os package to create a reproducible file path:\n\nfp = os.path.join('data','gbif_sus_scrofa_california','gbif_sus_scrofa_california.shp')\nfp\n\n'data/gbif_sus_scrofa_california/gbif_sus_scrofa_california.shp'\n\n\nUsing the os.path.join() function allows us to create file paths that work on any operating system. Each operating system uses a different way to separate folders in a path (e.g., Windows uses backslashes \\, while macOS and Linux use forward slashes /). By using os.path.join(), Python automatically handles the correct separator for the operating system you‚Äôre working on. This avoids errors and makes your code more portable.\nWe can then use this file path to read in a shapefile with geopandas by using the geopandas.read_file() function:\n\npigs = gpd.read_file(fp)\npigs.head()\n\n\n\n\n\n\n\n\ngbifID\nspecies\nstate\nindividual\nday\nmonth\nyear\ninst\ncollection\ncatalogNum\nidentified\ngeometry\n\n\n\n\n0\n899953814\nSus scrofa\nCalifornia\nNaN\n22.0\n3.0\n2014.0\niNaturalist\nObservations\n581956\nedwardrooks\nPOINT (-121.53812 37.08846)\n\n\n1\n899951348\nSus scrofa\nCalifornia\nNaN\n9.0\n6.0\n2007.0\niNaturalist\nObservations\n576047\nBruce Freeman\nPOINT (-120.54942 35.47354)\n\n\n2\n896560733\nSus scrofa\nCalifornia\nNaN\n20.0\n12.0\n1937.0\nMVZ\nHild\nMVZ:Hild:195\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-122.27063 37.87610)\n\n\n3\n896559958\nSus scrofa\nCalifornia\nNaN\n1.0\n4.0\n1969.0\nMVZ\nHild\nMVZ:Hild:1213\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-121.82297 38.44543)\n\n\n4\n896559722\nSus scrofa\nCalifornia\nNaN\n1.0\n1.0\n1961.0\nMVZ\nHild\nMVZ:Hild:1004\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-121.74559 38.54882)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne shapefile = multiple files\n\n\n\nAlthough the parameter for geopandas.read_file() is only the file with .shp extension, remember that we need to have at least the .shx and .dbf files in the same directory as the .shp to read in the data.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nCreate a file path using os.path.join() to import the shapefile of the California state boundary as a geopandas.GeoDataFrame. Once imported, take a look at the data.\n\n\n\n\n\n\nThe core data structure in GeoPandas is the geopandas.GeoDataFrame. We can think of it as a pandas.DataFrame with a dedicated geometry column that can perform spatial operations.\nThe geometry column in a geopandas.GeoDataFrame holds the geometry (point, polygon, etc) of each spatial feature. This geometry column is of type geopandas.GeoSeries. Columns in the geopandas.GeoDataFrame with attributes about the features are pandas.Series like in a regular pandas.DataFrame.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nFirst, notice that the leftmost column of the pigs geo-dataframe is a column named geometry whose values indicate points:\n\npigs.head(3)\n\n\n\n\n\n\n\n\ngbifID\nspecies\nstate\nindividual\nday\nmonth\nyear\ninst\ncollection\ncatalogNum\nidentified\ngeometry\n\n\n\n\n0\n899953814\nSus scrofa\nCalifornia\nNaN\n22.0\n3.0\n2014.0\niNaturalist\nObservations\n581956\nedwardrooks\nPOINT (-121.53812 37.08846)\n\n\n1\n899951348\nSus scrofa\nCalifornia\nNaN\n9.0\n6.0\n2007.0\niNaturalist\nObservations\n576047\nBruce Freeman\nPOINT (-120.54942 35.47354)\n\n\n2\n896560733\nSus scrofa\nCalifornia\nNaN\n20.0\n12.0\n1937.0\nMVZ\nHild\nMVZ:Hild:195\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-122.27063 37.87610)\n\n\n\n\n\n\n\nAs usual, we can check the type of our objects using the type Python function:\n\n# Check the data type of the pigs dataframe \nprint(type(pigs))\n\n# Check the data type of the geometry column\nprint(type(pigs.geometry))\n\n# Check the data type of the gbifID column\nprint(type(pigs.gbifID))\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\n&lt;class 'geopandas.geoseries.GeoSeries'&gt;\n&lt;class 'pandas.core.series.Series'&gt;\n\n\nThe data type of the geometry column is also reflected when we look at the data types of the values in each column:\n\n# Check the data type of each column\npigs.dtypes\n\ngbifID           int64\nspecies         object\nstate           object\nindividual     float64\nday            float64\nmonth          float64\nyear           float64\ninst            object\ncollection      object\ncatalogNum      object\nidentified      object\ngeometry      geometry\ndtype: object\n\n\nWe can also check the type of each element in the geometry column using the geom_type attribute of a geopandas.GeoDataFrame:\n\npigs.geom_type\n\n0       Point\n1       Point\n2       Point\n3       Point\n4       Point\n        ...  \n1041    Point\n1042    Point\n1043    Point\n1044    Point\n1045    Point\nLength: 1046, dtype: object\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWhat is the geometry type of the single feature in the California state boundary?\n\n\n\n\n\n\nTwo other important attributes of a geopandas.GeoDataFrame are its coordinate reference system (CRS) and its extent.\nWe can think of the coordinate reference system (CRS) as the instructions to locate each spatial feature of our data frame on the surface of the Earth. We access the CRS of a geopandas.GeoDataFrame using the crs attribute:\n\n\n# Access the CRS of the GeoDataFrame\npigs.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nThe extent of the geo-dataframe is the bounding box covering all the spatial features in our geo-dataframe. This is formed by finding the points that are furthest west, east, south, and north.\n\n\n\nSpatial extent of different vector data. Image adapted from: National Ecological Observatory Network (NEON)\n\n\nWe access the extent of a geopandas.GeoDataFrame using the total_bounds attribute:\n\n# Obtain the geographic extent of the geo-dataframe\npigs.total_bounds\n\narray([-124.29448 ,   32.593433, -115.4356  ,   40.934296])\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nPrint the CRS, and extent of the California boundary.\n\n\n\n\n\n\nGeoPandas is conveniently built on top of pandas, so we may use everything we have learned about data selection, wrangling, and modification for a pandas.DataFrame to wrange geopandas.GeoDataFrames.\n\n\nWe only want to use recent data for wild pig observations. A quick check shows that this dataframe has data since 1818:\n\n# Examine pig observation by year\npigs['year'].value_counts().sort_index()\n\nyear\n1818.0     31\n1910.0      1\n1925.0      1\n1927.0      4\n1929.0      3\n         ... \n2019.0    101\n2020.0    159\n2021.0    164\n2022.0    185\n2023.0     98\nName: count, Length: 61, dtype: int64\n\n\nWe can use our usual data selection to get data from 2020 onwards:\n\n# Select data from 2020 onwards\npigs_recent = pigs[pigs.year&gt;=2020]\n\n# Check length of original dataframe\nprint('Total number of observations: ' , len(pigs))\n\n# Check length of new dataframe\nprint('Number of observations since 2020: ' , len(pigs_recent))\n\nTotal number of observations:  1046\nNumber of observations since 2020:  606\n\n\n\n\n\n\n\n\nSimilarly to a pandas.DataFrame, a geopandas.GeoDataFrame has a plot() method that we can call directly to create a quick view of our data. The geospatial information of the geopandas.GeoDataFrame will be used to create the axes of the plot.\n\n\nLet us take a quick look at our recent pigs data:\n\npigs_recent.plot()\n\n\n\n\n\n\n\n\n\n\n\n\nGoing forward, we will make more complex visualizations where we add different layers to a graph and customize it. To do this, we will use the matplotlib Python library for creating visualizations. We can interact with matplotlib via its pyplot interface, which we imported at the top of the notebook.\nMatplotlib graphs the data in a figure which can have one or more axes. The axes is only the area specified by the \\(x\\) axis and \\(y\\) axis and what is plotted in it, while the figure can icnlude multiple axes in it.\n\n\n\nImage source: Getting Started with Matplotlib\n\n\nTo create a new blank figure:\n\nInitialize a new figure and axes by calling pyplot‚Äôs subplots() function, and\nshow the graph using plt.show():\n\n\n# Initialize empyt figure (fig) and axis (ax)\nfig, ax = plt.subplots()\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\nNotice that plt.subplots() is a function that returns two objects, when we call it, get a figure fig with a single empty axis ax. We can think of this step as setting a new blank canvas on which we will paint upon.\n\n\n\nWhen using matplotlib, it can be useful to think of creating a plot as adding layers to an axis. The general syntax to plot a datafram df onto an axis is:\n# Initialize empyt figure and axis\nfig, ax = plt.subplots()\n\n# Plot a df on the ax axis\ndf.plot(ax=ax,  # Add plot to axis\n        ...)    # Other arguments for plot function\n\n# Display figure\nplt.show()\n\n\nThe first layer that we want to add to our axis is the pigs_recent point data. We can plot our data using matplotlib like this:\n\n# Initialize empyt figure and axis\nfig, ax = plt.subplots()\n\n# Add pigs point plot to our figure's axis\npigs_recent.plot(ax=ax)\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nMatplotlib allows for a lot of customization. Some of it can be done directly in the plot() method for the dataframe (like we‚Äôve done when ploting data using pandas), while other is done by updating attributes of the axis ax. The following diagram shows some examples of elements in the axis that can be updated.\n\n\n\nImage source: Matplotlib documentation\n\n\n\n\nSome basic customization for our pigs data could looke like this:\n\n# Initialize empty figure\nfig, ax = plt.subplots()\n\n# Add data to axis\npigs_recent.plot(ax=ax,         # Add plot to axis\n                 alpha=0.5,     # Adjust transparency\n                 color='brown'  # Update point color\n                 )\n\n# Update axis \nax.set_title('Reported \"Sus scrofa\" sightings in CA (2020-2023)')\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nAdd the California state boundary to the plot so the boundary appears behind the points as below. Don‚Äôt forget to customize your graph!",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#about-the-data",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#about-the-data",
    "title": "9 geopandas",
    "section": "",
    "text": "Wild pigs (Sus scrofa) are a destructive invasive species in California, causing significant environmental and agricultural damage. Introduced to the region in the 1700s, they have since spread across the state, impacting native ecosystems through habitat destruction, soil disturbance due to their rooting behavior, and competition with native wildlife for food [1]. This widespread damage has made managing wild pig populations a critical issue for conservation and agricultural communities in California.\n\n\n\nWild boar in Santa Teresa Park, CA. Photo by Don DeBold\n\n\nIn this lesson we will use simplified point data about wild pig sightings in California from the Global Biodiversity Information Facility (GBIF). GBIF is an international network and data platform that provides open access to biodiversity data from around the world. By aggregating data from multiple sources, including museums, research institutions, and citizen science initiatives, GBIF enables scientists, policymakers, and the public to explore and analyze species distribution and environmental trends.\nThe data we will use today has been simplified from the complete Sus scrofa occurrencies data [2] accessed through the GBIF website.",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#reproducible-file-paths",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#reproducible-file-paths",
    "title": "9 geopandas",
    "section": "",
    "text": "In this lesson we will introduce three Python packages:\n\ngeopandas [3]: a package that extends pandas to work with geospatial data. This is the main package we will be working with in the next few lessons.\nos: a package that provides functions for interacting with the operating system, allowing us to perform tasks like file manipulation in a platform-independent way.\nmatplotlib [4]: one of the most popular and widely used Python libraries for data visualization.\n\nLet‚Äôs start by importing these packages:\n\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nTo import our data we will first use the os package to create a reproducible file path:\n\nfp = os.path.join('data','gbif_sus_scrofa_california','gbif_sus_scrofa_california.shp')\nfp\n\n'data/gbif_sus_scrofa_california/gbif_sus_scrofa_california.shp'\n\n\nUsing the os.path.join() function allows us to create file paths that work on any operating system. Each operating system uses a different way to separate folders in a path (e.g., Windows uses backslashes \\, while macOS and Linux use forward slashes /). By using os.path.join(), Python automatically handles the correct separator for the operating system you‚Äôre working on. This avoids errors and makes your code more portable.\nWe can then use this file path to read in a shapefile with geopandas by using the geopandas.read_file() function:\n\npigs = gpd.read_file(fp)\npigs.head()\n\n\n\n\n\n\n\n\ngbifID\nspecies\nstate\nindividual\nday\nmonth\nyear\ninst\ncollection\ncatalogNum\nidentified\ngeometry\n\n\n\n\n0\n899953814\nSus scrofa\nCalifornia\nNaN\n22.0\n3.0\n2014.0\niNaturalist\nObservations\n581956\nedwardrooks\nPOINT (-121.53812 37.08846)\n\n\n1\n899951348\nSus scrofa\nCalifornia\nNaN\n9.0\n6.0\n2007.0\niNaturalist\nObservations\n576047\nBruce Freeman\nPOINT (-120.54942 35.47354)\n\n\n2\n896560733\nSus scrofa\nCalifornia\nNaN\n20.0\n12.0\n1937.0\nMVZ\nHild\nMVZ:Hild:195\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-122.27063 37.87610)\n\n\n3\n896559958\nSus scrofa\nCalifornia\nNaN\n1.0\n4.0\n1969.0\nMVZ\nHild\nMVZ:Hild:1213\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-121.82297 38.44543)\n\n\n4\n896559722\nSus scrofa\nCalifornia\nNaN\n1.0\n1.0\n1961.0\nMVZ\nHild\nMVZ:Hild:1004\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-121.74559 38.54882)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne shapefile = multiple files\n\n\n\nAlthough the parameter for geopandas.read_file() is only the file with .shp extension, remember that we need to have at least the .shx and .dbf files in the same directory as the .shp to read in the data.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nCreate a file path using os.path.join() to import the shapefile of the California state boundary as a geopandas.GeoDataFrame. Once imported, take a look at the data.",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#geoseries-and-geodataframe",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#geoseries-and-geodataframe",
    "title": "9 geopandas",
    "section": "",
    "text": "The core data structure in GeoPandas is the geopandas.GeoDataFrame. We can think of it as a pandas.DataFrame with a dedicated geometry column that can perform spatial operations.\nThe geometry column in a geopandas.GeoDataFrame holds the geometry (point, polygon, etc) of each spatial feature. This geometry column is of type geopandas.GeoSeries. Columns in the geopandas.GeoDataFrame with attributes about the features are pandas.Series like in a regular pandas.DataFrame.\n\n\n\nImage adapted from Introduction to GeoPandas.\n\n\n\n\nFirst, notice that the leftmost column of the pigs geo-dataframe is a column named geometry whose values indicate points:\n\npigs.head(3)\n\n\n\n\n\n\n\n\ngbifID\nspecies\nstate\nindividual\nday\nmonth\nyear\ninst\ncollection\ncatalogNum\nidentified\ngeometry\n\n\n\n\n0\n899953814\nSus scrofa\nCalifornia\nNaN\n22.0\n3.0\n2014.0\niNaturalist\nObservations\n581956\nedwardrooks\nPOINT (-121.53812 37.08846)\n\n\n1\n899951348\nSus scrofa\nCalifornia\nNaN\n9.0\n6.0\n2007.0\niNaturalist\nObservations\n576047\nBruce Freeman\nPOINT (-120.54942 35.47354)\n\n\n2\n896560733\nSus scrofa\nCalifornia\nNaN\n20.0\n12.0\n1937.0\nMVZ\nHild\nMVZ:Hild:195\nMuseum of Vertebrate Zoology, University of Ca...\nPOINT (-122.27063 37.87610)\n\n\n\n\n\n\n\nAs usual, we can check the type of our objects using the type Python function:\n\n# Check the data type of the pigs dataframe \nprint(type(pigs))\n\n# Check the data type of the geometry column\nprint(type(pigs.geometry))\n\n# Check the data type of the gbifID column\nprint(type(pigs.gbifID))\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\n&lt;class 'geopandas.geoseries.GeoSeries'&gt;\n&lt;class 'pandas.core.series.Series'&gt;\n\n\nThe data type of the geometry column is also reflected when we look at the data types of the values in each column:\n\n# Check the data type of each column\npigs.dtypes\n\ngbifID           int64\nspecies         object\nstate           object\nindividual     float64\nday            float64\nmonth          float64\nyear           float64\ninst            object\ncollection      object\ncatalogNum      object\nidentified      object\ngeometry      geometry\ndtype: object\n\n\nWe can also check the type of each element in the geometry column using the geom_type attribute of a geopandas.GeoDataFrame:\n\npigs.geom_type\n\n0       Point\n1       Point\n2       Point\n3       Point\n4       Point\n        ...  \n1041    Point\n1042    Point\n1043    Point\n1044    Point\n1045    Point\nLength: 1046, dtype: object\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWhat is the geometry type of the single feature in the California state boundary?",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#crs-and-extent",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#crs-and-extent",
    "title": "9 geopandas",
    "section": "",
    "text": "Two other important attributes of a geopandas.GeoDataFrame are its coordinate reference system (CRS) and its extent.\nWe can think of the coordinate reference system (CRS) as the instructions to locate each spatial feature of our data frame on the surface of the Earth. We access the CRS of a geopandas.GeoDataFrame using the crs attribute:\n\n\n# Access the CRS of the GeoDataFrame\npigs.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nThe extent of the geo-dataframe is the bounding box covering all the spatial features in our geo-dataframe. This is formed by finding the points that are furthest west, east, south, and north.\n\n\n\nSpatial extent of different vector data. Image adapted from: National Ecological Observatory Network (NEON)\n\n\nWe access the extent of a geopandas.GeoDataFrame using the total_bounds attribute:\n\n# Obtain the geographic extent of the geo-dataframe\npigs.total_bounds\n\narray([-124.29448 ,   32.593433, -115.4356  ,   40.934296])\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nPrint the CRS, and extent of the California boundary.",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#data-wrangling",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#data-wrangling",
    "title": "9 geopandas",
    "section": "",
    "text": "GeoPandas is conveniently built on top of pandas, so we may use everything we have learned about data selection, wrangling, and modification for a pandas.DataFrame to wrange geopandas.GeoDataFrames.\n\n\nWe only want to use recent data for wild pig observations. A quick check shows that this dataframe has data since 1818:\n\n# Examine pig observation by year\npigs['year'].value_counts().sort_index()\n\nyear\n1818.0     31\n1910.0      1\n1925.0      1\n1927.0      4\n1929.0      3\n         ... \n2019.0    101\n2020.0    159\n2021.0    164\n2022.0    185\n2023.0     98\nName: count, Length: 61, dtype: int64\n\n\nWe can use our usual data selection to get data from 2020 onwards:\n\n# Select data from 2020 onwards\npigs_recent = pigs[pigs.year&gt;=2020]\n\n# Check length of original dataframe\nprint('Total number of observations: ' , len(pigs))\n\n# Check length of new dataframe\nprint('Number of observations since 2020: ' , len(pigs_recent))\n\nTotal number of observations:  1046\nNumber of observations since 2020:  606",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#create-a-map",
    "href": "book/chapters/lesson-10-geopandas-intro/lesson-10-geopandas-intro.html#create-a-map",
    "title": "9 geopandas",
    "section": "",
    "text": "Similarly to a pandas.DataFrame, a geopandas.GeoDataFrame has a plot() method that we can call directly to create a quick view of our data. The geospatial information of the geopandas.GeoDataFrame will be used to create the axes of the plot.\n\n\nLet us take a quick look at our recent pigs data:\n\npigs_recent.plot()\n\n\n\n\n\n\n\n\n\n\n\n\nGoing forward, we will make more complex visualizations where we add different layers to a graph and customize it. To do this, we will use the matplotlib Python library for creating visualizations. We can interact with matplotlib via its pyplot interface, which we imported at the top of the notebook.\nMatplotlib graphs the data in a figure which can have one or more axes. The axes is only the area specified by the \\(x\\) axis and \\(y\\) axis and what is plotted in it, while the figure can icnlude multiple axes in it.\n\n\n\nImage source: Getting Started with Matplotlib\n\n\nTo create a new blank figure:\n\nInitialize a new figure and axes by calling pyplot‚Äôs subplots() function, and\nshow the graph using plt.show():\n\n\n# Initialize empyt figure (fig) and axis (ax)\nfig, ax = plt.subplots()\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\nNotice that plt.subplots() is a function that returns two objects, when we call it, get a figure fig with a single empty axis ax. We can think of this step as setting a new blank canvas on which we will paint upon.\n\n\n\nWhen using matplotlib, it can be useful to think of creating a plot as adding layers to an axis. The general syntax to plot a datafram df onto an axis is:\n# Initialize empyt figure and axis\nfig, ax = plt.subplots()\n\n# Plot a df on the ax axis\ndf.plot(ax=ax,  # Add plot to axis\n        ...)    # Other arguments for plot function\n\n# Display figure\nplt.show()\n\n\nThe first layer that we want to add to our axis is the pigs_recent point data. We can plot our data using matplotlib like this:\n\n# Initialize empyt figure and axis\nfig, ax = plt.subplots()\n\n# Add pigs point plot to our figure's axis\npigs_recent.plot(ax=ax)\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nMatplotlib allows for a lot of customization. Some of it can be done directly in the plot() method for the dataframe (like we‚Äôve done when ploting data using pandas), while other is done by updating attributes of the axis ax. The following diagram shows some examples of elements in the axis that can be updated.\n\n\n\nImage source: Matplotlib documentation\n\n\n\n\nSome basic customization for our pigs data could looke like this:\n\n# Initialize empty figure\nfig, ax = plt.subplots()\n\n# Add data to axis\npigs_recent.plot(ax=ax,         # Add plot to axis\n                 alpha=0.5,     # Adjust transparency\n                 color='brown'  # Update point color\n                 )\n\n# Update axis \nax.set_title('Reported \"Sus scrofa\" sightings in CA (2020-2023)')\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\n\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nAdd the California state boundary to the plot so the boundary appears behind the points as below. Don‚Äôt forget to customize your graph!",
    "crumbs": [
      "notes",
      "Vector data",
      "9 `geopandas`"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html",
    "title": "12 Clipping",
    "section": "",
    "text": "In this lesson we will learn how to to clip different geometries.\n\n\nWe will use three datasets in this lesson.\nThe first dataset is a TIGER shapefile of the US states from the United States Census Bureau. Follow these steps to download shapefile with the United States‚Äô states:\n\nAt the bottom of the 2022 page, under Download, click on ‚ÄúWeb Interface‚Äù\nFor year, select 2022, and for layer type select ‚ÄúStates (and equivalent)‚Äù. Click submit.\nClick on ‚ÄúDownload national file‚Äù.\n\nYou can check the metadata for all the TIGER shapefiles here. The columns for this shapefile are:\n\n\n\nSource: TIGER/Line Shapefiles Technical Documentation\n\n\nThe second dataset we‚Äôll use is Natural Earth‚Äôs simple medium scale populated places dataset. We can obtain this dataset by downloading the shapefile (choose the one that says ‚Äúsimple (less columns)‚Äù).\nThe third dataset we‚Äôll use is Natural Earth‚Äôs road dataset. We can obtain this dataset by downloading the shapefile\nWe will combine these datasets to create the following map of infrastructure in Alaska:\n\nFor these notes, all the data is inside a data/ directory at the same level as the notebook.\n\n\n\nLet‚Äôs start by loading our libraries and then importing the datasets we will use. \n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\nfrom shapely.geometry import box  # To create polygon bounding box\n\npd.set_option(\"display.max.columns\", None)\n\n# -------------------------------------\n# Import and simplify states polygons\nstates = gpd.read_file(os.path.join('data',\n                                    'tl_2022_us_state',\n                                    'tl_2022_us_state.shp')\n                                    )\n\n# Import Natural Earth populated places points\nplaces = gpd.read_file(os.path.join('data',\n                                    'ne_50m_populated_places_simple',\n                                    'ne_50m_populated_places_simple.shp')\n                                    )\n\n# Import ferry routes lines\nroads = gpd.read_file(os.path.join('data',\n                                   'ne_10m_roads',\n                                   'ne_10m_roads.shp')\n                                   )\n\n\n\n\n\n\nCheck-in\n\n\n\nUse a for loop to iterate over the three geo-dataframes we imported and change their column names to lower caps.\n\n\n\n\n\n\nLet‚Äôs start by taking taking a look at our states geo-dataframe. Since this is a geospatial dataset, exploration should include at least checking the head of the dataset, plotting the data, and looking at its CRS.\n\nprint(f\"CRS: {states.crs}\")\n\nstates.head(3)\n\nCRS: EPSG:4269\n\n\n\n\n\n\n\n\n\nregion\ndivision\nstatefp\nstatens\ngeoid\nstusps\nname\nlsad\nmtfcc\nfuncstat\naland\nawater\nintptlat\nintptlon\ngeometry\n\n\n\n\n0\n3\n5\n54\n01779805\n54\nWV\nWest Virginia\n00\nG4000\nA\n62266456923\n489045863\n+38.6472854\n-080.6183274\nPOLYGON ((-77.75438 39.33346, -77.75422 39.333...\n\n\n1\n3\n5\n12\n00294478\n12\nFL\nFlorida\n00\nG4000\nA\n138962819934\n45971472526\n+28.3989775\n-082.5143005\nMULTIPOLYGON (((-83.10874 24.62949, -83.10711 ...\n\n\n2\n2\n3\n17\n01779784\n17\nIL\nIllinois\n00\nG4000\nA\n143778515726\n6216539665\n+40.1028754\n-089.1526108\nPOLYGON ((-87.89243 38.28285, -87.89334 38.282...\n\n\n\n\n\n\n\n\nstates.plot()\n\n\n\n\n\n\n\n\nFor this lesson, we are intersted in plotting data only Alaska, se let‚Äôs select this data:\n\nalaska = states[states.name =='Alaska']\nalaska.plot()\n\n\n\n\n\n\n\n\nNotice that the way the Alaska multipolygon is plotted under the NAD83/EPSG:4269 CRS separates the islands and unnaturally elongates the map. To fix this, we will reproject the Alaska geo-dataframe to the EPSG:3338 CRS. This CRS is a projected CRS, better suited for working with data from Alaska:\n\n\n\nSource: spatialreference.org\n\n\n\n# Reproject to CRS optimized for Alaska\nalaska = alaska.to_crs('epsg:3338')\n\n# Inspect the new CRS\nprint('Is this CRS projected? ', alaska.crs.is_projected)\nalaska.crs\n\nIs this CRS projected?  True\n\n\n&lt;Projected CRS: EPSG:3338&gt;\nName: NAD83 / Alaska Albers\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: United States (USA) - Alaska.\n- bounds: (172.42, 51.3, -129.99, 71.4)\nCoordinate Operation:\n- name: Alaska Albers (meters)\n- method: Albers Equal Area\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich\n\n\n\nalaska.plot()\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs now explore the populated places data.\n\nprint(f\"CRS: {places.crs}\")\n\nplaces.head(3)\n\nCRS: EPSG:4326\n\n\n\n\n\n\n\n\n\nscalerank\nnatscale\nlabelrank\nfeaturecla\nname\nnamepar\nnamealt\nnameascii\nadm0cap\ncapin\nworldcity\nmegacity\nsov0name\nsov_a3\nadm0name\nadm0_a3\nadm1name\niso_a2\nnote\nlatitude\nlongitude\npop_max\npop_min\npop_other\nrank_max\nrank_min\nmeganame\nls_name\nmax_pop10\nmax_pop20\nmax_pop50\nmax_pop300\nmax_pop310\nmax_natsca\nmin_areakm\nmax_areakm\nmin_areami\nmax_areami\nmin_perkm\nmax_perkm\nmin_permi\nmax_permi\nmin_bbxmin\nmax_bbxmin\nmin_bbxmax\nmax_bbxmax\nmin_bbymin\nmax_bbymin\nmin_bbymax\nmax_bbymax\nmean_bbxc\nmean_bbyc\ntimezone\nun_fid\npop1950\npop1955\npop1960\npop1965\npop1970\npop1975\npop1980\npop1985\npop1990\npop1995\npop2000\npop2005\npop2010\npop2015\npop2020\npop2025\npop2050\nmin_zoom\nwikidataid\nwof_id\ncapalt\nname_en\nname_de\nname_es\nname_fr\nname_pt\nname_ru\nname_zh\nlabel\nname_ar\nname_bn\nname_el\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_sv\nname_tr\nname_vi\nne_id\nname_fa\nname_he\nname_uk\nname_ur\nname_zht\ngeonamesid\nfclass_iso\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\nfclass_tlc\ngeometry\n\n\n\n\n0\n10\n1\n5\nAdmin-1 region capital\nBombo\nNone\nNone\nBombo\n0\nNone\n0\n0\nUganda\nUGA\nUganda\nUGA\nBamunanika\nUG\nNone\n0.583299\n32.533300\n75000\n21000\n0.0\n8\n7\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ4940747\n1141906025\n0\nBombo\nBombo\nBombo\nBombo\nBombo\n–ë–æ–º–±–æ\nÈÇ¶Âçö\nNone\nÿ®ŸàŸÖÿ®Ÿà\n‡¶¨‡ßã‡¶Æ‡ßç‡¶¨‡ßã\nŒúœÄœåŒºœÄŒø\n‡§¨‡•â‡§Æ‡•ç‡§¨‡•ã\nBombo\nBombo\nBombo\n„Éú„É≥„Éú\nÎ¥ÑÎ≥¥\nBombo\nBombo\nBombo\nBombo\nBombo\n1159113923\nÿ®ŸÖÿ®Ÿà\n◊ë◊ï◊û◊ë◊ï\n–ë–æ–º–±–æ\nÿ®ŸàŸÖÿ®Ÿà\nÈÇ¶Âçö\nNaN\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (32.53330 0.58330)\n\n\n1\n10\n1\n5\nAdmin-1 region capital\nFort Portal\nNone\nNone\nFort Portal\n0\nNone\n0\n0\nUganda\nUGA\nUganda\nUGA\nKabarole\nUG\nNone\n0.671004\n30.275002\n42670\n42670\n0.0\n7\n7\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nAfrica/Kampala\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ500107\n421174009\n0\nFort Portal\nFort Portal\nFort Portal\nFort Portal\nFort Portal\n–§–æ—Ä—Ç-–ü–æ—Ä—Ç–∞–ª\nÊ≥¢ÁâπÁàæÂ†°\nNone\nŸÅŸàÿ±ÿ™ ÿ®Ÿàÿ±ÿ™ÿßŸÑ\n‡¶´‡ßã‡¶∞‡ßç‡¶ü ‡¶™‡ßã‡¶∞‡ßç‡¶ü‡¶æ‡¶≤\nŒ¶ŒøœÅœÑ Œ†ŒøœÅœÑŒ¨Œª\n‡§´‡•ã‡§∞‡•ç‡§ü ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤\nFort Portal\nFort Portal\nFort Portal\n„Éï„Ç©„Éº„Éà„Éª„Éù„Éº„Çø„É´\nÌè¨Ìä∏Ìè¨ÌÑ∏\nFort Portal\nFort Portal\nFort Portal\nFort Portal\nFort Portal\n1159113959\nŸÅŸàÿ±ÿ™ ŸæŸàÿ±ÿ™ÿßŸÑ\n◊§◊ï◊®◊ò ◊§◊ï◊®◊ò◊ú\n–§–æ—Ä—Ç-–ü–æ—Ä—Ç–∞–ª\nŸÅŸàÿ±Ÿπ ŸæŸàÿ±ŸπŸÑ\nÊ≥¢ÁâπÁàæÂ†°\n233476.0\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (30.27500 0.67100)\n\n\n2\n10\n1\n3\nAdmin-1 region capital\nPotenza\nNone\nNone\nPotenza\n0\nNone\n0\n0\nItaly\nITA\nItaly\nITA\nBasilicata\nIT\nNone\n40.642002\n15.798997\n69060\n69060\n0.0\n8\n8\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nEurope/Rome\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ3543\n101752567\n0\nPotenza\nPotenza\nPotenza\nPotenza\nPotenza\n–ü–æ—Ç–µ–Ω—Ü–∞\nÊ≥¢Âù¶ÂØü\nNone\nÿ®Ÿàÿ™ŸÜÿ≥ÿß\n‡¶™‡ßã‡¶ü‡ßá‡¶û‡ßç‡¶ú‡¶æ\nŒ†ŒøœÑŒ≠ŒΩœÑœÉŒ±\n‡§™‡•ã‡§ü‡•á‡§Ç‡§ú‡§æ\nPotenza\nPotenza\nPotenza\n„Éù„ÉÜ„É≥„ÉÑ„Ç°\nÌè¨ÌÖêÏ∞®\nPotenza\nPotenza\nPotenza\nPotenza\nPotenza\n1159117259\nŸæŸàÿ™ŸÜÿ≤ÿß\n◊§◊ï◊ò◊†◊¶◊î\n–ü–æ—Ç–µ–Ω—Ü–∞\nŸæŸàÿ™€åŸÜÿ™ÿ≥ÿß\nÊ≥¢Âù¶ÂØü\n3170027.0\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (15.79900 40.64200)\n\n\n\n\n\n\n\n\nplaces.plot()\n\n\n\n\n\n\n\n\nThis dataset has the EPSG:4326 CRS. Remember this is the EPSG code for the WGS 84 CRS. This is not a surprise since the places data is global and EPSG:4326/WGS84 is the most widely used CRS for such data.\nLet‚Äôs see what happens when we try to plot this data on top of Alaska:\n\n# Trouble\nfig, ax = plt.subplots()\n\nalaska.plot(ax=ax)\nplaces.plot(ax=ax, color='red')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData in weird places? Check your CRSs\n\n\n\nThis is a classic slip in geospatial analysis. To plot, analyze, or integrate different geospatial datasets they must have the same CRS.\nHere, alaska and places have different CRSs, leading to unexpected results when plotting them together:\n\nalaska.crs == places.crs\n\nFalse\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nReproject the places geo-datafarme into alaska‚Äôs CRS and verify the CRSs match using assert.\n\n\n\nLet‚Äôs check that map again:\n\nfig, ax = plt.subplots()\n\nalaska.plot(ax=ax)\nplaces.plot(ax=ax, color='red', markersize=2)\n\nplt.show()\n\n\n\n\n\n\n\n\nThis is better: we can see there the Alaska poygons and some of the places points on top of it. Our next step is to select these points.\n\n\n\n\nClipping means using a polygon (or polygons) to only select geospatial data within them. Clipping a geopandas.GeoDataFrame is simple using the geopandas clip() function. The general syntax is:\nupdated_geodf = geopandas.clip(geodf, mask)\nwhere:\n\nupdated_geodf is the output of the method: the intersection of the geometries in geodf with mask,\ngeodf is the geopandas.GeoDataFrame we want to clip,\nmask is a geopandas.GeoDataFrame with the polygon(s) we want to use for clipping. This mask must be in the same CRS as geodf!\n\nIn our case:\n\n# Clip populated places to Alaska multipolygon\nak_places = gpd.clip(places, alaska)\n\nfig, ax = plt.subplots()\nalaska.plot(ax=ax)\nak_places.plot(ax=ax, color='red')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nNow we move on to our roads dataset.\n\nprint(roads.crs)\n\nroads.head(3)\n\nEPSG:4326\n\n\n\n\n\n\n\n\n\nscalerank\nfeaturecla\ntype\nsov_a3\nnote\nedited\nname\nnamealt\nnamealtt\nrouteraw\nquestion\nlength_km\ntoll\nne_part\nlabel\nlabel2\nlocal\nlocaltype\nlocalalt\nlabelrank\nignore\nadd\nrwdb_rd_id\norig_fid\nprefix\nuident\ncontinent\nexpressway\nlevel\nmin_zoom\nmin_label\ngeometry\n\n\n\n\n0\n8\nRoad\nSecondary Highway\nCAN\nNone\nVersion 1.5: Changed alignment, a few adds in ...\nNone\nNone\nNone\nNone\n0\n3\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n314705\nNorth America\n0\nNone\n7.1\n9.6\nLINESTRING (-133.32533 62.21571, -133.31664 62...\n\n\n1\n7\nRoad\nSecondary Highway\nUSA\nNone\nVersion 1.5: Changed alignment, a few adds in ...\n83\nNone\nNone\nNone\n0\n164\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n108105\nNorth America\n0\nFederal\n7.0\n8.6\nLINESTRING (-100.50543 42.80753, -100.53495 42...\n\n\n2\n7\nRoad\nSecondary Highway\nUSA\nNone\nVersion 1.5: Changed alignment, a few adds in ...\n840\nNone\nNone\nNone\n0\n98\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n0\nNorth America\n0\nU/C\n7.0\n9.5\nLINESTRING (-87.27432 36.02439, -87.22916 35.9...\n\n\n\n\n\n\n\n\nroads.plot()\n\n\n\n\n\n\n\n\nYou may have already noticed that the roads data is not in the same CRS as the alaska polygons, so these geo-datasets shound‚Äôt interact until they‚Äôre in the same CRS. Before jumping right into reprojecting and clipping, we will subset the data to select only US roads:\n\nusa_roads = roads[roads.sov_a3 == 'USA']\nusa_roads.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReduce your tabular data before reducing via geometries\n\n\n\nGeospatial operations are usually costly in terms of computing power. The more detailed our geometries are, the longer in takes to do geospatial computations. It‚Äôs a good practice to reduce your data as much as possible before applying any geospatial transformation.\n\n\n\nWe will now compose functions to clip usa_roads using the alaska multipolygon. Notice we are using the ouput of usa_roads.to_crs(alaska.crs) directly and thus not changing the usa_roads geo-dataframe or creating new variables:\n\n# Clip usa_roads to alaska geometry\nak_roads = gpd.clip(usa_roads.to_crs(alaska.crs), alaska)\n\n\nfig, ax = plt.subplots()\nalaska.plot(ax=ax)\nak_roads.plot(ax=ax, color='red')\nplt.show()\n\n\n\n\n\n\n\n\nNotice how the lines break on the small islands? However, in the usa_roads there are no broken lines. This should make us suspect we are leaving data out and clipping exactly to the polygons in alaska is not quite what we want.\n\n\nWe will clip the usa_roads geo-dataframe with the bounding box of alaska instead of its polygons. To create a bounding box, we first use the box() function we imported from shapely.geometry. The syntax for box() is:\nbox(minx, miny, maxx, maxy)\nthe output is a polygon representing a box constructed like this:\n\n\n\nImage adapted from: National Ecological Observatory Network (NEON)\n\n\nIf we want to create a shapely polygon from the bounds of a geo-dataframe gdf, a more straightforward syntax is:\nbox(*gdf.total_bounds)\nIn our case:\n\nbbox = box(*alaska.total_bounds)\nprint(type(bbox))\nbbox\n\n&lt;class 'shapely.geometry.polygon.Polygon'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n* = unpacking operator\n\n\n\nIn the last syntax we used the asterisk * as an unpacking operator on the array alaska.total_bounds. Think about it as unpacking the elements of alaska.total_bounds and assigning them one-by-one to the paremeters minx, miny, maxx, maxy of the box() function.\nThis is a good article explaining more about unpacking with * in Python: https://geekflare.com/python-unpacking-operators/\n\n\nNotice that the bounding box is not a geodataframe, it is a stand alone, abstract polygon without any geospatial information. To interpret this polygon as something on the Earth‚Äôs surface we need to wrap it into a geo-datfrane abd assign it a CRS:\n\n# Create geo-dataframe from bounding box\nak_bbox = gpd.GeoDataFrame(geometry = [bbox],  # Assign geometry column\n                           crs = alaska.crs)  # Assign CRS\nprint(type(ak_bbox))\nak_bbox\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\n\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((1493082.309 404545.108, 1493082.309 ...\n\n\n\n\n\n\n\nWe can now clip the roads using Alaska‚Äôs bounding box:\n\nak_complete_roads = gpd.clip(usa_roads.to_crs(ak_bbox.crs), ak_bbox)\n\nNotice the difference between the two clipping methods:\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,10))\n\nak_roads.plot(ax=ax1)\nax1.set_title('Roads clipped with AK multipolygon')\n\nak_complete_roads.plot(ax=ax2)\nax2.set_title('Roads clipped with AK bounding box')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, we can put all our data together in the same map:\n\n\nCode\nfig, ax = plt.subplots(figsize=(11,5))\nax.axis('off')\n\nalaska.plot(ax=ax, color='whitesmoke', edgecolor='0.7')\n\nak_complete_roads.plot(ax=ax, \n                       zorder=1,  # Specify layer plotting order\n                       column='type', \n                       legend=True,\n                       legend_kwds={'title': \"Road Types\", \n                                    'loc': 'upper left',\n                                    'bbox_to_anchor':(0,0.9),\n                                    'fontsize':'small'}\n                                    )\n\nak_places.plot(ax=ax, \n               zorder=2,  # Specify layer plotting order\n               color='red', \n               marker='s'  # Square marker\n               )\n# Add city names as text annotations\nfor x, y, name in zip(ak_places.geometry.x, ak_places.geometry.y, ak_places['name']):\n    ax.text(x-30000, y+20000, name, fontsize=8, ha='right')\n\nax.set_title(\"Road Networks and Major Cities in Alaska\", fontsize=14, fontweight='bold')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nNotice the overlaying labels for Anchorage and Valdez:\n\n\n\n\n\nUpdate the map so these labels do not overlap. One way to do it is using an if when iterating over the Alaska populated places.",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#about-the-data",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#about-the-data",
    "title": "12 Clipping",
    "section": "",
    "text": "We will use three datasets in this lesson.\nThe first dataset is a TIGER shapefile of the US states from the United States Census Bureau. Follow these steps to download shapefile with the United States‚Äô states:\n\nAt the bottom of the 2022 page, under Download, click on ‚ÄúWeb Interface‚Äù\nFor year, select 2022, and for layer type select ‚ÄúStates (and equivalent)‚Äù. Click submit.\nClick on ‚ÄúDownload national file‚Äù.\n\nYou can check the metadata for all the TIGER shapefiles here. The columns for this shapefile are:\n\n\n\nSource: TIGER/Line Shapefiles Technical Documentation\n\n\nThe second dataset we‚Äôll use is Natural Earth‚Äôs simple medium scale populated places dataset. We can obtain this dataset by downloading the shapefile (choose the one that says ‚Äúsimple (less columns)‚Äù).\nThe third dataset we‚Äôll use is Natural Earth‚Äôs road dataset. We can obtain this dataset by downloading the shapefile\nWe will combine these datasets to create the following map of infrastructure in Alaska:\n\nFor these notes, all the data is inside a data/ directory at the same level as the notebook.",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#import-data",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#import-data",
    "title": "12 Clipping",
    "section": "",
    "text": "Let‚Äôs start by loading our libraries and then importing the datasets we will use. \n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\nfrom shapely.geometry import box  # To create polygon bounding box\n\npd.set_option(\"display.max.columns\", None)\n\n# -------------------------------------\n# Import and simplify states polygons\nstates = gpd.read_file(os.path.join('data',\n                                    'tl_2022_us_state',\n                                    'tl_2022_us_state.shp')\n                                    )\n\n# Import Natural Earth populated places points\nplaces = gpd.read_file(os.path.join('data',\n                                    'ne_50m_populated_places_simple',\n                                    'ne_50m_populated_places_simple.shp')\n                                    )\n\n# Import ferry routes lines\nroads = gpd.read_file(os.path.join('data',\n                                   'ne_10m_roads',\n                                   'ne_10m_roads.shp')\n                                   )\n\n\n\n\n\n\nCheck-in\n\n\n\nUse a for loop to iterate over the three geo-dataframes we imported and change their column names to lower caps.",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-alaska-multipolygon",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-alaska-multipolygon",
    "title": "12 Clipping",
    "section": "",
    "text": "Let‚Äôs start by taking taking a look at our states geo-dataframe. Since this is a geospatial dataset, exploration should include at least checking the head of the dataset, plotting the data, and looking at its CRS.\n\nprint(f\"CRS: {states.crs}\")\n\nstates.head(3)\n\nCRS: EPSG:4269\n\n\n\n\n\n\n\n\n\nregion\ndivision\nstatefp\nstatens\ngeoid\nstusps\nname\nlsad\nmtfcc\nfuncstat\naland\nawater\nintptlat\nintptlon\ngeometry\n\n\n\n\n0\n3\n5\n54\n01779805\n54\nWV\nWest Virginia\n00\nG4000\nA\n62266456923\n489045863\n+38.6472854\n-080.6183274\nPOLYGON ((-77.75438 39.33346, -77.75422 39.333...\n\n\n1\n3\n5\n12\n00294478\n12\nFL\nFlorida\n00\nG4000\nA\n138962819934\n45971472526\n+28.3989775\n-082.5143005\nMULTIPOLYGON (((-83.10874 24.62949, -83.10711 ...\n\n\n2\n2\n3\n17\n01779784\n17\nIL\nIllinois\n00\nG4000\nA\n143778515726\n6216539665\n+40.1028754\n-089.1526108\nPOLYGON ((-87.89243 38.28285, -87.89334 38.282...\n\n\n\n\n\n\n\n\nstates.plot()\n\n\n\n\n\n\n\n\nFor this lesson, we are intersted in plotting data only Alaska, se let‚Äôs select this data:\n\nalaska = states[states.name =='Alaska']\nalaska.plot()\n\n\n\n\n\n\n\n\nNotice that the way the Alaska multipolygon is plotted under the NAD83/EPSG:4269 CRS separates the islands and unnaturally elongates the map. To fix this, we will reproject the Alaska geo-dataframe to the EPSG:3338 CRS. This CRS is a projected CRS, better suited for working with data from Alaska:\n\n\n\nSource: spatialreference.org\n\n\n\n# Reproject to CRS optimized for Alaska\nalaska = alaska.to_crs('epsg:3338')\n\n# Inspect the new CRS\nprint('Is this CRS projected? ', alaska.crs.is_projected)\nalaska.crs\n\nIs this CRS projected?  True\n\n\n&lt;Projected CRS: EPSG:3338&gt;\nName: NAD83 / Alaska Albers\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: United States (USA) - Alaska.\n- bounds: (172.42, 51.3, -129.99, 71.4)\nCoordinate Operation:\n- name: Alaska Albers (meters)\n- method: Albers Equal Area\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich\n\n\n\nalaska.plot()",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-populated-places-points",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-populated-places-points",
    "title": "12 Clipping",
    "section": "",
    "text": "Let‚Äôs now explore the populated places data.\n\nprint(f\"CRS: {places.crs}\")\n\nplaces.head(3)\n\nCRS: EPSG:4326\n\n\n\n\n\n\n\n\n\nscalerank\nnatscale\nlabelrank\nfeaturecla\nname\nnamepar\nnamealt\nnameascii\nadm0cap\ncapin\nworldcity\nmegacity\nsov0name\nsov_a3\nadm0name\nadm0_a3\nadm1name\niso_a2\nnote\nlatitude\nlongitude\npop_max\npop_min\npop_other\nrank_max\nrank_min\nmeganame\nls_name\nmax_pop10\nmax_pop20\nmax_pop50\nmax_pop300\nmax_pop310\nmax_natsca\nmin_areakm\nmax_areakm\nmin_areami\nmax_areami\nmin_perkm\nmax_perkm\nmin_permi\nmax_permi\nmin_bbxmin\nmax_bbxmin\nmin_bbxmax\nmax_bbxmax\nmin_bbymin\nmax_bbymin\nmin_bbymax\nmax_bbymax\nmean_bbxc\nmean_bbyc\ntimezone\nun_fid\npop1950\npop1955\npop1960\npop1965\npop1970\npop1975\npop1980\npop1985\npop1990\npop1995\npop2000\npop2005\npop2010\npop2015\npop2020\npop2025\npop2050\nmin_zoom\nwikidataid\nwof_id\ncapalt\nname_en\nname_de\nname_es\nname_fr\nname_pt\nname_ru\nname_zh\nlabel\nname_ar\nname_bn\nname_el\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_sv\nname_tr\nname_vi\nne_id\nname_fa\nname_he\nname_uk\nname_ur\nname_zht\ngeonamesid\nfclass_iso\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\nfclass_tlc\ngeometry\n\n\n\n\n0\n10\n1\n5\nAdmin-1 region capital\nBombo\nNone\nNone\nBombo\n0\nNone\n0\n0\nUganda\nUGA\nUganda\nUGA\nBamunanika\nUG\nNone\n0.583299\n32.533300\n75000\n21000\n0.0\n8\n7\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ4940747\n1141906025\n0\nBombo\nBombo\nBombo\nBombo\nBombo\n–ë–æ–º–±–æ\nÈÇ¶Âçö\nNone\nÿ®ŸàŸÖÿ®Ÿà\n‡¶¨‡ßã‡¶Æ‡ßç‡¶¨‡ßã\nŒúœÄœåŒºœÄŒø\n‡§¨‡•â‡§Æ‡•ç‡§¨‡•ã\nBombo\nBombo\nBombo\n„Éú„É≥„Éú\nÎ¥ÑÎ≥¥\nBombo\nBombo\nBombo\nBombo\nBombo\n1159113923\nÿ®ŸÖÿ®Ÿà\n◊ë◊ï◊û◊ë◊ï\n–ë–æ–º–±–æ\nÿ®ŸàŸÖÿ®Ÿà\nÈÇ¶Âçö\nNaN\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (32.53330 0.58330)\n\n\n1\n10\n1\n5\nAdmin-1 region capital\nFort Portal\nNone\nNone\nFort Portal\n0\nNone\n0\n0\nUganda\nUGA\nUganda\nUGA\nKabarole\nUG\nNone\n0.671004\n30.275002\n42670\n42670\n0.0\n7\n7\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nAfrica/Kampala\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ500107\n421174009\n0\nFort Portal\nFort Portal\nFort Portal\nFort Portal\nFort Portal\n–§–æ—Ä—Ç-–ü–æ—Ä—Ç–∞–ª\nÊ≥¢ÁâπÁàæÂ†°\nNone\nŸÅŸàÿ±ÿ™ ÿ®Ÿàÿ±ÿ™ÿßŸÑ\n‡¶´‡ßã‡¶∞‡ßç‡¶ü ‡¶™‡ßã‡¶∞‡ßç‡¶ü‡¶æ‡¶≤\nŒ¶ŒøœÅœÑ Œ†ŒøœÅœÑŒ¨Œª\n‡§´‡•ã‡§∞‡•ç‡§ü ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤\nFort Portal\nFort Portal\nFort Portal\n„Éï„Ç©„Éº„Éà„Éª„Éù„Éº„Çø„É´\nÌè¨Ìä∏Ìè¨ÌÑ∏\nFort Portal\nFort Portal\nFort Portal\nFort Portal\nFort Portal\n1159113959\nŸÅŸàÿ±ÿ™ ŸæŸàÿ±ÿ™ÿßŸÑ\n◊§◊ï◊®◊ò ◊§◊ï◊®◊ò◊ú\n–§–æ—Ä—Ç-–ü–æ—Ä—Ç–∞–ª\nŸÅŸàÿ±Ÿπ ŸæŸàÿ±ŸπŸÑ\nÊ≥¢ÁâπÁàæÂ†°\n233476.0\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (30.27500 0.67100)\n\n\n2\n10\n1\n3\nAdmin-1 region capital\nPotenza\nNone\nNone\nPotenza\n0\nNone\n0\n0\nItaly\nITA\nItaly\nITA\nBasilicata\nIT\nNone\n40.642002\n15.798997\n69060\n69060\n0.0\n8\n8\nNone\nNone\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nEurope/Rome\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n7.0\nQ3543\n101752567\n0\nPotenza\nPotenza\nPotenza\nPotenza\nPotenza\n–ü–æ—Ç–µ–Ω—Ü–∞\nÊ≥¢Âù¶ÂØü\nNone\nÿ®Ÿàÿ™ŸÜÿ≥ÿß\n‡¶™‡ßã‡¶ü‡ßá‡¶û‡ßç‡¶ú‡¶æ\nŒ†ŒøœÑŒ≠ŒΩœÑœÉŒ±\n‡§™‡•ã‡§ü‡•á‡§Ç‡§ú‡§æ\nPotenza\nPotenza\nPotenza\n„Éù„ÉÜ„É≥„ÉÑ„Ç°\nÌè¨ÌÖêÏ∞®\nPotenza\nPotenza\nPotenza\nPotenza\nPotenza\n1159117259\nŸæŸàÿ™ŸÜÿ≤ÿß\n◊§◊ï◊ò◊†◊¶◊î\n–ü–æ—Ç–µ–Ω—Ü–∞\nŸæŸàÿ™€åŸÜÿ™ÿ≥ÿß\nÊ≥¢Âù¶ÂØü\n3170027.0\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nPOINT (15.79900 40.64200)\n\n\n\n\n\n\n\n\nplaces.plot()\n\n\n\n\n\n\n\n\nThis dataset has the EPSG:4326 CRS. Remember this is the EPSG code for the WGS 84 CRS. This is not a surprise since the places data is global and EPSG:4326/WGS84 is the most widely used CRS for such data.\nLet‚Äôs see what happens when we try to plot this data on top of Alaska:\n\n# Trouble\nfig, ax = plt.subplots()\n\nalaska.plot(ax=ax)\nplaces.plot(ax=ax, color='red')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData in weird places? Check your CRSs\n\n\n\nThis is a classic slip in geospatial analysis. To plot, analyze, or integrate different geospatial datasets they must have the same CRS.\nHere, alaska and places have different CRSs, leading to unexpected results when plotting them together:\n\nalaska.crs == places.crs\n\nFalse\n\n\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nReproject the places geo-datafarme into alaska‚Äôs CRS and verify the CRSs match using assert.\n\n\n\nLet‚Äôs check that map again:\n\nfig, ax = plt.subplots()\n\nalaska.plot(ax=ax)\nplaces.plot(ax=ax, color='red', markersize=2)\n\nplt.show()\n\n\n\n\n\n\n\n\nThis is better: we can see there the Alaska poygons and some of the places points on top of it. Our next step is to select these points.",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#clipping-1",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#clipping-1",
    "title": "12 Clipping",
    "section": "",
    "text": "Clipping means using a polygon (or polygons) to only select geospatial data within them. Clipping a geopandas.GeoDataFrame is simple using the geopandas clip() function. The general syntax is:\nupdated_geodf = geopandas.clip(geodf, mask)\nwhere:\n\nupdated_geodf is the output of the method: the intersection of the geometries in geodf with mask,\ngeodf is the geopandas.GeoDataFrame we want to clip,\nmask is a geopandas.GeoDataFrame with the polygon(s) we want to use for clipping. This mask must be in the same CRS as geodf!\n\nIn our case:\n\n# Clip populated places to Alaska multipolygon\nak_places = gpd.clip(places, alaska)\n\nfig, ax = plt.subplots()\nalaska.plot(ax=ax)\nak_places.plot(ax=ax, color='red')\nplt.show()",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-roads",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#prepare-roads",
    "title": "12 Clipping",
    "section": "",
    "text": "Now we move on to our roads dataset.\n\nprint(roads.crs)\n\nroads.head(3)\n\nEPSG:4326\n\n\n\n\n\n\n\n\n\nscalerank\nfeaturecla\ntype\nsov_a3\nnote\nedited\nname\nnamealt\nnamealtt\nrouteraw\nquestion\nlength_km\ntoll\nne_part\nlabel\nlabel2\nlocal\nlocaltype\nlocalalt\nlabelrank\nignore\nadd\nrwdb_rd_id\norig_fid\nprefix\nuident\ncontinent\nexpressway\nlevel\nmin_zoom\nmin_label\ngeometry\n\n\n\n\n0\n8\nRoad\nSecondary Highway\nCAN\nNone\nVersion 1.5: Changed alignment, a few adds in ...\nNone\nNone\nNone\nNone\n0\n3\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n314705\nNorth America\n0\nNone\n7.1\n9.6\nLINESTRING (-133.32533 62.21571, -133.31664 62...\n\n\n1\n7\nRoad\nSecondary Highway\nUSA\nNone\nVersion 1.5: Changed alignment, a few adds in ...\n83\nNone\nNone\nNone\n0\n164\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n108105\nNorth America\n0\nFederal\n7.0\n8.6\nLINESTRING (-100.50543 42.80753, -100.53495 42...\n\n\n2\n7\nRoad\nSecondary Highway\nUSA\nNone\nVersion 1.5: Changed alignment, a few adds in ...\n840\nNone\nNone\nNone\n0\n98\n0\nne_1d4_original\nNone\nNone\nNone\nNone\nNone\n0\n0\n0\n0\n0\nNone\n0\nNorth America\n0\nU/C\n7.0\n9.5\nLINESTRING (-87.27432 36.02439, -87.22916 35.9...\n\n\n\n\n\n\n\n\nroads.plot()\n\n\n\n\n\n\n\n\nYou may have already noticed that the roads data is not in the same CRS as the alaska polygons, so these geo-datasets shound‚Äôt interact until they‚Äôre in the same CRS. Before jumping right into reprojecting and clipping, we will subset the data to select only US roads:\n\nusa_roads = roads[roads.sov_a3 == 'USA']\nusa_roads.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReduce your tabular data before reducing via geometries\n\n\n\nGeospatial operations are usually costly in terms of computing power. The more detailed our geometries are, the longer in takes to do geospatial computations. It‚Äôs a good practice to reduce your data as much as possible before applying any geospatial transformation.\n\n\n\nWe will now compose functions to clip usa_roads using the alaska multipolygon. Notice we are using the ouput of usa_roads.to_crs(alaska.crs) directly and thus not changing the usa_roads geo-dataframe or creating new variables:\n\n# Clip usa_roads to alaska geometry\nak_roads = gpd.clip(usa_roads.to_crs(alaska.crs), alaska)\n\n\nfig, ax = plt.subplots()\nalaska.plot(ax=ax)\nak_roads.plot(ax=ax, color='red')\nplt.show()\n\n\n\n\n\n\n\n\nNotice how the lines break on the small islands? However, in the usa_roads there are no broken lines. This should make us suspect we are leaving data out and clipping exactly to the polygons in alaska is not quite what we want.\n\n\nWe will clip the usa_roads geo-dataframe with the bounding box of alaska instead of its polygons. To create a bounding box, we first use the box() function we imported from shapely.geometry. The syntax for box() is:\nbox(minx, miny, maxx, maxy)\nthe output is a polygon representing a box constructed like this:\n\n\n\nImage adapted from: National Ecological Observatory Network (NEON)\n\n\nIf we want to create a shapely polygon from the bounds of a geo-dataframe gdf, a more straightforward syntax is:\nbox(*gdf.total_bounds)\nIn our case:\n\nbbox = box(*alaska.total_bounds)\nprint(type(bbox))\nbbox\n\n&lt;class 'shapely.geometry.polygon.Polygon'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n* = unpacking operator\n\n\n\nIn the last syntax we used the asterisk * as an unpacking operator on the array alaska.total_bounds. Think about it as unpacking the elements of alaska.total_bounds and assigning them one-by-one to the paremeters minx, miny, maxx, maxy of the box() function.\nThis is a good article explaining more about unpacking with * in Python: https://geekflare.com/python-unpacking-operators/\n\n\nNotice that the bounding box is not a geodataframe, it is a stand alone, abstract polygon without any geospatial information. To interpret this polygon as something on the Earth‚Äôs surface we need to wrap it into a geo-datfrane abd assign it a CRS:\n\n# Create geo-dataframe from bounding box\nak_bbox = gpd.GeoDataFrame(geometry = [bbox],  # Assign geometry column\n                           crs = alaska.crs)  # Assign CRS\nprint(type(ak_bbox))\nak_bbox\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\n\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((1493082.309 404545.108, 1493082.309 ...\n\n\n\n\n\n\n\nWe can now clip the roads using Alaska‚Äôs bounding box:\n\nak_complete_roads = gpd.clip(usa_roads.to_crs(ak_bbox.crs), ak_bbox)\n\nNotice the difference between the two clipping methods:\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,10))\n\nak_roads.plot(ax=ax1)\nax1.set_title('Roads clipped with AK multipolygon')\n\nak_complete_roads.plot(ax=ax2)\nax2.set_title('Roads clipped with AK bounding box')\n\nplt.show()",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#plot",
    "href": "book/chapters/lesson-13-clipping/lesson-13-clipping.html#plot",
    "title": "12 Clipping",
    "section": "",
    "text": "Finally, we can put all our data together in the same map:\n\n\nCode\nfig, ax = plt.subplots(figsize=(11,5))\nax.axis('off')\n\nalaska.plot(ax=ax, color='whitesmoke', edgecolor='0.7')\n\nak_complete_roads.plot(ax=ax, \n                       zorder=1,  # Specify layer plotting order\n                       column='type', \n                       legend=True,\n                       legend_kwds={'title': \"Road Types\", \n                                    'loc': 'upper left',\n                                    'bbox_to_anchor':(0,0.9),\n                                    'fontsize':'small'}\n                                    )\n\nak_places.plot(ax=ax, \n               zorder=2,  # Specify layer plotting order\n               color='red', \n               marker='s'  # Square marker\n               )\n# Add city names as text annotations\nfor x, y, name in zip(ak_places.geometry.x, ak_places.geometry.y, ak_places['name']):\n    ax.text(x-30000, y+20000, name, fontsize=8, ha='right')\n\nax.set_title(\"Road Networks and Major Cities in Alaska\", fontsize=14, fontweight='bold')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nNotice the overlaying labels for Anchorage and Valdez:\n\n\n\n\n\nUpdate the map so these labels do not overlap. One way to do it is using an if when iterating over the Alaska populated places.",
    "crumbs": [
      "notes",
      "Vector data",
      "12 Clipping"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html",
    "href": "book/chapters/lesson-1-python-review.html",
    "title": "Python review",
    "section": "",
    "text": "This is a short review about some core concepts in Python exemplified by objects in the NumPy library. The goal is to recall basic Python vocabulary that will be used throughout the course, rather than to serve as an introduction to Python programming.\n\n\nBy the end of this lesson, students will be able to:\n\nDefine and provide examples for basic terms in Python programming like variable, object, function, class, attribute, and method.\nRecognize optional and non-optional arguments in a function.\nUnderstand some of the basic differences in R and Python syntax.\n\n\n\n\nA library is a collection of code that we can use to perform specific tasks in our programs. It can be a single file or multiple ones. NumPy [1] is one of the core libraries for numerical computing in Python. Many of the libraries we will use in this course use NumPy‚Äôs arrays as their building blocks. Additionally, NumPy objects have been optimized for processing, so computations on them are really fast and use less memory than doing the equivalent using the core Python data structures.\nIn this lesson we will use NumPy to review some fundamental concepts in Python you should be already familiar with.\n\n\n\n\n\n\nLibrary or package?\n\n\n\nA package in Python refers to a specific way of organizing multiple files of code into a directory hierarcy, often within a large code library. The words ‚Äúlibrary‚Äù and ‚Äúpackage‚Äù are often used interchangeably. NumPy, for example, is both a library and a package.\n\n\nLet‚Äôs start by importing the NumPy library by using the standard to abbreviation, np:\n\nimport numpy as np\n\nBy importing numpy, all the objects and functions in this library will be available for us to use in our notebook.\n\n\n\nWe can think of a variable as a name we assign to a particular object in Python. For example:\n\n# Assign a small array to variable a\na = np.array([[1,1,2],[3,5,8]])\n\nWhen we run the cell, we store the variables and their value. We can view a variable‚Äôs value in two ways from within our Jupyter notebook:\n\nrunning a cell with the variable name\nusing the print function to print the value\n\n\n# Show the value\na\n\narray([[1, 1, 2],\n       [3, 5, 8]])\n\n\n\n# Print the value \nprint(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\n\n\n\n\n\n\nR and Python: assigning values\n\n\n\nRemember that in Python we use the equal sign = to assign values to variables in the same way the left-arrow &lt;- is used in R:\n# R: assign value 10 to variable a\na &lt;- 10\n# Python: assign value 10 to variable a\na = 10\n\n\n\n\n\n\n\n\nConvention: Use snake_case for naming variables\n\n\n\nThere are many ways of constructing multi-word variable names. In this course we will name variables using snake_case, where words are all in small caps and separated by underscores (ex: raw_data, fires_2023). This is the naming convention suggested by the PEP 8 - Style Guide for Python Code [2]. Remember variable names should be both descriptive and concise!\n\n\n\n\n\nYou will often encounter the word object in Python documentation and tutorials. Informally speaking, an object is a bundle of properties and actions about something specific. For example, an object could represent a data frame with properties such as number of rows, names of columns, and date created, and actions suchs as selecting a specific row or adding a new column.\nA variable is the name we give a specific object, and the same object can be referenced by different variables. An analogy for this is the following: the Sun (object) is called ‚Äúsol‚Äù in Spanish and ‚Äúsoleil‚Äù in French, so two different names (variables) represent the same object. You can read more technical details about the difference between objects and variables in Python here [3].\nIn practice, we can often use the word variable and object interchangeably (for example, in the next subsection!). I want to bring up what objects are so you are not caught off-guard with vocabulary you will often encounter in the documentation, StackExchange, etc.\n\n\n\nEvery object in Python has a type, the type tells us what kind of object it is. We can also call the type of an object, the class of an object, so class and type both mean what kind of object we have.\nWe can see the type/class of a variable/object by using the type function:\n\nprint(a)\ntype(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\nnumpy.ndarray\n\n\nThe numpy.ndarray is the core object/data type in the NumPy package. We can check the type of an entry in the array by indexing:\n\nprint(a[0,0])\ntype(a[0,0])\n\n1\n\n\nnumpy.int64\n\n\nNotice the type of the value 1 in the array is numpy.int64 and not just the standard Python integer type int. The NumPy type numpy.int64 is telling us 1 is an integer stored as a 64-bit number. NumPy has its own data types to deal with numbers depending on memory storage and floating point precision, click here to know see all the types.\n\n\n\n\n\n\nR and Python: indexing\n\n\n\nRemember that in Python the indexing starts from 0, while in R it starts from 1. If you learned R first, this might seem odd but it‚Äôs easy to get used to it with some practice. A way to understand this 0-indexing is that, in Python, the index indicates the displacement from the start of the collection. So ‚Äò0 index in an array‚Äô means ‚Äòzero displacement from the start of the array‚Äô, in other words, the first element of the array.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nHow would you access the value 5 in the array a?\n\n\nSince ‚Äúeverything in Python is an object‚Äù and every object belongs to a class, we will interact with SO MANY classes in this course. Often, knowing the type of an object is the first step to finding information to code what you want!\n\n\n\nprint was our first example of a Python function. Functions take in a set of arguments, separated by commas, and use those arguments to create an output. There are several built-in funcions in Python, most of them are for interacting with the Python basic data types such as int (integers), float (decimal numbers), str (strings), and bool (boolean values).\n\n\n\n\n\n\nArgument or parameter?\n\n\n\nIn this course we will use argument and parameter interchangeably. They do, however, have related but different meanings.\nA parameter is a variable in the function definition that accepts an argument passed to the function. It is a placeholder in the function that will receive the value of an argument when the function is called.\nFor example, in the function\ndef my_function(parameter1, parameter2):\n    return parameter1 + parameter2\nparameter1 and parameter2 are parameters. When we call the function\nresult = my_function(5, 10)\nwe have that 5 and 10 are arguments passed to the function my_function.\nYou will probably see parameter more often in a package‚Äôs documentation!\n\n\nWe can ask for information about what a function does function by executing ? followed by the function name:\n\n?print\n\n\nWhat we obtain is a docstring, a special type of comment that is used to document how a function (or class, or module) works. The first line in the docstring is telling us the function name followed by all of its arguments in parentheses. Then there is a short description of what the function does. And finally a list of the arguments and a brief explanation about each of them.\nYou can see there are different types of arguments inside the parenthesis. Roughly speaking, a function has two types of arguments:\n\nnon-optional arguments: arguments you need to specify for the function to do something, and\noptional arguments: arguments that are pre-filled with a default value by the function, but you can override them. Optional arguments appear inside the parenthesis () in the form optional_argument = default_value.\n\n\n\nend is a parameter in print with the default value a new line. We can pass the value ^_^ to this parameter so that finishes the line with ^_^ instead:\n\nprint('changing the default end argument of the print function', end=' ^_^')\n\nchanging the default end argument of the print function ^_^\n\n\nNotice that before we had always used print without specifying any value for the end parameter.\n\n\n\n\nAn object in Python has attributes and methods. An attribute is a property of the object, some piece of information about it. A method is a procedure associated with an object, so it is an action where the main ingredient is the object.\nFor example, these could be some attributes and methods for class cat:\n\n\n\n.\n\n\nMore formally, a method is a function that acts on the object it is part of.\nWe can access a variable‚Äôs attributes and methods by adding a period . at the end of the variable‚Äôs name. So we would write variable.variable_method() or variable.variable_attribute.\n\n\n\n\n\n\nCheck-in\n\n\n\nSuppose we have a class fish, make a diagram similar to the cat class diagram showing 3 attributes for the class and 3 methods.\n\n\n\n\nNumPy arrays have many methods and attributes. Let‚Äôs see some concrete examples.\n\n# A 3x3 array\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nT is an example of attribute, it returns the transpose of var:\n\nprint(var.T)\nprint(type(var.T))\n\n[[1 4 7]\n [2 5 8]\n [3 6 9]]\n&lt;class 'numpy.ndarray'&gt;\n\n\nshape, another attribute, tells us the shape of the array:\n\nprint(var.shape)\nprint(type(var.shape))\n\n(3, 3)\n&lt;class 'tuple'&gt;\n\n\nndim is an attribute holding the number of array dimensions\n\nprint(var.ndim)\nprint(type(var.ndim))\n\n2\n&lt;class 'int'&gt;\n\n\nNotice these attributes can have many different data types. Here we saw a tuple and an int (two of the basic Python classes) and also a NumPy array as attributes of var.\nNow some examples of methods.\nThe tolist method returns the array as a nested list of scalars:\n\nvar.tolist()\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nThe min method returns the minimum value in the array along a specified axis:\n\nvar.min(axis=0)\n\narray([1, 2, 3])\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can also call the min method without any parameters:\n\nvar.min()\n\n1\n\n\nWhat kind of parameter is axis in our previous call of the var method?\n\n\nRemember, methods are functions associated to an object. We can confirm this!\n\ntype(var.tolist)\n\nbuiltin_function_or_method\n\n\n\ntype(var.min)\n\nbuiltin_function_or_method\n\n\nYou can see a complete list of NumPy array‚Äôs methods and attributes in the documentation.\n\n\n\n\n\n\nR and Python: are there methods in R?\n\n\n\nIt is uncommon to use methods within an object in R. Rather, functions are extrinsic to the objects they are acting on. In R, for example, there would usually be two separate items: the variable var and a separate function min that gets var as a parameter:\n# This is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nmin(var)\nUsing the pipe operator %&gt;% in R‚Äôs tidyverse is closer to the dot . in Python:\n# This is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nvar %&gt;% min()\nWhat happens here is that the pipe %&gt;% is passing var to the min() function as its first argument. This is similar to what happens in Python when a function is a method of a class:\n# This is Python code\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar.min()\nWhen working in Python, remember that methods are functions that are part of an object and a method uses the object it is part of to produce some information.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#learning-objectives",
    "href": "book/chapters/lesson-1-python-review.html#learning-objectives",
    "title": "Python review",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nDefine and provide examples for basic terms in Python programming like variable, object, function, class, attribute, and method.\nRecognize optional and non-optional arguments in a function.\nUnderstand some of the basic differences in R and Python syntax.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#libraries-and-packages",
    "href": "book/chapters/lesson-1-python-review.html#libraries-and-packages",
    "title": "Python review",
    "section": "",
    "text": "A library is a collection of code that we can use to perform specific tasks in our programs. It can be a single file or multiple ones. NumPy [1] is one of the core libraries for numerical computing in Python. Many of the libraries we will use in this course use NumPy‚Äôs arrays as their building blocks. Additionally, NumPy objects have been optimized for processing, so computations on them are really fast and use less memory than doing the equivalent using the core Python data structures.\nIn this lesson we will use NumPy to review some fundamental concepts in Python you should be already familiar with.\n\n\n\n\n\n\nLibrary or package?\n\n\n\nA package in Python refers to a specific way of organizing multiple files of code into a directory hierarcy, often within a large code library. The words ‚Äúlibrary‚Äù and ‚Äúpackage‚Äù are often used interchangeably. NumPy, for example, is both a library and a package.\n\n\nLet‚Äôs start by importing the NumPy library by using the standard to abbreviation, np:\n\nimport numpy as np\n\nBy importing numpy, all the objects and functions in this library will be available for us to use in our notebook.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#variables",
    "href": "book/chapters/lesson-1-python-review.html#variables",
    "title": "Python review",
    "section": "",
    "text": "We can think of a variable as a name we assign to a particular object in Python. For example:\n\n# Assign a small array to variable a\na = np.array([[1,1,2],[3,5,8]])\n\nWhen we run the cell, we store the variables and their value. We can view a variable‚Äôs value in two ways from within our Jupyter notebook:\n\nrunning a cell with the variable name\nusing the print function to print the value\n\n\n# Show the value\na\n\narray([[1, 1, 2],\n       [3, 5, 8]])\n\n\n\n# Print the value \nprint(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\n\n\n\n\n\n\nR and Python: assigning values\n\n\n\nRemember that in Python we use the equal sign = to assign values to variables in the same way the left-arrow &lt;- is used in R:\n# R: assign value 10 to variable a\na &lt;- 10\n# Python: assign value 10 to variable a\na = 10\n\n\n\n\n\n\n\n\nConvention: Use snake_case for naming variables\n\n\n\nThere are many ways of constructing multi-word variable names. In this course we will name variables using snake_case, where words are all in small caps and separated by underscores (ex: raw_data, fires_2023). This is the naming convention suggested by the PEP 8 - Style Guide for Python Code [2]. Remember variable names should be both descriptive and concise!",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#objects",
    "href": "book/chapters/lesson-1-python-review.html#objects",
    "title": "Python review",
    "section": "",
    "text": "You will often encounter the word object in Python documentation and tutorials. Informally speaking, an object is a bundle of properties and actions about something specific. For example, an object could represent a data frame with properties such as number of rows, names of columns, and date created, and actions suchs as selecting a specific row or adding a new column.\nA variable is the name we give a specific object, and the same object can be referenced by different variables. An analogy for this is the following: the Sun (object) is called ‚Äúsol‚Äù in Spanish and ‚Äúsoleil‚Äù in French, so two different names (variables) represent the same object. You can read more technical details about the difference between objects and variables in Python here [3].\nIn practice, we can often use the word variable and object interchangeably (for example, in the next subsection!). I want to bring up what objects are so you are not caught off-guard with vocabulary you will often encounter in the documentation, StackExchange, etc.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#types",
    "href": "book/chapters/lesson-1-python-review.html#types",
    "title": "Python review",
    "section": "",
    "text": "Every object in Python has a type, the type tells us what kind of object it is. We can also call the type of an object, the class of an object, so class and type both mean what kind of object we have.\nWe can see the type/class of a variable/object by using the type function:\n\nprint(a)\ntype(a)\n\n[[1 1 2]\n [3 5 8]]\n\n\nnumpy.ndarray\n\n\nThe numpy.ndarray is the core object/data type in the NumPy package. We can check the type of an entry in the array by indexing:\n\nprint(a[0,0])\ntype(a[0,0])\n\n1\n\n\nnumpy.int64\n\n\nNotice the type of the value 1 in the array is numpy.int64 and not just the standard Python integer type int. The NumPy type numpy.int64 is telling us 1 is an integer stored as a 64-bit number. NumPy has its own data types to deal with numbers depending on memory storage and floating point precision, click here to know see all the types.\n\n\n\n\n\n\nR and Python: indexing\n\n\n\nRemember that in Python the indexing starts from 0, while in R it starts from 1. If you learned R first, this might seem odd but it‚Äôs easy to get used to it with some practice. A way to understand this 0-indexing is that, in Python, the index indicates the displacement from the start of the collection. So ‚Äò0 index in an array‚Äô means ‚Äòzero displacement from the start of the array‚Äô, in other words, the first element of the array.\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nHow would you access the value 5 in the array a?\n\n\nSince ‚Äúeverything in Python is an object‚Äù and every object belongs to a class, we will interact with SO MANY classes in this course. Often, knowing the type of an object is the first step to finding information to code what you want!",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#functions",
    "href": "book/chapters/lesson-1-python-review.html#functions",
    "title": "Python review",
    "section": "",
    "text": "print was our first example of a Python function. Functions take in a set of arguments, separated by commas, and use those arguments to create an output. There are several built-in funcions in Python, most of them are for interacting with the Python basic data types such as int (integers), float (decimal numbers), str (strings), and bool (boolean values).\n\n\n\n\n\n\nArgument or parameter?\n\n\n\nIn this course we will use argument and parameter interchangeably. They do, however, have related but different meanings.\nA parameter is a variable in the function definition that accepts an argument passed to the function. It is a placeholder in the function that will receive the value of an argument when the function is called.\nFor example, in the function\ndef my_function(parameter1, parameter2):\n    return parameter1 + parameter2\nparameter1 and parameter2 are parameters. When we call the function\nresult = my_function(5, 10)\nwe have that 5 and 10 are arguments passed to the function my_function.\nYou will probably see parameter more often in a package‚Äôs documentation!\n\n\nWe can ask for information about what a function does function by executing ? followed by the function name:\n\n?print\n\n\nWhat we obtain is a docstring, a special type of comment that is used to document how a function (or class, or module) works. The first line in the docstring is telling us the function name followed by all of its arguments in parentheses. Then there is a short description of what the function does. And finally a list of the arguments and a brief explanation about each of them.\nYou can see there are different types of arguments inside the parenthesis. Roughly speaking, a function has two types of arguments:\n\nnon-optional arguments: arguments you need to specify for the function to do something, and\noptional arguments: arguments that are pre-filled with a default value by the function, but you can override them. Optional arguments appear inside the parenthesis () in the form optional_argument = default_value.\n\n\n\nend is a parameter in print with the default value a new line. We can pass the value ^_^ to this parameter so that finishes the line with ^_^ instead:\n\nprint('changing the default end argument of the print function', end=' ^_^')\n\nchanging the default end argument of the print function ^_^\n\n\nNotice that before we had always used print without specifying any value for the end parameter.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-1-python-review.html#attributes-methods",
    "href": "book/chapters/lesson-1-python-review.html#attributes-methods",
    "title": "Python review",
    "section": "",
    "text": "An object in Python has attributes and methods. An attribute is a property of the object, some piece of information about it. A method is a procedure associated with an object, so it is an action where the main ingredient is the object.\nFor example, these could be some attributes and methods for class cat:\n\n\n\n.\n\n\nMore formally, a method is a function that acts on the object it is part of.\nWe can access a variable‚Äôs attributes and methods by adding a period . at the end of the variable‚Äôs name. So we would write variable.variable_method() or variable.variable_attribute.\n\n\n\n\n\n\nCheck-in\n\n\n\nSuppose we have a class fish, make a diagram similar to the cat class diagram showing 3 attributes for the class and 3 methods.\n\n\n\n\nNumPy arrays have many methods and attributes. Let‚Äôs see some concrete examples.\n\n# A 3x3 array\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nT is an example of attribute, it returns the transpose of var:\n\nprint(var.T)\nprint(type(var.T))\n\n[[1 4 7]\n [2 5 8]\n [3 6 9]]\n&lt;class 'numpy.ndarray'&gt;\n\n\nshape, another attribute, tells us the shape of the array:\n\nprint(var.shape)\nprint(type(var.shape))\n\n(3, 3)\n&lt;class 'tuple'&gt;\n\n\nndim is an attribute holding the number of array dimensions\n\nprint(var.ndim)\nprint(type(var.ndim))\n\n2\n&lt;class 'int'&gt;\n\n\nNotice these attributes can have many different data types. Here we saw a tuple and an int (two of the basic Python classes) and also a NumPy array as attributes of var.\nNow some examples of methods.\nThe tolist method returns the array as a nested list of scalars:\n\nvar.tolist()\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nThe min method returns the minimum value in the array along a specified axis:\n\nvar.min(axis=0)\n\narray([1, 2, 3])\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nWe can also call the min method without any parameters:\n\nvar.min()\n\n1\n\n\nWhat kind of parameter is axis in our previous call of the var method?\n\n\nRemember, methods are functions associated to an object. We can confirm this!\n\ntype(var.tolist)\n\nbuiltin_function_or_method\n\n\n\ntype(var.min)\n\nbuiltin_function_or_method\n\n\nYou can see a complete list of NumPy array‚Äôs methods and attributes in the documentation.\n\n\n\n\n\n\nR and Python: are there methods in R?\n\n\n\nIt is uncommon to use methods within an object in R. Rather, functions are extrinsic to the objects they are acting on. In R, for example, there would usually be two separate items: the variable var and a separate function min that gets var as a parameter:\n# This is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nmin(var)\nUsing the pipe operator %&gt;% in R‚Äôs tidyverse is closer to the dot . in Python:\n# This is R code\nvar &lt;- array(c(1,4,7,2,5,8,3,6,9), dim =c(3,3))\nvar %&gt;% min()\nWhat happens here is that the pipe %&gt;% is passing var to the min() function as its first argument. This is similar to what happens in Python when a function is a method of a class:\n# This is Python code\nvar = np.array([[1,2,3],[4,5,6],[7,8,9]])\nvar.min()\nWhen working in Python, remember that methods are functions that are part of an object and a method uses the object it is part of to produce some information.",
    "crumbs": [
      "notes",
      "Python review"
    ]
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html",
    "title": "Import Thomas fire perimeter",
    "section": "",
    "text": "from matplotlib.colors import ListedColormap\nimport pystac_client\n\nimport numpy as np\nimport pandas as pd\nimport planetary_computer\nimport rasterio\nfrom shapely import Polygon\n\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely import box\nfrom IPython.display import Image  # To nicely display images\nfire_perimeters = gpd.read_file('data/California_Fire_Perimeters_2017/California_Fire_Perimeters_2017.shp')\nthomas_fire = fire_perimeters[fire_perimeters['FIRE_NAME']=='THOMAS']\nthomas_fire.plot()\n# Examine CRS of boundary\nthomas_fire.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06¬∞S and 85.06¬∞N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich"
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#retrieve-lulc-data-over-fire-perimeter",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#retrieve-lulc-data-over-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Retrieve LULC data over fire perimeter",
    "text": "Retrieve LULC data over fire perimeter\n\n# Open MPC data catalog\ncatalog = pystac_client.Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n\n# Reproject fire perimeter to match CRS needed for search\nthomas_fire = thomas_fire.to_crs('epsg:4326')\n\n# Create bounding box for search\nthomas_fire_bbox = list(thomas_fire.total_bounds)\n\nsearch = catalog.search(collections=['gap'], \n                        bbox=thomas_fire_bbox)\n\n# Retrieve search items\nitems = search.item_collection()\nprint(f\"Returned {len(items)} Items\")\nitems\n\nReturned 1 Items\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        features[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        stac_extensions[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/label/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            id\n            \"gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 5 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.69342028\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.99971716\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.49405483\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            36.60171547\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -122.74636922\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            35.90181191\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -121.84549185\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.32121517\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -118.69342028\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.99971716\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -122.74636921535789\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            33.32121516682673\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -118.69342027702393\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            36.60171546740399\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            datetime\n            \"2011-12-31T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            proj:wkt2\n            \"PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]\"\n        \n    \n            \n        \n            \n                \n        \n            label:type\n            \"raster\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            10000\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10000\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            end_datetime\n            \"2011-12-31T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        label:classes[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"\"\n        \n    \n            \n        \n            \n                \n        classes[] 585 items\n        \n            \n        \n            \n                \n        \n            0\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"South Florida Bayhead Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"South Florida Cypress Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"South Florida Dwarf Cypress Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"South Florida Mangrove Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"South Florida Hardwood Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"Southeast Florida Coastal Strand and Maritime Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"Southwest Florida Coastal Strand and Maritime Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"South Florida Pine Rockland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Open Understory\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Scrub/Shrub Understory\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"Atlantic Coastal Plain Upland Longleaf Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"Atlantic Coastal Plain Xeric River Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Scrub/Shrub Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"Florida Longleaf Pine Sandhill - Scrub/Shrub Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"Florida Longleaf Pine Sandhill- Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"West Gulf Coastal Plain Upland Longleaf Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"Atlantic Coastal Plain Central Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"Atlantic Coastal Plain Southern Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"Central and South Texas Coastal Fringe Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            21\n            \"East Gulf Coastal Plain Limestone Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            22\n            \"East Gulf Coastal Plain Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            23\n            \"East Gulf Coastal Plain Southern Loess Bluff Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            24\n            \"East Gulf Coastal Plain Southern Mesic Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            25\n            \"Mississippi Delta Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            26\n            \"Southern Coastal Plain Dry Upland Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            27\n            \"Southern Coastal Plain Oak Dome and Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            28\n            \"West Gulf Coastal Plain Chenier and Upper Texas Coastal Fringe Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            29\n            \"West Gulf Coastal Plain Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            30\n            \"East-Central Texas Plains Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            31\n            \"West Gulf Coastal Plain Pine-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            32\n            \"West Gulf Coastal Plain Sandhill Oak and Shortleaf Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            33\n            \"Atlantic Coastal Plain Fall-Line Sandhills Longleaf Pine Woodland - Loblolly Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            34\n            \"Deciduous Plantations\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            35\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Loblolly Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            36\n            \"East Gulf Coastal Plain Interior Upland Longleaf Pine Woodland - Offsite Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            37\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Offsite Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            38\n            \"Evergreen Plantation or Managed Pine\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            39\n            \"California Central Valley Mixed Oak Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            40\n            \"California Coastal Closed-Cone Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            41\n            \"California Coastal Live Oak Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            42\n            \"California Lower Montane Blue Oak-Foothill Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            43\n            \"Central and Southern California Mixed Evergreen Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            44\n            \"Mediterranean California Lower Montane Black Oak-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            45\n            \"Southern California Oak Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            46\n            \"Madrean Encinal\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            47\n            \"Madrean Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            48\n            \"Madrean Pine-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            49\n            \"Madrean Upper Montane Conifer-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            50\n            \"Edwards Plateau Dry-Mesic Slope Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            51\n            \"Edwards Plateau Limestone Savanna and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            52\n            \"Edwards Plateau Mesic Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            53\n            \"Llano Uplift Acidic Forest, Woodland and Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            54\n            \"East Cascades Oak-Ponderosa Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            55\n            \"Mediterranean California Mixed Evergreen Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            56\n            \"Mediterranean California Mixed Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            57\n            \"North Pacific Dry Douglas-fir-(Madrone) Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            58\n            \"North Pacific Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            59\n            \"Edwards Plateau Limestone Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            60\n            \"Allegheny-Cumberland Dry Oak Forest and Woodland - Hardwood\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            61\n            \"Allegheny-Cumberland Dry Oak Forest and Woodland - Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            62\n            \"Central and Southern Appalachian Montane Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            63\n            \"Central and Southern Appalachian Northern Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            64\n            \"Central Appalachian Oak and Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            65\n            \"Crosstimbers Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            66\n            \"East Gulf Coastal Plain Black Belt Calcareous Prairie and Woodland - Woodland Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            67\n            \"East Gulf Coastal Plain Northern Dry Upland Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            68\n            \"East Gulf Coastal Plain Northern Loess Plain Oak-Hickory Upland - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            69\n            \"East Gulf Coastal Plain Northern Loess Plain Oak-Hickory Upland - Juniper Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            70\n            \"East-Central Texas Plains Post Oak Savanna and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            71\n            \"Lower Mississippi River Dune Woodland and Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            72\n            \"Mississippi River Alluvial Plain Dry-Mesic Loess Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            73\n            \"North-Central Interior Dry Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            74\n            \"North-Central Interior Dry-Mesic Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            75\n            \"Northeastern Interior Dry Oak Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            76\n            \"Northeastern Interior Dry Oak Forest - Virginia/Pitch Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            77\n            \"Northeastern Interior Dry Oak Forest-Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            78\n            \"Northeastern Interior Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            79\n            \"Northern Atlantic Coastal Plain Dry Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            80\n            \"Crowleys Ridge Sand Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            81\n            \"Ouachita Montane Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            82\n            \"Ozark-Ouachita Dry Oak Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            83\n            \"Ozark-Ouachita Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            84\n            \"Southern and Central Appalachian Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            85\n            \"Southern and Central Appalachian Oak Forest - Xeric\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            86\n            \"Southern Interior Low Plateau Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            87\n            \"Southern Ridge and Valley Dry Calcareous Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            88\n            \"Southern Ridge and Valley Dry Calcareous Forest - Pine modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            89\n            \"East Gulf Coastal Plain Northern Dry Upland Hardwood Forest - Offsite Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            90\n            \"Managed Tree Plantation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            91\n            \"Ruderal forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            92\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Loblolly Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            93\n            \"Acadian Low-Elevation Spruce-Fir-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            94\n            \"Acadian-Appalachian Montane Spruce-Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            95\n            \"Appalachian Hemlock-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            96\n            \"Central and Southern Appalachian Spruce-Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            97\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            98\n            \"Laurentian-Acadian Northern Hardwoods Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            99\n            \"Laurentian-Acadian Northern Pine-(Oak) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            100\n            \"Laurentian-Acadian Pine-Hemlock-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            101\n            \"Paleozoic Plateau Bluff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            102\n            \"Southern Appalachian Northern Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            103\n            \"Atlantic Coastal Plain Dry and Dry-Mesic Oak Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            104\n            \"Atlantic Coastal Plain Fall-line Sandhills Longleaf Pine Woodland - Offsite Hardwood\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            105\n            \"East Gulf Coastal Plain Interior Shortleaf Pine-Oak Forest - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            106\n            \"East Gulf Coastal Plain Interior Shortleaf Pine-Oak Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            107\n            \"Ozark-Ouachita Shortleaf Pine-Bluestem Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            108\n            \"Ozark-Ouachita Shortleaf Pine-Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            109\n            \"Southeastern Interior Longleaf Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            110\n            \"Southern Appalachian Low Mountain Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            111\n            \"Southern Piedmont Dry Oak-(Pine) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            112\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Hardwood Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            113\n            \"Southern Piedmont Dry Oak-(Pine) Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            114\n            \"Southern Piedmont Dry Oak-Heath Forest - Mixed Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            115\n            \"Eastern Great Plains Tallgrass Aspen Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            116\n            \"Northwestern Great Plains Aspen Forest and Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            117\n            \"Northwestern Great Plains Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            118\n            \"Western Great Plains Dry Bur Oak Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            119\n            \"Western Great Plains Wooded Draw and Ravine\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            120\n            \"Southern Atlantic Coastal Plain Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            121\n            \"East Gulf Coastal Plain Northern Loess Bluff Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            122\n            \"East Gulf Coastal Plain Northern Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            123\n            \"North-Central Interior Beech-Maple Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            124\n            \"North-Central Interior Maple-Basswood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            125\n            \"Ozark-Ouachita Mesic Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            126\n            \"South-Central Interior Mesophytic Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            127\n            \"Southern and Central Appalachian Cove Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            128\n            \"Crowleys Ridge Mesic Loess Slope Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            129\n            \"Southern Piedmont Mesic Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            130\n            \"Appalachian Shale Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            131\n            \"Atlantic Coastal Plain Northern Maritime Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            132\n            \"Laurentian Pine-Oak Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            133\n            \"Northeastern Interior Pine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            134\n            \"Northern Atlantic Coastal Plain Pitch Pine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            135\n            \"Southern Appalachian Montane Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            136\n            \"East Cascades Mesic Montane Mixed-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            137\n            \"Middle Rocky Mountain Montane Douglas-fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            138\n            \"Northern Rocky Mountain Dry-Mesic Montane Mixed Conifer Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            139\n            \"Northern Rocky Mountain Foothill Conifer Wooded Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            140\n            \"Northern Rocky Mountain Mesic Montane Mixed Conifer Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            141\n            \"Northern Rocky Mountain Ponderosa Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            142\n            \"Northern Rocky Mountain Western Larch Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            143\n            \"Northwestern Great Plains - Black Hills Ponderosa Pine Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            144\n            \"Rocky Mountain Foothill Limber Pine-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            145\n            \"Inter-Mountain Basins Aspen-Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            146\n            \"Inter-Mountain Basins Subalpine Limber-Bristlecone Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            147\n            \"Northern Rocky Mountain Subalpine Woodland and Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            148\n            \"Rocky Mountain Aspen Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            149\n            \"Rocky Mountain Lodgepole Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            150\n            \"Rocky Mountain Poor-Site Lodgepole Pine Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            151\n            \"Rocky Mountain Subalpine Dry-Mesic Spruce-Fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            152\n            \"Rocky Mountain Subalpine Mesic Spruce-Fir Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            153\n            \"Rocky Mountain Subalpine-Montane Limber-Bristlecone Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            154\n            \"Rocky Mountain Bigtooth Maple Ravine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            155\n            \"Southern Rocky Mountain Dry-Mesic Montane Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            156\n            \"Southern Rocky Mountain Mesic Montane Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            157\n            \"Southern Rocky Mountain Ponderosa Pine Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            158\n            \"Southern Rocky Mountain Ponderosa Pine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            159\n            \"California Montane Jeffrey Pine-(Ponderosa Pine) Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            160\n            \"Klamath-Siskiyou Lower Montane Serpentine Mixed Conifer Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            161\n            \"Klamath-Siskiyou Upper Montane Serpentine Mixed Conifer Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            162\n            \"Mediterranean California Dry-Mesic Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            163\n            \"Mediterranean California Mesic Mixed Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            164\n            \"Sierran-Intermontane Desert Western White Pine-White Fir Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            165\n            \"California Coastal Redwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            166\n            \"North Pacific Broadleaf Landslide Forest and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            167\n            \"North Pacific Dry-Mesic Silver Fir-Western Hemlock-Douglas-fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            168\n            \"North Pacific Hypermaritime Sitka Spruce Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            169\n            \"North Pacific Hypermaritime Western Red-cedar-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            170\n            \"North Pacific Lowland Mixed Hardwood-Conifer Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            171\n            \"North Pacific Maritime Dry-Mesic Douglas-fir-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            172\n            \"North Pacific Maritime Mesic-Wet Douglas-fir-Western Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            173\n            \"North Pacific Mesic Western Hemlock-Silver Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            174\n            \"North Pacific Wooded Volcanic Flowage\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            175\n            \"Mediterranean California Red Fir Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            176\n            \"Mediterranean California Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            177\n            \"North Pacific Maritime Mesic Subalpine Parkland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            178\n            \"North Pacific Mountain Hemlock Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            179\n            \"Northern California Mesic Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            180\n            \"Northern Pacific Mesic Subalpine Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            181\n            \"Sierra Nevada Subalpine Lodgepole Pine Forest and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            182\n            \"Columbia Plateau Western Juniper Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            183\n            \"Great Basin Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            184\n            \"Inter-Mountain Basins Curl-leaf Mountain Mahogany Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            185\n            \"Inter-Mountain Basins Juniper Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            186\n            \"Colorado Plateau Pinyon-Juniper Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            187\n            \"Colorado Plateau Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            188\n            \"Southern Rocky Mountain Juniper Woodland and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            189\n            \"Southern Rocky Mountain Pinyon-Juniper Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            190\n            \"Northwestern Great Plains Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            191\n            \"Northwestern Great Plains Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            192\n            \"Western Great Plains Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            193\n            \"Western Great Plains Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            194\n            \"Western Great Plains Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            195\n            \"Central Appalachian Floodplain - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            196\n            \"Central Appalachian Riparian - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            197\n            \"Central Interior and Appalachian Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            198\n            \"Central Interior and Appalachian Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            199\n            \"Laurentian-Acadian Floodplain Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            200\n            \"Ozark-Ouachita Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            201\n            \"South-Central Interior Large Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            202\n            \"South-Central Interior Large Floodplain - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            203\n            \"South-Central Interior Small Stream and Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            204\n            \"North-Central Interior and Appalachian Rich Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            205\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            206\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            207\n            \"Laurentian-Acadian Swamp Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            208\n            \"North-Central Interior Wet Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            209\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            210\n            \"South-Central Interior / Upper Coastal Plain Wet Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            211\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            212\n            \"Southern Piedmont/Ridge and Valley Upland Depression Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            213\n            \"Atlantic Coastal Plain Blackwater Stream Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            214\n            \"Atlantic Coastal Plain Brownwater Stream Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            215\n            \"Atlantic Coastal Plain Northern Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            216\n            \"Atlantic Coastal Plain Small Blackwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            217\n            \"Atlantic Coastal Plain Small Brownwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            218\n            \"Atlantic Coastal Plain Southern Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            219\n            \"East Gulf Coastal Plain Large River Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            220\n            \"East Gulf Coastal Plain Small Stream and River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            221\n            \"East Gulf Coastal Plain Tidal Wooded Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            222\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            223\n            \"Southeastern Great Plains Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            224\n            \"Southeastern Great Plains Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            225\n            \"Mississippi River Bottomland Depression\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            226\n            \"Mississippi River Floodplain and Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            227\n            \"Mississippi River Low Floodplain (Bottomland) Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            228\n            \"Mississippi River Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            229\n            \"Red River Large Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            230\n            \"Southern Coastal Plain Blackwater River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            231\n            \"Southern Piedmont Large Floodplain Forest - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            232\n            \"Southern Piedmont Small Floodplain and Riparian Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            233\n            \"West Gulf Coastal Plain Large River Floodplain Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            234\n            \"West Gulf Coastal Plain Near-Coast Large River Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            235\n            \"West Gulf Coastal Plain Small Stream and River Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            236\n            \"Atlantic Coastal Plain Streamhead Seepage Swamp -  Pocosin -  and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            237\n            \"Gulf and Atlantic Coastal Plain Swamp Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            238\n            \"Southern Coastal Plain Hydric Hammock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            239\n            \"Southern Coastal Plain Seepage Swamp and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            240\n            \"West Gulf Coastal Plain Seepage Swamp and Baygall\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            241\n            \"Atlantic Coastal Plain Nonriverine Swamp and Wet Hardwood Forest  - Taxodium/Nyssa Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            242\n            \"Atlantic Coastal Plain Nonriverine Swamp and Wet Hardwood Forest - Oak Dominated Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            243\n            \"East Gulf Coastal Plain Southern Loblolly-Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            244\n            \"Lower Mississippi River Bottomland Depressions - Forest Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            245\n            \"Lower Mississippi River Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            246\n            \"Northern Atlantic Coastal Plain Basin Swamp and Wet Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            247\n            \"Southern Coastal Plain Nonriverine Basin Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            248\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Bay/Gum Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            249\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Pine Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            250\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Taxodium Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            251\n            \"West Gulf Coastal Plain Nonriverine Wet Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            252\n            \"West Gulf Coastal Plain Pine-Hardwood Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            253\n            \"Edwards Plateau Riparian\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            254\n            \"Atlantic Coastal Plain Clay-Based Carolina Bay Forested Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            255\n            \"Atlantic Coastal Plain Clay-Based Carolina Bay Herbaceous Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            256\n            \"Atlantic Coastal Plain Southern Wet Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            257\n            \"Central Atlantic Coastal Plain Wet Longleaf Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            258\n            \"Central Florida Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            259\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            260\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            261\n            \"East Gulf Coastal Plain Near-Coast Pine Flatwoods - Scrub/Shrub Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            262\n            \"South Florida Pine Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            263\n            \"Southern Coastal Plain Nonriverine Cypress Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            264\n            \"West Gulf Coastal Plain Wet Longleaf Pine Savanna and Flatwoods\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            265\n            \"Columbia Basin Foothill Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            266\n            \"Great Basin Foothill and Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            267\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            268\n            \"Northern Rocky Mountain Conifer Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            269\n            \"Northern Rocky Mountain Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            270\n            \"Rocky Mountain Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            271\n            \"Rocky Mountain Montane Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            272\n            \"Rocky Mountain Subalpine-Montane Riparian Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            273\n            \"North Pacific Hardwood-Conifer Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            274\n            \"North Pacific Lowland Riparian Forest and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            275\n            \"North Pacific Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            276\n            \"North Pacific Shrub Swamp\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            277\n            \"California Central Valley Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            278\n            \"Mediterranean California Foothill and Lower Montane Riparian Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            279\n            \"Mediterranean California Serpentine Foothill and Lower Montane Riparian Woodland and Seep\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            280\n            \"North American Warm Desert Lower Montane Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            281\n            \"North American Warm Desert Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            282\n            \"North American Warm Desert Riparian Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            283\n            \"Tamaulipan Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            284\n            \"Tamaulipan Riparian Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            285\n            \"Boreal Aspen-Birch Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            286\n            \"Boreal Jack Pine-Black Spruce Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            287\n            \"Boreal White Spruce-Fir-Hardwood Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            288\n            \"Boreal-Laurentian Conifer Acidic Swamp and Treed Poor Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            289\n            \"Eastern Boreal Floodplain\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            290\n            \"South Florida Shell Hash Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            291\n            \"Southeast Florida Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            292\n            \"Southwest Florida Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            293\n            \"South Florida Everglades Sawgrass Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            294\n            \"South Florida Freshwater Slough and Gator Hole\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            295\n            \"South Florida Wet Marl Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            296\n            \"California Maritime Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            297\n            \"California Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            298\n            \"California Xeric Serpentine Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            299\n            \"Klamath-Siskiyou Xeromorphic Serpentine Savanna and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            300\n            \"Mediterranean California Mesic Serpentine Woodland and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            301\n            \"Northern and Central California Dry-Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            302\n            \"Southern California Dry-Mesic Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            303\n            \"Southern California Coastal Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            304\n            \"California Central Valley and Southern Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            305\n            \"California Mesic Serpentine Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            306\n            \"Columbia Basin Foothill and Canyon Dry Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            307\n            \"Columbia Basin Palouse Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            308\n            \"North Pacific Alpine and Subalpine Dry Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            309\n            \"North Pacific Montane Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            310\n            \"North Pacific Montane Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            311\n            \"Northern Rocky Mountain Lower Montane, Foothill and Valley Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            312\n            \"Northern Rocky Mountain Montane-Foothill Deciduous Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            313\n            \"Northern Rocky Mountain Subalpine Deciduous Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            314\n            \"Northern Rocky Mountain Subalpine-Upper Montane Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            315\n            \"Southern Rocky Mountain Montane-Subalpine Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            316\n            \"Rocky Mountain Gambel Oak-Mixed Montane Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            317\n            \"Rocky Mountain Lower Montane-Foothill Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            318\n            \"California Northern Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            319\n            \"North Pacific Herbaceous Bald and Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            320\n            \"North Pacific Hypermaritime Shrub and Herbaceous Headland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            321\n            \"Willamette Valley Upland Prairie and Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            322\n            \"Mediterranean California Subalpine Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            323\n            \"Rocky Mountain Subalpine-Montane Mesic Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            324\n            \"Central Mixedgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            325\n            \"Northwestern Great Plains Mixedgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            326\n            \"Western Great Plains Foothill and Piedmont Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            327\n            \"Western Great Plains Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            328\n            \"Western Great Plains Sand Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            329\n            \"Western Great Plains Sandhill Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            330\n            \"Western Great Plains Mesquite Woodland and Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            331\n            \"Western Great Plains Shortgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            332\n            \"Arkansas Valley Prairie and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            333\n            \"Central Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            334\n            \"North-Central Interior Oak Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            335\n            \"North-Central Interior Sand and Gravel Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            336\n            \"North-Central Oak Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            337\n            \"Northern Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            338\n            \"Southeastern Great Plains Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            339\n            \"Texas Blackland Tallgrass Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            340\n            \"Texas-Louisiana Coastal Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            341\n            \"Central Appalachian Pine-Oak Rocky Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            342\n            \"Southern Appalachian Grass and Shrub Bald\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            343\n            \"Southern Appalachian Grass and Shrub Bald - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            344\n            \"Southern Appalachian Grass and Shrub Bald - Shrub Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            345\n            \"Central Appalachian Alkaline Glade and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            346\n            \"Central Interior Highlands Calcareous Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            347\n            \"Central Interior Highlands Dry Acidic Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            348\n            \"Cumberland Sandstone Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            349\n            \"Great Lakes Alvar\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            350\n            \"Nashville Basin Limestone Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            351\n            \"Southern Ridge and Valley / Cumberland Dry Calcareous Forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            352\n            \"Southern Piedmont Glade and Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            353\n            \"East Gulf Coastal Plain Black Belt Calcareous Prairie and Woodland - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            354\n            \"East Gulf Coastal Plain Jackson Prairie and Woodland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            355\n            \"Eastern Highland Rim Prairie and Barrens - Dry Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            356\n            \"Coahuilan Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            357\n            \"Madrean Oriental Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            358\n            \"Mogollon Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            359\n            \"Sonora-Mojave Semi-Desert Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            360\n            \"California Montane Woodland and Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            361\n            \"Great Basin Semi-Desert Chaparral\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            362\n            \"Florida Dry Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            363\n            \"Florida Peninsula Inland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            364\n            \"West Gulf Coastal Plain Catahoula Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            365\n            \"West Gulf Coastal Plain Nepheline Syenite Glade\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            366\n            \"East Gulf Coastal Plain Jackson Plain Dry Flatwoods - Open Understory Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            367\n            \"West Gulf Coastal Plain Northern Calcareous Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            368\n            \"West Gulf Coastal Plain Southern Calcareous Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            369\n            \"Acadian-Appalachian Subalpine Woodland and Heath-Krummholz\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            370\n            \"Atlantic and Gulf Coastal Plain Interdunal Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            371\n            \"Atlantic Coastal Plain Southern Dune and Maritime Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            372\n            \"Central and Upper Texas Coast Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            373\n            \"East Gulf Coastal Plain Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            374\n            \"Great Lakes Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            375\n            \"Northern Atlantic Coastal Plain Dune and Swale\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            376\n            \"Northern Atlantic Coastal Plain Heathland and Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            377\n            \"South Texas Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            378\n            \"South Texas Sand Sheet Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            379\n            \"Southwest Florida Dune and Coastal Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            380\n            \"North Pacific Coastal Cliff and Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            381\n            \"North Pacific Maritime Coastal Sand Dune and Strand\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            382\n            \"Northern California Coastal Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            383\n            \"Mediterranean California Coastal Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            384\n            \"Mediterranean California Northern Coastal Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            385\n            \"Mediterranean California Southern Coastal Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            386\n            \"Atlantic Coastal Plain Northern Sandy Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            387\n            \"Atlantic Coastal Plain Sea Island Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            388\n            \"Atlantic Coastal Plain Southern Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            389\n            \"Florida Panhandle Beach Vegetation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            390\n            \"Louisiana Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            391\n            \"Northern Atlantic Coastal Plain Sandy Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            392\n            \"Texas Coastal Bend Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            393\n            \"Upper Texas Coast Beach\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            394\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            395\n            \"Mediterranean California Serpentine Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            396\n            \"Mediterranean California Subalpine-Montane Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            397\n            \"North Pacific Bog and Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            398\n            \"Rocky Mountain Subalpine-Montane Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            399\n            \"Atlantic Coastal Plain Peatland Pocosin\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            400\n            \"Southern and Central Appalachian Bog and Fen\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            401\n            \"Atlantic Coastal Plain Central Fresh-Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            402\n            \"Atlantic Coastal Plain Embayed Region Tidal Freshwater Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            403\n            \"Atlantic Coastal Plain Northern Fresh and Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            404\n            \"Florida Big Bend Fresh-Oligohaline Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            405\n            \"Atlantic Coastal Plain Depression Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            406\n            \"Atlantic Coastal Plain Large Natural Lakeshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            407\n            \"Central Florida Herbaceous Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            408\n            \"Central Florida Herbaceous Seep\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            409\n            \"East Gulf Coastal Plain Savanna and Wet Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            410\n            \"East Gulf Coastal Plain Depression Pondshore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            411\n            \"Floridian Highlands Freshwater Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            412\n            \"Southern Coastal Plain Herbaceous Seepage Bog\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            413\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Clethra Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            414\n            \"Southern Coastal Plain Nonriverine Basin Swamp - Okefenokee Nupea Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            415\n            \"Texas-Louisiana Coastal Prairie Slough\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            416\n            \"Central Interior and Appalachian Shrub-Herbaceous Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            417\n            \"Great Lakes Coastal Marsh Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            418\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            419\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            420\n            \"Laurentian-Acadian Shrub-Herbaceous Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            421\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            422\n            \"Eastern Great Plains Wet Meadow, Prairie  and Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            423\n            \"Great Lakes Wet-Mesic Lakeplain Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            424\n            \"Great Plains Prairie Pothole\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            425\n            \"Western Great Plains Closed Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            426\n            \"Western Great Plains Depressional Wetland Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            427\n            \"Western Great Plains Open Freshwater Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            428\n            \"Cumberland Riverscour\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            429\n            \"Inter-Mountain Basins Interdunal Swale Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            430\n            \"North Pacific Avalanche Chute Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            431\n            \"North Pacific Intertidal Freshwater Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            432\n            \"Temperate Pacific Freshwater Emergent Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            433\n            \"Temperate Pacific Freshwater Mudflat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            434\n            \"Columbia Plateau Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            435\n            \"Northern California Claypan Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            436\n            \"Northern Rocky Mountain Wooded Vernal Pool\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            437\n            \"Columbia Plateau Silver Sagebrush Seasonally Flooded Shrub-Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            438\n            \"Rocky Mountain Alpine-Montane Wet Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            439\n            \"Rocky Mountain Subalpine-Montane Riparian Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            440\n            \"Temperate Pacific Montane Wet Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            441\n            \"Willamette Valley Wet Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            442\n            \"Chihuahuan-Sonoran Desert Bottomland and Swale Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            443\n            \"North American Arid West Emergent Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            444\n            \"North American Warm Desert Riparian Mesquite Bosque\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            445\n            \"Western Great Plains Saline Depression Wetland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            446\n            \"Acadian Salt Marsh and Estuary Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            447\n            \"Atlantic Coastal Plain Central Salt and Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            448\n            \"Atlantic Coastal Plain Embayed Region Tidal Salt and Brackish Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            449\n            \"Atlantic Coastal Plain Indian River Lagoon Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            450\n            \"Atlantic Coastal Plain Northern Tidal Salt Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            451\n            \"Florida Big Bend Salt-Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            452\n            \"Gulf and Atlantic Coastal Plain Tidal Marsh Systems\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            453\n            \"Mississippi Sound Salt and Brackish Tidal Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            454\n            \"Texas Saline Coastal Prairie\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            455\n            \"Temperate Pacific Tidal Salt and Brackish Marsh\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            456\n            \"Inter-Mountain Basins Alkaline Closed Depression\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            457\n            \"Inter-Mountain Basins Greasewood Flat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            458\n            \"Inter-Mountain Basins Playa\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            459\n            \"North American Warm Desert Playa\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            460\n            \"Apacherian-Chihuahuan Mesquite Upland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            461\n            \"Apacherian-Chihuahuan Semi-Desert Grassland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            462\n            \"Chihuahuan Creosotebush, Mixed Desert and Thorn Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            463\n            \"Chihuahuan Gypsophilous Grassland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            464\n            \"Chihuahuan Loamy Plains Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            465\n            \"Chihuahuan Mixed Desert and Thorn Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            466\n            \"Chihuahuan Sandy Plains Semi-Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            467\n            \"Chihuahuan Stabilized Coppice Dune and Sand Flat Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            468\n            \"Chihuahuan Succulent Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            469\n            \"Madrean Juniper Savanna\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            470\n            \"Mojave Mid-Elevation Mixed Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            471\n            \"North American Warm Desert Active and Stabilized Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            472\n            \"Sonora-Mojave Creosotebush-White Bursage Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            473\n            \"Sonoran Mid-Elevation Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            474\n            \"Sonoran Paloverde-Mixed Cacti Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            475\n            \"Chihuahuan Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            476\n            \"Sonora-Mojave Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            477\n            \"North American Warm Desert Wash\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            478\n            \"South Texas Lomas\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            479\n            \"Tamaulipan Calcareous Thornscrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            480\n            \"Tamaulipan Clay Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            481\n            \"Tamaulipan Mesquite Upland Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            482\n            \"Tamaulipan Mixed Deciduous Thornscrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            483\n            \"Tamaulipan Savanna Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            484\n            \"Inter-Mountain Basins Mat Saltbush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            485\n            \"Inter-Mountain Basins Mixed Salt Desert Scrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            486\n            \"Inter-Mountain Basins Wash\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            487\n            \"Columbia Plateau Steppe and Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            488\n            \"Great Basin Xeric Mixed Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            489\n            \"Inter-Mountain Basins Big Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            490\n            \"Inter-Mountain Basins Big Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            491\n            \"Inter-Mountain Basins Montane Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            492\n            \"Colorado Plateau Mixed Low Sagebrush Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            493\n            \"Columbia Plateau Low Sagebrush Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            494\n            \"Columbia Plateau Scabland Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            495\n            \"Wyoming Basins Dwarf Sagebrush Shrubland and Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            496\n            \"Colorado Plateau Blackbrush-Mormon-tea Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            497\n            \"Inter-Mountain Basins Semi-Desert Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            498\n            \"Inter-Mountain Basins Semi-Desert Shrub Steppe\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            499\n            \"Southern Colorado Plateau Sand Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            500\n            \"Acadian-Appalachian Alpine Tundra\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            501\n            \"Rocky Mountain Alpine Dwarf-Shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            502\n            \"Rocky Mountain Alpine Fell-Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            503\n            \"Rocky Mountain Alpine Turf\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            504\n            \"Mediterranean California Alpine Dry Tundra\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            505\n            \"Mediterranean California Alpine Fell-Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            506\n            \"North Pacific Dry and Mesic Alpine Dwarf-Shrubland, Fell-field and Meadow\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            507\n            \"Rocky Mountain Alpine Tundra/Fell-field/Dwarf-shrub Map Unit\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            508\n            \"Temperate Pacific Intertidal Mudflat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            509\n            \"Mediterranean California Eelgrass Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            510\n            \"North Pacific Maritime Eelgrass Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            511\n            \"South-Central Interior Large Floodplain - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            512\n            \"East Gulf Coastal Plain Large River Floodplain Forest - Herbaceous Modifier\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            513\n            \"Temperate Pacific Freshwater Aquatic Bed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            514\n            \"Central California Coast Ranges Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            515\n            \"Mediterranean California Serpentine Barrens\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            516\n            \"Southern California Coast Ranges Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            517\n            \"Central Interior Acidic Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            518\n            \"Central Interior Calcareous Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            519\n            \"East Gulf Coastal Plain Dry Chalk Bluff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            520\n            \"North-Central Appalachian Acidic Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            521\n            \"North-Central Appalachian Circumneutral Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            522\n            \"Southern Appalachian Montane Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            523\n            \"Southern Interior Acid Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            524\n            \"Southern Interior Calcareous Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            525\n            \"Southern Piedmont Cliff\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            526\n            \"Southern Appalachian Granitic Dome\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            527\n            \"Southern Appalachian Rocky Summit\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            528\n            \"Southern Piedmont Granite Flatrock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            529\n            \"Rocky Mountain Cliff, Canyon and Massive Bedrock\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            530\n            \"Klamath-Siskiyou Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            531\n            \"North Pacific Montane Massive Bedrock, Cliff and Talus\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            532\n            \"North Pacific Serpentine Barren\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            533\n            \"North Pacific Active Volcanic Rock and Cinder Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            534\n            \"Sierra Nevada Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            535\n            \"Western Great Plains Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            536\n            \"Southwestern Great Plains Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            537\n            \"Western Great Plains Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            538\n            \"North American Warm Desert Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            539\n            \"North American Warm Desert Bedrock Cliff and Outcrop\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            540\n            \"North American Warm Desert Pavement\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            541\n            \"North American Warm Desert Volcanic Rockland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            542\n            \"Colorado Plateau Mixed Bedrock Canyon and Tableland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            543\n            \"Columbia Plateau Ash and Tuff Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            544\n            \"Geysers and Hot Springs\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            545\n            \"Inter-Mountain Basins Active and Stabilized Dune\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            546\n            \"Inter-Mountain Basins Cliff and Canyon\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            547\n            \"Inter-Mountain Basins Shale Badland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            548\n            \"Inter-Mountain Basins Volcanic Rock and Cinder Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            549\n            \"Rocky Mountain Alpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            550\n            \"Mediterranean California Alpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            551\n            \"North Pacific Alpine and Subalpine Bedrock and Scree\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            552\n            \"Unconsolidated Shore\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            553\n            \"Undifferentiated Barren Land\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            554\n            \"North American Alpine Ice Field\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            555\n            \"Orchards Vineyards and Other High Structure Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            556\n            \"Cultivated Cropland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            557\n            \"Pasture/Hay\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            558\n            \"Introduced Upland Vegetation - Annual Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            559\n            \"Introduced Upland Vegetation - Perennial Grassland and Forbland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            560\n            \"Modified/Managed Southern Tall Grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            561\n            \"Introduced Upland Vegetation - Shrub\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            562\n            \"Introduced Riparian and Wetland Vegetation\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            563\n            \"Introduced Upland Vegetation - Treed\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            564\n            \"0\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            565\n            \"Disturbed, Non-specific\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            566\n            \"Recently Logged Areas\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            567\n            \"Harvested Forest - Grass/Forb Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            568\n            \"Harvested Forest-Shrub Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            569\n            \"Harvested Forest - Northwestern Conifer Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            570\n            \"Recently Burned\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            571\n            \"Recently burned grassland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            572\n            \"Recently burned shrubland\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            573\n            \"Recently burned forest\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            574\n            \"Disturbed/Successional - Grass/Forb Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            575\n            \"Disturbed/Successional - Shrub Regeneration\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            576\n            \"Disturbed/Successional - Recently Chained Pinyon-Juniper\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            577\n            \"Open Water (Aquaculture)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            578\n            \"Open Water (Brackish/Salt)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            579\n            \"Open Water (Fresh)\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            580\n            \"Quarries, Mines, Gravel Pits and Oil Wells\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            581\n            \"Developed, Open Space\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            582\n            \"Developed, Low Intensity\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            583\n            \"Developed, Medium Intensity\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            584\n            \"Developed, High Intensity\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        proj:transform[] 9 items\n        \n            \n        \n            \n                \n        \n            0\n            30.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -2361135.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -30.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            1762215.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2010-01-01T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            label:description\n            \"USGS GAP/LANDFIRE\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 5 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/gap/items/gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            data\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edataeuwest.blob.core.windows.net/usgs-gap/conus/gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215.tif?st=2024-11-30T18%3A35%3A39Z&se=2024-12-01T19%3A20%3A39Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-12-01T00%3A09%3A35Z&ske=2024-12-08T00%3A09%3A35Z&sks=b&skv=2024-05-04&sig=aUc2TLccpiHnSIgYhnNwCrOBPY7F/qUwzQ9JRVatljk%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoTIFF data\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215&assets=data&tile_format=png&colormap_name=gap-lulc&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=gap&item=gap_landfire_nationalterrestrialecosystems2011_-2361135_1762215_-2061135_1462215&assets=data&tile_format=png&colormap_name=gap-lulc&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"gap\""
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#explore-lulc-item-around-thomas-fire-perimeter",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#explore-lulc-item-around-thomas-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Explore LULC item around Thomas Fire perimeter",
    "text": "Explore LULC item around Thomas Fire perimeter\n\nitem = items[0]  # Select item\n\n# Display pre-rendered image\nImage(url=item.assets['rendered_preview'].href)\n\n\n\n\n\n# Access raster data from item\nlulc = rioxr.open_rasterio(item.assets['data'].href)\nlulc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 10000, x: 10000)&gt; Size: 200MB\n[100000000 values with dtype=uint16]\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 80kB -2.361e+06 -2.361e+06 ... -2.061e+06\n  * y            (y) float64 80kB 1.762e+06 1.762e+06 ... 1.462e+06 1.462e+06\n    spatial_ref  int64 8B 0\nAttributes:\n    TIFFTAG_SOFTWARE:        ERDAS IMAGINE\n    TIFFTAG_XRESOLUTION:     1\n    TIFFTAG_YRESOLUTION:     1\n    TIFFTAG_RESOLUTIONUNIT:  2 (pixels/inch)\n    AREA_OR_POINT:           Area\n    scale_factor:            1.0\n    add_offset:              0.0xarray.DataArrayband: 1y: 10000x: 10000...[100000000 values with dtype=uint16]Coordinates: (4)band(band)int641array([1])x(x)float64-2.361e+06 ... -2.061e+06array([-2361120., -2361090., -2361060., ..., -2061210., -2061180., -2061150.])y(y)float641.762e+06 1.762e+06 ... 1.462e+06array([1762200., 1762170., 1762140., ..., 1462290., 1462260., 1462230.])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / Conus Albersgrid_mapping_name :albers_conical_equal_areastandard_parallel :(29.5, 45.5)latitude_of_projection_origin :23.0longitude_of_central_meridian :-96.0false_easting :0.0false_northing :0.0spatial_ref :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]GeoTransform :-2361135.0 30.0 0.0 1762215.0 0.0 -30.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([-2361120.0, -2361090.0, -2361060.0, -2361030.0, -2361000.0, -2360970.0,\n       -2360940.0, -2360910.0, -2360880.0, -2360850.0,\n       ...\n       -2061420.0, -2061390.0, -2061360.0, -2061330.0, -2061300.0, -2061270.0,\n       -2061240.0, -2061210.0, -2061180.0, -2061150.0],\n      dtype='float64', name='x', length=10000))yPandasIndexPandasIndex(Index([1762200.0, 1762170.0, 1762140.0, 1762110.0, 1762080.0, 1762050.0,\n       1762020.0, 1761990.0, 1761960.0, 1761930.0,\n       ...\n       1462500.0, 1462470.0, 1462440.0, 1462410.0, 1462380.0, 1462350.0,\n       1462320.0, 1462290.0, 1462260.0, 1462230.0],\n      dtype='float64', name='y', length=10000))Attributes: (7)TIFFTAG_SOFTWARE :ERDAS IMAGINETIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1TIFFTAG_RESOLUTIONUNIT :2 (pixels/inch)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\nLet‚Äôs visually explore the extent of the lulc23 tile relative to the CA boundary:\n\n# Create GeoDataFrame from raster bounding box\nlulc_bbox = gpd.GeoDataFrame(geometry = [box(*lulc.rio.bounds())],\n                 crs = lulc.rio.crs)\nca = gpd.read_file('data/ca_state_boundary/ca_state_boundary.shp')\n\n# Plot raster boundary, fire perimeter, and CA boundary\nfig, ax = plt.subplots()\nca.plot(ax=ax, color='white', edgecolor ='black')\nlulc_bbox.to_crs(ca.crs).plot(ax=ax, alpha=0.3)   # Reproject to match CA crs\nthomas_fire.to_crs(ca.crs).plot(ax=ax, color='red')\nplt.show()"
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#clip-raster-to-fire-perimeter",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#clip-raster-to-fire-perimeter",
    "title": "Import Thomas fire perimeter",
    "section": "Clip raster to fire perimeter",
    "text": "Clip raster to fire perimeter\nFirst, we need to ensure our raster and fire perimeter have the same CRS.\n\nthomas_fire_match = thomas_fire.to_crs(lulc.rio.crs)\nassert thomas_fire_match.crs == lulc.rio.crs\n\nClipping directly with the fire perimeter is computationally expensive. It is best to first reduce with the thomas_fire bounding box, and then clip to the actual fire perimeter.\n\nlulc_clip = lulc.rio.clip_box(*thomas_fire_match.total_bounds)\n\n\nlulc_clip.plot()\n\n\n\n\n\n\n\n\n\nlulc_thomasfire = lulc_clip.rio.clip(thomas_fire_match.geometry)\n\n/Users/galaz-garcia/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/xarray/core/duck_array_ops.py:215: RuntimeWarning: invalid value encountered in cast\n  return data.astype(dtype, **kwargs)\n\n\n\nlulc_thomasfire.plot()\n\n\n\n\n\n\n\n\n\nlulc_clip = lulc_clip.rio.write_nodata(0)\nlulc_clip.rio.nodata\n\n0\n\n\n\nlulc_thomasfire = lulc_clip.rio.clip(thomas_fire_match.geometry)\n\n\nlulc_thomasfire.plot()\n\n\n\n\n\n\n\n\n\nlulc_clip.dtype\n\ndtype('uint16')"
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#save-and-reopen",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#save-and-reopen",
    "title": "Import Thomas fire perimeter",
    "section": "Save and reopen",
    "text": "Save and reopen\n\nlulc_thomasfire.rio.to_raster('USGS_National_Terrestrial_Ecosystems_Over_Thomas_Fire_Perimeter.tif')\n\n\nreopen = rioxr.open_rasterio('USGS_National_Terrestrial_Ecosystems_Over_Thomas_Fire_Perimeter.tif')\nreopen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 1434, x: 2228)&gt; Size: 6MB\n[3194952 values with dtype=uint16]\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 18kB -2.136e+06 -2.136e+06 ... -2.07e+06 -2.07e+06\n  * y            (y) float64 11kB 1.548e+06 1.548e+06 ... 1.505e+06 1.505e+06\n    spatial_ref  int64 8B 0\nAttributes:\n    TIFFTAG_SOFTWARE:        ERDAS IMAGINE\n    TIFFTAG_XRESOLUTION:     1\n    TIFFTAG_YRESOLUTION:     1\n    TIFFTAG_RESOLUTIONUNIT:  2 (pixels/inch)\n    AREA_OR_POINT:           Area\n    _FillValue:              0\n    scale_factor:            1.0\n    add_offset:              0.0xarray.DataArrayband: 1y: 1434x: 2228...[3194952 values with dtype=uint16]Coordinates: (4)band(band)int641array([1])x(x)float64-2.136e+06 -2.136e+06 ... -2.07e+06array([-2136450., -2136420., -2136390., ..., -2069700., -2069670., -2069640.])y(y)float641.548e+06 1.548e+06 ... 1.505e+06array([1547610., 1547580., 1547550., ..., 1504680., 1504650., 1504620.])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / Conus Albersgrid_mapping_name :albers_conical_equal_areastandard_parallel :(29.5, 45.5)latitude_of_projection_origin :23.0longitude_of_central_meridian :-96.0false_easting :0.0false_northing :0.0spatial_ref :PROJCS[\"NAD83 / Conus Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"5070\"]]GeoTransform :-2136465.0 30.0 0.0 1547625.0 0.0 -30.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([-2136450.0, -2136420.0, -2136390.0, -2136360.0, -2136330.0, -2136300.0,\n       -2136270.0, -2136240.0, -2136210.0, -2136180.0,\n       ...\n       -2069910.0, -2069880.0, -2069850.0, -2069820.0, -2069790.0, -2069760.0,\n       -2069730.0, -2069700.0, -2069670.0, -2069640.0],\n      dtype='float64', name='x', length=2228))yPandasIndexPandasIndex(Index([1547610.0, 1547580.0, 1547550.0, 1547520.0, 1547490.0, 1547460.0,\n       1547430.0, 1547400.0, 1547370.0, 1547340.0,\n       ...\n       1504890.0, 1504860.0, 1504830.0, 1504800.0, 1504770.0, 1504740.0,\n       1504710.0, 1504680.0, 1504650.0, 1504620.0],\n      dtype='float64', name='y', length=1434))Attributes: (8)TIFFTAG_SOFTWARE :ERDAS IMAGINETIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1TIFFTAG_RESOLUTIONUNIT :2 (pixels/inch)AREA_OR_POINT :Area_FillValue :0scale_factor :1.0add_offset :0.0\n\n\n\nreopen.plot()"
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#reprojection",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#reprojection",
    "title": "Import Thomas fire perimeter",
    "section": "Reprojection",
    "text": "Reprojection\n\nreprojected = lulc_thomasfire.rio.reproject(thomas_fire.crs)\n\n\n## How does the reprojection affect the data values?\nnp.unique(reprojected)\n\narray([  0,  39,  40,  41,  42,  43,  45,  55, 159, 162, 165, 183, 277,\n       278, 282, 296, 297, 300, 302, 303, 304, 305, 359, 360, 383, 385,\n       432, 470, 472, 485, 489, 516, 539, 540, 547, 552, 553, 556, 557,\n       558, 567, 568, 578, 579, 581, 582, 583, 584], dtype=uint16)\n\n\n\nreprojected.plot()"
  },
  {
    "objectID": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#land-cover-statistics",
    "href": "book/chapters/lesson-17-raster-wrangling/lulc_cover_USGS_GAP.html#land-cover-statistics",
    "title": "Import Thomas fire perimeter",
    "section": "Land cover statistics",
    "text": "Land cover statistics\n\nlabels = pd.read_csv('data/GAP_National_Terrestrial_Ecosystems.csv')\nlabels.head()\n\n\n\n\n\n\n\n\nclass_label\ncode\n\n\n\n\n0\n0\n0\n\n\n1\nSouth Florida Bayhead Swamp\n1\n\n\n2\nSouth Florida Cypress Dome\n2\n\n\n3\nSouth Florida Dwarf Cypress Savanna\n3\n\n\n4\nSouth Florida Mangrove Swamp\n4\n\n\n\n\n\n\n\n\nunique_counts = np.unique(lulc_thomasfire, return_counts=True)\n\npix_counts = pd.DataFrame({'code':unique_counts[0], \n                           'n_pixels':unique_counts[1]})\npix_counts = pix_counts[pix_counts['code']!=0]\npix_counts\n\n\n\n\n\n\n\n\ncode\nn_pixels\n\n\n\n\n1\n39\n6856\n\n\n2\n40\n361\n\n\n3\n41\n133704\n\n\n4\n42\n3638\n\n\n5\n43\n23150\n\n\n6\n45\n2907\n\n\n7\n55\n4974\n\n\n8\n159\n3727\n\n\n9\n162\n60203\n\n\n10\n165\n5102\n\n\n11\n183\n75925\n\n\n12\n277\n378\n\n\n13\n278\n11098\n\n\n14\n282\n29\n\n\n15\n296\n98\n\n\n16\n297\n64072\n\n\n17\n300\n69700\n\n\n18\n302\n183963\n\n\n19\n303\n454489\n\n\n20\n304\n88504\n\n\n21\n305\n799\n\n\n22\n359\n750\n\n\n23\n360\n684\n\n\n24\n383\n28\n\n\n25\n385\n90\n\n\n26\n432\n865\n\n\n27\n470\n262\n\n\n28\n472\n1329\n\n\n29\n485\n54\n\n\n30\n489\n44\n\n\n31\n516\n27\n\n\n32\n539\n298\n\n\n33\n540\n24\n\n\n34\n547\n15\n\n\n35\n552\n43\n\n\n36\n553\n7\n\n\n37\n556\n18996\n\n\n38\n557\n2181\n\n\n39\n558\n485\n\n\n40\n567\n13\n\n\n41\n568\n20\n\n\n42\n578\n10\n\n\n43\n579\n1858\n\n\n44\n581\n40653\n\n\n45\n582\n3782\n\n\n46\n583\n829\n\n\n47\n584\n58\n\n\n\n\n\n\n\n\nclasses = pd.merge(left=labels, \n                   right=pix_counts, \n                   on='code')\nclasses\n\n\n\n\n\n\n\n\nclass_label\ncode\nn_pixels\n\n\n\n\n0\nCalifornia Central Valley Mixed Oak Savanna\n39\n6856\n\n\n1\nCalifornia Coastal Closed-Cone Conifer Forest ...\n40\n361\n\n\n2\nCalifornia Coastal Live Oak Woodland and Savanna\n41\n133704\n\n\n3\nCalifornia Lower Montane Blue Oak-Foothill Pin...\n42\n3638\n\n\n4\nCentral and Southern California Mixed Evergree...\n43\n23150\n\n\n5\nSouthern California Oak Woodland and Savanna\n45\n2907\n\n\n6\nMediterranean California Mixed Evergreen Forest\n55\n4974\n\n\n7\nCalifornia Montane Jeffrey Pine-(Ponderosa Pin...\n159\n3727\n\n\n8\nMediterranean California Dry-Mesic Mixed Conif...\n162\n60203\n\n\n9\nCalifornia Coastal Redwood Forest\n165\n5102\n\n\n10\nGreat Basin Pinyon-Juniper Woodland\n183\n75925\n\n\n11\nCalifornia Central Valley Riparian Woodland an...\n277\n378\n\n\n12\nMediterranean California Foothill and Lower Mo...\n278\n11098\n\n\n13\nNorth American Warm Desert Riparian Woodland a...\n282\n29\n\n\n14\nCalifornia Maritime Chaparral\n296\n98\n\n\n15\nCalifornia Mesic Chaparral\n297\n64072\n\n\n16\nMediterranean California Mesic Serpentine Wood...\n300\n69700\n\n\n17\nSouthern California Dry-Mesic Chaparral\n302\n183963\n\n\n18\nSouthern California Coastal Scrub\n303\n454489\n\n\n19\nCalifornia Central Valley and Southern Coastal...\n304\n88504\n\n\n20\nCalifornia Mesic Serpentine Grassland\n305\n799\n\n\n21\nSonora-Mojave Semi-Desert Chaparral\n359\n750\n\n\n22\nCalifornia Montane Woodland and Chaparral\n360\n684\n\n\n23\nMediterranean California Coastal Bluff\n383\n28\n\n\n24\nMediterranean California Southern Coastal Dune\n385\n90\n\n\n25\nTemperate Pacific Freshwater Emergent Marsh\n432\n865\n\n\n26\nMojave Mid-Elevation Mixed Desert Scrub\n470\n262\n\n\n27\nSonora-Mojave Creosotebush-White Bursage Deser...\n472\n1329\n\n\n28\nInter-Mountain Basins Mixed Salt Desert Scrub\n485\n54\n\n\n29\nInter-Mountain Basins Big Sagebrush Shrubland\n489\n44\n\n\n30\nSouthern California Coast Ranges Cliff and Canyon\n516\n27\n\n\n31\nNorth American Warm Desert Bedrock Cliff and O...\n539\n298\n\n\n32\nNorth American Warm Desert Pavement\n540\n24\n\n\n33\nInter-Mountain Basins Shale Badland\n547\n15\n\n\n34\nUnconsolidated Shore\n552\n43\n\n\n35\nUndifferentiated Barren Land\n553\n7\n\n\n36\nCultivated Cropland\n556\n18996\n\n\n37\nPasture/Hay\n557\n2181\n\n\n38\nIntroduced Upland Vegetation - Annual Grassland\n558\n485\n\n\n39\nHarvested Forest - Grass/Forb Regeneration\n567\n13\n\n\n40\nHarvested Forest-Shrub Regeneration\n568\n20\n\n\n41\nOpen Water (Brackish/Salt)\n578\n10\n\n\n42\nOpen Water (Fresh)\n579\n1858\n\n\n43\nDeveloped, Open Space\n581\n40653\n\n\n44\nDeveloped, Low Intensity\n582\n3782\n\n\n45\nDeveloped, Medium Intensity\n583\n829\n\n\n46\nDeveloped, High Intensity\n584\n58\n\n\n\n\n\n\n\n\n# What percentage of the area defined by the fire perimeter was estimated to be developed (categories 44-47)\narea_per_pixel = 30**2  # In meters^2\nclasses.iloc[43:47].n_pixels.sum() * area_per_pixel / 1000**2\n\n40.7898\n\n\n\n# What were the top 10 habitats most affected by the fire ? OR sth like that\n\n\ntotal_pixels = classes.n_pixels.sum()\ntotal_pixels\n\n1267082\n\n\n\n\n\nObject `classes.order` not found.\n\n\n\nclasses['percentage'] = classes.n_pixels/total_pixels * 100\n\n\n\n\n\n\n\n\nclass_label\ncode\nn_pixels\npercentage\n\n\n\n\n0\nCalifornia Central Valley Mixed Oak Savanna\n39\n6856\n0.541086\n\n\n1\nCalifornia Coastal Closed-Cone Conifer Forest ...\n40\n361\n0.028491\n\n\n2\nCalifornia Coastal Live Oak Woodland and Savanna\n41\n133704\n10.552119\n\n\n3\nCalifornia Lower Montane Blue Oak-Foothill Pin...\n42\n3638\n0.287116\n\n\n4\nCentral and Southern California Mixed Evergree...\n43\n23150\n1.827033\n\n\n5\nSouthern California Oak Woodland and Savanna\n45\n2907\n0.229425\n\n\n6\nMediterranean California Mixed Evergreen Forest\n55\n4974\n0.392555\n\n\n7\nCalifornia Montane Jeffrey Pine-(Ponderosa Pin...\n159\n3727\n0.294140\n\n\n8\nMediterranean California Dry-Mesic Mixed Conif...\n162\n60203\n4.751310\n\n\n9\nCalifornia Coastal Redwood Forest\n165\n5102\n0.402657\n\n\n10\nGreat Basin Pinyon-Juniper Woodland\n183\n75925\n5.992114\n\n\n11\nCalifornia Central Valley Riparian Woodland an...\n277\n378\n0.029832\n\n\n12\nMediterranean California Foothill and Lower Mo...\n278\n11098\n0.875871\n\n\n13\nNorth American Warm Desert Riparian Woodland a...\n282\n29\n0.002289\n\n\n14\nCalifornia Maritime Chaparral\n296\n98\n0.007734\n\n\n15\nCalifornia Mesic Chaparral\n297\n64072\n5.056658\n\n\n16\nMediterranean California Mesic Serpentine Wood...\n300\n69700\n5.500828\n\n\n17\nSouthern California Dry-Mesic Chaparral\n302\n183963\n14.518634\n\n\n18\nSouthern California Coastal Scrub\n303\n454489\n35.868949\n\n\n19\nCalifornia Central Valley and Southern Coastal...\n304\n88504\n6.984868\n\n\n20\nCalifornia Mesic Serpentine Grassland\n305\n799\n0.063058\n\n\n21\nSonora-Mojave Semi-Desert Chaparral\n359\n750\n0.059191\n\n\n22\nCalifornia Montane Woodland and Chaparral\n360\n684\n0.053982\n\n\n23\nMediterranean California Coastal Bluff\n383\n28\n0.002210\n\n\n24\nMediterranean California Southern Coastal Dune\n385\n90\n0.007103\n\n\n25\nTemperate Pacific Freshwater Emergent Marsh\n432\n865\n0.068267\n\n\n26\nMojave Mid-Elevation Mixed Desert Scrub\n470\n262\n0.020677\n\n\n27\nSonora-Mojave Creosotebush-White Bursage Deser...\n472\n1329\n0.104887\n\n\n28\nInter-Mountain Basins Mixed Salt Desert Scrub\n485\n54\n0.004262\n\n\n29\nInter-Mountain Basins Big Sagebrush Shrubland\n489\n44\n0.003473\n\n\n30\nSouthern California Coast Ranges Cliff and Canyon\n516\n27\n0.002131\n\n\n31\nNorth American Warm Desert Bedrock Cliff and O...\n539\n298\n0.023519\n\n\n32\nNorth American Warm Desert Pavement\n540\n24\n0.001894\n\n\n33\nInter-Mountain Basins Shale Badland\n547\n15\n0.001184\n\n\n34\nUnconsolidated Shore\n552\n43\n0.003394\n\n\n35\nUndifferentiated Barren Land\n553\n7\n0.000552\n\n\n36\nCultivated Cropland\n556\n18996\n1.499193\n\n\n37\nPasture/Hay\n557\n2181\n0.172128\n\n\n38\nIntroduced Upland Vegetation - Annual Grassland\n558\n485\n0.038277\n\n\n39\nHarvested Forest - Grass/Forb Regeneration\n567\n13\n0.001026\n\n\n40\nHarvested Forest-Shrub Regeneration\n568\n20\n0.001578\n\n\n41\nOpen Water (Brackish/Salt)\n578\n10\n0.000789\n\n\n42\nOpen Water (Fresh)\n579\n1858\n0.146636\n\n\n43\nDeveloped, Open Space\n581\n40653\n3.208395\n\n\n44\nDeveloped, Low Intensity\n582\n3782\n0.298481\n\n\n45\nDeveloped, Medium Intensity\n583\n829\n0.065426\n\n\n46\nDeveloped, High Intensity\n584\n58\n0.004577\n\n\n\n\n\n\n\n\nclasses = classes.sort_values(by='percentage', ascending=True)\n\n\nclasses[classes['percentage']&gt;1].set_index('class_label').percentage.plot(kind='barh')\n\n\n\n\n\n\n\n\n\n# Filter and set index as in the original code\nfiltered_classes = classes[classes['percentage'] &gt; 1].set_index('class_label')\n\n# Create the horizontal plot\nax = filtered_classes.percentage.plot(kind='barh', \n            figsize=(8, 6), \n            color='skyblue', \n            edgecolor='black')\n\n# Add title and axis labels\nax.set_title('Land cover within Thomas Fire perimeter (Classes &gt; 1% from USGS National Terrestrial Ecosystems data)', \n            fontsize=14, \n            pad=15\n            )\nax.set_xlabel('Percentage (%)', fontsize=12)\nax.set_ylabel('')\n\n# Add gridlines for easier interpretation\nax.grid(axis='x', linestyle='--', alpha=0.7)\n\n# Add percentage values to the bars\nfor i, v in enumerate(filtered_classes.percentage):\n    ax.text(v + 0.5, i, f\"{v:.1f}%\", va='center', fontsize=10)\n\n# Adjust layout for better spacing\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Filter and set index as in the original code\nfiltered_classes = classes[classes['percentage'] &gt; 1].set_index('class_label')\n\n# Create the horizontal bar plot\nfig, ax = plt.subplots(figsize=(10, 6))  # Adjusted figure size for better proportions\n\n# Plot with improved style\nfiltered_classes.percentage.plot(\n    kind='barh',\n    ax=ax,\n    color='skyblue',\n    edgecolor='black'\n)\n\n# Add title and axis labels\nax.set_title(\n    'Land cover within Thomas Fire perimeter (Classes &gt; 1% from USGS National Terrestrial Ecosystems data)',\n    fontsize=14,\n    pad=15\n)\nax.set_xlabel('Percentage (%)', fontsize=12)\nax.set_ylabel('')  # No label for y-axis\n\n# Add gridlines for easier interpretation\nax.grid(axis='x', linestyle='--', alpha=0.7)\n\n# Add percentage values to the bars\nfor i, v in enumerate(filtered_classes.percentage):\n    ax.text(v + 0.5, i, f\"{v:.1f}%\", va='center', fontsize=10)\n\n# Make the axis box wider relative to the figure area\nfig.subplots_adjust(left=0.25, right=0.95)  # Adjust space around the plot\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter and set index as in the original code\nfiltered_classes = classes[classes['percentage'] &gt; 1].set_index('class_label')\n\n# Create the horizontal bar plot\nfig, ax = plt.subplots(figsize=(10, 6))  # Adjusted figure size for better proportions\n\n# Plot with improved style\nfiltered_classes.percentage.plot(\n    kind='barh',\n    ax=ax,\n    color='skyblue',\n    edgecolor='black'\n)\n\n# Add an improved title and center it relative to the entire figure\nfig.suptitle(\n    'Distribution of Land Cover Within the Thomas Fire Perimeter\\n(Classes &gt; 1% from USGS National Terrestrial Ecosystems Data)',\n    fontsize=16,\n    y=0.98  # Adjust position slightly for spacing\n)\n\n# Add axis labels\nax.set_xlabel('Percentage (%)', fontsize=12)\nax.set_ylabel('')  # No label for y-axis\n\n# Add gridlines for easier interpretation\nax.grid(axis='x', linestyle='--', alpha=0.7)\n\n# Add percentage values to the bars\nfor i, v in enumerate(filtered_classes.percentage):\n    ax.text(v + 0.5, i, f\"{v:.1f}%\", va='center', fontsize=10)\n\n# Remove top and right edges of the plot\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Make the axis box wider relative to the figure area\nfig.subplots_adjust(left=0.25, right=0.95, top=0.85)  # Adjust spacing for the centered title\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n&lt;!--\n```{python}\n# Filter and set index as in the original code\nfiltered_classes = classes[classes['percentage']&gt;1].set_index('class_label')\n\n# Create the horizontal bar plot\nfig, ax = plt.subplots(figsize=(10, 6))  # Adjusted figure size for better proportions\n\n# Plot with improved style\nfiltered_classes.percentage.plot(\n    kind='barh',\n    ax=ax,\n    color='skyblue',\n    edgecolor='black'\n)\n\n# Add an improved title and center it relative to the entire figure\nfig.suptitle(\n    'Distribution of Land Cover Within the Thomas Fire Perimeter\\n(Classes &gt; 1% from USGS National Terrestrial Ecosystems Data)',\n    fontsize=16,\n    y=0.98  # Adjust position slightly for spacing\n)\n\n# Add axis labels\nax.set_xlabel('Percentage (%)', fontsize=12)\nax.set_ylabel('')  # No label for y-axis\n\n# Add gridlines for easier interpretation\nax.grid(axis='x', linestyle='--', alpha=0.7)\n\n# Add percentage values to the bars\nfor i, v in enumerate(filtered_classes.percentage):\n    ax.text(v + 0.5, i, f\"{v:.1f}%\", va='center', fontsize=10)\n\n# Remove top and right edges of the plot\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Make the axis box wider relative to the figure area\nfig.subplots_adjust(left=0.25, right=0.95, top=0.85)  # Adjust spacing for the centered title\n\n# Show the plot\nplt.show()\n\n\n  Cell In[82], line 1\n    &lt;!--\n    ^\nSyntaxError: invalid syntax"
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html",
    "title": "10 Streamline your code",
    "section": "",
    "text": "In this lesson we will learn how to extract geospatial data from a CSV to create a geopandas.GeoDataFrame, introduce more customizations for maps and matplotlib figures, and go over strategies to streamline our code.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#about-the-data",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#about-the-data",
    "title": "10 Streamline your code",
    "section": "About the data",
    "text": "About the data\nThe U.S. energy landscape relies on a mix of fossil fuels and renewables, each with unique environmental and economic impacts. As the nation works toward sustainability and energy security, understanding this energy mix is essential for informed policy and progress toward cleaner energy.\nIn this lesson, we will use data from the U.S. Energy Information Administration (EIA) about operable electric generating plants in the United States by energy source, as of May 2023. The dataset includes information on plant types and energy sources, offering insights into the diversity of power sources‚Äîfrom fossil fuels to renewables‚Äîthat supply electricity nationwide. The dataset‚Äôs metadata can be accessed here   The EIA data on electric plants has been downloaded as a CSV and reprojected into the EPSG:4269 CRS for this lesson. It can be accessed here.\n\nAdditionally, we will use a TIGER shapefile of the US states from the United States Census Bureau. TIGER stands for Topologically Integrated Geographic Encoding and Referencing. This used to be the data format the US Census distributed geospatial data, but since 2008 TIGER files are converted to shapefiles. You can view the metadata for all the TIGER shapefiles here.\nFollow these steps to download shapefile with the United States‚Äô states:\n\nAt the bottom of the 2022 page, under Download, click on ‚ÄúWeb Interface‚Äù\nFor year, select 2022, and for layer type select ‚ÄúStates (and equivalent)‚Äù. Click submit.\nClick on ‚ÄúDownload national file‚Äù.\n\nThe column descriptions for the US states shapefile are:\n\n\n\nSource: TIGER/Line Shapefiles Technical Documentation",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#csv-to-geopandas.geodataframe",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#csv-to-geopandas.geodataframe",
    "title": "10 Streamline your code",
    "section": "CSV to geopandas.GeoDataFrame",
    "text": "CSV to geopandas.GeoDataFrame\nLet‚Äôs start by importing packages and updating viewing options:\n\nimport os\n\nimport pandas as pd\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n\n# Display all columns when looking at dataframes\npd.set_option(\"display.max.columns\", None)\n\nNext, we import the power plants dataset. In this lesson, we have downloaded the data into a data/ folder in the same level as our notebook.\n\n# Import power plants data\nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/refs/heads/main/data/power_plants_epsg4269.csv'\npower_plants = pd.read_csv(URL)\n\n# Simpify column names\npower_plants.columns = power_plants.columns.str.lower()\n\n# Drop first column\npower_plants = power_plants.drop(columns='unnamed: 0')\n\npower_plants.head(3)\n\n\n\n\n\n\n\n\nobjectid\nplant_code\nplant_name\nutility_id\nutility_name\nsector_name\nstreet_address\ncity\ncounty\nstate\nzip\nprimsource\nsource_desc\ntech_desc\ninstall_mw\ntotal_mw\nbat_mw\nbio_mw\ncoal_mw\ngeo_mw\nhydro_mw\nhydrops_mw\nng_mw\nnuclear_mw\ncrude_mw\nsolar_mw\nwind_mw\nother_mw\nsource\nperiod\nlongitude\nlatitude\n\n\n\n\n0\n11570\n1\nSand Point\n63560\nTDX Sand Point Generating, LLC\nElectric Utility\n100 Power Plant Way\nSand Point\nAleutians East\nAlaska\n99661.0\npetroleum\nPetroleum = 1.3 MW, Wind = 0.4 MW\nPetroleum Liquids; Onshore Wind Turbine;\n3.7\n1.7\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.3\nNaN\n0.4\nNaN\nEIA-860, EIA-860M and EIA-923\n202305.0\n-160.497222\n55.339722\n\n\n1\n11571\n2\nBankhead Dam\n195\nAlabama Power Co\nElectric Utility\n19001 Lock 17 Road\nNorthport\nTuscaloosa\nAlabama\n35476.0\nhydroelectric\nHydroelectric = 53 MW\nConventional Hydroelectric\n53.9\n53.0\nNaN\nNaN\nNaN\nNaN\n53.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nEIA-860, EIA-860M and EIA-923\n202305.0\n-87.356823\n33.458665\n\n\n2\n11572\n3\nBarry\n195\nAlabama Power Co\nElectric Utility\nNorth Highway 43\nBucks\nMobile\nAlabama\n36512.0\nnatural gas\nCoal = 1118.5 MW, Natural Gas = 1296.2 MW\nConventional Steam Coal; Natural Gas Fired Com...\n2569.5\n2414.7\nNaN\nNaN\n1118.5\nNaN\nNaN\nNaN\n1296.2\nNaN\nNaN\nNaN\nNaN\nNaN\nEIA-860, EIA-860M and EIA-923\n202305.0\n-88.010300\n31.006900\n\n\n\n\n\n\n\n\nThe power plants file is a CSV. Unlike shapefiles or other geospatial file formats, geopandas doesn‚Äôt have a way to extract a geometry column from a CSV file, so we will need to create this geometry manually.\nTo do so we will use the longitude and latitude columns in the CSV, these indicate the location of the power plants in the NAD83 CRS (EPSG:4269). We can use this information to create a new geopandas.GeoDataFrame from the pandas.DataFrame using the geopandas function points_from_xy():\n\n# Create points from latitude and longitude\npoints = gpd.points_from_xy(power_plants.longitude, \n                            power_plants.latitude)\n\n# Create geodataframe\npower_plants = gpd.GeoDataFrame(power_plants,    # Data\n                                geometry=points, # Specify geometry column\n                                crs='EPSG:4269'  # Specify CRS\n                                )\n\nLet‚Äôs check that we now have a geometry column:\n\npower_plants['geometry']\n\n0        POINT (-160.49722 55.33972)\n1         POINT (-87.35682 33.45867)\n2         POINT (-88.01030 31.00690)\n3         POINT (-86.28306 32.58389)\n4        POINT (-106.37500 31.75690)\n                    ...             \n12004     POINT (-82.37595 35.38014)\n12005     POINT (-79.36770 36.00932)\n12006     POINT (-79.73631 35.27343)\n12007     POINT (-73.91048 42.87657)\n12008     POINT (-77.27590 41.83800)\nName: geometry, Length: 12009, dtype: geometry\n\n\nWith the geometry column and CRS, we can plot our dataset:\n\npower_plants.plot()",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#f-strings",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#f-strings",
    "title": "10 Streamline your code",
    "section": "f-strings",
    "text": "f-strings\nSo far, we have printed variables using string concatenation inside the print() function. This means that we write commas between every string and variable we want to print, and then the print() function concatenates these into a single string. For example:\n\nprint('CRS: ', power_plants.crs)\n\nCRS:  EPSG:4269\n\n\nAnother popular way of mixing strings and variables in print statements is by creating an f-string which stands for ‚Äúformatted string‚Äù. The simplest syntax for an f-string is:\nf\" some text {replace}\"\nwhere replace can be a variable, an expression, or a function or method call. For example:\n\n# Explore CRS\nprint(f\"ellipsoid: {power_plants.crs.ellipsoid}\")\nprint(f\"datum: {power_plants.crs.datum}\")\n\nellipsoid: GRS 1980\ndatum: North American Datum 1983\n\n\nWe just created a string replacing the value inside the curly brackets {}.\nOne of the advantages of using f-strings is that they offer customization for formatting the output:\n\n# Set the label width to 25 characters, aligning the answers\nprint(f\"{'Is the CRS geographic?:':&lt;25} {power_plants.crs.is_geographic}\")\nprint(f\"{'Is the CRS projected?:':&lt;25} {power_plants.crs.is_projected}\")\n\nIs the CRS geographic?:   True\nIs the CRS projected?:    False\n\n\n\n\n\n\n\n\nUse f-strings or not?\n\n\n\nWhether you use an f-string or simply concatenate strings with variables inside your print statements depends entirely on the application. For quickly checking a variable, a print statement might be enough, while using f-strings can be better to include custom messages during runtime. The best tool can be different depending on the task!\nThese are some good resources to learn more about f-string formatting:\n\nReal Python - Python‚Äôs F-String for String Interpolation and Formatting\nPython documentation- Format Specification Mini-Language",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#import-shapefile",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#import-shapefile",
    "title": "10 Streamline your code",
    "section": "Import shapefile",
    "text": "Import shapefile\nLet‚Äôs import the TIGER shapefile\n\n# Import states data\nfp = os.path.join('data','tl_2022_us_state','tl_2022_us_state.shp')\nstates = gpd.read_file(fp)\n\n# Simplify column names \nstates.columns = states.columns.str.lower()\n\nstates.head(3)\n\n\n\n\n\n\n\n\nregion\ndivision\nstatefp\nstatens\ngeoid\nstusps\nname\nlsad\nmtfcc\nfuncstat\naland\nawater\nintptlat\nintptlon\ngeometry\n\n\n\n\n0\n3\n5\n54\n01779805\n54\nWV\nWest Virginia\n00\nG4000\nA\n62266456923\n489045863\n+38.6472854\n-080.6183274\nPOLYGON ((-77.75438 39.33346, -77.75422 39.333...\n\n\n1\n3\n5\n12\n00294478\n12\nFL\nFlorida\n00\nG4000\nA\n138962819934\n45971472526\n+28.3989775\n-082.5143005\nMULTIPOLYGON (((-83.10874 24.62949, -83.10711 ...\n\n\n2\n2\n3\n17\n01779784\n17\nIL\nIllinois\n00\nG4000\nA\n143778515726\n6216539665\n+40.1028754\n-089.1526108\nPOLYGON ((-87.89243 38.28285, -87.89334 38.282...\n\n\n\n\n\n\n\nand obtain some preliminary geospatial information about the states geodataframe:\n\nprint(states.crs)\nstates.plot()\n\nEPSG:4269",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#for-loops",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#for-loops",
    "title": "10 Streamline your code",
    "section": "for loops",
    "text": "for loops\nIt can be easier to work with the codes as numbers instead of strings, so let‚Äôs update the corresponding columns in the states geo-dataframe. We start by checking the data type of the region, division, and statefp columns:\n\n code_cols = ['region', 'division', 'statefp']\n\n# Check whether codes columns are strings\n for column in code_cols: \n    print(f\"{column} is string dtype? {is_string_dtype(states[column])}\")\n\nregion is string dtype? True\ndivision is string dtype? True\nstatefp is string dtype? True\n\n\nRemember for loops execute a block of code a fixed number of times, iterating over a set of objects. In this case, we iterate over the list of column names code_cols = ['region', 'division', 'statefp'].\n\n\n\n\n\n\nDRY code\n\n\n\nWe could have checked whether all the region, division, and statefp columns were of string data type by using the following code:\nprint(f\"region is string dtype? {is_string_dtype(states['region'])}\")\nprint(f\"division is string dtype? {is_string_dtype(states['division'])}\")\nprint(f\"statefp is string dtype? {is_string_dtype(states['statefp'])}\")\nHowever, this is inconvenient as it repeats the same pieces of code, only changing the column name. Instead, using the for loop allows us to succintly print the same information:\ncode_cols = ['region', 'division', 'statefp']\n\nfor column in code_cols: \n    print(f\"{column} is string dtype? {is_string_dtype(states[column])}\")\nDon‚Äôt Repeat Yourself (DRY) is a core programming principle that encourages reducing redundancy and consolidating repeated logic. Try implementing it as much as possible! If you need to repeat the ‚Äúsame‚Äù code more than twice, you likely need a for loop.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#assert",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#assert",
    "title": "10 Streamline your code",
    "section": "assert",
    "text": "assert\nNext, we update the data type of the code columns to be integers. This time, we check the data type of the column using the is_numeric_dtype() function inside an assert statement:\n\n# Update code columns into integers\nfor column in code_cols:\n    states[column] = states[column].astype('int')\n    assert is_numeric_dtype(states[column])  # Check conversion\n\nThe assert keyword does nothing if the expression next to it evaluates to True and raises an AssertionError exception and stops your code form running any further. For example,\n\n# Does nothing if statement is True\nassert 2+2 == 4\n\n# Raises an error if statement is False\nassert 2+2 == 3\n\n\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[13], line 5\n      2 assert 2+2 == 4\n      4 # Raises an error if statement is False\n----&gt; 5 assert 2+2 == 3\n\nAssertionError: \n\n\n\nIn our data type conversion code, since no AssertionError was raised, we can be confident that the data type was updated.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#data-selection",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#data-selection",
    "title": "10 Streamline your code",
    "section": "Data selection",
    "text": "Data selection\nFor this lesson, we want to use only the contiguous states. As seen in the plot, the data covers a bigger extension.\n\n\n\n\n\n\nCheck-in\n\n\n\nFrom the TIGER shapefiles metadata we know that:\n\nIn addition to the fifty states, the Census Bureau treats the District of Columbia, Puerto Rico, and the Island areas (American Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S. Virgin Islands) as statistical equivalents of states for the purpose of data presentation.\n\nIn this US Census Bureau file we can see what each code for the region, division, and state corresponds to.\n\nWhat are the unique values for region, division, or state codes in the data?\nWhich codes should should we select to keep only states in the contiguous US?\n\n\n\n\nLet‚Äôs go ahead and select the data:\n\n# Select contiguous US states\ncontiguous = states[(states.region!=9) & (~states.statefp.isin([2,15]))]\n\nIn this code we used the syntax\n~df.column.isin([val1, val2, val3])\nThe ~ tilde symbol is used in Python to negate a statement. So the previous line could be read as ‚Äúthe values in df‚Äôs column which are not in the list [val1, val2, val3].‚Äù\n\n\n\n\n\n\nCheck-in\n\n\n\nSelect the data in the power_plants data frame for the contiguous US states.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#plotting",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#plotting",
    "title": "10 Streamline your code",
    "section": "Plotting",
    "text": "Plotting\nBefore we plot our data, let‚Äôs make sure they are in the same CRS:\n\ncontiguous.crs == power_plants.crs\n\nTrue\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(9, 5)) # Update figure size\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Title for the plot\nax.set_title('Operable electric generating plants in the contiguous United States', \n              fontsize=15)\n\n# Add states\ncontiguous.plot(ax=ax,\n               color='none',\n               edgecolor='#362312')\n\n# Add electric power plants colored by energy source\npower_plants.plot(ax=ax, \n                  column='primsource',\n                  legend=True,\n                  markersize=4,\n                  cmap='tab20',\n                  alpha=0.5,\n                  legend_kwds={\n                      'title': 'Primary energy source',\n                      'title_fontsize': 'small',\n                      'fontsize': 'small',\n                      'loc': 'upper left',\n                      'bbox_to_anchor': (0, 0),\n                      'ncol': 6  \n                  })\n                  \nplt.show()\n\n\n/Users/galaz-garcia/opt/anaconda3/envs/mpc-env/lib/python3.11/site-packages/geopandas/plotting.py:732: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(values.dtype):\n\n\n\n\n\n\n\n\n\nIn the map above we specified the figure size when creating the plot. This size is given in inches, but can be updated to other units (pixels, cm, etc).\nWe also controlled the legend location using loc and bbox_to_anchor in the legend_kwds:\n\nloc indicates the corner of the legend we want to use for placement, and\nbbox_to_anchor is a tuple with coordinates indicating where to place the corner specified in loc relative to the axes. Values between 0 and 1 are within the axes.\n\n\nmatplotlib uses a variety of ways to locate elements within the graph and it is best to check the documentation to not spend too much time fidling with locations.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#for-with-zip",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#for-with-zip",
    "title": "10 Streamline your code",
    "section": "for with zip",
    "text": "for with zip\nOften, we need to iterate simultaneously over two lists (or other iterables). The zip() function in Python allows you to combine two or more lists (or other iterables) so that you can iterate over their elements in pairs. When used with a for loop, it lets you process elements from each list together, like this example:\n\n# Iterate over a single list\nnumbers = [1, 2, 3]\nfor num in numbers:\n    print(num)\n\nprint('\\n')  # Blank line\n\n# Iterate over two lists in pairs using zip()\nletters = ['a', 'b', 'c']\nfor num, letter in zip(numbers, letters):\n    print(num, letter)\n\n1\n2\n3\n\n\n1 a\n2 b\n3 c\n\n\nLet‚Äôs see a practical application of for loops and zip() with matplotlib subplots. A common situation when code gets repeated is when creating subplots. For example:\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(7, 3))\n\naxes[0].set_title('This is axis 0')\naxes[1].set_title('This is axis 1')\naxes[2].set_title('This is axis 2')\n\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, notice that the axes variable returned by the plt.subplots() function is actually an array of axes we can iterate over. Remember that the figure and the axes are separete elements in a matplotlib plot.\n\n\n\nImage source: Getting Started with Matplotlib\n\n\n\n\n\n\n\n\nCheck-in\n\n\n\nUse for and zip() to create the same subplots and avoid redundancy. \n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nSelect the power plants in California in a variable named ca_power_plants.\nCreate a list named top_sources with California‚Äôs top 3 electric primary sources.\nIsolate the California state boundary in a variable named ca_boundary.\nRecreate the following plot:",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#functions",
    "href": "book/chapters/lesson-11-csv-to-geodataframe/lesson-11-csv-to-geo.html#functions",
    "title": "10 Streamline your code",
    "section": "Functions",
    "text": "Functions\nNext, we want to keep exploring these maps of the top 3 electric primary sources for different states. This is a scenario where creating functions can be useful. In Python, functions are blocks of reusable code designed to perform specific tasks, helping to make your code more modular and organized. The general syntax for defining a function is the following:\ndef function_name(parameter_1, ..., parameter_n):\n    \"\"\"Docstring\"\"\"\n    &lt;body of the function&gt;\n    return value  # Depending on the function\nWe define a function using:\n\nthe def keyword, followed by the function name, parentheses (which can contain parameters), and a colon.\nThe first line(s) of the function should be a docstring, this is a special kind of comment used to describe what the function will do. It must be indented and in between triple quotes \"\"\".\nAfter the docstring, you write the body of the function, this is the code that will be executed when the function is called. The wholek body of the function should be indentated to indicate the function‚Äôs scope.\nThe return keywork is used to allow the function to return values. Functions that do not return any values don‚Äôt need to have a return keyword.\n\nLet‚Äôs see two simple examples just to get familiar with the syntax. In the first one we have a simple function with a one-line docstring, no parameters, and no return values.\ndef greet():\n   \"\"\"Print a greeting message.\"\"\"\n   print(\"Hello, welcome to the class!\")\nThe second one has a single parameter and a more detailed docstring with information abou the arguments and return values.\ndef calculate_area(radius):\n   \"\"\"\n   Calculate the area of a circle given its radius.\n   \n   Args:\n       radius (float): The radius of the circle.\n       \n   Returns:\n       float: The area of the circle, calculated as œÄ * radius^2.\n   \"\"\"\n   area = 3.14159 * radius ** 2\n   return area\n\nExample\nGoing back to our power plants data frame, let‚Äôs create a function that will give us the top 3 primary energy sources for a given state:\n\ndef top3_sources(state, power_plants):\n    \"\"\"\n    Find the top 3 electric primary sources of given state.\n    \n    Args:\n        state (str): The US state we want information about.\n        power_plants (pd.DataFrame): DataFrame containing data \n        on power plants, with at least 'state' and 'primsource' columns.\n    Returns:\n        list: A list of the top 3 primary sources of the state within the power_plants data frame.\n    \"\"\"\n    state_power_plants = power_plants[power_plants['state']==state]\n    top_sources = (state_power_plants['primsource']\n                                .value_counts()\n                                .index[:3]\n                                .tolist()\n                                )\n    return top_sources\n\nWe may now reuse this function as much as we want!\n\nprint('Top 3 primary energy sources in Division 2 states:')\nfor state in ['New Jersey', 'New York', 'Pennsylvania']:\n    print(state, ': ', top3_sources(state, power_plants))\n\nTop 3 primary energy sources in Division 2 states:\nNew Jersey :  ['solar', 'natural gas', 'biomass']\nNew York :  ['solar', 'hydroelectric', 'natural gas']\nPennsylvania :  ['natural gas', 'solar', 'biomass']\n\n\nLet‚Äôs do one more example and create a function that will produce a plot given a list of primary sources and a state name:\n\ndef plot_3_energy_sources(state, sources, power_plants):\n    \n    # Raise error if there are more than three sources\n    assert len(sources) == 3, 'sources must have three elements to produce the plot'\n\n    # Isolate the state boundary and power plants\n    boundary = states[states.name==state]\n    state_power_plants = power_plants[power_plants['state']==state]\n\n    # Create plot\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(6, 3))\n\n    for ax, source in zip(axes, sources):\n        boundary.plot(ax=ax,                \n                      color='none',\n                      edgecolor='#362312')\n        subset = state_power_plants[state_power_plants['primsource'] == source]\n        subset.plot(ax=ax, markersize=5, alpha=0.5)\n        ax.set_title(source)\n        ax.axis('off')  # Remove axes for a cleaner look\n\n    plt.suptitle(f\"Top 3 energy sources for electric power plants in {state}\")\n    plt.tight_layout()\n    plt.show()\n\nWe can now use our functions to produce plots for any state:\n\nplot_3_energy_sources('New Jersey', \n                         top3_sources('New Jersey', power_plants),\n                         power_plants)\n\n\n\n\n\n\n\n\nWriting functions can feel challenging at first, but with practice, they‚Äôll start to come naturally whenever you find yourself reusing blocks of code. Keep experimenting and practicing‚Äîit gets easier with each function you write!\n\n\n\n\n\n\n\nExercise\n\n\n\nWrite a function states_with_source that takes a primary energy source (e.g., ‚Äòsolar‚Äô) and returns a list of states that use that source.",
    "crumbs": [
      "notes",
      "Vector data",
      "10 Streamline your code"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html",
    "href": "book/chapters/lesson-7-time-series.html",
    "title": "6 Time series",
    "section": "",
    "text": "In this section we will learn some basic handling of time series.\nThis lesson was adapted from Dr.¬†Sam Stevenson‚Äôs lecture on Data quality control and outliers: 1D time series and Earth Lab‚Äôs Le‚Äùsson 1. Work With Datetime Format in Python - Time Series Data [1].\n\n\n\nTo exemplify some of the basic time series functionalities we will use data about hourly precipitation in the county of Boulder, Colorado from 2000 to 2014. In September 2013, an unusual weather pattern led to some of the most intense precipitation ever recorded in this region, causing devastating floods throughout the Colorado Front Range. Our goal is to visualize precipitation data in 2013 and identify this unusual weather event.\n\n\n\nAerial view of floods during September 2013 in Colorado. Photo by State of Colorado.\n\n\nThis data was obtained via the National Oceanic and Atmosperic Administration (NOAA) Climate Data Online service and the resulting CSV that can be acceses at this link. The following is a a short description of the columns we will work with (the full documentation can be accessed here):\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nSTATION\nIdentification number indentifying the station.\n\n\nSTATION_NAME\nOptional field, name identifying the station location.\n\n\nDATE\nthis is the year of the record (4 digits), followed by month (2 digits), followed by day of the month (2 digits), followed by a space and ending with a time of observation that is a two digit indication of the local time hour, followed by a colon (:) followed by a two digit indication of the minute which for this dataset will always be 00. Note: The subsequent data value will be for the hour ending at the time specified here. Hour 00:00 will be listed as the first hour of each date, however since this data is by definition an accumulation of the previous 60 minutes, it actually occurred on the previous day.\n\n\nHPCP\nThe amount of precipitation recorded at the station for the hour ending at the time specified for DATE above given in inches. The values 999.99 means the data value is missing. Hours with no precipitation are not shown.\n\n\n\n\n\n\nThe pandas library represents an instant in time using the pandas.Timestamp class. For example:\n\nimport pandas as pd\n\n# Create a timestamp\npd.Timestamp(year=2020, \n             month=10, \n             day=18, \n             hour=12, \n             minute=30, \n             second=15)\n\nTimestamp('2020-10-18 12:30:15')\n\n\nWhen we store multiple pandas.Timestamps in a pandas.Series the data type of the column is set to datetime64[ns]:\n\n# Notice the data type of the column is datetime64\npd.Series([pd.Timestamp(2020,10,18), \n           pd.Timestamp(2020,10,17),\n           pd.Timestamp(2020,10,16)])\n\n0   2020-10-18\n1   2020-10-17\n2   2020-10-16\ndtype: datetime64[ns]\n\n\n\n\n\n\nLet‚Äôs start by reading in the data and taking a look at it:\n\n# Read in data \nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL)\n\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nDATE\nHPCP\nMeasurement Flag\nQuality Flag\n\n\n\n\n0\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 00:00\n999.99\n]\n\n\n\n1\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 01:00\n0.00\ng\n\n\n\n2\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000102 20:00\n0.00\n\nq\n\n\n3\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 01:00\n0.00\n\nq\n\n\n4\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 05:00\n0.00\n\nq\n\n\n\n\n\n\n\n\n# Plot hourly precipitation in Boulder CO \nprecip.plot()\n\n\n\n\n\n\n\n\nThere are a few things going on with this graph:\n\nOutliers: There are many jumps close to 1000. This is clearly not right and these are outliers. Looking at the column descriptions we can see 999.99 indicates the hourly precipitation data is missing.\nIndexing: The \\(x\\)-axis values are given by the index of the dataframe and not relative to time.\nTime range: We are only intersted in the precipitation data from 2013, this graph is trying to plot all our data.\n\nLet‚Äôs fix each one of these issues separately.\n\n\n\nThe metadata states the missing values are indicated by the number 999.99. We can use this information to reload the dataframe indicating 999.99 is the missing value. To do this, we add the na_values parameter to the pandas.read_csv() function to indicitate additional values that should be recognized as NA:\n\n# Read in CSV indicating NA values based on metadata\nprecip = pd.read_csv(URL, na_values=[999.99])\n\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nDATE\nHPCP\nMeasurement Flag\nQuality Flag\n\n\n\n\n0\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 00:00\nNaN\n]\n\n\n\n1\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 01:00\n0.0\ng\n\n\n\n2\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000102 20:00\n0.0\n\nq\n\n\n3\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 01:00\n0.0\n\nq\n\n\n4\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 05:00\n0.0\n\nq\n\n\n\n\n\n\n\nNotice that the first hourly precipitation value used to be 999.99 and it is now set to a NaN. Check the na_values parameter in the pd.read_csv() documentation to learn more about which values are identified as NA by default.\nWe can try making our plot again:\n\nprecip.plot()\n\n\n\n\n\n\n\n\nThis looks better and we can already see there is something going on close to the end of the time series.\n\n\n\nNotice that the DATE column in our dataframe is not of type datetime. We can check this using the dtypes attribute for dataframes:\n\n# Check whether DATE column is of type datetime\nprecip.dtypes\n\nSTATION              object\nSTATION_NAME         object\nDATE                 object\nHPCP                float64\nMeasurement Flag     object\nQuality Flag         object\ndtype: object\n\n\n\nRemember that the object dtype means that (most likely) all values in that column are strings. We can easily convert strings to datetime objects using the pandas.to_datetime() function:\n\npandas.to_datetime() input: a pandas.Series with strings that can be converted to dates\npandas.to_datetime() output: a pandas.Series with the strings converted to datetime objects\n\n#### Example\n\n# Convert DATE column to timestamps\npd.to_datetime(precip.DATE)\n\n0      2000-01-01 00:00:00\n1      2000-01-01 01:00:00\n2      2000-01-02 20:00:00\n3      2000-01-03 01:00:00\n4      2000-01-03 05:00:00\n               ...        \n9001   2013-12-22 01:00:00\n9002   2013-12-23 00:00:00\n9003   2013-12-23 02:00:00\n9004   2013-12-29 01:00:00\n9005   2013-12-31 00:00:00\nName: DATE, Length: 9006, dtype: datetime64[ns]\n\n\nWe can overwrite the DATE column with this output:\n\n# Convert DATE column to timestamps\nprecip.DATE = pd.to_datetime(precip.DATE)\n\n# Check DATE column data type is updated\nprint(precip.dtypes)\n\n# Check new values\nprecip.DATE.head()\n\nSTATION                     object\nSTATION_NAME                object\nDATE                datetime64[ns]\nHPCP                       float64\nMeasurement Flag            object\nQuality Flag                object\ndtype: object\n\n\n0   2000-01-01 00:00:00\n1   2000-01-01 01:00:00\n2   2000-01-02 20:00:00\n3   2000-01-03 01:00:00\n4   2000-01-03 05:00:00\nName: DATE, dtype: datetime64[ns]\n\n\nWe can make another attempt at plotting our precipitation data:\n\nprecip.plot(x='DATE', y='HPCP')\n\n\n\n\n\n\n\n\nNotice the \\(x\\)-axis is now neatly organized into years.\nNext, using our DATE column as the index will allows to perform operations with respect to time, including subsetting and resampling.\n\n# Set DATE coumn as index\nprecip = precip.set_index('DATE')\n\n# Inspect new index\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2000-01-01 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2000-01-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\ng\n\n\n\n2000-01-02 20:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n2000-01-03 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n2000-01-03 05:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n\n\n\n\n\nSince we know the default behaviour of plot() is to use the index as the \\(x\\)-axis and make a line plot for each numeric column, we can simplify our plot making like this:\n\nprecip.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeverage pandas.read_csv() to set a known index\n\n\n\nIf we already have information about our data frame and know which column we will use as the index, we can directly set the index when we load the data by using:\ndf = pandas.read_csv(file, index_col=['index_column'])\nIf we also need our index to be of type datetime and we have a known dates column, then we can also create a datetime index directly when loading the data:\ndf = pandas.read_csv(file, index_col=['date_column'], parse_dates=['date_column'])\n\n\n\n\n\npandas has great functionality to subset a dataframe when using a time index.\n\n\nWe can use .loc[year-month] to select data from a specific year and month:\n\n# Select precipitation data from September 2013\nprecip.loc['2013-09']\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-09-01 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2013-09-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n[\n\n\n\n2013-09-01 00:00:00\nCOOP:050183\nALLENSPARK 2 SE CO US\nNaN\n]\n\n\n\n2013-09-01 01:00:00\nCOOP:050183\nALLENSPARK 2 SE CO US\nNaN\n[\n\n\n\n2013-09-01 00:00:00\nCOOP:055121\nLONGMONT 6 NW CO US\nNaN\n}\n\n\n\n...\n...\n...\n...\n...\n...\n\n\n2013-09-23 02:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.2\n\n\n\n\n2013-09-27 10:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 15:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 17:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 18:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n\n\n128 rows √ó 5 columns\n\n\n\nOr simply select data from a given year using .loc[year]:\n\n# Select 2013 precipitation data\nprecip.loc['2013']\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-01-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\ng\n\n\n\n2013-01-10 02:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n[\n\n\n\n2013-01-13 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2013-01-26 20:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.1\n\n\n\n\n2013-01-28 23:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.1\n\n\n\n\n...\n...\n...\n...\n...\n...\n\n\n2013-12-22 01:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n[\n\n\n\n2013-12-23 00:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n]\n\n\n\n2013-12-23 02:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-12-29 01:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n[\n\n\n\n2013-12-31 00:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n]\n\n\n\n\n\n662 rows √ó 5 columns\n\n\n\nWe can use this selection to plot data as usual. Notice we have a lot of gaps due to missing data:\n\nprecip.loc['2013'].plot()\n\n\n\n\n\n\n\n\n\n\n\n\nResampling a time series means converting a time series from one frequency to another. For example, monthly to yearly (downsampling) or weekly to daily (upsampling). We can resample with the resample() method. The simplest use is to call\ndf.resample(new_frequency).aggregator_function()\nwhere: - new_frequency is a string representing the new frequence to resample the data, for example 'D' for day, w for week, M for month, Y for year, and - aggregator_function() is the function we will use to aggregate the data into the new frequency. For example, max(), min(), sum(), or average().\nThe resample() method works similarly to groupby() in the sense that you need to specify a way to aggregate the data to get any output.\n\n\nOur 2013 precipitation data has hourly frequency, we want to resample it to daily frequency.\n\n# Resample 2013 hourly data to daily frequency: no output\nprecip.loc['2013'].resample('D')\n\n&lt;pandas.core.resample.DatetimeIndexResampler object at 0x14b7c2990&gt;\n\n\nTo get an output we need to add an aggregator function that indicates how we want to summarize the data that falls on each day. In this case we want the total precipitation on a day, so we will aggreagate it using sum():\n\n# Total daily precipitation in 2013\ndaily_precip_2013 = precip.loc['2013'].resample('D').sum()\n\ndaily_precip_2013.head(3)\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-01-01\nCOOP:050183COOP:055881COOP:050183COOP:055121CO...\nALLENSPARK 2 SE CO USNEDERLAND 5 NNW CO USALLE...\n0.0\n]g[gg\n\n\n\n2013-01-02\n0\n0\n0.0\n0\n0\n\n\n2013-01-03\n0\n0\n0.0\n0\n0\n\n\n\n\n\n\n\nNotice the index has now changed to be days in 2013. We should also rename the HPCP column since it is not longer hourly precipitation:\n\n# Rename hourly precipitation column to match resample\ndaily_precip_2013 = daily_precip_2013.rename(columns={'HPCP':'daily_precipitation'})\ndaily_precip_2013.columns\n\nIndex(['STATION', 'STATION_NAME', 'daily_precipitation', 'Measurement Flag',\n       'Quality Flag'],\n      dtype='object')\n\n\nFinally, we can plot our data:\n\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)\n\n\n\n\n\n\n\n\n\n\n\n\nThe previous code includes a lot of exploratory functions and trials. While it is important to keep our data exploration documented, once we are certain of our data wrangling, we can streamline our analyses to only include the code that directly contributes to the output. Moving on, we will start to collect all our relevant code to create such complete workflows. For this lesson, the code below will produce the final graph:\n\nimport pandas as pd\n\n'''\nRead in Boulder, CO hourly precipitation data \nHPCP = hourly precipitation (unique numerical column in data frame)\n'''\nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL, \n                    na_values=[999.99],  # Known from metadata\n                    index_col=['DATE'], \n                    parse_dates=['DATE']\n                    )\n\n\n# Calculate daily total precipitation during 2013\ndaily_precip_2013 = (precip.loc['2013']\n                            .resample('D')\n                            .sum()\n                            .rename(columns={'HPCP':'daily_precipitation'})  \n                            )\n\n# Plot time series\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)\n\n\n\n\n\n\n\n\n\n\n\n\nThere is so much more to learn about time series data. These resources will allow you to dive deeper:\nüìñ pandas getting started tutorials - How to handle time series data with ease\nüìñ Time Series Chapter, Python for Data Analysis, Wes McKinney\nüìñ pandas User Guide - Time series/date functionality",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#about-the-data",
    "href": "book/chapters/lesson-7-time-series.html#about-the-data",
    "title": "6 Time series",
    "section": "",
    "text": "To exemplify some of the basic time series functionalities we will use data about hourly precipitation in the county of Boulder, Colorado from 2000 to 2014. In September 2013, an unusual weather pattern led to some of the most intense precipitation ever recorded in this region, causing devastating floods throughout the Colorado Front Range. Our goal is to visualize precipitation data in 2013 and identify this unusual weather event.\n\n\n\nAerial view of floods during September 2013 in Colorado. Photo by State of Colorado.\n\n\nThis data was obtained via the National Oceanic and Atmosperic Administration (NOAA) Climate Data Online service and the resulting CSV that can be acceses at this link. The following is a a short description of the columns we will work with (the full documentation can be accessed here):\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nSTATION\nIdentification number indentifying the station.\n\n\nSTATION_NAME\nOptional field, name identifying the station location.\n\n\nDATE\nthis is the year of the record (4 digits), followed by month (2 digits), followed by day of the month (2 digits), followed by a space and ending with a time of observation that is a two digit indication of the local time hour, followed by a colon (:) followed by a two digit indication of the minute which for this dataset will always be 00. Note: The subsequent data value will be for the hour ending at the time specified here. Hour 00:00 will be listed as the first hour of each date, however since this data is by definition an accumulation of the previous 60 minutes, it actually occurred on the previous day.\n\n\nHPCP\nThe amount of precipitation recorded at the station for the hour ending at the time specified for DATE above given in inches. The values 999.99 means the data value is missing. Hours with no precipitation are not shown.",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#timestamps",
    "href": "book/chapters/lesson-7-time-series.html#timestamps",
    "title": "6 Time series",
    "section": "",
    "text": "The pandas library represents an instant in time using the pandas.Timestamp class. For example:\n\nimport pandas as pd\n\n# Create a timestamp\npd.Timestamp(year=2020, \n             month=10, \n             day=18, \n             hour=12, \n             minute=30, \n             second=15)\n\nTimestamp('2020-10-18 12:30:15')\n\n\nWhen we store multiple pandas.Timestamps in a pandas.Series the data type of the column is set to datetime64[ns]:\n\n# Notice the data type of the column is datetime64\npd.Series([pd.Timestamp(2020,10,18), \n           pd.Timestamp(2020,10,17),\n           pd.Timestamp(2020,10,16)])\n\n0   2020-10-18\n1   2020-10-17\n2   2020-10-16\ndtype: datetime64[ns]",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#data-exploration",
    "href": "book/chapters/lesson-7-time-series.html#data-exploration",
    "title": "6 Time series",
    "section": "",
    "text": "Let‚Äôs start by reading in the data and taking a look at it:\n\n# Read in data \nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL)\n\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nDATE\nHPCP\nMeasurement Flag\nQuality Flag\n\n\n\n\n0\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 00:00\n999.99\n]\n\n\n\n1\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 01:00\n0.00\ng\n\n\n\n2\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000102 20:00\n0.00\n\nq\n\n\n3\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 01:00\n0.00\n\nq\n\n\n4\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 05:00\n0.00\n\nq\n\n\n\n\n\n\n\n\n# Plot hourly precipitation in Boulder CO \nprecip.plot()\n\n\n\n\n\n\n\n\nThere are a few things going on with this graph:\n\nOutliers: There are many jumps close to 1000. This is clearly not right and these are outliers. Looking at the column descriptions we can see 999.99 indicates the hourly precipitation data is missing.\nIndexing: The \\(x\\)-axis values are given by the index of the dataframe and not relative to time.\nTime range: We are only intersted in the precipitation data from 2013, this graph is trying to plot all our data.\n\nLet‚Äôs fix each one of these issues separately.",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#reading-in-missing-data-values",
    "href": "book/chapters/lesson-7-time-series.html#reading-in-missing-data-values",
    "title": "6 Time series",
    "section": "",
    "text": "The metadata states the missing values are indicated by the number 999.99. We can use this information to reload the dataframe indicating 999.99 is the missing value. To do this, we add the na_values parameter to the pandas.read_csv() function to indicitate additional values that should be recognized as NA:\n\n# Read in CSV indicating NA values based on metadata\nprecip = pd.read_csv(URL, na_values=[999.99])\n\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nDATE\nHPCP\nMeasurement Flag\nQuality Flag\n\n\n\n\n0\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 00:00\nNaN\n]\n\n\n\n1\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000101 01:00\n0.0\ng\n\n\n\n2\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000102 20:00\n0.0\n\nq\n\n\n3\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 01:00\n0.0\n\nq\n\n\n4\nCOOP:055881\nNEDERLAND 5 NNW CO US\n20000103 05:00\n0.0\n\nq\n\n\n\n\n\n\n\nNotice that the first hourly precipitation value used to be 999.99 and it is now set to a NaN. Check the na_values parameter in the pd.read_csv() documentation to learn more about which values are identified as NA by default.\nWe can try making our plot again:\n\nprecip.plot()\n\n\n\n\n\n\n\n\nThis looks better and we can already see there is something going on close to the end of the time series.",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#casting-strings-into-dates",
    "href": "book/chapters/lesson-7-time-series.html#casting-strings-into-dates",
    "title": "6 Time series",
    "section": "",
    "text": "Notice that the DATE column in our dataframe is not of type datetime. We can check this using the dtypes attribute for dataframes:\n\n# Check whether DATE column is of type datetime\nprecip.dtypes\n\nSTATION              object\nSTATION_NAME         object\nDATE                 object\nHPCP                float64\nMeasurement Flag     object\nQuality Flag         object\ndtype: object\n\n\n\nRemember that the object dtype means that (most likely) all values in that column are strings. We can easily convert strings to datetime objects using the pandas.to_datetime() function:\n\npandas.to_datetime() input: a pandas.Series with strings that can be converted to dates\npandas.to_datetime() output: a pandas.Series with the strings converted to datetime objects\n\n#### Example\n\n# Convert DATE column to timestamps\npd.to_datetime(precip.DATE)\n\n0      2000-01-01 00:00:00\n1      2000-01-01 01:00:00\n2      2000-01-02 20:00:00\n3      2000-01-03 01:00:00\n4      2000-01-03 05:00:00\n               ...        \n9001   2013-12-22 01:00:00\n9002   2013-12-23 00:00:00\n9003   2013-12-23 02:00:00\n9004   2013-12-29 01:00:00\n9005   2013-12-31 00:00:00\nName: DATE, Length: 9006, dtype: datetime64[ns]\n\n\nWe can overwrite the DATE column with this output:\n\n# Convert DATE column to timestamps\nprecip.DATE = pd.to_datetime(precip.DATE)\n\n# Check DATE column data type is updated\nprint(precip.dtypes)\n\n# Check new values\nprecip.DATE.head()\n\nSTATION                     object\nSTATION_NAME                object\nDATE                datetime64[ns]\nHPCP                       float64\nMeasurement Flag            object\nQuality Flag                object\ndtype: object\n\n\n0   2000-01-01 00:00:00\n1   2000-01-01 01:00:00\n2   2000-01-02 20:00:00\n3   2000-01-03 01:00:00\n4   2000-01-03 05:00:00\nName: DATE, dtype: datetime64[ns]\n\n\nWe can make another attempt at plotting our precipitation data:\n\nprecip.plot(x='DATE', y='HPCP')\n\n\n\n\n\n\n\n\nNotice the \\(x\\)-axis is now neatly organized into years.\nNext, using our DATE column as the index will allows to perform operations with respect to time, including subsetting and resampling.\n\n# Set DATE coumn as index\nprecip = precip.set_index('DATE')\n\n# Inspect new index\nprecip.head()\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2000-01-01 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2000-01-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\ng\n\n\n\n2000-01-02 20:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n2000-01-03 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n2000-01-03 05:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\n\nq\n\n\n\n\n\n\n\nSince we know the default behaviour of plot() is to use the index as the \\(x\\)-axis and make a line plot for each numeric column, we can simplify our plot making like this:\n\nprecip.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeverage pandas.read_csv() to set a known index\n\n\n\nIf we already have information about our data frame and know which column we will use as the index, we can directly set the index when we load the data by using:\ndf = pandas.read_csv(file, index_col=['index_column'])\nIf we also need our index to be of type datetime and we have a known dates column, then we can also create a datetime index directly when loading the data:\ndf = pandas.read_csv(file, index_col=['date_column'], parse_dates=['date_column'])",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#subsetting-by-date",
    "href": "book/chapters/lesson-7-time-series.html#subsetting-by-date",
    "title": "6 Time series",
    "section": "",
    "text": "pandas has great functionality to subset a dataframe when using a time index.\n\n\nWe can use .loc[year-month] to select data from a specific year and month:\n\n# Select precipitation data from September 2013\nprecip.loc['2013-09']\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-09-01 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2013-09-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n[\n\n\n\n2013-09-01 00:00:00\nCOOP:050183\nALLENSPARK 2 SE CO US\nNaN\n]\n\n\n\n2013-09-01 01:00:00\nCOOP:050183\nALLENSPARK 2 SE CO US\nNaN\n[\n\n\n\n2013-09-01 00:00:00\nCOOP:055121\nLONGMONT 6 NW CO US\nNaN\n}\n\n\n\n...\n...\n...\n...\n...\n...\n\n\n2013-09-23 02:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.2\n\n\n\n\n2013-09-27 10:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 15:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 17:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-09-27 18:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n\n\n128 rows √ó 5 columns\n\n\n\nOr simply select data from a given year using .loc[year]:\n\n# Select 2013 precipitation data\nprecip.loc['2013']\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-01-01 01:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.0\ng\n\n\n\n2013-01-10 02:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n[\n\n\n\n2013-01-13 00:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\nNaN\n]\n\n\n\n2013-01-26 20:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.1\n\n\n\n\n2013-01-28 23:00:00\nCOOP:055881\nNEDERLAND 5 NNW CO US\n0.1\n\n\n\n\n...\n...\n...\n...\n...\n...\n\n\n2013-12-22 01:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n[\n\n\n\n2013-12-23 00:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n]\n\n\n\n2013-12-23 02:00:00\nCOOP:050843\nBOULDER 2 CO US\n0.1\n\n\n\n\n2013-12-29 01:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n[\n\n\n\n2013-12-31 00:00:00\nCOOP:050843\nBOULDER 2 CO US\nNaN\n]\n\n\n\n\n\n662 rows √ó 5 columns\n\n\n\nWe can use this selection to plot data as usual. Notice we have a lot of gaps due to missing data:\n\nprecip.loc['2013'].plot()",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#resample",
    "href": "book/chapters/lesson-7-time-series.html#resample",
    "title": "6 Time series",
    "section": "",
    "text": "Resampling a time series means converting a time series from one frequency to another. For example, monthly to yearly (downsampling) or weekly to daily (upsampling). We can resample with the resample() method. The simplest use is to call\ndf.resample(new_frequency).aggregator_function()\nwhere: - new_frequency is a string representing the new frequence to resample the data, for example 'D' for day, w for week, M for month, Y for year, and - aggregator_function() is the function we will use to aggregate the data into the new frequency. For example, max(), min(), sum(), or average().\nThe resample() method works similarly to groupby() in the sense that you need to specify a way to aggregate the data to get any output.\n\n\nOur 2013 precipitation data has hourly frequency, we want to resample it to daily frequency.\n\n# Resample 2013 hourly data to daily frequency: no output\nprecip.loc['2013'].resample('D')\n\n&lt;pandas.core.resample.DatetimeIndexResampler object at 0x14b7c2990&gt;\n\n\nTo get an output we need to add an aggregator function that indicates how we want to summarize the data that falls on each day. In this case we want the total precipitation on a day, so we will aggreagate it using sum():\n\n# Total daily precipitation in 2013\ndaily_precip_2013 = precip.loc['2013'].resample('D').sum()\n\ndaily_precip_2013.head(3)\n\n\n\n\n\n\n\n\nSTATION\nSTATION_NAME\nHPCP\nMeasurement Flag\nQuality Flag\n\n\nDATE\n\n\n\n\n\n\n\n\n\n2013-01-01\nCOOP:050183COOP:055881COOP:050183COOP:055121CO...\nALLENSPARK 2 SE CO USNEDERLAND 5 NNW CO USALLE...\n0.0\n]g[gg\n\n\n\n2013-01-02\n0\n0\n0.0\n0\n0\n\n\n2013-01-03\n0\n0\n0.0\n0\n0\n\n\n\n\n\n\n\nNotice the index has now changed to be days in 2013. We should also rename the HPCP column since it is not longer hourly precipitation:\n\n# Rename hourly precipitation column to match resample\ndaily_precip_2013 = daily_precip_2013.rename(columns={'HPCP':'daily_precipitation'})\ndaily_precip_2013.columns\n\nIndex(['STATION', 'STATION_NAME', 'daily_precipitation', 'Measurement Flag',\n       'Quality Flag'],\n      dtype='object')\n\n\nFinally, we can plot our data:\n\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#complete-workflow",
    "href": "book/chapters/lesson-7-time-series.html#complete-workflow",
    "title": "6 Time series",
    "section": "",
    "text": "The previous code includes a lot of exploratory functions and trials. While it is important to keep our data exploration documented, once we are certain of our data wrangling, we can streamline our analyses to only include the code that directly contributes to the output. Moving on, we will start to collect all our relevant code to create such complete workflows. For this lesson, the code below will produce the final graph:\n\nimport pandas as pd\n\n'''\nRead in Boulder, CO hourly precipitation data \nHPCP = hourly precipitation (unique numerical column in data frame)\n'''\nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL, \n                    na_values=[999.99],  # Known from metadata\n                    index_col=['DATE'], \n                    parse_dates=['DATE']\n                    )\n\n\n# Calculate daily total precipitation during 2013\ndaily_precip_2013 = (precip.loc['2013']\n                            .resample('D')\n                            .sum()\n                            .rename(columns={'HPCP':'daily_precipitation'})  \n                            )\n\n# Plot time series\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/chapters/lesson-7-time-series.html#more-info",
    "href": "book/chapters/lesson-7-time-series.html#more-info",
    "title": "6 Time series",
    "section": "",
    "text": "There is so much more to learn about time series data. These resources will allow you to dive deeper:\nüìñ pandas getting started tutorials - How to handle time series data with ease\nüìñ Time Series Chapter, Python for Data Analysis, Wes McKinney\nüìñ pandas User Guide - Time series/date functionality",
    "crumbs": [
      "notes",
      "Tabular data",
      "6 Time series"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html",
    "href": "book/appendices/A-python-environments.html",
    "title": "Conda environments",
    "section": "",
    "text": "This hands-on lesson gives a brief introduction to Conda environments, focusing on practical usage. You can use this lesson as a standalone introduction to environments, ideally preceding the installation of the course-specific environment (see Setup section). The last section includes a table with the Conda commands used in this lesson for quick reference.\n\n\nBy the end of this lesson, students will be able to:\n\nDescribe what Conda environments are and their role in managing Python packages and dependencies\nUse standard Conda commands to list, activate, deactivate, create, and delete environments\nBuild Conda environments and install packages using the command line\nGenerate and edit a .yml file with environment specifications to enhance project reproducibility\n\n\n\n\nEnvironments are a way to keep the packages and Python versions you use for different projects organized.\n\n\n\nSome environments can have lots of packages and dependencies, while others can keep it simple.\n\n\nThe main reasons to create an environment for each of your projects are:\n\nTo not interfere with your computer‚Äôs pre-installed Python\nPackages usually depend on other packages to work properly, this is called a package dependency. Dependencies across different packages need to be carefully managed and may potentially be different across projects.\nReproducibility! Being able to share your code and what it needs to run it with others\n\n\n\n\nConda is an environment and package management system: it can both create and administer the environments and install compatible versions of software and their dependencies within an environment.\nEnvironments created with Conda are usually called Conda environments. A Conda environment doesn‚Äôt need to be a Python environment, Conda can manage packages for any programming language.\n\n\n\n\n\n\n\n\nConda channels are the remote locations where packages are stored. Think of them as shops for getting packages. By default, packages are downloaded to your computer and updated from the conda default channel. But there are others! Conda-forge and bioconda are two popular ones. We can choose which Conda channel to install a package from.\n\n\n\npip is a package management system only for Python. We can use it to install packages from the Python Package Index (PyPI). We can use pip inside a Conda environment when a package is not available from a Conda channel.\n\n\n\n\n\n\n\n\nThe following exercises will guide you through the basic commands to work with Conda environments. Unless otherwise specified, all the commands should be run in the command line. For a deeper dive after completing this introduction, check out the Conda documentation.\n\n\nTo list all the Conda environments available in your computer and their location we use:\nconda env list\nThe output should look something like this:\n# conda environments:\n#\nbase                  *  /Users/galaz-garcia/opt/anaconda3\neds220-env               /Users/galaz-garcia/opt/anaconda3/envs/eds220-env\nNotice the file path next to the environment name. This is the absolute path to the environment‚Äôs installation directory on my local machine. This is where Conda has created the environment and stored the packages!\nWhat is my currently active environment?\n\nWhen you run conda env list, the asterisk next to the environment path indicates which environment is active. In the previous example, I am using the base Python environment.\nThe currently active environment also appears in the terminal in parenthesis at the beginning of each line, something like this:\n\n(base) my-computer:MEDS-eds-220-course galaz-garcia$\n\n\n\nTo create a new environment called test-env wiht a specific version of Python (in this case Python 3.11) we simply run:\nconda create --name test-env python=3.11\nWhen you run this command, it will print out information about the packages that will be installed and ask you whether to proceed or not. Type y and press enter to create the environment and install the packages.\nIf we don‚Äôt include a Python version, the command conda create --name test-env python will install the most recent version of Python.\n\n\n\n\n\n\nCheck-in\n\n\n\nCheck whether the new test-env environment is listed by Conda. Is it activated or not?\n\n\n\n\n\nTo activate the test-env environment we use the command\nconda activate test-env\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that test-env is now your current environment.\n\n\n\n\n\nTo see which packages are installed within the currently active environment we run:\nconda list\nThe output will be a long list that looks something like this:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbzip2                     1.0.8                h6c40b1e_6  \npip                       24.2            py312hecd8cb5_0  \nsqlite                    3.45.3               h6c40b1e_0  \n[...]\nThe name and version of each installed package in the environment appear in their respective columns. The ‚ÄòBuild‚Äô column shows a build string for each package. This string encodes important information about how the package was compiled, including any updates or changes made without altering the package version. It also reflects any compatibility or performance optimizations that were integrated during the build process.\nFor example, the same package with the same version might have different builds (and therefore different build strings) depending on whether it was installed on macOS, Windows, or Linux. This difference arises because the package may need to be compiled differently to optimize performance and ensure compatibility with each operating system.\nThe channel column shows the source from which the package was downloaded and installed. In this example the entries on this column are blank, signaling these packages were downloaded from the defeault Conda channel. We‚Äôll see other channels appear in the next examples.\nWe can also request information about a specific package. For example, if we run\nconda list pip\nwe obtain only the information about the pip package:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\npip                       24.2            py312hecd8cb5_0  \nWe can use the same command to verify whether a package is installed. For example, if we run\nconda list numpy\nwe will get empty columns:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbecause the numpy package is not intalled in this environment.\n\n\n\nSuppose we want to install numpy in our currently active environment test-env. To do this we can simply use the command:\nconda install numpy\nSince we have not specified another channel, this command will install numpy from the default channel.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that numpy is now installed.\n\n\nNow, suppose we want to install rioxarray, this is a Python package for raster data analysis. This is a relatively new package, so it might not be available from the default Conda channels. A sensible measure would be to first look if rioxarray is available in the defaults channels, which we can do by running:\nconda search rioxarray\nThe output will look similar to\nLoading channels: done\nNo match found for: rioxarray. Search: *rioxarray*\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - rioxarray\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/osx-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/osx-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the Conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\nAs stated, rioxarray is not available on the default channels for my Conda installation. Notice a couple of the channels it is seraching on are specific to macOS (my current operating system). The last two channels are actually channels for R packages. If we had tried to install rioxarray using conda install rioxarray we would have obtained an error message with similar information (you can try it if you want!).\nWe may have better luck searching for rioxarray in the conda-forge channel, which we can do like this:\nconda search --channel conda-forge rioxarray\nThe result will be a list of available versions and builds of this package in the conda-forge channel:\nLoading channels: done\n# Name                       Version           Build  Channel             \nrioxarray                      0.0.3            py_0  conda-forge         \nrioxarray                      0.0.4            py_0  conda-forge         \nrioxarray                      0.0.5            py_0  conda-forge     \n[...]\nrioxarray                     0.16.0    pyhd8ed1ab_0  conda-forge         \nrioxarray                     0.17.0    pyhd8ed1ab_0  conda-forge   \n\n\n\n\n\n\nCheck-in\n\n\n\nDo you see any versions of rioxarray with multiple builds?\n\n\nSince we now know that we can find rioxarray in the conda-forge channel, we can go ahead and install it from this channel using the command\nconda install --channel conda-forge rioxarray\nYou‚Äôll see a moving bar that says Conda is solving (the) environment - this is Conda doing its package management job! It means Conda is working on:\n\nfinding the dependencies for the packages you are trying to install,\nfinding versions of these dependencies that are compatible with each other,\nmaking sure these new packages are compatible with the packages already present in the environment,\ndowngrade, upgrade, or remove packages as needed in the environment.\n\nOverall, Conda tries to install what we need with the least disruption. Solving an environment can often take time but it is crucial so that the environment remains stable and functional.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nCheck whether pandas is installed in the environment.\nWhich channels were used to install dependencies for rioxarray?\n\n\n\n\n\n\n\nTo deactivate our current environment and return to our base environment we simply run\nconda deactivate\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify we are no longer in the test-env. What environment are we on?\n\n\n\n\n\nSince this was a test environment, we can go ahead and delete all of it using the command:\nconda remove --name test-env  --all\nIt will ask you whether you want to proceed. Type y and press enter to go ahead and delete the environment.\nWe can run conda env list to verify the test-env does not exist anymore.\n\n\n\nWe can also create a new environment by specifying the package versions and channel priorities. For example, to install the numpy and rioxarray versions we previously had in a new environment called my-env we run:\nconda create --name my-env rioxarray=0.17.0 numpy=1.26.4 --channel conda-forge\nNotice we are explicitely requiring certain versions of our packages, and the --channel conda-forge option is asking Conda to prioritize getting the packages from conda-forge.\n\n\n\n\n\n\nCheck-in\n\n\n\nTake a look at the dependencies that were installed with these two packages.\n\n\n\n\n\nOne of the main goals of using an environment to manage the packages used in your project is being able to share the environment so that other people can rerun your code and reproduce your results.\n‚ÄúSharing the environment‚Äù means sharing instructions that Conda can use to recreate the environment you have. These instructions are, basically, a list of the packages installed in the environment, their versions, which channels were used to install them, and, optionally, build specifications.\nThere are several ways of creating these instructions to reconstruct an environment depending on the level of cross-platform compatibility we are looking for. However, each of the following methods to export the environment specifications will generate a new YAML file. This file type with .yml extension is human-readable markup language that is commonly used for configuration in software applications.\n\n\n\n\n\n\nNavigate to project directory\n\n\n\nEach of the commands for exporting the environment specifications will create a .yml file in our terminal‚Äôs current working directory. Remember you can use pwd (Mac & Linux) or echo %cd% (Windows CMD) on the command line to check which is your current working directory. If you need to change directories you can use cd navigation in the terminal.\nThe best practice is to have the environment.yml file in the directory that holds your project. This way, you can use version control on it and push it to your remote repository.\n\n\n\n\nThe first method to export the environment specifications is running\nconda env export &gt; environment.yml\nThe environment.yml is the name of the YAML file that will have the environment specifications.\nOpen the environment.yml file that was generated, it will look similar to this excerpt:\nname: my-env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - affine=2.4.0=pyhd8ed1ab_0\n  - attrs=24.2.0=pyh71513ae_0\n  [...]\n  - zlib=1.3.1=h87427d6_1\n  - zstd=1.5.6=h915ae27_0\nprefix: /Users/galaz-garcia/opt/anaconda3/envs/my-env\nHere we can see the name of the environment, the channels used to install packages (in order of priority), and the package names, each with a version and build string. This ensures that the environment can be recreated exactly as it is on another system. This first method to export the environment specifications is the most detailed and it is both platform and package specific.\n\n\n\n\n\n\nDelete prefix line before sharing environment\n\n\n\nNotice the last line in the environment.yml file, this prefix indicates the absolute path to the environment‚Äôs installation on your local machine.\nYou should delete the prefix line when sharing the environment file. Leaving it there is unnecessary and could cause confusion since it points to specific directroy in your local machine.\n\n\n\n\n\nOur second method to export the environment specifications is to run\nconda env export --from-history &gt; environment_hist.yml\nHere I named the file environment_hist.yml to not overwrite the previous environmnet.yml, that way you can compare both of them. Open the environment_hist.yml file, it will look similar to this (much shorter than the previous one):\nname: my-env\nchannels:\n  - defaults\ndependencies:\n  - numpy=1.26.4\n  - rioxarray=0.17.0\nprefix: /Users/galaz-garcia/opt/anaconda3/envs/my-env\nAdding the --from-history option tells Conda to only include packages that we explicitely installed (in this case numpy=1.26.4 and rioxarray=0.17.0), omitting any dependencies that were automatically installed and channel information. This will create a minimal environment file that lists only the packages you explicitly installed, making it simpler and more portable for sharing with others. While this method ensures reproducibility of the core setup, Conda will resolve dependencies on its own and these might not be the same as your original environment.\n\n\n\n\n\n\nAdding channels to environment.yml file\n\n\n\nIn section 5 we saw that the rioxarray package is available on the conda-forge channel, but not the defaults channel. The output of conda env export with the --from-history option only includes the defaults channel, so we wouldn‚Äôt be able to recreate the environment with that file as is. Remember the .yml file can be manually modified and we can edit it to include conda-forge as the first priority channel, followed by the defaults channel. Rememember to also delete the prefix line before sharing. The modified version of the --from-history output that will allow us to recreate the environment will be:\nname: my-env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - numpy=1.26.4\n  - rioxarray=0.17.0\n\n\nBefore moving to the last exercise, delete the environment.yml and environment_hist.yml files.\n\n\n\n\n\nFor this last exercise, click here and download the environment.yml file in this repository. Move to a directory for a mock project and navigate to that directory in the terminal.\n\nTo create an environment from specifications in a .yml file we run\nconda env create --name test-env --file environment.yml\nThen --name option states how we want to name our environment (test-env in this case). If no --name option is given, Conda will name of the environment using the name field in the environment.yml file.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that the new environment was created, activate it, and take a look at the installed packages.\n\n\n\n\n\n\nThe following table includes the commands covered in this lesson‚Äôs exercises. Check out Conda‚Äôs cheatsheet for more commands and tips.\n\n\n\n\n\n\n\nCommand\nWhat it does\n\n\n\n\nconda env list\nlist available Conda environments\n\n\nconda create --name ENVNAME python\ncreate a new Python environment named ENVNAME\n\n\nconda remove --name ENVNAME  --all\ndelete ENVNAME environment\n\n\nconda activate ENVNAME\nactivate environment\n\n\nconda deactivate\ndeactivate active environment\n\n\npython -V\nprint Python version installed in active environment\n\n\nconda list\nlist installed packages in active environment\n\n\nconda list PKGNAME\ncheck if PKGNAME package is installed in active environment\n\n\nconda install PKGNAME\ninstall PKGNAME package in environment using environment channel priorities (generally just from defaults channel)\n\n\nconda install --channel CHANNELNAME PKGNAME\ninstall PKGNAME package in environment from from CHANNELNAME channel\n\n\nconda search PKGNAME\nsearch for PKGNAME package in environment‚Äôs channels\n\n\nconda search --channel CHANNELNAME PKGNAME\nsearch for PKGNAME package in CHANNELNAME channel\n\n\nconda env export &gt; ENV.yml\nexport environment specifications of currently active environmemt into ENV.yml file (includes all dependencies, buildstrings, and channels)\n\n\nconda env export --from-history &gt; ENV.yml\nexport environment specifications of currently active environmemt into ENV.yml file (only packages explicitely installed, no dependencies, buildstrings, or channels)\n\n\nconda env create --name ENVNAME --file ENV.yml\ncreate an environment named ENVNAME from specifications in ENV.yml file",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#learning-objectives",
    "href": "book/appendices/A-python-environments.html#learning-objectives",
    "title": "Conda environments",
    "section": "",
    "text": "By the end of this lesson, students will be able to:\n\nDescribe what Conda environments are and their role in managing Python packages and dependencies\nUse standard Conda commands to list, activate, deactivate, create, and delete environments\nBuild Conda environments and install packages using the command line\nGenerate and edit a .yml file with environment specifications to enhance project reproducibility",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#environments-what-and-why",
    "href": "book/appendices/A-python-environments.html#environments-what-and-why",
    "title": "Conda environments",
    "section": "",
    "text": "Environments are a way to keep the packages and Python versions you use for different projects organized.\n\n\n\nSome environments can have lots of packages and dependencies, while others can keep it simple.\n\n\nThe main reasons to create an environment for each of your projects are:\n\nTo not interfere with your computer‚Äôs pre-installed Python\nPackages usually depend on other packages to work properly, this is called a package dependency. Dependencies across different packages need to be carefully managed and may potentially be different across projects.\nReproducibility! Being able to share your code and what it needs to run it with others",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-environments-1",
    "href": "book/appendices/A-python-environments.html#conda-environments-1",
    "title": "Conda environments",
    "section": "",
    "text": "Conda is an environment and package management system: it can both create and administer the environments and install compatible versions of software and their dependencies within an environment.\nEnvironments created with Conda are usually called Conda environments. A Conda environment doesn‚Äôt need to be a Python environment, Conda can manage packages for any programming language.",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-channels",
    "href": "book/appendices/A-python-environments.html#conda-channels",
    "title": "Conda environments",
    "section": "",
    "text": "Conda channels are the remote locations where packages are stored. Think of them as shops for getting packages. By default, packages are downloaded to your computer and updated from the conda default channel. But there are others! Conda-forge and bioconda are two popular ones. We can choose which Conda channel to install a package from.",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#pip",
    "href": "book/appendices/A-python-environments.html#pip",
    "title": "Conda environments",
    "section": "",
    "text": "pip is a package management system only for Python. We can use it to install packages from the Python Package Index (PyPI). We can use pip inside a Conda environment when a package is not available from a Conda channel.",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#hands-on-environments",
    "href": "book/appendices/A-python-environments.html#hands-on-environments",
    "title": "Conda environments",
    "section": "",
    "text": "The following exercises will guide you through the basic commands to work with Conda environments. Unless otherwise specified, all the commands should be run in the command line. For a deeper dive after completing this introduction, check out the Conda documentation.\n\n\nTo list all the Conda environments available in your computer and their location we use:\nconda env list\nThe output should look something like this:\n# conda environments:\n#\nbase                  *  /Users/galaz-garcia/opt/anaconda3\neds220-env               /Users/galaz-garcia/opt/anaconda3/envs/eds220-env\nNotice the file path next to the environment name. This is the absolute path to the environment‚Äôs installation directory on my local machine. This is where Conda has created the environment and stored the packages!\nWhat is my currently active environment?\n\nWhen you run conda env list, the asterisk next to the environment path indicates which environment is active. In the previous example, I am using the base Python environment.\nThe currently active environment also appears in the terminal in parenthesis at the beginning of each line, something like this:\n\n(base) my-computer:MEDS-eds-220-course galaz-garcia$\n\n\n\nTo create a new environment called test-env wiht a specific version of Python (in this case Python 3.11) we simply run:\nconda create --name test-env python=3.11\nWhen you run this command, it will print out information about the packages that will be installed and ask you whether to proceed or not. Type y and press enter to create the environment and install the packages.\nIf we don‚Äôt include a Python version, the command conda create --name test-env python will install the most recent version of Python.\n\n\n\n\n\n\nCheck-in\n\n\n\nCheck whether the new test-env environment is listed by Conda. Is it activated or not?\n\n\n\n\n\nTo activate the test-env environment we use the command\nconda activate test-env\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that test-env is now your current environment.\n\n\n\n\n\nTo see which packages are installed within the currently active environment we run:\nconda list\nThe output will be a long list that looks something like this:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbzip2                     1.0.8                h6c40b1e_6  \npip                       24.2            py312hecd8cb5_0  \nsqlite                    3.45.3               h6c40b1e_0  \n[...]\nThe name and version of each installed package in the environment appear in their respective columns. The ‚ÄòBuild‚Äô column shows a build string for each package. This string encodes important information about how the package was compiled, including any updates or changes made without altering the package version. It also reflects any compatibility or performance optimizations that were integrated during the build process.\nFor example, the same package with the same version might have different builds (and therefore different build strings) depending on whether it was installed on macOS, Windows, or Linux. This difference arises because the package may need to be compiled differently to optimize performance and ensure compatibility with each operating system.\nThe channel column shows the source from which the package was downloaded and installed. In this example the entries on this column are blank, signaling these packages were downloaded from the defeault Conda channel. We‚Äôll see other channels appear in the next examples.\nWe can also request information about a specific package. For example, if we run\nconda list pip\nwe obtain only the information about the pip package:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\npip                       24.2            py312hecd8cb5_0  \nWe can use the same command to verify whether a package is installed. For example, if we run\nconda list numpy\nwe will get empty columns:\n# packages in environment at /Users/galaz-garcia/opt/anaconda3/envs/test-env:\n#\n# Name                    Version                   Build  Channel\nbecause the numpy package is not intalled in this environment.\n\n\n\nSuppose we want to install numpy in our currently active environment test-env. To do this we can simply use the command:\nconda install numpy\nSince we have not specified another channel, this command will install numpy from the default channel.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that numpy is now installed.\n\n\nNow, suppose we want to install rioxarray, this is a Python package for raster data analysis. This is a relatively new package, so it might not be available from the default Conda channels. A sensible measure would be to first look if rioxarray is available in the defaults channels, which we can do by running:\nconda search rioxarray\nThe output will look similar to\nLoading channels: done\nNo match found for: rioxarray. Search: *rioxarray*\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - rioxarray\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/osx-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/osx-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the Conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\nAs stated, rioxarray is not available on the default channels for my Conda installation. Notice a couple of the channels it is seraching on are specific to macOS (my current operating system). The last two channels are actually channels for R packages. If we had tried to install rioxarray using conda install rioxarray we would have obtained an error message with similar information (you can try it if you want!).\nWe may have better luck searching for rioxarray in the conda-forge channel, which we can do like this:\nconda search --channel conda-forge rioxarray\nThe result will be a list of available versions and builds of this package in the conda-forge channel:\nLoading channels: done\n# Name                       Version           Build  Channel             \nrioxarray                      0.0.3            py_0  conda-forge         \nrioxarray                      0.0.4            py_0  conda-forge         \nrioxarray                      0.0.5            py_0  conda-forge     \n[...]\nrioxarray                     0.16.0    pyhd8ed1ab_0  conda-forge         \nrioxarray                     0.17.0    pyhd8ed1ab_0  conda-forge   \n\n\n\n\n\n\nCheck-in\n\n\n\nDo you see any versions of rioxarray with multiple builds?\n\n\nSince we now know that we can find rioxarray in the conda-forge channel, we can go ahead and install it from this channel using the command\nconda install --channel conda-forge rioxarray\nYou‚Äôll see a moving bar that says Conda is solving (the) environment - this is Conda doing its package management job! It means Conda is working on:\n\nfinding the dependencies for the packages you are trying to install,\nfinding versions of these dependencies that are compatible with each other,\nmaking sure these new packages are compatible with the packages already present in the environment,\ndowngrade, upgrade, or remove packages as needed in the environment.\n\nOverall, Conda tries to install what we need with the least disruption. Solving an environment can often take time but it is crucial so that the environment remains stable and functional.\n\n\n\n\n\n\nCheck-in\n\n\n\n\nCheck whether pandas is installed in the environment.\nWhich channels were used to install dependencies for rioxarray?\n\n\n\n\n\n\n\nTo deactivate our current environment and return to our base environment we simply run\nconda deactivate\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify we are no longer in the test-env. What environment are we on?\n\n\n\n\n\nSince this was a test environment, we can go ahead and delete all of it using the command:\nconda remove --name test-env  --all\nIt will ask you whether you want to proceed. Type y and press enter to go ahead and delete the environment.\nWe can run conda env list to verify the test-env does not exist anymore.\n\n\n\nWe can also create a new environment by specifying the package versions and channel priorities. For example, to install the numpy and rioxarray versions we previously had in a new environment called my-env we run:\nconda create --name my-env rioxarray=0.17.0 numpy=1.26.4 --channel conda-forge\nNotice we are explicitely requiring certain versions of our packages, and the --channel conda-forge option is asking Conda to prioritize getting the packages from conda-forge.\n\n\n\n\n\n\nCheck-in\n\n\n\nTake a look at the dependencies that were installed with these two packages.\n\n\n\n\n\nOne of the main goals of using an environment to manage the packages used in your project is being able to share the environment so that other people can rerun your code and reproduce your results.\n‚ÄúSharing the environment‚Äù means sharing instructions that Conda can use to recreate the environment you have. These instructions are, basically, a list of the packages installed in the environment, their versions, which channels were used to install them, and, optionally, build specifications.\nThere are several ways of creating these instructions to reconstruct an environment depending on the level of cross-platform compatibility we are looking for. However, each of the following methods to export the environment specifications will generate a new YAML file. This file type with .yml extension is human-readable markup language that is commonly used for configuration in software applications.\n\n\n\n\n\n\nNavigate to project directory\n\n\n\nEach of the commands for exporting the environment specifications will create a .yml file in our terminal‚Äôs current working directory. Remember you can use pwd (Mac & Linux) or echo %cd% (Windows CMD) on the command line to check which is your current working directory. If you need to change directories you can use cd navigation in the terminal.\nThe best practice is to have the environment.yml file in the directory that holds your project. This way, you can use version control on it and push it to your remote repository.\n\n\n\n\nThe first method to export the environment specifications is running\nconda env export &gt; environment.yml\nThe environment.yml is the name of the YAML file that will have the environment specifications.\nOpen the environment.yml file that was generated, it will look similar to this excerpt:\nname: my-env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - affine=2.4.0=pyhd8ed1ab_0\n  - attrs=24.2.0=pyh71513ae_0\n  [...]\n  - zlib=1.3.1=h87427d6_1\n  - zstd=1.5.6=h915ae27_0\nprefix: /Users/galaz-garcia/opt/anaconda3/envs/my-env\nHere we can see the name of the environment, the channels used to install packages (in order of priority), and the package names, each with a version and build string. This ensures that the environment can be recreated exactly as it is on another system. This first method to export the environment specifications is the most detailed and it is both platform and package specific.\n\n\n\n\n\n\nDelete prefix line before sharing environment\n\n\n\nNotice the last line in the environment.yml file, this prefix indicates the absolute path to the environment‚Äôs installation on your local machine.\nYou should delete the prefix line when sharing the environment file. Leaving it there is unnecessary and could cause confusion since it points to specific directroy in your local machine.\n\n\n\n\n\nOur second method to export the environment specifications is to run\nconda env export --from-history &gt; environment_hist.yml\nHere I named the file environment_hist.yml to not overwrite the previous environmnet.yml, that way you can compare both of them. Open the environment_hist.yml file, it will look similar to this (much shorter than the previous one):\nname: my-env\nchannels:\n  - defaults\ndependencies:\n  - numpy=1.26.4\n  - rioxarray=0.17.0\nprefix: /Users/galaz-garcia/opt/anaconda3/envs/my-env\nAdding the --from-history option tells Conda to only include packages that we explicitely installed (in this case numpy=1.26.4 and rioxarray=0.17.0), omitting any dependencies that were automatically installed and channel information. This will create a minimal environment file that lists only the packages you explicitly installed, making it simpler and more portable for sharing with others. While this method ensures reproducibility of the core setup, Conda will resolve dependencies on its own and these might not be the same as your original environment.\n\n\n\n\n\n\nAdding channels to environment.yml file\n\n\n\nIn section 5 we saw that the rioxarray package is available on the conda-forge channel, but not the defaults channel. The output of conda env export with the --from-history option only includes the defaults channel, so we wouldn‚Äôt be able to recreate the environment with that file as is. Remember the .yml file can be manually modified and we can edit it to include conda-forge as the first priority channel, followed by the defaults channel. Rememember to also delete the prefix line before sharing. The modified version of the --from-history output that will allow us to recreate the environment will be:\nname: my-env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - numpy=1.26.4\n  - rioxarray=0.17.0\n\n\nBefore moving to the last exercise, delete the environment.yml and environment_hist.yml files.\n\n\n\n\n\nFor this last exercise, click here and download the environment.yml file in this repository. Move to a directory for a mock project and navigate to that directory in the terminal.\n\nTo create an environment from specifications in a .yml file we run\nconda env create --name test-env --file environment.yml\nThen --name option states how we want to name our environment (test-env in this case). If no --name option is given, Conda will name of the environment using the name field in the environment.yml file.\n\n\n\n\n\n\nCheck-in\n\n\n\nVerify that the new environment was created, activate it, and take a look at the installed packages.",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/appendices/A-python-environments.html#conda-commands",
    "href": "book/appendices/A-python-environments.html#conda-commands",
    "title": "Conda environments",
    "section": "",
    "text": "The following table includes the commands covered in this lesson‚Äôs exercises. Check out Conda‚Äôs cheatsheet for more commands and tips.\n\n\n\n\n\n\n\nCommand\nWhat it does\n\n\n\n\nconda env list\nlist available Conda environments\n\n\nconda create --name ENVNAME python\ncreate a new Python environment named ENVNAME\n\n\nconda remove --name ENVNAME  --all\ndelete ENVNAME environment\n\n\nconda activate ENVNAME\nactivate environment\n\n\nconda deactivate\ndeactivate active environment\n\n\npython -V\nprint Python version installed in active environment\n\n\nconda list\nlist installed packages in active environment\n\n\nconda list PKGNAME\ncheck if PKGNAME package is installed in active environment\n\n\nconda install PKGNAME\ninstall PKGNAME package in environment using environment channel priorities (generally just from defaults channel)\n\n\nconda install --channel CHANNELNAME PKGNAME\ninstall PKGNAME package in environment from from CHANNELNAME channel\n\n\nconda search PKGNAME\nsearch for PKGNAME package in environment‚Äôs channels\n\n\nconda search --channel CHANNELNAME PKGNAME\nsearch for PKGNAME package in CHANNELNAME channel\n\n\nconda env export &gt; ENV.yml\nexport environment specifications of currently active environmemt into ENV.yml file (includes all dependencies, buildstrings, and channels)\n\n\nconda env export --from-history &gt; ENV.yml\nexport environment specifications of currently active environmemt into ENV.yml file (only packages explicitely installed, no dependencies, buildstrings, or channels)\n\n\nconda env create --name ENVNAME --file ENV.yml\ncreate an environment named ENVNAME from specifications in ENV.yml file",
    "crumbs": [
      "notes",
      "Appendices",
      "Conda environments"
    ]
  },
  {
    "objectID": "book/preface.html",
    "href": "book/preface.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the ‚ÄòEDS 220 - Working with Environmental Datasets‚Äô course notes!\nDesigned for the UCSB Masters in Environmental Data Science (MEDS), this course will guide you through widely used environmental data formats and Python libraries for analyzing diverse environmental datasets.\nThe notes are organized following the increasing dimensions of different environmental datasets, from familiar tabular data to intricate multi-dimensional arrays. Through hands-on code and activities, you‚Äôll analyze real-world environmental datasets sourced from leading open data repositories and cloud platforms.\nWho is this course for? EDS 220 is tailored for beginner Python programmers eager to deepen their skills. If you‚Äôre familiar with the basics of Python and have experience working in Jupyter notebooks, you‚Äôre in the right place. You are also encouraged to bring along your git skills and GitHub profile, ready to practice the essential git pull - git push workflow as you progress.\nOverall, these notes are just the beginning! They offer a solid foundation but are, inevitably, a partial exposition of the incredibly vast ecosystem of data formats, repositories, and Python tools available in environmental data science. By the end of this course, you‚Äôll have a strong grasp of the fundamentals and also the confidence to dive deeper into using Python for environmental data science and continue your MEDS journey.\n\n\nA big thanks to the creators of the open-source Python libraries, datasets, and educational materials that have helped shape this course. Your contributions have made our learning journey richer and more impactful. Attribution is included in any materials where content is adapted from other resources.\n\n\n\nüìù If you have suggestions on how to correct, improve, or expand these notes, please feel free to email Carmen Galaz Garc√≠a at galazgarcia@bren.ucsb.edu or file a GitHub issue.\nüåü If these course materials have been useful to you, consider adding a star to the project‚Äôs repository.\n\n\n\nThis work, including the course notes, discussion sections, and assignments, is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) License. For attribution, please cite these materials as:\n\nC. Galaz Garc√≠a, EDS 220 - Working with Environmental Datasets, Course Notes. 2024. [Online]. Available: https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html\n\nor use the bib reference:\n@misc{galaz_garcia_eds_2024,\n    title = {EDS 220 - Working with Environmental Datasets, Course Notes},\n    url = {https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html},\n    author = {Galaz Garc√≠a, Carmen},\n    year = {2024},\n}",
    "crumbs": [
      "notes",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#acknowledgements",
    "href": "book/preface.html#acknowledgements",
    "title": "About",
    "section": "",
    "text": "A big thanks to the creators of the open-source Python libraries, datasets, and educational materials that have helped shape this course. Your contributions have made our learning journey richer and more impactful. Attribution is included in any materials where content is adapted from other resources.",
    "crumbs": [
      "notes",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#contribute",
    "href": "book/preface.html#contribute",
    "title": "About",
    "section": "",
    "text": "üìù If you have suggestions on how to correct, improve, or expand these notes, please feel free to email Carmen Galaz Garc√≠a at galazgarcia@bren.ucsb.edu or file a GitHub issue.\nüåü If these course materials have been useful to you, consider adding a star to the project‚Äôs repository.",
    "crumbs": [
      "notes",
      "About"
    ]
  },
  {
    "objectID": "book/preface.html#attribution",
    "href": "book/preface.html#attribution",
    "title": "About",
    "section": "",
    "text": "This work, including the course notes, discussion sections, and assignments, is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) License. For attribution, please cite these materials as:\n\nC. Galaz Garc√≠a, EDS 220 - Working with Environmental Datasets, Course Notes. 2024. [Online]. Available: https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html\n\nor use the bib reference:\n@misc{galaz_garcia_eds_2024,\n    title = {EDS 220 - Working with Environmental Datasets, Course Notes},\n    url = {https://meds-eds-220.github.io/MEDS-eds-220-course/book/preface.html},\n    author = {Galaz Garc√≠a, Carmen},\n    year = {2024},\n}",
    "crumbs": [
      "notes",
      "About"
    ]
  },
  {
    "objectID": "discussion-sections-upcoming/gif-empty.html",
    "href": "discussion-sections-upcoming/gif-empty.html",
    "title": "Creating a GIF of water level change at Lake Cachuma",
    "section": "",
    "text": "About\nLake Cachuma was once a primary water source for Santa Barbara County, but the California drought has made it an unreliable resevoir. In 2017, the reservoir was part of the 2.13% of California that was considered to be in an ‚Äúexceptional drought‚Äù. Given that this resevoir is the majority water source for over 200,000 Santa Barbara residents, the water levels in the Cachuma have a major impact on its residents. While the drought is not over, heavy rains in 2022 - 2023 helped Lake Cachuma reach it‚Äôs capacity for the first time in 11 years.\n\n\n\nPurpose\nWe will use satelittle imagery to see if we can notice changes in water levels when the reservoir was at an all time low versus the following years. We will be specifically looking at the water levels in Harvey Bay. In order to show the water level change in this 6 year time span, we will create a gif.\n\n\n\nAbout the data:\nTo carry out this task, we will use the Microsoft Planetary Computer Catalog. We will be using NAIP imagery from the catalog in the years 2016 to 2022.\n\nLoad libraries and data\nFirst, lets load our libraries. To create the GIF we‚Äôll be using the geogif library, which makes it simple to create gifs from xarray.DataArrays.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom pystac_client import Client  # To access STAC catalogs\nimport planetary_computer  # To sign items from the MPC STAC catalog \nfrom IPython.display import Image  # To nicely display images\nfrom geogif import gif\nfrom shapely.geometry import box\nimport xarray as xr\nimport os\n\nNext we will access our data via the MPC catalog. Access the naip collection and store the collection in naip_collection.\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n\ncatalog.get_collections()\ncollections = ...  # Turn generator into list\n\n# Print the number of collections\nprint('Number of collections:', len(collections))\n\n# Pull out the NAIP collection\nnaip_collection = ...\nnaip_collection\n\nNow that we have our data, we need to specify the temporal and spatial information we are interested in. Specify the range of interest in the time_range variable. We are intersted at the time when Lake Cachuma was at its lowest (01/01/2016) until the heavy rain storms (01/01/2024).\n\n# Temporal range of interest during drought\ntime_range = ...\n\nThe following bounding box coordinates are around Harvey‚Äôs Cove at lake cachuma.\n\nbbox = [-119.96541203059391,34.57264927127669 ,-119.96035687994136,  34.57849481511495]\n\nNow that we specificed our bounding box and time range, lets do a catalog search to get our data. Be sure to include your bbox and time_range in your search. After completing your search, retrieve your search items and assign the first item in your catalog search to the variable item.\n\n# Catalog search\nsearch = ...\n\n# Get items from search\nitems = ...\n\n\n# Determine number of items in search\nprint(f'There are {len(items)} items in the search.')\n\n\n# Get first item in the catalog search\nitem = ...\ntype(item)\n\n\n\nLet‚Äôs look at a single raster.\nThe NAIP data is available at the item‚Äôs ‚Äòimage‚Äô asset. Use rioxr.open_rasterio to open the image asset. We want to open item.assets['image'].href to get the xarray.\n\nlake_levels = ...\nlake_levels\n\nThis rater is way bigger than our area of interest. To verify this and then clip the raster, let‚Äôs make a gpd.GeoDataFrame from the bbox coordinates:\nRun the cell below. What is the box() function doing?\n\n# Bounding box as geodataframe\nbox_df = gpd.GeoDataFrame(geometry=[box(*bbox)],\n                 crs='epsg:4326') \n\n\n# Clip raster to bounding box, ensuring the crs' are the same\nlake_levels = lake_levels.rio.clip_box(*box_df.to_crs(lake_levels.rio.crs).total_bounds)\n\nNAIP data has four bands, Red, Green, Blue, and Near-Infrared. To make it easier to plot RGB images, select only the first three bands, and then plot the selected data.\n\n# Select the the first three bands of the NAIP data\nlake_levels = ...\n\n# Plot the first three bands\n...\n\n\n\nStack Rasters\nOur goal is to use the gif function to create a gif with the four NAIP images over Lake Cachuma.\nThe gif documentation indicates that to do so we will need to put our images/rasters in a single xarray.DataArray with dimensions (time, band, y, x). Check your raster to see what the dimmensions are. Do they match the dimensions that the gif function requires?\n\n# Check raster dimensions\nlake_levels.dims\n\n# Check the shape of the raster\nlake_levels.shape\n\nTo create a single xarray.DataArray with a time dimensions we will stack the four rasters we obtained in our search. We use a for loop to repeat the previous steps for each item in the search (access the item‚Äôs image asset, clip, and select bands) and store each processed raster in a list rasters.\n\nrasters = []\nfor item in items: \n    # Access the image asset\n    ... \n    # Clip the raster\n    ...\n    # Select the first three bands\n    ...\n    rasters.append(lake_levels)\n\nNext lets use the xarray.concat() function to concatenate these rasters along a new dimensions we will call time.\n\n# Concatenate rasters into single xarray.DataArray\nstack = xr.concat(rasters, dim='time')\nstack\n\nNotice our new dimension time does not have any coordinates associated to it. To add coordinates to this dimensions we use the assign_coords() method for xarray.DataArray.\nIt would be reasonable to use the year of collection of each raster (as a timestamp) as its coordinate on the time dimension. We can see this year in the item‚Äôs properties:\n\n# year of collection of an item \nitem = items[0]\nitem.properties['naip:year']\n\n\n# convert strings to datetime\n...\n\nTo get this timestamp for each year we can create a list using list comprehension:\nList comprehension format reminder: [expression for item in items if condition]\n\ntimes = ...\ntimes\n\nAnd finally we assign these times as the coordinates (using assign_coords()) and sort by the vlaues of time dimension:\n\nstack = stack.assign_coords(time=times).sortby(\"time\")\nstack\n\n\n\nNow its time to make a GIF!\nUse the gif function to create a gif of our stacked raster. Look at the documentation for gif(). What does the fps argument stand for?\n\n# Create gif\n# adding to=\"lake_cachuma.gif\" will save GIF\n\n\n\n\n\nReferences\nSanta Maria Times. ‚ÄúCachuma Lake Among the Last of State‚Äôs Reservoirs in Exceptional Drought.‚Äù Santa Maria Times. January 26, 2017. https://santamariatimes.com/news/local/cachuma-lake-among-the-last-of-states-reservoirs-in-exceptional-drought/article_e358ca8e-654d-5ff7-9b58-857914a4ccd4.html.\nThe Santa Barbara Independent. ‚ÄúCachuma Fills and Flood Gates to Open.‚Äù The Santa Barbara Independent, January 14, 2023. https://www.independent.com/2023/01/14/cachuma-fills-and-flood-gates-to-open/."
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "",
    "text": "This discussion section will guide you through answering questions about water-related conflicts at the Colorado River Basin using data from the U.S. Geological Survey (USGS). In this discussion section, you will:"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#setup",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#setup",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Setup",
    "text": "Setup\n\n\n\n\n\n\n\nIn the Taylor server, start a new JupyterLab session or access an active one.\nIn the terminal, use cd to navigate into the eds-220-sections directory. Use pwd to verify eds-220-sections is your current working directory.\nCreate a new Python Notebook inside your eds-220-sections directory and rename it to section-2-co-basin-water-conflicts.ipynb.\nUse the terminal to stage, commit, and push this file to the remote repository. Remember:\n\ngit status : check git status\ngit add FILE-NAME : stage updated file\ngit status : check git status again to confirm\ngit commit -m \"Commit message\" : commit with message\ngit pull : check local repo is up to date (best practice)\ngit push : push changes to upstream repository\n\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY SET UP YOUR NOTEBOOKS BEFORE CONTINUING"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#general-directions",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#general-directions",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "General directions",
    "text": "General directions\n\n\n\n\n\n\n\nAdd comments in your code cells following comments best practices.\nOn each exercise, include markdown cells in between your code cells to add titles and information.\nIndications about when to commit and push changes are included, but you are encouraged to commit and push more often."
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#about-the-data",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#about-the-data",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "About the data",
    "text": "About the data\nFor these exercises we will use data about Water Conflict and Crisis Events in the Colorado River Basin [1]. This dataset is stored at ScienceBase,a digital repository from the U.S. Geological Survey (USGS) created to share scientific data products and USGS resources.\nThe dataset is a CSV file containing information about conflict or crisis around water resource management in the Colorado River Basin. The Colorado River Basin, inhabited by several Native American tribes for centuries, is a crucial water source in the southwestern United States and northern Mexico, supporting over 40 million people, extensive agricultural lands, and diverse ecosystems. Its management is vital due to the region‚Äôs arid climate and the competing demands for water, leading to significant challenges related to water allocation and conservation.\n\n\n\nColorado River Basin. U.S. Bureau of Reclamation."
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#string-accessor-for-pandas.series",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#string-accessor-for-pandas.series",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "1. String accessor for pandas.Series",
    "text": "1. String accessor for pandas.Series\nIn this session we will work with pandas.Series whose values are strings. This is a common scenario and pandas has special string methods for this kind of series. These methods are accessed via the str accessor. Accessors provide additional functionality for working with specific kinds of data (in this case, strings).\n\nCarefully read the code below. We‚Äôll use some of it in the next exercises.\n\n\nimport pandas as pd \nimport numpy as np\n\n# Example series\ns = pd.Series(['California; Nevada', 'Arizona', np.nan, 'Utah; Colorado'])\nprint(s)\n\n# str accessor (doesn't do anything by itself)\nprint(s.str)\n\n# Use str accessor with additional methods to perform string operations\n# .split splits strings by ';' and expands output into separate columns\ns.str.split(';', expand=True)\n\n0    California; Nevada\n1               Arizona\n2                   NaN\n3        Utah; Colorado\ndtype: object\n&lt;pandas.core.strings.accessor.StringMethods object at 0x166f07090&gt;\n\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\nCalifornia\nNevada\n\n\n1\nArizona\nNone\n\n\n2\nNaN\nNaN\n\n\n3\nUtah\nColorado"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#archive-exploration",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#archive-exploration",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "2. Archive exploration",
    "text": "2. Archive exploration\nTake some time to look through the dataset‚Äôs description in the ScienceBase repository. Discuss the following questions with your team:\n\nWhere was the data collected from? \nDuring what time frame were the observations in the dataset collected? \nWhta was the author‚Äôs perceived value of this dataset? \nBriefly discuss anything else that seems like relevant information.\n\nIn a markdown cell, use your answers to the previous questions to add a brief description of the dataset. Include a citation, date of access, and a link to the archive.\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#data-loading",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#data-loading",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "3. Data loading",
    "text": "3. Data loading\n\nIn class we have (so far) loaded data into our workspace either by downloading the file and storing a copy of it in our computer or by accessing the file directly through a URL. With your team, discuss what are, in general, the advantages and disadvantages of these two methods of data access.\nImport the Colorado River Basin Water Conflict Table.csv file from the Science Base repository into your workspace. Name your data frame variable df.\n\n\nCHECK IN WITH YOUR TEAM\n\n\nMAKE SURE YOU‚ÄôVE ALL SUCCESSFULLY LOADED THE DATA BEFORE CONTINUING\n\n\ncheck git status -&gt; stage changes -&gt; check git status -&gt; commit with message -&gt; pull -&gt; push changes\n\n\nimport pandas as pd\n\ndf = pd.read_csv('data/Colorado River Basin Water Conflict Table.csv')\ndf.head(5)\n\n\n\n\n\n\n\n\nEvent\nSearch Source\nNewspaper\nArticle Title\nDuplicate\nReport Date\nReport Year\nEvent Date\nEvent Day\nEvent Month\n...\nArticle Text Search - water rights\nArticle Text Search - intergovernmental\nArticle Text Search - water transfers\nArticle Text Search - navigation\nArticle Text Search - fish\nArticle Text Search - invasive\nArticle Text Search - diversion\nArticle Text Search - water diversion\nArticle Text Search - instream\nArticle Text Search - aquatic\n\n\n\n\n0\n1\nUSGS1-50.docx\nThe Durango Herald (Colorado)\nTribes assert water rights on Colorado River B...\nFalse\n7-Apr-22\n2022.0\nNaN\nNaN\n4.0\n...\n17\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n2\nUSGS1-50.docx\nJournal, The (Cortez, Dolores, Mancos, CO)\nNative American tribes assert water rights on ...\nFalse\n7-Apr-22\n2022.0\nNaN\nNaN\n4.0\n...\n17\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n3\nUSGS1-50.docx\nThe Salt Lake Tribune\n'Very positive change.' New Utah law will be a...\nFalse\n17-Mar-22\n2022.0\nNaN\nNaN\n3.0\n...\n12\n0\n0\n0\n1\n0\n0\n0\n12\n1\n\n\n3\n4\nUSGS1-50.docx\nCasa Grande Dispatch (AZ)\nLegislation would let an Arizona tribe lease C...\nFalse\n11-Dec-21\n2021.0\nNaN\nNaN\n12.0\n...\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n5\nUSGS1-50.docx\nThe Aspen Times (Colorado)\nHistorically excluded from Colorado River poli...\nFalse\n19-Dec-21\n2021.0\nNaN\nNaN\n11.0\n...\n18\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows √ó 48 columns"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#preliminary-data-exploration",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#preliminary-data-exploration",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "4. Preliminary data exploration",
    "text": "4. Preliminary data exploration\nWrite a list with at least four ways in which you coud gain preliminary information about this dataset and why these are relevant.\n\n# df.head()\n# df.shape\n# df.columns\n# df.Stakeholders.unique()\n\n\n(df['State'].dropna()\n            .str.split(';', expand=True)\n            .stack()\n            .str.strip()\n            .value_counts())\n\nAZ    87\nCO    45\nUT    40\nNV    19\nCA    16\nNM    13\nWY     8\nOH     1\nTX     1\nName: count, dtype: int64\n\n\n\noh_row = df[df['State'].str.contains('OH', case=False, na=False)]\noh_row.iat[0,3]\n\n'Environmentalists secure water rights for Great Salt Lake'\n\n\n\noh_row['State']\n\n11    OH; UT\nName: State, dtype: object\n\n\n\ndf[df['State'].str.contains('TX', case=False, na=False)]\n\n\n\n\n\n\n\n\nEvent\nSearch Source\nNewspaper\nArticle Title\nDuplicate\nReport Date\nReport Year\nEvent Date\nEvent Day\nEvent Month\n...\nArticle Text Search - water rights\nArticle Text Search - intergovernmental\nArticle Text Search - water transfers\nArticle Text Search - navigation\nArticle Text Search - fish\nArticle Text Search - invasive\nArticle Text Search - diversion\nArticle Text Search - water diversion\nArticle Text Search - instream\nArticle Text Search - aquatic\n\n\n\n\n220\n221\nUSGS251-300.docx\nAssociated Press State & Local\nAustin water supply long-term plans appear to ...\nFalse\n5-Mar-15\n2015.0\n3\nNaN\n3.0\n...\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n1 rows √ó 48 columns"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#examine-state-codes",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#examine-state-codes",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Examine state codes",
    "text": "Examine state codes\nOur goal today is to find which states are reported in the dataset as having a water-conflict.\n\nExamine the unique values in the States column. What could be a challenge to writing code to find which states are listed (without repetition)? Remember to write longer answers in mardown cells, not as comments.\n\n\nprint(df['State'].unique())\n\n['CO' 'UT' nan 'AZ' 'OH; UT' 'AZ; CO; NM; UT' 'CA' 'AZ; UT' 'AZ; NV'\n 'CO; UT; WY; NM' 'AZ; CA' 'UT; AZ' 'CO; WY' 'NV; AZ' 'CO; AZ'\n 'AZ; CA; CO; NV; NM; UT; WY' 'AZ; CA; NV' 'NV' 'NM' 'UT; CO; WY'\n 'CA; NV; AZ' 'AZ; NM' 'WY; UT; CO' 'TX']\n\n\n\nfor x in df['State'].unique():\n    print(x)\n\nCO\nUT\nnan\nAZ\nOH; UT\nAZ; CO; NM; UT\nCA\nAZ; UT\nAZ; NV\nCO; UT; WY; NM\nAZ; CA\nUT; AZ\nCO; WY\nNV; AZ\nCO; AZ\nAZ; CA; CO; NV; NM; UT; WY\nAZ; CA; NV\nNV\nNM\nUT; CO; WY\nCA; NV; AZ\nAZ; NM\nWY; UT; CO\nTX"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#brainstorm",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#brainstorm",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Brainstorm",
    "text": "Brainstorm\n\nFirst, individually, write step-by-step instructions of how you would create a list with the state codes in which there‚Äôs a water-conflict reported (without repetition). It‚Äôs ok if you don‚Äôt know how to code each step, it‚Äôs just important to have an idea of what we‚Äôll do before starting to code.\nDiscuss your ideas with your team.\n\nThe next exercises will guide you through finding the state codes in the dataset. There are many ways of extracting this information from the dataset. The one presented here might not be the same way you thought about doing it - that‚Äôs ok! This one was designed to practice using the .str accessor in a pandas.Series."
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#drop-nas",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#drop-nas",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Drop NAs",
    "text": "Drop NAs\nUse the dropna() method for pandas.Series on the State column to create a new pandas.Series states without NAs. Check there are no NAs in the new states series.\n\nstates = df['State'].dropna()\nstates\n\n0          CO\n1          CO\n2          UT\n5          AZ\n11     OH; UT\n        ...  \n263        CO\n264        CO\n265    AZ; CA\n266        AZ\n267        AZ\nName: State, Length: 178, dtype: object\n\n\n\nstates.hasnans\n\nFalse"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#split-strings",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#split-strings",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Split strings",
    "text": "Split strings"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#stack-the-data-frame",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#stack-the-data-frame",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Stack the data frame",
    "text": "Stack the data frame"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#string-accessor",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#string-accessor",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "String accessor",
    "text": "String accessor"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#value-counts",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#value-counts",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Value counts",
    "text": "Value counts"
  },
  {
    "objectID": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#method-chaining",
    "href": "discussion-sections-upcoming/ds-2-water-crisis-exploration.html#method-chaining",
    "title": "Exploring water conflicts in the Colorado River Basin",
    "section": "Method chaining",
    "text": "Method chaining\n\n# stakeholders = (df['Stakeholders'].dropna()\n#                      .str.split(',', expand=True)\n#                      .apply(lambda x: x.str.strip())\n#                      .values\n#                      .ravel())\n\n# stakeholders = pd.unique(stakeholders)\n# print(stakeholders)"
  },
  {
    "objectID": "discussion-sections-upcoming/gif.html",
    "href": "discussion-sections-upcoming/gif.html",
    "title": "Creating a GIF of water level change at Lake Cachuma",
    "section": "",
    "text": "About\nLake Cachuma was once a primary water source for Santa Barbara County, but the California drought has made it an unreliable resevoir.In 2017, the reservoir was part of the 2.13% of California that was considered to be in an ‚Äúexceptional drought‚Äù.Given that this resevoir is the majority water source for over 200,000 Santa Barbara residents, the water levels in the Cachuma have a major impact on its residents. While the drought is not over, heavy rains in 2022 - 2023 helped Lake Cachuma reach it‚Äôs capacity for the first time in 11 years.\n\n\n\nPurpose\nWe will use satelittle imagery to see if we can notice changes in water levels when the reservoir was at an all time low versus the following years. We will be specifically looking at the water levels in Harvey Bay. In order to show the water level change in this 6 year time span, we will create a gif.\n\n\n\nAbout the data:\nTo carry out this task, we will use the Microsoft Planetary Computer Catalog. We will be using NAIP imagery from the catalog in the years 2016 to 2022.\n\nLoad libraries and data\nFirst, lets load our libraries. To create the GIF we‚Äôll be using the geogif library, which makes it simple to create gifs from xarray.DataArrays.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom pystac_client import Client  # To access STAC catalogs\nimport planetary_computer  # To sign items from the MPC STAC catalog \nfrom IPython.display import Image  # To nicely display images\nfrom geogif import gif\nfrom shapely.geometry import box\nfrom shapely.geometry import Polygon\nimport xarray as xr\nfrom PIL import Image\nimport os\n\nNext we will access our data via the MPC catalog. Access the naip collection and store the collection in naip_collection.\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n\ncatalog.get_collections()\ncollections = list(catalog.get_collections())  # Turn generator into list\n\nprint('Number of collections:', len(collections))\n\nprint(\"Collections IDs (first 10):\")\n\nfor i in range(10):\n    print('-', collections[i].id)\n    \n    \nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\nNumber of collections: 124\nCollections IDs (first 10):\n- daymet-annual-pr\n- daymet-daily-hi\n- 3dep-seamless\n- 3dep-lidar-dsm\n- fia\n- sentinel-1-rtc\n- gridmet\n- daymet-annual-na\n- daymet-monthly-na\n- daymet-annual-hi\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) \nprovides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR). \nNAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) \nwithin the [US Department of Agriculture](https://www.usda.gov/) (USDA). \nData are captured at least once every three years for each state. \nThis dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\nYou can visualize the coverage of current and past collections [here](https://naip-usdaonline.hub.arcgis.com/). \n\"\n        \n    \n                \n            \n                \n                    \n        links[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"license\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://www.fsa.usda.gov/help/policies-and-links/\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Public Domain\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"describedby\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/dataset/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Human readable dataset overview and reference\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        stac_extensions[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            item_assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            msft:region\n            \"westeurope\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:container\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:storage_account\n            \"naipeuwest\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:short_description\n            \"NAIP provides US-wide, high-resolution aerial imagery.  This dataset includes NAIP images from 2010 to the present.\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"NAIP: National Agriculture Imagery Program\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        0[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -124.784\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            24.744\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -66.951\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            49.346\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -156.003\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            19.059\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -154.809\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            20.127\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -67.316\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            17.871\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -65.596\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            18.565\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -64.94\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            17.622\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -64.56\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            17.814\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        interval[] 1 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2010-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2022-12-31T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        keywords[] 7 items\n        \n            \n        \n            \n                \n        \n            0\n            \"NAIP\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"Aerial\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"Imagery\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"USDA\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"AFPO\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"United States\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        providers[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Esri\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.esri.com/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Microsoft\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://planetarycomputer.microsoft.com\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        gsd[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            0.3\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            1\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        eo:bands[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"NAIP thumbnail\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geoparquet-items\n            \n        \n            \n                \n        \n            href\n            \"abfs://items/naip.parquet\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/x-parquet\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoParquet STAC items\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Snapshot of the collection's STAC items exported to GeoParquet format.\"\n        \n    \n            \n        \n            \n                \n        \n            msft:partition_info\n            \n        \n            \n                \n        \n            is_partitioned\n            True\n        \n    \n            \n        \n            \n                \n        \n            partition_frequency\n            \"AS\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            table:storage_options\n            \n        \n            \n                \n        \n            account_name\n            \"pcstacitems\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"stac-items\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nNow that we have our data, we need to specify the temporal and spatial information we are interested in. Specify the range of interest in the time_range variable. We are intersted at the time when Lake Cachuma was at its lowest (01/01/2016) until the heavy rain storms (01/01/2024).\nWe will use the geojson.io tool in order to easily get our bounding box. Head to this link and either use the rectangle tool to draw a bounding box around Harvey Bay or insert four different points. Look at the coordinates on each point and instead them in thebbox variable in the following order: [minx, miny, maxx, maxy].\n\n# Temporal range of interest during drought\ntime_range = \"2016-01-01/2022-01-01\"\n\n\nbbox = [-119.96541203059391,34.57264927127669 ,-119.96035687994136,  34.57849481511495]\n\n\nNow that we specificed our bounding box and time range, lets do a catalog search to get our data. Be sure to include your bbox and time_range in your search. After completing your search, retrieve your search items and assign the first item in your catalog search to the variable item.\n\n# Catalog search\n# search \nsearch = catalog.search(\n    collections=[\"naip\"], \n    bbox=bbox, \n    datetime='2016/2023'\n)\n\n# get items from search\nitems = search.item_collection()\nprint(f'There are {len(items)} items in the search.')\n\nThere are 4 items in the search.\n\n\n\n# Get first item in the catalog search\nitem = items[0]\ntype(item)\n\npystac.item.Item\n\n\n\n\nLet‚Äôs look at a single raster.\nThe NAIP data is available at the item‚Äôs ‚Äòimage‚Äô asset. Use rioxr.open_rasterio to open the image asset.\n\nlake_levels = rioxr.open_rasterio(item.assets['image'].href)\nlake_levels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12510, x: 10570)&gt; Size: 529MB\n[528922800 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 32B 1 2 3 4\n  * x            (x) float64 85kB 2.246e+05 2.246e+05 ... 2.309e+05 2.309e+05\n  * y            (y) float64 100kB 3.836e+06 3.836e+06 ... 3.828e+06 3.828e+06\n    spatial_ref  int64 8B 0\nAttributes:\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    AREA_OR_POINT:             Area\n    _FillValue:                0\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12510x: 10570...[528922800 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.246e+05 2.246e+05 ... 2.309e+05array([224550.3, 224550.9, 224551.5, ..., 230890.5, 230891.1, 230891.7])y(y)float643.836e+06 3.836e+06 ... 3.828e+06array([3835751.7, 3835751.1, 3835750.5, ..., 3828247.5, 3828246.9, 3828246.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :224550.0 0.6 0.0 3835752.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          224550.3,           224550.9,           224551.5,\n       224552.09999999998, 224552.69999999998,           224553.3,\n                 224553.9,           224554.5, 224555.09999999998,\n       224555.69999999998,\n       ...\n                 230886.3,           230886.9,           230887.5,\n       230888.09999999998, 230888.69999999998,           230889.3,\n                 230889.9,           230890.5, 230891.09999999998,\n       230891.69999999998],\n      dtype='float64', name='x', length=10570))yPandasIndexPandasIndex(Index([         3835751.7,          3835751.1,          3835750.5,\n       3835749.9000000004, 3835749.3000000003,          3835748.7,\n                3835748.1,          3835747.5, 3835746.9000000004,\n       3835746.3000000003,\n       ...\n                3828251.7,          3828251.1,          3828250.5,\n       3828249.9000000004, 3828249.3000000003,          3828248.7,\n                3828248.1,          3828247.5, 3828246.9000000004,\n       3828246.3000000003],\n      dtype='float64', name='y', length=12510))Attributes: (9)TIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1TIFFTAG_RESOLUTIONUNIT :1 (unitless)AREA_OR_POINT :Area_FillValue :0scale_factor :1.0add_offset :0.0\n\n\nThis rater is way bigger than our area of interest. To verify this and then clip the raster, let‚Äôs make a gpd.GeoDataFrame from the bbox coordinates:\n\n# bounding box as geodataframe\nbox_df = gpd.GeoDataFrame(geometry=[box(*bbox)],\n                 crs='epsg:4326') \n\n\n# clip raster to bounding box\nlake_levels = lake_levels.rio.clip_box(*box_df.to_crs(lake_levels.rio.crs).total_bounds)\n\nNAIP data has four bands, Red, Green, Blue, and Near-Infrared. To make it easier to plot RGB images, select only the first three bands.\n\nlake_levels = lake_levels.sel(band=[1,2,3])\nlake_levels.plot.imshow()\n\n\n\n\n\n\n\n\n\n\nStack Rasters\nOur goal is to use the gif function to create a gif with the four NAIP images over Lake Cachuma.\nThe gif documentation indicates that to do so we will need to put our images/rasters in a single xarray.DataArray with dimensions (time, band, y, x). Check your raster to see what the dimmensions are.\n\n# Check raster dimensions\nlake_levels.dims\n\n# Check the shape of the raster\nlake_levels.shape\n\n(3, 1105, 806)\n\n\nTo create a single xarray.DataArray with a time dimensions we will stack the four rasters we obtained in our search. We use a for loop to repeat the previous steps for each item in the search (access the item‚Äôs image asset, clip, and select bands) and store each processed raster in a list rasters.\n\nrasters = []\nfor item in items: \n    lake_levels = rioxr.open_rasterio(item.assets['image'].href)\n    lake_levels = lake_levels.rio.clip_box(*box_df.to_crs(lake_levels.rio.crs).total_bounds)\n    lake_levels = lake_levels.sel(band=[1,2,3])\n    rasters.append(lake_levels)\n\nNext lets use the xarray.concat() function to concatenate these rasters along a new dimensions we will call time.\n\n# concatenate rasters into single xarray.DataArray\nstack = xr.concat(rasters, dim='time')\nstack\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 4, band: 3, y: 1105, x: 806)&gt; Size: 11MB\narray([[[[ 23,  23,  20, ..., 119, 129, 128],\n         [ 23,  23,  20, ..., 135, 137, 125],\n         [ 20,  20,  23, ..., 131, 115, 118],\n         ...,\n         [ 65,  68,  98, ..., 148, 133, 125],\n         [ 81,  94, 116, ..., 118, 116, 114],\n         [ 64,  65,  94, ..., 111, 113, 116]],\n\n        [[ 66,  66,  65, ..., 108, 117, 116],\n         [ 66,  65,  65, ..., 119, 124, 117],\n         [ 65,  65,  65, ..., 117, 104, 113],\n         ...,\n         [ 79,  82,  98, ..., 147, 129, 122],\n         [ 88,  93, 109, ..., 117, 115, 115],\n         [ 81,  80,  97, ..., 114, 115, 116]],\n\n        [[ 55,  55,  55, ...,  82,  90,  86],\n         [ 55,  55,  55, ...,  94,  96,  89],\n         [ 55,  54,  57, ...,  94,  80,  89],\n         ...,\n...\n         ...,\n         [ 68,  70,  56, ..., 168, 166, 163],\n         [ 61,  66,  58, ..., 151, 143, 142],\n         [ 61,  68,  61, ..., 138, 136, 136]],\n\n        [[ 77,  72,  70, ..., 107, 124, 128],\n         [ 76,  72,  64, ...,  93, 103, 122],\n         [ 74,  71,  71, ...,  94, 104, 125],\n         ...,\n         [ 66,  62,  57, ..., 160, 164, 164],\n         [ 60,  64,  58, ..., 152, 145, 140],\n         [ 58,  63,  61, ..., 134, 132, 130]],\n\n        [[ 74,  65,  66, ...,  90, 100, 105],\n         [ 69,  65,  64, ...,  83,  88, 103],\n         [ 70,  66,  71, ...,  84,  94, 101],\n         ...,\n         [ 64,  63,  59, ..., 156, 155, 151],\n         [ 60,  66,  61, ..., 141, 135, 134],\n         [ 64,  64,  62, ..., 128, 128, 126]]]], dtype=uint8)\nCoordinates:\n  * band         (band) int64 24B 1 2 3\n  * x            (x) float64 6kB 2.28e+05 2.28e+05 ... 2.284e+05 2.284e+05\n  * y            (y) float64 9kB 3.83e+06 3.83e+06 ... 3.83e+06 3.83e+06\n    spatial_ref  int64 8B 0\nDimensions without coordinates: time\nAttributes:\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    AREA_OR_POINT:             Area\n    scale_factor:              1.0\n    add_offset:                0.0\n    _FillValue:                0xarray.DataArraytime: 4band: 3y: 1105x: 80623 23 20 23 23 23 23 23 23 23 ... 152 147 141 138 133 129 128 128 126array([[[[ 23,  23,  20, ..., 119, 129, 128],\n         [ 23,  23,  20, ..., 135, 137, 125],\n         [ 20,  20,  23, ..., 131, 115, 118],\n         ...,\n         [ 65,  68,  98, ..., 148, 133, 125],\n         [ 81,  94, 116, ..., 118, 116, 114],\n         [ 64,  65,  94, ..., 111, 113, 116]],\n\n        [[ 66,  66,  65, ..., 108, 117, 116],\n         [ 66,  65,  65, ..., 119, 124, 117],\n         [ 65,  65,  65, ..., 117, 104, 113],\n         ...,\n         [ 79,  82,  98, ..., 147, 129, 122],\n         [ 88,  93, 109, ..., 117, 115, 115],\n         [ 81,  80,  97, ..., 114, 115, 116]],\n\n        [[ 55,  55,  55, ...,  82,  90,  86],\n         [ 55,  55,  55, ...,  94,  96,  89],\n         [ 55,  54,  57, ...,  94,  80,  89],\n         ...,\n...\n         ...,\n         [ 68,  70,  56, ..., 168, 166, 163],\n         [ 61,  66,  58, ..., 151, 143, 142],\n         [ 61,  68,  61, ..., 138, 136, 136]],\n\n        [[ 77,  72,  70, ..., 107, 124, 128],\n         [ 76,  72,  64, ...,  93, 103, 122],\n         [ 74,  71,  71, ...,  94, 104, 125],\n         ...,\n         [ 66,  62,  57, ..., 160, 164, 164],\n         [ 60,  64,  58, ..., 152, 145, 140],\n         [ 58,  63,  61, ..., 134, 132, 130]],\n\n        [[ 74,  65,  66, ...,  90, 100, 105],\n         [ 69,  65,  64, ...,  83,  88, 103],\n         [ 70,  66,  71, ...,  84,  94, 101],\n         ...,\n         [ 64,  63,  59, ..., 156, 155, 151],\n         [ 60,  66,  61, ..., 141, 135, 134],\n         [ 64,  64,  62, ..., 128, 128, 126]]]], dtype=uint8)Coordinates: (4)band(band)int641 2 3array([1, 2, 3])x(x)float642.28e+05 2.28e+05 ... 2.284e+05axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([227958.3, 227958.9, 227959.5, ..., 228440.1, 228440.7, 228441.3])y(y)float643.83e+06 3.83e+06 ... 3.83e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([3830298.9, 3830298.3, 3830297.7, ..., 3829637.7, 3829637.1, 3829636.5])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :227958.0 0.6 0.0 3830299.2 0.0 -0.6000000000003375array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          227958.3,           227958.9,           227959.5,\n       227960.09999999998, 227960.69999999998,           227961.3,\n                 227961.9,           227962.5, 227963.09999999998,\n       227963.69999999998,\n       ...\n                 228435.9,           228436.5, 228437.09999999998,\n       228437.69999999998,           228438.3,           228438.9,\n                 228439.5, 228440.09999999998, 228440.69999999998,\n                 228441.3],\n      dtype='float64', name='x', length=806))yPandasIndexPandasIndex(Index([3830298.9000000004, 3830298.3000000003,          3830297.7,\n                3830297.1,          3830296.5, 3830295.9000000004,\n       3830295.3000000003,          3830294.7,          3830294.1,\n                3830293.5,\n       ...\n       3829641.9000000004, 3829641.3000000003,          3829640.7,\n                3829640.1,          3829639.5, 3829638.9000000004,\n       3829638.3000000003,          3829637.7,          3829637.1,\n                3829636.5],\n      dtype='float64', name='y', length=1105))Attributes: (9)TIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1TIFFTAG_RESOLUTIONUNIT :1 (unitless)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0_FillValue :0\n\n\nNotice our new dimension time does not have any coordinates associated to it. To add coordinates to this dimensions we use the assign_coords() method for xarray.DataArray.\nIt would be reasonable to use the year of collection of each raster (as a timestamp) as its coordinate on the time dimension. We can see this year in the item‚Äôs properties:\n\n# year of collection of an item \nitem = items[0]\nitem.properties['naip:year']\n\n'2022'\n\n\n\n# convert strings to datetime\npd.to_datetime(item.properties['naip:year'])\n\nTimestamp('2022-01-01 00:00:00')\n\n\nTo get this timestamp for each year we can create a list using list comprehension:\nList comprehension format reminder: [expression for item in items if condition]\n\ntimes = [pd.to_datetime(item.properties['naip:year']) for item in items]\ntimes\n\n[Timestamp('2022-01-01 00:00:00'),\n Timestamp('2020-01-01 00:00:00'),\n Timestamp('2018-01-01 00:00:00'),\n Timestamp('2016-01-01 00:00:00')]\n\n\nAnd finally we assign these times as the coordinates (using assign_coords()) and sort by the vlaues of time dimension:\n\nstack = stack.assign_coords(time=times).sortby(\"time\")\nstack\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 4, band: 3, y: 1105, x: 806)&gt; Size: 11MB\narray([[[[ 81,  72,  71, ..., 114, 139, 142],\n         [ 78,  75,  67, ...,  92, 105, 135],\n         [ 76,  71,  75, ..., 103, 115, 136],\n         ...,\n         [ 68,  70,  56, ..., 168, 166, 163],\n         [ 61,  66,  58, ..., 151, 143, 142],\n         [ 61,  68,  61, ..., 138, 136, 136]],\n\n        [[ 77,  72,  70, ..., 107, 124, 128],\n         [ 76,  72,  64, ...,  93, 103, 122],\n         [ 74,  71,  71, ...,  94, 104, 125],\n         ...,\n         [ 66,  62,  57, ..., 160, 164, 164],\n         [ 60,  64,  58, ..., 152, 145, 140],\n         [ 58,  63,  61, ..., 134, 132, 130]],\n\n        [[ 74,  65,  66, ...,  90, 100, 105],\n         [ 69,  65,  64, ...,  83,  88, 103],\n         [ 70,  66,  71, ...,  84,  94, 101],\n         ...,\n...\n         ...,\n         [ 65,  68,  98, ..., 148, 133, 125],\n         [ 81,  94, 116, ..., 118, 116, 114],\n         [ 64,  65,  94, ..., 111, 113, 116]],\n\n        [[ 66,  66,  65, ..., 108, 117, 116],\n         [ 66,  65,  65, ..., 119, 124, 117],\n         [ 65,  65,  65, ..., 117, 104, 113],\n         ...,\n         [ 79,  82,  98, ..., 147, 129, 122],\n         [ 88,  93, 109, ..., 117, 115, 115],\n         [ 81,  80,  97, ..., 114, 115, 116]],\n\n        [[ 55,  55,  55, ...,  82,  90,  86],\n         [ 55,  55,  55, ...,  94,  96,  89],\n         [ 55,  54,  57, ...,  94,  80,  89],\n         ...,\n         [ 60,  65,  78, ..., 139, 123, 116],\n         [ 69,  76,  91, ..., 112, 112, 112],\n         [ 60,  61,  75, ..., 111, 109, 110]]]], dtype=uint8)\nCoordinates:\n  * band         (band) int64 24B 1 2 3\n  * x            (x) float64 6kB 2.28e+05 2.28e+05 ... 2.284e+05 2.284e+05\n  * y            (y) float64 9kB 3.83e+06 3.83e+06 ... 3.83e+06 3.83e+06\n    spatial_ref  int64 8B 0\n  * time         (time) datetime64[ns] 32B 2016-01-01 2018-01-01 ... 2022-01-01\nAttributes:\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    AREA_OR_POINT:             Area\n    scale_factor:              1.0\n    add_offset:                0.0\n    _FillValue:                0xarray.DataArraytime: 4band: 3y: 1105x: 80681 72 71 67 69 85 80 71 69 84 ... 119 115 113 111 109 110 111 109 110array([[[[ 81,  72,  71, ..., 114, 139, 142],\n         [ 78,  75,  67, ...,  92, 105, 135],\n         [ 76,  71,  75, ..., 103, 115, 136],\n         ...,\n         [ 68,  70,  56, ..., 168, 166, 163],\n         [ 61,  66,  58, ..., 151, 143, 142],\n         [ 61,  68,  61, ..., 138, 136, 136]],\n\n        [[ 77,  72,  70, ..., 107, 124, 128],\n         [ 76,  72,  64, ...,  93, 103, 122],\n         [ 74,  71,  71, ...,  94, 104, 125],\n         ...,\n         [ 66,  62,  57, ..., 160, 164, 164],\n         [ 60,  64,  58, ..., 152, 145, 140],\n         [ 58,  63,  61, ..., 134, 132, 130]],\n\n        [[ 74,  65,  66, ...,  90, 100, 105],\n         [ 69,  65,  64, ...,  83,  88, 103],\n         [ 70,  66,  71, ...,  84,  94, 101],\n         ...,\n...\n         ...,\n         [ 65,  68,  98, ..., 148, 133, 125],\n         [ 81,  94, 116, ..., 118, 116, 114],\n         [ 64,  65,  94, ..., 111, 113, 116]],\n\n        [[ 66,  66,  65, ..., 108, 117, 116],\n         [ 66,  65,  65, ..., 119, 124, 117],\n         [ 65,  65,  65, ..., 117, 104, 113],\n         ...,\n         [ 79,  82,  98, ..., 147, 129, 122],\n         [ 88,  93, 109, ..., 117, 115, 115],\n         [ 81,  80,  97, ..., 114, 115, 116]],\n\n        [[ 55,  55,  55, ...,  82,  90,  86],\n         [ 55,  55,  55, ...,  94,  96,  89],\n         [ 55,  54,  57, ...,  94,  80,  89],\n         ...,\n         [ 60,  65,  78, ..., 139, 123, 116],\n         [ 69,  76,  91, ..., 112, 112, 112],\n         [ 60,  61,  75, ..., 111, 109, 110]]]], dtype=uint8)Coordinates: (5)band(band)int641 2 3array([1, 2, 3])x(x)float642.28e+05 2.28e+05 ... 2.284e+05axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([227958.3, 227958.9, 227959.5, ..., 228440.1, 228440.7, 228441.3])y(y)float643.83e+06 3.83e+06 ... 3.83e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([3830298.9, 3830298.3, 3830297.7, ..., 3829637.7, 3829637.1, 3829636.5])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :227958.0 0.6 0.0 3830299.2 0.0 -0.6000000000003375array(0)time(time)datetime64[ns]2016-01-01 ... 2022-01-01array(['2016-01-01T00:00:00.000000000', '2018-01-01T00:00:00.000000000',\n       '2020-01-01T00:00:00.000000000', '2022-01-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (4)bandPandasIndexPandasIndex(Index([1, 2, 3], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          227958.3,           227958.9,           227959.5,\n       227960.09999999998, 227960.69999999998,           227961.3,\n                 227961.9,           227962.5, 227963.09999999998,\n       227963.69999999998,\n       ...\n                 228435.9,           228436.5, 228437.09999999998,\n       228437.69999999998,           228438.3,           228438.9,\n                 228439.5, 228440.09999999998, 228440.69999999998,\n                 228441.3],\n      dtype='float64', name='x', length=806))yPandasIndexPandasIndex(Index([3830298.9000000004, 3830298.3000000003,          3830297.7,\n                3830297.1,          3830296.5, 3830295.9000000004,\n       3830295.3000000003,          3830294.7,          3830294.1,\n                3830293.5,\n       ...\n       3829641.9000000004, 3829641.3000000003,          3829640.7,\n                3829640.1,          3829639.5, 3829638.9000000004,\n       3829638.3000000003,          3829637.7,          3829637.1,\n                3829636.5],\n      dtype='float64', name='y', length=1105))timePandasIndexPandasIndex(DatetimeIndex(['2016-01-01', '2018-01-01', '2020-01-01', '2022-01-01'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (9)TIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1TIFFTAG_RESOLUTIONUNIT :1 (unitless)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0_FillValue :0\n\n\n\n\nNow its time to make a GIF!\nUse the gif function to create a gif of our stacked raster. Look at the documentation for gif(). What does the fps argument stand for?\n\n# create gif\n# fps = frames per second\n# adding to=\"lake_cachuma.gif\" will save GIF\n\ngif(stack, fps = 0.5)\n\n&lt;IPython.core.display.Image object&gt;\n\n\n\n\n\nReferences\nSanta Maria Times. ‚ÄúCachuma Lake Among the Last of State‚Äôs Reservoirs in Exceptional Drought.‚Äù Santa Maria Times. January 26, 2017. https://santamariatimes.com/news/local/cachuma-lake-among-the-last-of-states-reservoirs-in-exceptional-drought/article_e358ca8e-654d-5ff7-9b58-857914a4ccd4.html.\nThe Santa Barbara Independent. ‚ÄúCachuma Fills and Flood Gates to Open.‚Äù The Santa Barbara Independent, January 14, 2023. https://www.independent.com/2023/01/14/cachuma-fills-and-flood-gates-to-open/."
  },
  {
    "objectID": "discussion-sections-upcoming/corals.html",
    "href": "discussion-sections-upcoming/corals.html",
    "title": "EDS 220 - Working with Environmental Datasets",
    "section": "",
    "text": "https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1K35S3H\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\ndata = gpd.read_file('data/GCC_Data/allreefs_gcc.geojson')\n\n\ndata.columns\n\nIndex(['objectid', 'region', 'country', 'country_iso', 'eez', 'realm',\n       'province', 'ecoregion', 'latitude', 'longitude', 'gebco_depth',\n       'pct_hardcoral', 'pct_hardcoral_min', 'pct_hardcoral_max',\n       'pct_hardcoral_nsurveys', 'sample_yr_median', 'sample_yr_min',\n       'sample_yr_max', 'method_cat', 'dhw_max_cumul', 'dhw0', 'dhw4',\n       'sst_annualtrend', 'sst_kurtosis', 'sst_max', 'sst_range',\n       'sst_skewness', 'sst_var', 'aca_pr_bank', 'aca_pr_crest',\n       'aca_pr_lagoon', 'aca_pr_seagrass', 'aca_pr_slope',\n       'aca_top_geo_simple', 'calcite', 'currents_velocity_mean',\n       'diffuse_atn_max', 'dissolved_oxygen', 'gs_vr_score', 'npp_mean',\n       'npp_sd', 'par_max', 'ph_mean', 'reef_area_15km', 'score_cn',\n       'score_cy', 'wave_energy_mean', 'effluent_open_n', 'effluent_septic_n',\n       'effluent_total_n', 'effluent_treated_n', 'nutrient_raw',\n       'sediment_raw', 'grav_nc_raw', 'mgmt_highest', 'num_ports_raw',\n       'pop_count_raw', 'reef_value_raw', 'geometry'],\n      dtype='object')\n\n\n\ndata.plot()\n\n\n\n\n\n\n\n\n\ndata.realm.unique()\n\narray(['Temperate Northern Pacific', 'Tropical Atlantic',\n       'Western Indo-Pacific', 'Central Indo-Pacific',\n       'Eastern Indo-Pacific', 'Temperate Northern Atlantic', None,\n       'Tropical Eastern Pacific', 'Temperate Australasia'], dtype=object)\n\n\n\nwip = data[data.realm=='Western Indo-Pacific']\n\n\n# Ensure your GeoDataFrame is in the Web Mercator projection\nwip = wip.to_crs(epsg=3857)\n\nfig, ax = plt.subplots()\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\n# Plot your data\nwip.plot(ax=ax, column='pct_hardcoral')\n\n# Add a basemap with a specified zoom level\nctx.add_basemap(ax, zoom=3)  # Adjust the zoom level as needed for your map extent\n\nplt.show()"
  }
]