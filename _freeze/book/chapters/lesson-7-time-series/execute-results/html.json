{
  "hash": "7a2364e8186700c39282cb21bb4f2890",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntoc-title: In this lesson\nfig-cap-location: margin\n---\n\n\n\n\n# 6 Time series\n\nIn this section we will learn some basic handling of time series. \n\nThis lesson was adapted from [Dr. Sam Stevenson's lecture on Data quality control and outliers: 1D time series](https://github.com/samanthastevenson/EDS220_Fall2022/blob/main/Precipitation_QCexample_BoulderCO.ipynb) and [Earth Lab's Lesson 1. Work With Datetime Format in Python - Time Series Data](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/introduction-to-time-series-in-pandas-python/) @wasser_earthlabearth_textbook_2024.\n\n\n<!--\nTODO\n## Learning objectives\n\n-->\n\n## About the data\n\nTo exemplify some of the basic time series functionalities we will use data about hourly precipitation in the county of Boulder, Colorado from 2000 to 2014. In September 2013, an unusual weather pattern led to some of the most intense precipitation ever recorded in this region, causing [devastating floods throughout the Colorado Front Range](https://www.weather.gov/safety/flood-states-co). Our goal is to visualize precipitation data in 2013 and identify this unusual weather event.\n\n![Aerial view of floods during September 2013 in Colorado. Photo by State of Colorado.](/book/images/lesson-7/co-2013-2.jpg)\n\nThis data was obtained via the [National Oceanic and Atmosperic Administration (NOAA) Climate Data Online service](https://www.ncdc.noaa.gov/cdo-web/) and the resulting CSV that can be acceses at [this link](https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv). The following is a a short description of the columns we will work with (the full documentation can be accessed [here](https://www.ncei.noaa.gov/pub/data/cdo/documentation/PRECIP_HLY_documentation.pdf)):\n\n| Column | Description |\n|-| -----|\n| STATION | Identification number indentifying the station. |\n|STATION_NAME | Optional field, name identifying the station location.  |\n| DATE | this is the year of the record (4 digits), followed by month (2 digits), followed by day of the month (2 digits), followed by a space and ending with a time of observation that is a two digit indication of the local time hour, followed by a colon (:) followed by a two digit indication of the minute which for this dataset will always be 00. Note: The subsequent data value will be for the hour ending at the time specified here. Hour 00:00 will be listed as the first hour of each date, however since this data is by definition an accumulation of the previous 60 minutes, it actually occurred on the previous day.\n| HPCP | The amount of precipitation recorded at the station for the hour ending at the time specified for DATE above given in inches. The values 999.99 means the data value is missing. Hours with no precipitation are not shown. |\n\n\n## Timestamps\n\nThe `pandas` library represents an instant in time using the `pandas.Timestamp` class. For example:\n\n::: {#317cdc91 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Create a timestamp\npd.Timestamp(year=2020, \n             month=10, \n             day=18, \n             hour=12, \n             minute=30, \n             second=15)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nTimestamp('2020-10-18 12:30:15')\n```\n:::\n:::\n\n\nWhen we store multiple `pandas.Timestamps` in a `pandas.Series` the data type of the column is set to `datetime64[ns]`:\n\n::: {#2a79d0ca .cell execution_count=2}\n``` {.python .cell-code}\n# Notice the data type of the column is datetime64\npd.Series([pd.Timestamp(2020,10,18), \n           pd.Timestamp(2020,10,17),\n           pd.Timestamp(2020,10,16)])\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n0   2020-10-18\n1   2020-10-17\n2   2020-10-16\ndtype: datetime64[ns]\n```\n:::\n:::\n\n\n<!--\n- NaT = not a time. `pd.NaT` = nd behaves similar as np.nan does for float data.\n-->\n\n## Data exploration\n\nLet's start by reading in the data and taking a look at it:\n\n::: {#5f171ae2 .cell execution_count=3}\n``` {.python .cell-code}\n# Read in data \nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL)\n\nprecip.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>DATE</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000101 00:00</td>\n      <td>999.99</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000101 01:00</td>\n      <td>0.00</td>\n      <td>g</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000102 20:00</td>\n      <td>0.00</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000103 01:00</td>\n      <td>0.00</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000103 05:00</td>\n      <td>0.00</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#5b18c76a .cell execution_count=4}\n``` {.python .cell-code}\n# Plot hourly precipitation in Boulder CO \nprecip.plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-5-output-1.png){width=583 height=411}\n:::\n:::\n\n\nThere are a few things going on with this graph:\n \n1. Outliers: There are many jumps close to 1000. This is clearly not right and these are outliers. Looking at the column descriptions we can see 999.99 indicates the hourly precipitation data is missing.\n\n2. Indexing: The $x$-axis values are given by the index of the dataframe and not relative to time. \n\n3. Time range: We are only intersted in the precipitation data from 2013, this graph is trying to plot all our data.\n\nLet's fix each one of these issues separately.\n\n## Reading in missing data values\n\nThe metadata states the missing values are indicated by the number 999.99. \nWe can use this information to reload the dataframe indicating 999.99 is the missing value. \nTo do this, we add the `na_values` parameter to the `pandas.read_csv()` function to indicitate additional values that should be recognized as `NA`:\n\n::: {#19c80d36 .cell execution_count=5}\n``` {.python .cell-code}\n# Read in CSV indicating NA values based on metadata\nprecip = pd.read_csv(URL, na_values=[999.99])\n\nprecip.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>DATE</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000101 00:00</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000101 01:00</td>\n      <td>0.0</td>\n      <td>g</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000102 20:00</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000103 01:00</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>20000103 05:00</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNotice that the first hourly precipitation value used to be 999.99 and it is now set to a `NaN`. Check the `na_values` parameter in the [`pd.read_csv()` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to learn more about which values are identified as `NA` by default. \n\nWe can try making our plot again:\n\n::: {#9939b0ea .cell execution_count=6}\n``` {.python .cell-code}\nprecip.plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-7-output-1.png){width=571 height=411}\n:::\n:::\n\n\nThis looks better and we can already see there is something going on close to the end of the time series. \n\n## Casting strings into dates\nNotice that the `DATE` column in our dataframe is not of type `datetime`. We can check this using the `dtypes` attribute for dataframes:\n\n::: {#e5307f0d .cell execution_count=7}\n``` {.python .cell-code}\n# Check whether DATE column is of type datetime\nprecip.dtypes\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nSTATION              object\nSTATION_NAME         object\nDATE                 object\nHPCP                float64\nMeasurement Flag     object\nQuality Flag         object\ndtype: object\n```\n:::\n:::\n\n\n<!--\nprecip.DATE.apply(type).unique()\n-->\nRemember that the `object` dtype means that (most likely) all values in that column are strings. We can easily convert strings to datetime objects using the `pandas.to_datetime()` function:\n\n- `pandas.to_datetime()` input: a `pandas.Series` with strings that can be converted to dates\n- `pandas.to_datetime()` output: a `pandas.Series` with the strings converted to `datetime` objects\n \n #### Example\n\n::: {#54d223f8 .cell execution_count=8}\n``` {.python .cell-code}\n# Convert DATE column to timestamps\npd.to_datetime(precip.DATE)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n0      2000-01-01 00:00:00\n1      2000-01-01 01:00:00\n2      2000-01-02 20:00:00\n3      2000-01-03 01:00:00\n4      2000-01-03 05:00:00\n               ...        \n9001   2013-12-22 01:00:00\n9002   2013-12-23 00:00:00\n9003   2013-12-23 02:00:00\n9004   2013-12-29 01:00:00\n9005   2013-12-31 00:00:00\nName: DATE, Length: 9006, dtype: datetime64[ns]\n```\n:::\n:::\n\n\nWe can overwrite the `DATE` column with this output:\n\n::: {#d2859e93 .cell execution_count=9}\n``` {.python .cell-code}\n# Convert DATE column to timestamps\nprecip.DATE = pd.to_datetime(precip.DATE)\n\n# Check DATE column data type is updated\nprint(precip.dtypes)\n\n# Check new values\nprecip.DATE.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSTATION                     object\nSTATION_NAME                object\nDATE                datetime64[ns]\nHPCP                       float64\nMeasurement Flag            object\nQuality Flag                object\ndtype: object\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0   2000-01-01 00:00:00\n1   2000-01-01 01:00:00\n2   2000-01-02 20:00:00\n3   2000-01-03 01:00:00\n4   2000-01-03 05:00:00\nName: DATE, dtype: datetime64[ns]\n```\n:::\n:::\n\n\nWe can make another attempt at plotting our precipitation data:\n\n::: {#575e44ca .cell execution_count=10}\n``` {.python .cell-code}\nprecip.plot(x='DATE', y='HPCP')\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-11-output-1.png){width=571 height=402}\n:::\n:::\n\n\nNotice the $x$-axis is now neatly organized into years. \n\nNext, using our `DATE` column as the index will allows to perform operations with respect to time, including subsetting and resampling. \n\n::: {#49bdfde8 .cell execution_count=11}\n``` {.python .cell-code}\n# Set DATE coumn as index\nprecip = precip.set_index('DATE')\n\n# Inspect new index\nprecip.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-01-01 00:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2000-01-01 01:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.0</td>\n      <td>g</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2000-01-02 20:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>2000-01-03 01:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n    <tr>\n      <th>2000-01-03 05:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.0</td>\n      <td></td>\n      <td>q</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSince we know the default behaviour of `plot()` is to use the index as the $x$-axis and make a line plot for each numeric column, we can simplify our plot making like this:\n\n::: {#3e4d22dd .cell execution_count=12}\n``` {.python .cell-code}\nprecip.plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-13-output-1.png){width=571 height=402}\n:::\n:::\n\n\n:::{.callout-note}\n## Leverage `pandas.read_csv()` to set a known index\n\nIf we already have information about our data frame and know which column we will use as the index, we can directly set the index when we load the data by using:\n```python\ndf = pandas.read_csv(file, index_col=['index_column'])\n```\nIf we also need our index to be of type `datetime` and we have a known dates column, then we can also create a `datetime` index directly when loading the data:\n```python\ndf = pandas.read_csv(file, index_col=['date_column'], parse_dates=['date_column'])\n```\n:::\n\n## Subsetting by date\n`pandas` has great functionality to subset a dataframe when using a time index. \n\n#### Example\n\nWe can use `.loc[year-month]` to select data from a specific year and month:\n\n::: {#0b622ca1 .cell execution_count=13}\n``` {.python .cell-code}\n# Select precipitation data from September 2013\nprecip.loc['2013-09']\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-09-01 00:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-01 01:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>NaN</td>\n      <td>[</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-01 00:00:00</th>\n      <td>COOP:050183</td>\n      <td>ALLENSPARK 2 SE CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-01 01:00:00</th>\n      <td>COOP:050183</td>\n      <td>ALLENSPARK 2 SE CO US</td>\n      <td>NaN</td>\n      <td>[</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-01 00:00:00</th>\n      <td>COOP:055121</td>\n      <td>LONGMONT 6 NW CO US</td>\n      <td>NaN</td>\n      <td>}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2013-09-23 02:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.2</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-27 10:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-27 15:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-27 17:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-09-27 18:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 5 columns</p>\n</div>\n```\n:::\n:::\n\n\nOr simply select data from a given year using `.loc[year]`:\n\n::: {#3f418d1a .cell execution_count=14}\n``` {.python .cell-code}\n# Select 2013 precipitation data\nprecip.loc['2013']\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-01-01 01:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.0</td>\n      <td>g</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-01-10 02:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>NaN</td>\n      <td>[</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-01-13 00:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-01-26 20:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-01-28 23:00:00</th>\n      <td>COOP:055881</td>\n      <td>NEDERLAND 5 NNW CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2013-12-22 01:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>NaN</td>\n      <td>[</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-12-23 00:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-12-23 02:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>0.1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-12-29 01:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>NaN</td>\n      <td>[</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-12-31 00:00:00</th>\n      <td>COOP:050843</td>\n      <td>BOULDER 2 CO US</td>\n      <td>NaN</td>\n      <td>]</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>662 rows × 5 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe can use this selection to plot data as usual. Notice we have a lot of gaps due to missing data: \n\n::: {#745c9b6b .cell execution_count=15}\n``` {.python .cell-code}\nprecip.loc['2013'].plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-16-output-1.png){width=571 height=412}\n:::\n:::\n\n\n## Resample\nResampling a time series means converting a time series from one frequency to another. For example, monthly to yearly (downsampling) or weekly to daily (upsampling). We can resample with the [`resample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) method. The simplest use is to call\n```python\ndf.resample(new_frequency).aggregator_function()\n```\nwhere:\n\n-  `new_frequency` is a string representing the new frequence to resample the data, for example `'D'` for day, `w` for week, `M` for month, `Y` for year, and\n- `aggregator_function()` is the function we will use to aggregate the data into the new frequency. For example, `max()`, `min()`, `sum()`, or `average()`. \n\nThe `resample()` method works similarly to `groupby()` in the sense that you need to specify a way to aggregate the data to get any output. \n\n#### Example\n\nOur 2013 precipitation data has hourly frequency, we want to resample it to daily frequency. \n\n::: {#9ac243d9 .cell execution_count=16}\n``` {.python .cell-code}\n# Resample 2013 hourly data to daily frequency: no output\nprecip.loc['2013'].resample('D')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n<pandas.core.resample.DatetimeIndexResampler object at 0x16449c8d0>\n```\n:::\n:::\n\n\nTo get an output we need to add an aggregator function that indicates how we want to summarize the data that falls on each day. In this case we want the total precipitation on a day, so we will aggreagate it using `sum()`:\n\n::: {#fcc1aef3 .cell execution_count=17}\n``` {.python .cell-code}\n# Total daily precipitation in 2013\ndaily_precip_2013 = precip.loc['2013'].resample('D').sum()\n\ndaily_precip_2013.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>STATION_NAME</th>\n      <th>HPCP</th>\n      <th>Measurement Flag</th>\n      <th>Quality Flag</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-01-01</th>\n      <td>COOP:050183COOP:055881COOP:050183COOP:055121CO...</td>\n      <td>ALLENSPARK 2 SE CO USNEDERLAND 5 NNW CO USALLE...</td>\n      <td>0.0</td>\n      <td>]g[gg</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2013-01-02</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2013-01-03</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNotice the index has now changed to be days in 2013. We should also rename the `HPCP` column since it is not longer hourly precipitation:\n\n::: {#1cbce515 .cell execution_count=18}\n``` {.python .cell-code}\n# Rename hourly precipitation column to match resample\ndaily_precip_2013 = daily_precip_2013.rename(columns={'HPCP':'daily_precipitation'})\ndaily_precip_2013.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\nIndex(['STATION', 'STATION_NAME', 'daily_precipitation', 'Measurement Flag',\n       'Quality Flag'],\n      dtype='object')\n```\n:::\n:::\n\n\n Finally, we can plot our data:\n\n::: {#1b0ac42e .cell execution_count=19}\n``` {.python .cell-code}\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-20-output-1.png){width=576 height=464}\n:::\n:::\n\n\n## Complete workflow\n\nThe previous code includes a lot of exploratory functions and trials. While it is important to keep our data exploration documented, once we are certain of our data wrangling, we can streamline our analyses to only include the code that directly contributes to the output. Moving on, we will start to collect all our relevant code to create such complete workflows. For this lesson, the code below will produce the final graph:\n\n::: {#d870e960 .cell execution_count=20}\n``` {.python .cell-code}\nimport pandas as pd\n\n'''\nRead in Boulder, CO hourly precipitation data \nHPCP = hourly precipitation (unique numerical column in data frame)\n'''\nURL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/main/data/boulder_colorado_2013_hourly_precipitation.csv'\nprecip = pd.read_csv(URL, \n                    na_values=[999.99],  # Known from metadata\n                    index_col=['DATE'], \n                    parse_dates=['DATE']\n                    )\n\n\n# Calculate daily total precipitation during 2013\ndaily_precip_2013 = (precip.loc['2013']\n                            .resample('D')\n                            .sum()\n                            .rename(columns={'HPCP':'daily_precipitation'})  \n                            )\n\n# Plot time series\ndaily_precip_2013.plot(ylabel='daily precipitation (in)', \n                       xlabel=' ',\n                       title='Precipitation in Boulder, CO during 2013',\n                       legend=False)\n```\n\n::: {.cell-output .cell-output-display}\n![](lesson-7-time-series_files/figure-html/cell-21-output-1.png){width=576 height=464}\n:::\n:::\n\n\n<!-- TODO Add plot description. -->\n\n## More info\n\nThere is so much more to learn about time series data. These resources will allow you to dive deeper:\n\n📖 [`pandas` getting started tutorials - How to handle time series data with ease](https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html#min-tut-09-timeseries)\n\n📖 [Time Series Chapter, Python for Data Analysis, Wes McKinney](https://wesmckinney.com/book/time-series)\n\n📖 [`pandas` User Guide - Time series/date functionality](https://pandas.pydata.org/docs/user_guide/timeseries.html)\n\n",
    "supporting": [
      "lesson-7-time-series_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}