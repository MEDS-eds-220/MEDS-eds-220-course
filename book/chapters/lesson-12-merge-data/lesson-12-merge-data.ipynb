{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!--\n",
        "Ignore ShapelyDeprecationWarning warning in render"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import shapely\n",
        "import warnings\n",
        "from shapely.errors import ShapelyDeprecationWarning\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-->\n",
        "\n",
        "# 11 Reprojecting\n",
        "\n",
        "In this section we will learn how to join dataframes and will apply this to creating a [choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) with `geopandas`.\n",
        "\n",
        "## About the data\n",
        "\n",
        "The first dataset we will use is a [list of Arctic communities and their location](https://search.dataone.org/view/doi%3A10.18739%2FA28S4JQ80) @brook_approximate_2023 created by the [Alaska Native Tribal Health Consortium](https://www.anthc.org). This data comes in a GeoJSON file with the following attributes:\n",
        "\n",
        "- **name**: name of Arctic community, \n",
        "- **population**: population of Arctic community, as of 2022\n",
        "- **country**: country that the Arctic community falls within (see dataset metadata for the codes)\n",
        "- **geoname-id**: numeric codes that uniquely identify all administrative/legal and statistical geographic areas for which the Census Bureau tabulates data\n",
        "\n",
        "The second dataset is [Natural Earth's medium-scale  cultural boundaries data for countries (1:50m)](https://www.naturalearthdata.com/downloads/50m-cultural-vectors/). \n",
        "We can obtain this dataset by downloading the shapefile. \n",
        "[Natural Earth](https://www.naturalearthdata.com) is a public domain dataset with free, ready-to-use data for creating maps. \n",
        "\n",
        "The third dataset we will use is a CSV file with the country codes and names of the Arctic countries in the Arctic communities dataset. This dataset was created for educational purposes for this lesson based on the metadata of the Arctic communities dataset and the country names in Natural Earth's dataset. It can be accessed [here]().\n",
        "\n",
        "## Import data\n",
        "\n",
        "We will first import the countries shapefile and adapt it for wrangling purposes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "\n",
        "# Import countries polygons\n",
        "fp = os.path.join('data', 'ne_50m_admin_0_countries', 'ne_50m_admin_0_countries.shp')\n",
        "countries = gpd.read_file(fp)\n",
        "\n",
        "# Simplify column names\n",
        "countries.columns = countries.columns.str.lower()\n",
        "\n",
        "# Select columns for analysis\n",
        "countries = countries[['admin', 'type', 'geometry']]\n",
        "\n",
        "countries.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick view\n",
        "countries.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import the Arctic communities data. Similar to how we previously used `pandas.read_csv()`, we can read in the Arctic communities GeoJSON data directly from the data repository using `geopandas.read_file()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import Arctic communities data\n",
        "URL = 'https://cn.dataone.org/cn/v2/resolve/urn%3Auuid%3Aed7718ae-fb0d-43dd-9270-fbfe80bfc7a4'\n",
        "communities = gpd.read_file(URL)\n",
        "\n",
        "communities.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CRS of the `communities` is EPSG:4326. Remember all GeoJSON files are given in this CRS and all points are expressed in longitude and latitude units of decimal degrees. In this case, the `countries` and `communities` GeoDataFrames both have the same CRS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(countries.crs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the CRSs match, it is easy to take a quick look at our communities data by plotting it on top of the countries dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify CRSs match\n",
        "assert countries.crs == communities.crs\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "countries.plot(ax=ax)\n",
        "communities.plot(ax=ax, color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we import the country names and codes CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "country_names = pd.read_csv(os.path.join('data','country_names.csv'))\n",
        "country_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arctic communities by country\n",
        "\n",
        "Next, we want to calculate the number of Arctic communities by country. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create data frame with number of communities per country\n",
        "n_comms = (communities.groupby('country')\n",
        "                      .size()\n",
        "                      .reset_index(name='n_communities'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's break this down:\n",
        "\n",
        "- We start with our `communities` dataframe and use `groupby('country')` to group by country code.\n",
        "- Then we use [`size()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html) as an aggregator function to calculate the size of each group.\n",
        "- The result of this operation is a `pandas.Series` indexed by the `country` values.\n",
        "- By resetting the index we transform the `pandas.Series` into a `pandas.DataFrame`, the index is now a column named `country` and the values of the series are named `n_communities`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of Arctic communities per country\n",
        "n_comms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `if`-`else` statements\n",
        "\n",
        "Our goal is to merge the `n_comms` and the `countries` data frames. To merge two data frames they need to have at least one column in common. \n",
        "Currently our datasets do not have any columns in common:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set(countries.columns).intersection(n_comms.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output `set()` represents the empty set. This might not be as informative, so let's write a different information statement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "common_columns = set(countries.columns).intersection(n_comms.columns)\n",
        "\n",
        "# Check if there are any common columns\n",
        "if len(common_columns) != 0:\n",
        "    print(f\"Common columns: {common_columns}\")\n",
        "else:\n",
        "    print(\"No common columns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember that an `if-else` statement is a control structure that allows code to make decisions: it checks a condition, and if that condition is true, it executes one block of code (the `if` block); if the condition is false, it executes a different block (the `else` block). This enables programs to respond differently depending on specific criteria or inputs.\n",
        "\n",
        ":::{.callout-tip}\n",
        "## Check-in\n",
        "Wrap up the previous code into a function called `check_common_columns` that prints a message depending of whether two data frames have common columns or not. Don't forget to include a docstring!\n",
        "<!--"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def check_common_columns(df1, df2):\n",
        "    \"\"\"\n",
        "    Prints a message depending whether df1 and df2 have columns in common\n",
        "\n",
        "     Parameters:\n",
        "    - df1: The first DataFrame.\n",
        "    - df2: The second DataFrame.\n",
        "    \n",
        "    Returns:\n",
        "    - A set of common column names. If no columns are common, returns an empty set.\n",
        "    \"\"\"\n",
        "\n",
        "    common_columns = set(df1.columns).intersection(df2.columns)\n",
        "    \n",
        "    if common_columns:\n",
        "        print(f\"Common columns: {common_columns}\")\n",
        "    else:\n",
        "        print(\"No common columns\")\n",
        "    \n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-->\n",
        ":::\n",
        "\n",
        "## Merging data frames\n",
        "\n",
        "We can use the `country_names` data frame to add the names countries into the `n_comms` data which, in turn, will allow us to merge that data frame with the `country_names` data. To merge dataframes we can use the [`pandas.merge()` function](https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge). \n",
        "The basic syntax for it is:\n",
        "\n",
        "```python\n",
        "output_df = pd.merge(left_df,\n",
        "                     right_df, \n",
        "                     how = type_of_join, \n",
        "                     on = column_to_join)\n",
        "```\n",
        "where\n",
        "\n",
        "- `output_df` is the dataframe resulting from the merge,\n",
        "- `left_df` is the dataframe we have \"on the left side\",\n",
        "- `right_df` is the dataframe we have \"on the right side\",\n",
        "- `how` specifies the type of join between the left and right dataframes, ([check the options here](https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge)), the default is to do an inner join,\n",
        "- `on` specifies the column to join on, this column must be present in both our dataframes. \n",
        "\n",
        "So, we merge the `n_comms` and `country_names` data frames using a left join:\n",
        "\n",
        "![Image source: Data Modeling Essentials, NCEAS Learning Hub @do-linh_open_2023](/book/images/merging_data/join-diagrams-left.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_comms = pd.merge(n_comms,\n",
        "                   country_names,\n",
        "                   how='left',\n",
        "                   on='country')\n",
        "n_comms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can reuse our function to check that `n_comms` and `countries` now have a common column on which we can merge them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "check_common_columns(n_comms, countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-tip}\n",
        "## Check-in\n",
        "Perform an inner join between our `countries` and `n_comms` dataframes. This will merge the subset of rows that have matches in both the left table and the right table.\n",
        "\n",
        "![Image source: Data Modeling Essentials, NCEAS Learning Hub @do-linh_open_2023](/book/images/merging_data/join-diagrams-inner.png)\n",
        "<!--"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Merge data frames \n",
        "arctic_countries = pd.merge(countries,\n",
        "                            n_comms,\n",
        "                            how='inner',\n",
        "                            on='admin')\n",
        "# Update index\n",
        "arctic_countries = arctic_countries.set_index('admin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-->\n",
        ":::\n",
        "\n",
        "## Reviewing results\n",
        "\n",
        "Notice that the row for Aland Islands is not present in the merged dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "arctic_countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `values` attribute of a data frame returns *all* the values in the data frame as an array. We can verify the value 'Aland Islands' was *nowhere* in our original countries dataframe like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check Aland Islands is nowhere in data frame\n",
        "'Aland Islands' not in countries.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Aland Islands is an autonomous region of Finland and there is one Arctic community registered in this region. \n",
        "We will directly add one to Finland to not lose this piece of data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "arctic_countries.at['Finland', 'n_communities'] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choropleth map\n",
        "\n",
        "A [choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) is an efficient way to visualize aggregate data per region. \n",
        "\n",
        "Making a choropleth map from our polygons `GeoDataFrame` is easy; we just need to specify the `column` parameter in `plot()` and make it equal to the column with the values we want to plot in each country:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "arctic_countries.plot(column='n_communities',\n",
        "                      legend=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reprojecting\n",
        "\n",
        "Remember that CRSs reflect cultural views and even biases. Any map projection involves choices about which areas to emphasize, minimize, or distort, and those choices can influence how viewers perceive different regions. In our map, using the EPSG:4326 CRS is, among other things, mapping the Arctic regions as far apart, while they are actually near each other.\n",
        "\n",
        "**Reprojecting** means changing the coordinate reference system of your geospatial data. Do\n",
        "In our case, we will reproject the Alaska geo-dataframe to the CRS EPSG:3413. \n",
        "This CRS is a *projected* CRS, better suited for working with data from the Arctic region:\n",
        "\n",
        "![Source: [spatialreference.org](https://spatialreference.org/ref/epsg/3413/) ](/book/images/lesson-12/epsg_3413.png)\n",
        "\n",
        "Changing CRSs in GeoPandas is very simple using the `to_crs()` method for `geopandas.GeoDataFrame`s. \n",
        "The general syntax is:\n",
        "```python\n",
        "updated_geodf = geodf.to_crs(new_crs)\n",
        "```\n",
        "where:\n",
        "\n",
        "- `updated_geodf` is the output of the method, a new geodataframe (`to_crs()` does not work in place), \n",
        "- `geodf` is the `geopandas.GeoDataFrame` we want to transform, \n",
        "- `new_crs` the CRS we want to convert to, this is an object of type CRS or string representing the CRS (ex: `'epsg:3413'`). \n",
        "\n",
        "In our case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reproject to CRS optimized for Arctic region\n",
        "arctic_countries = arctic_countries.to_crs('epsg:3413')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the reprojected data to update our map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| \n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Remove the axis for a cleaner map\n",
        "ax.axis('off')\n",
        "\n",
        "# Create choropleth map of communities\n",
        "# Plot with refined color and edge style\n",
        "arctic_countries.plot(\n",
        "    ax=ax,\n",
        "    column='n_communities',\n",
        "    cmap='PuBuGn',\n",
        "    legend=True,\n",
        "    edgecolor=\"0.6\",\n",
        "    linewidth=0.5,\n",
        "    legend_kwds={\n",
        "        \"shrink\": 0.7,\n",
        "        \"label\": \"Number of Arctic Communities\",\n",
        "        \"orientation\": \"horizontal\",\n",
        "        \"pad\": 0.05\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add title and subtitle for better context\n",
        "ax.set_title('Distribution of Arctic Communities', fontsize=18, weight='bold', pad=15)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although the new projection clearly improves the presentation of the data, there are still issues with this plot! Mainly, the entire United States territory is in it, when we should only have Alaska. **In our next lesson we will review startegies to clip and subset vector data and return to this plot in our discussion section.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "mpc-env-kernel",
      "language": "python",
      "display_name": "mpc-env-kernel",
      "path": "/Users/galaz-garcia/Library/Jupyter/kernels/mpc-env-kernel"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}