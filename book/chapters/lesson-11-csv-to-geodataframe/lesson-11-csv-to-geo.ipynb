{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 `for` loops\n",
        "\n",
        "In this lesson we will learn how to extract geospatial data from a CSV to create a `geopandas.GeoDataFrame` and go over some more customizations for maps and matplotlib figures.\n",
        "\n",
        "<!--\n",
        "TODO: learning objectives\n",
        "-->\n",
        "\n",
        "## About the data\n",
        "\n",
        "The U.S. energy landscape relies on a mix of fossil fuels and renewables, each with unique environmental and economic impacts. As the nation works toward sustainability and energy security, understanding this energy mix is essential for informed policy and progress toward cleaner energy.\n",
        "\n",
        "In this lesson, we will use data from the U.S. [Energy Information Administration (EIA)](https://www.eia.gov) about [operable electric generating plants in the United States by energy source, as of May 2023](https://atlas.eia.gov/datasets/eia::power-plants/about). The dataset includes information on plant types and energy sources, offering insights into the diversity of power sources—from fossil fuels to renewables—that supply electricity nationwide. The dataset's metadata can be [accessed here](https://eia.maps.arcgis.com/sharing/rest/content/items/bf5c5110b1b944d299bb683cdbd02d2a/info/metadata/metadata.xml?format=default&output=html)\n",
        "<!-- TODO: add citation -->\n",
        "<!-- TODO: add image -->\n",
        "The EIA data on electric plants has been downloaded as a CSV and reprojected into the EPSG:4269 CRS for this lesson. It can be accessed [here](https://github.com/carmengg/eds-220-book/blob/main/data/power_plants_epsg4269.csv).\n",
        "\n",
        "<!-- TODO: column descriptions: lat lon, -->\n",
        "\n",
        "Additionally, we will use a [TIGER shapefile of the US states from the United States Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2022.html#list-tab-790442341). \n",
        "[TIGER](https://en.wikipedia.org/wiki/Topologically_Integrated_Geographic_Encoding_and_Referencing) stands for Topologically Integrated Geographic Encoding and Referencing. This used to be the data format the US Census distributed geospatial data, but since 2008 TIGER files are converted to shapefiles. You can view the metadata for all the TIGER shapefiles [here](https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/tiger-geo-line.html). \n",
        "\n",
        "Follow these steps to download shapefile with the United States' states:\n",
        "\n",
        "1. At the bottom of the [2022 page](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2022.html#list-tab-790442341), under Download, click on \"Web Interface\"\n",
        "2. For year, select 2022, and for layer type select \"States (and equivalent)\". Click submit. \n",
        "3. Click on \"Download national file\".\n",
        "\n",
        "\n",
        "The column descriptions for the US states shapefile are:\n",
        "\n",
        "![Source: TIGER/Line Shapefiles Technical Documentation](/book/images/lesson-11/tiger_shp_columns.png)\n",
        "\n",
        "\n",
        "## CSV to `geopandas.GeoDataFrame`\n",
        "\n",
        "Let's start by importing packages and updating viewing options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Display all columns when looking at dataframes\n",
        "pd.set_option(\"display.max.columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import the power plants dataset.  In this lesson, we have downloaded the data into a `data/` folder in the same level as our notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import power plants data\n",
        "URL = 'https://raw.githubusercontent.com/carmengg/eds-220-book/refs/heads/main/data/power_plants_epsg4269.csv'\n",
        "power_plants = pd.read_csv(URL)\n",
        "\n",
        "# Simpify column names\n",
        "power_plants.columns = power_plants.columns.str.lower()\n",
        "\n",
        "# Drop first column\n",
        "power_plants = power_plants.drop(columns='unnamed: 0')\n",
        "\n",
        "power_plants.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!--TO DO: Need to drop the unnamed column from file--> \n",
        "\n",
        "The power plants file is a CSV. Unlike shapefiles or other geospatial file formats, `geopandas` doesn't have a way to extract a geometry column from a CSV file, so we will need to create this geometry manually. \n",
        "\n",
        "To do so we will use the longitude and latitude columns in the CSV, these indicate the location of the power plants in the NAD83 CRS (EPSG:4269).\n",
        "We can use this information to create a new `geopandas.GeoDataFrame` from the `pandas.DataFrame` using the `geopandas` function [`points_from_xy()`](https://geopandas.org/en/stable/docs/reference/api/geopandas.points_from_xy.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create points from latitude and longitude\n",
        "points = gpd.points_from_xy(power_plants.longitude, \n",
        "                            power_plants.latitude)\n",
        "\n",
        "# Create geodataframe\n",
        "power_plants = gpd.GeoDataFrame(power_plants,    # Data\n",
        "                                geometry=points, # Specify geometry column\n",
        "                                crs='EPSG:4269'  # Specify CRS\n",
        "                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check that we now have a `geometry` column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "power_plants['geometry']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the `geometry` column and CRS, we can plot our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "power_plants.plot()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## f-strings\n",
        "\n",
        "So far, we have printed variables using string concatenation inside the `print()` function. \n",
        "This means that we write commas between every string and variable we want to print, and then the `print()` function concatenates these into a single string. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('CRS: ', power_plants.crs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another popular way of mixing strings and variables in print statements is by creating an **f-string** which stands for \"formatted string\". \n",
        "The simplest syntax for an f-string is:\n",
        "```python\n",
        "f\" some text {replace}\"\n",
        "```\n",
        "where `replace` can be a variable, an expression, or a function or method call. \n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Explore CRS\n",
        "print(f\"ellipsoid: {power_plants.crs.ellipsoid}\")\n",
        "print(f\"datum: {power_plants.crs.datum}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We just created a string replacing the value inside the curly brackets `{}`. \n",
        "\n",
        "One of the advantages of using f-strings is that they offer customization for formatting the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set the label width to 25 characters, aligning the answers\n",
        "print(f\"{'Is the CRS geographic?:':<25} {power_plants.crs.is_geographic}\")\n",
        "print(f\"{'Is the CRS projected?:':<25} {power_plants.crs.is_projected}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-caution}\n",
        "## Use f-strings or not?\n",
        "\n",
        "Whether you use an f-string or simply concatenate strings with variables inside your print statements depends entirely on the application. For quickly checking a variable, a print statement might be enough, while using f-strings can be better to include custom messages during runtime. The best tool can be different depending on the task!\n",
        "\n",
        "These are some good resources to learn more about f-string formatting:\n",
        "\n",
        "- [Real Python - Python's F-String for String Interpolation and Formatting](https://realpython.com/python-f-strings/)\n",
        "\n",
        "- [Python documentation- Format Specification Mini-Language](https://docs.python.org/3/library/string.html#formatspec)\n",
        ":::\n",
        "\n",
        "## Import shapefile\n",
        "\n",
        "Let's import the TIGER shapefile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import states data\n",
        "fp = os.path.join('data','tl_2022_us_state','tl_2022_us_state.shp')\n",
        "states = gpd.read_file(fp)\n",
        "\n",
        "# Simplify column names \n",
        "states.columns = states.columns.str.lower()\n",
        "\n",
        "states.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and obtain some preliminary geospatial information about the states geodataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(states.crs)\n",
        "states.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `for` loops\n",
        "\n",
        " It can be easier to work with the codes as numbers instead of strings, so let's update the corresponding columns in the states geo-dataframe. We start by checking the data type of the `region`, `division`, and `statefp` columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        " code_cols = ['region', 'division', 'statefp']\n",
        "\n",
        "# Check whether codes columns are strings\n",
        " for column in code_cols: \n",
        "    print(f\"{column} is string dtype? {is_string_dtype(states[column])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember `for` loops execute a block of code a fixed number of times, iterating over a set of objects. In this case, we iterate over the list of column names `code_cols = ['region', 'division', 'statefp']`.\n",
        "\n",
        ":::{.callout-caution}\n",
        "## DRY code\n",
        "We could have checked whether all the `region`, `division`, and `statefp` columns were of string data type by using the following code:\n",
        "\n",
        "```python\n",
        "print(f\"region is string dtype? {is_string_dtype(states['region'])}\")\n",
        "print(f\"division is string dtype? {is_string_dtype(states['division'])}\")\n",
        "print(f\"statefp is string dtype? {is_string_dtype(states['statefp'])}\")\n",
        "```\n",
        "However, this is inconvenient as it repeats the same pieces of code, only changing the column name. Instead, using the `for` loop allows us to succintly print the same information:\n",
        "```python\n",
        "code_cols = ['region', 'division', 'statefp']\n",
        "\n",
        "for column in code_cols: \n",
        "    print(f\"{column} is string dtype? {is_string_dtype(states[column])}\")\n",
        "```\n",
        "**Don't Repeat Yourself (DRY)** is a core programming principle that encourages  reducing redundancy and consolidating repeated logic. Try implementing it as much as possible! If you need to repeat the \"same\" code more than twice, you likely need a `for` loop.\n",
        ":::\n",
        "\n",
        "Next, we update the data type of the code columns to be integers. This time, we check the data type of the column using the `is_numeric_dtype()` function inside an **`assert`** statement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Update code columns into integers\n",
        "for column in code_cols:\n",
        "    states[column] = states[column].astype('int')\n",
        "    assert is_numeric_dtype(states[column])  # Check conversion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `assert` keyword does nothing if the expression next to it evaluates to `True` and raises an `AssertionError` exception and stops your code form running any further. For example, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "# Does nothing if statement is True\n",
        "assert 2+2 == 4\n",
        "\n",
        "# Raises an error if statement is False\n",
        "assert 2+2 == 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our data type conversion code, since no `AssertionError` was raised, we can be confident that the data type was updated. \n",
        "\n",
        "## Data selection\n",
        "\n",
        "For this lesson, we want to use only the contiguous states. As seen in the plot, the data covers a bigger extension. \n",
        "\n",
        ":::{.callout-tip}\n",
        "## Check-in\n",
        "From the TIGER shapefiles metadata we know that:\n",
        " \n",
        "> In addition to the fifty states, the Census Bureau treats the District of Columbia, Puerto Rico, and the Island areas (American Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S. Virgin Islands) as statistical equivalents of states for the purpose of data presentation. \n",
        "\n",
        "In [this US Census Bureau file](https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf) we can see what each code for the region, division, and state corresponds to. \n",
        "\n",
        "- What are the unique values for region, division, or state codes in the data?\n",
        "- Which codes should should we select to keep only states in the contiguous US?\n",
        "\n",
        "<!--\n",
        " States correspond to regions 1 through 4. \n",
        " However, there's also a region code 9.\n",
        " Hawaii = state code 15\n",
        " Alaska = satate code 02\n",
        " Need to exclude: region code 9 ans state codes 15 and 02\n",
        " -->\n",
        ":::\n",
        "\n",
        "Let's go ahead and select the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select contiguous US states\n",
        "contiguous = states[(states.region!=9) & (~states.statefp.isin([2,15]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this code we used the syntax \n",
        "```python\n",
        "~df.column.isin([val1, val2, val3])\n",
        "```\n",
        "The `~` tilde symbol is used in Python to negate a statement. \n",
        "So the previous line could be read as \"the values in `df`'s column which are *not* in the list `[val1, val2, val3]`.\"\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Check-in\n",
        "Select the data in the `power_plants` data frame for the contiguous US states. \n",
        "<!--"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "power_plants = power_plants[~power_plants.state.isin(['Puerto Rico','Hawaii','Alaska'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-->\n",
        ":::\n",
        "\n",
        "## Plotting\n",
        "\n",
        "Before we plot our data, let's make sure they are in the same CRS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "contiguous.crs == power_plants.crs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 5)) # Update figure size\n",
        "\n",
        "# Remove the axis for a cleaner map\n",
        "ax.axis('off')\n",
        "\n",
        "# Title for the plot\n",
        "ax.set_title('Operable electric generating plants in the contiguous United States', \n",
        "              fontsize=15)\n",
        "\n",
        "# Add states\n",
        "contiguous.plot(ax=ax,\n",
        "               color='none',\n",
        "               edgecolor='#362312')\n",
        "\n",
        "# Add electric power plants colored by energy source\n",
        "power_plants.plot(ax=ax, \n",
        "                  column='primsource',\n",
        "                  legend=True,\n",
        "                  markersize=4,\n",
        "                  cmap='tab20',\n",
        "                  alpha=0.5,\n",
        "                  legend_kwds={\n",
        "                      'title': 'Primary energy source',\n",
        "                      'title_fontsize': 'small',\n",
        "                      'fontsize': 'small',\n",
        "                      'loc': 'upper left',\n",
        "                      'bbox_to_anchor': (0, 0),\n",
        "                      'ncol': 6  \n",
        "                  })\n",
        "                  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the map above we specified the figure size when creating the plot. This size is given in inches, but [can be updated to other units](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/figure_size_units.html) (pixels, cm, etc). \n",
        "\n",
        "We also controlled the legend location using `loc` and `bbox_to_anchor` in the `legend_kwds`:\n",
        "\n",
        "- `loc` indicates the corner of the legend we want to use for placement, and\n",
        "- `bbox_to_anchor` is a tuple with coordinates indicating where to place the corner specified in `loc` relative to the axes. Values between 0 and 1 are within the axes.\n",
        "\n",
        "<!--TODO: add diagram of bbox-->\n",
        "\n",
        "`matplotlib` uses a variety of ways to locate elements within the graph and it is best to check the documentation to not spend too much time fidling with locations.\n",
        "\n",
        "<!--\n",
        "\n",
        "https://www.flexprojector.com\n",
        "\n",
        "https://www.earthdatascience.org/courses/scientists-guide-to-plotting-data-in-python/plot-spatial-data/customize-vector-plots/python-customize-map-legends-geopandas/\n",
        "\n",
        "https://stackoverflow.com/questions/74143732/customize-legend-labels-in-geopandas\n",
        "-->\n",
        "\n",
        "## `for` with `zip`\n",
        "\n",
        "Often, we need to iterate simultaneously over two iterables. \n",
        "The `zip()` function in Python allows you to combine two or more lists (or other iterables) so that you can iterate over their elements in pairs. When used with a `for` loop, it lets you process elements from each list together, like this example:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Iterate over a single list\n",
        "numbers = [1, 2, 3]\n",
        "for num in numbers:\n",
        "    print(num)\n",
        "\n",
        "print('\\n')  # Blank line\n",
        "\n",
        "# Iterate over two lists in pairs using zip()\n",
        "letters = ['a', 'b', 'c']\n",
        "for num, letter in zip(numbers, letters):\n",
        "    print(num, letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A common situation when code gets repeated is when creating subplots. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(7, 3))\n",
        "\n",
        "axes[0].set_title('This is axis 0')\n",
        "axes[1].set_title('This is axis 1')\n",
        "axes[2].set_title('This is axis 2')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, notice that the `axes` variable returned by the `plt.subplots()` function is actually a list of axes we can iterate over. \n",
        "\n",
        ":::{.callout-tip}\n",
        "## Check-in\n",
        "Use `for` and `zip()` to create the same subplots and avoid redundancy.\n",
        "<!--\n",
        "```python\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(7, 3))\n",
        "for ax, i in zip(axes, [0,1,2]):\n",
        "    ax.set_title(f'This is axis {i}')\n",
        "plt.show()\n",
        "```\n",
        "-->\n",
        ":::\n",
        "\n",
        "Remember that the figure and the axes are separete elements in a `matplotlib` plot.\n",
        "\n",
        "![Image source: [Getting Started with Matplotlib](https://www.skytowner.com/explore/getting_started_with_matplotlib)](/book/images/lesson-10/matplotlib_figure_axes_axis.png)\n",
        "\n",
        "\n",
        ":::{.callout-tip}\n",
        "## Exercise\n",
        "1. Select the power plants in California in a variable named `ca_power_plants`.\n",
        "\n",
        "2. Create a _list_ named `top_sources` with California's top 3 electric primary sources.\n",
        "\n",
        "3. Isolate the California state boundary in a variable named `ca_boundary`.\n",
        "\n",
        "4. Recreate the following plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Create a list with california top 3 electric primary sources\n",
        "ca_power_plants = power_plants[power_plants.state=='California']\n",
        "top_sources = (ca_power_plants['primsource']\n",
        "                            .value_counts()\n",
        "                            .index[:3]\n",
        "                            .tolist()\n",
        "                            )\n",
        "\n",
        "# Isolate the CA boundary\n",
        "ca_boundary = states[states.name=='California']\n",
        "\n",
        "# Create plot\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(6, 3))\n",
        "\n",
        "for ax, source in zip(axes, top_sources):\n",
        "    ca_boundary.plot(ax=ax,                \n",
        "                    color='none',\n",
        "                    edgecolor='#362312')\n",
        "    subset = ca_power_plants[ca_power_plants['primsource'] == source]\n",
        "    subset.plot(ax=ax, markersize=5, alpha=0.5)\n",
        "    ax.set_title(source)\n",
        "    ax.axis('off')  # Remove axes for a cleaner look\n",
        "\n",
        "plt.suptitle(\"Top 3 energy sources for electric power plants in CA\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "<!--TODO: add functions here-->"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "mpc-env-kernel",
      "language": "python",
      "display_name": "mpc-env-kernel",
      "path": "/Users/galaz-garcia/Library/Jupyter/kernels/mpc-env-kernel"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}