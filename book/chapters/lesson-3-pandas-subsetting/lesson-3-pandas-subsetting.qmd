---
toc-title: In this lesson
---

# 2 Subsetting

In this lesson we will learn different methods to select data from a `pandas.DataFrame`. Like it's often the case when working with the `pandas` package, there are *many* ways in which we can subset a data frame. Here we will review the core methods to do this. 

## Learning objectives
By the end of this lesson, students will be able to:

- Choose appropriate methods for selecting rows and columns from a `pandas.DataFrame`
- Construct conditions to subset rows
- Describe the difference between label-based subsetting and position-based subsetting
- Apply best practies when using `iloc` and `loc` selection


## About the data

In this lesson we will use annual estimates of bird species abundance in four coastal wetlands along the California coast. This dataset was derived for education purposes from the [UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset](https://portal.edirepository.org/nis/mapbrowse?packageid=edi.649.6)@schroeter_ucsb_2024. 
The SONGS dataset was collected as part of the [San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program](https://marinemitigation.msi.ucsb.edu). 

<!-- TO DO: add image -->
![](/book/images/lesson-3/SONGS__aerial.png)

The annual bird species abundance estimates is a CSV file with 17 columns. You can see the first three rows below.

```{python}
#| echo: false
import pandas as pd

# read in file
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')

# see the first five rows
df.head(3)
```

The four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM),  Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the `CSM_fall` column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The `year` column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023. 

![](/book/images/lesson-3/Mugu_Lagoon_from_the_Mugu_Peak_Trail.png)

<!--
There are two ways to subset data in a Data Frame: by position and by label. 

* **Subsetting by label** means we want to select data from our data frame using the *names* of the columns or the index.

* **Subsetting by position** means we want to select data from our data frame based on the data's *order* in the data frame.
-->

## CSV files

A **CSV (Comma-Separated Values) file** is an open, simple text format for storing tabular data, with rows separated by line breaks and columns by commas. It's widely used in environmental science for sharing datasets like species counts and environmental monitoring data because itâ€™s easy to create, read, and process in different platforms, without the need of proprietary software.

To read in a CSV file into our Python workspace as `pandas.DataFrame` we use the `pandas.read_csv` function:

```{python}
#| eval: false
import pandas as pd

# Read in file, argument is the file path
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')
```

Next, we obtain some high-level information about this dataframe: 
```{python}
# Print dataframe's first five rows 
df.head()
```

```{python}
# Print dataframe's last five rows 
df.tail()
```

```{python}
# Print dataframe's column names
df.columns
```

```{python}
# List the data types of each column
df.dtypes
```

```{python}
# Print dataframe's shape: output is a tuple (# rows, # columns)
df.shape
```

## Selecting a single column

Selecting a single column by column name is the simplest case for selecting data in a dataframe. The genereal syntax to do this is:
```python
df['column_name']
```
Notice the column name is given as string inside the square brackets. 
This is an example of **label-based subsetting**, which means we want to select data from our dataframe using the *names* of the columns, *not their position*. When we select rows or column using their position, we are doing **position-based subsetting**. We'll see some methods to do this when we move into selecting rows.

#### Example 
 Suppose we are interested in the number of bird species observed at the Mugu Lagoon in spring. We can access that single column in this way:
```{python}
# Select a single column by using square brackets []
mul_spring = df['MUL_spring']

# Print first five elements in this column
mul_spring.head()
```

Since we only selected a single column, `mul_spring` is a `pandas.Series`:
```{python}
# Check the type of the ouput
print(type(mul_spring))
```
:::{.callout-note}
## `pd.DataFrame` = dictionary of columns
Remember we can think of a `pandas.DataFrame` as a dictionary of its columns? Then we can access a single column using the column name as the key, just like we would do in a dictionary. That is the  we just used: `df['column_name']`.
:::

We can also do label-based subsetting of a single column  using attribute syntax:
```python
df.column_name
```

For example, to see the head of the `MUL_spring` column we would do:
```{python}
df.MUL_spring.head()
```

:::{.callout-caution}
## Favor `df['column_name']` instead of `df.column_name`
In general, it is better to use the `df['column_name']` syntax. A couple reasons why are:

- `df['column_name']` can take in any column name, while `df.column_name` only works if the column name has no spaces or special characters
- `df['column_name']` avoids conflicts with `pd.DataFrame` methods and attributes. For example, if `df` has a column named `count`, it's ambiguous whehter `pd.count` is referring to the [`count()` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html) or the `count` column.
:::

## Selecting multiple columns...

### ... using a list of column names

We can select multiple columns in a single call by passing a list with the column names to the square brackets `[]`:

```python
df[['column_1', 'column_10', 'column_245']]
```

Notice there are double square brackets. This is because we are passing the list of names `['column_1', 'column_10', 'column_245']` to the selection brakcets `[]`. 


:::{.callout-tip}
## Check-in
Is this an example of label-based selection or location-based selection?
:::

#### Example
If we want to look at the species in the Tijuana Estuary during winter and fall, then we can select these columns like this:

```{python}
# select columns with names "europe" and "asia"
tje_wf = df[['TJE_winter','TJE_fall']]
```

Notice there are double square brackets. This is because we are passing the list of names `['europe','asia']` to the selection brakcets `[]`. 

:::{.callout-tip}
## Check-in
What is the type and shape of the `tje_wf` output? Verify your answer.

```{python}
#| eval: false 
#| echo: false
# check the type of the resulting selection
print(type(tje_wf))

# check the shape of the selection
print((tje_wf.shape))
```
:::

### ... using a slice

To select a slice of the columns we will use a special case of **`loc` selection** (we'll cover the general one by the end of the lesson). The syntax will be

```python
df.loc[ : , 'column_start':'column_end']
```
where `column_start` and `column_end` are, respectively, the starting point and endpoint of the column slice we want to subset from the dataframe. 

Notice two things:

- the first value passed to `loc` is used for selecting rows, using a colon `:` as the row-selection parameter means "select all the rows"
- the slice of the dataframe we'll obtain includes both endpoints of the slice `'column_start':'column_end'`. In other words, we'll get the `column_start` column *and* the `column_end` column. This is different from how slicing works in base Python and NumPy, where the endpoint is not included.

#### Example

Let's select the slice of columns that covers all data from Carpinteria Salt Marsh and Mugu Lagoon. This corresponds to all columns between `CSM_winter` and `MUL_fall`.

```{python}
# Select columns between 'CSM_winter' and 'MUL_fall'
csm_mul = df.loc[:,'CSM_winter':'MUL_fall']
csm_mul.head()
```

### ... using a condition

<!-- TO DO -->

## Selecting rows...
Now that we are familiar with some methods for selecting columns, let's move on to selecting rows. 

### ... using a condition
Selecting rows that satisfy a particular condition is one of the most usual kinds of row subsetting. The general syntax for this type of selection is 
```python
df[condition_on_rows]
```
That `condition_of_rows` can be a myriad things, let's see some usual scenarios.

#### Example

Suppose we are intersted in all data after 2020. We can select these rows in this way:

```{python}
# Select all rows with year > 2020
post_2020 = df[df['year']>2020]
post_2020
```

Let's break down what is happening here. The condition for our rows is `df['year']>2020`, this is a `pandas.Series` with boolean values (`True` or `False`) indicating which rows satisfy the condition year>2020:

```{python}
# Check the type of df['year']>1996
print(type(df['year']>2020))

# Print the boolean series
df['year']>2020
```

 When we pass such a series of boolean values to the selection brackets `[]` we keep only the rows that correspond to a `True` value. 

<!-- TO DO: would be nice to add a diagram about selecting rows -->

:::{.callout-tip}
## Check-in
 Get the subset of our dataframe on which the San Dieguito Wetland has at least 75 species recorded during spring.
:::

#### Example

Suppose we want to look at data from years 2012 to 2015 (including both years). One way of doing this is to use the `between` operator in our condition:

```{python}
subset = df[df['year'].between(2012, 2015)]
subset
```

Let's break down this code: 

1. `df['year']` is the column with the year values, a `pandas.Series`

2. in `df['year'].between()`, we have that [`between` is a method for the `pandas.Series`](https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html) and we are calling it using the dot `.`

3. `(2012, 2015)` are the parameters for the `between()` method, from the `pandas` documentation we can see this method will subset including both endpoints

4. `df['year'].between(2012, 2015)` is then a `pandas.Series` of boolean values indicating which rows have year equal to 2012, 2013, 2014, or 2015. 

5. when we put `df['year'].between(2012, 2015)` inside the selection brackets `[]` we obtain the rows of the data frame with year equal to 2012, ..., 2015.

:::{.callout-warning}
## Avoid using `loc` for selecting only rows
It is equivalent to write

```python
# Select rows with year<2015
df[df['year'] < 2015]
```
and
```python
# Select rows with year<2015 using loc
df.loc[ df['year'] <2015 , :]
```
In the second one:

- we are using the `df.loc[ row-selection , column-selection]` syntax

- the `row-selection` parameter is the condition `df['year']<2015`

- the `column-selection` parameter is a colon `:`, which indicates we want all columns for the rows we are selecting.

We prefer the first syntax when we are selecting rows and not columns since it is simpler.
:::

### ... using multiple conditions
We can combine multipe conditions to select rows by surrounding each one in parenthesis `()` and using the or operator `|` and the and operator `&`.

#### Example: or 

Let's select rows in which the Carpinteria Salt Marsh has more than 50 registered in winter *or* fall:

```{python}
df[ (df['CSM_winter']>50) | (df['CSM_fall']>50)]
```

#### Example: and

Let's select rows with in which both the Carpinteria Salt Marsh and the San Dieguito Wetland have more than 60 reported bird species during spring:

```{python}
df[ (df['CSM_spring']>60) & (df['SDW_spring']>60)]
```

An empty dataframe! That's ok, it just means there are no rows that satisfy the given condition.

### ... by position

All the selections we have done so far have been using labels. Sometimes we may want to select certain rows depending on their *actual position* in the data frame in other words, using **position-based subsetting**.  To do this, we use **`iloc` selection** with the syntax
```python
 df.iloc[row-indices]
 ```
 `iloc` stands for integer-location based indexing.

#### Example

```{python}
# Select the fifth row (index=4)
df.iloc[4]
```

```{python}
# Select rows 9 through 13, inclduing 13
df.iloc[9:14]
```

Notice that, since we are back to indexing by position, the right endpoint of the slice is not included in the ouput. 

## Selecting rows and columns simultaneously...

Selecting rows and columns simultaneously can be done using `loc` (labels) or `iloc` (positions).

### ...by labels or conditions
When we want to select rows and columns simultaneously by labels (including using conditions) we can use `loc` selection with the syntax 

```python
df.loc[ row-selection , column-selection]
```

specifying both paratmers: `row-selection` and `column-selection`. These parameters can be a condition or a subset of labels from the index or the column names. 

#### Example

Let's select the winter surveys for Mugu Lagoon and the Tijuana Estuary after 2020:

```{python}
df.loc[df['year']>2020, ['MUL_winter','TJE_winter']]
```
Let's break down this code:

- we are using the `df.loc[ row-selection , column-selection]` syntax

- the `row-selection` parameter is the condition `df['year']>2020`, which is a boolean array saying which years are greater than 2020

- the `column-selection` parameter is `['MUL_winter','TJE_winter']` which is a list with the names of the two columns we are interested in. 