---
toc-title: In this lesson
---

# 2 Subsetting

In this lesson we will learn different methods to select data from a `pandas.DataFrame`. Like it's often the case when working with the `pandas` package, there are *many* ways in which we can subset a data frame. Here we will review the core methods to do this. 

## Learning objectives
By the end of this lesson, students will be able to:

- Choose appropriate methods for selecting rows and columns from a `pandas.DataFrame`
- Construct conditions to subset rows
- Describe the difference between label-based subsetting and position-based subsetting
- Apply best practies when using `iloc` and `loc` selection


## About the data

In this lesson we will use annual estimates of bird species abundance in four coastal wetlands along the California coast. This dataset was derived for education purposes from the [UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset](https://portal.edirepository.org/nis/mapbrowse?packageid=edi.649.6)@schroeter_ucsb_2024. 
The SONGS dataset was collected as part of the [San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program](https://marinemitigation.msi.ucsb.edu). 

<!-- TO DO: add image -->

The annual bird species abundance estimates is a CSV file with 17 columns. You can see the first three rows below.

```{python}
#| echo: false
import pandas as pd

# read in file
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')

# see the first five rows
df.head(3)
```

The four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM),  Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the `CSM_fall` column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The `year` column corresponds to the calendar year on which the data was collected. 

<!--
There are two ways to subset data in a Data Frame: by position and by label. 

* **Subsetting by label** means we want to select data from our data frame using the *names* of the columns or the index.

* **Subsetting by position** means we want to select data from our data frame based on the data's *order* in the data frame.
-->

## CSV files

A **CSV (Comma-Separated Values) file** is an open, simple text format for storing tabular data, with rows separated by line breaks and columns by commas. It's widely used in environmental science for sharing datasets like species counts and environmental monitoring data because itâ€™s easy to create, read, and process in different platforms, without the need of proprietary software.

To read in a CSV file into our Python workspace as `pandas.DataFrame` we use the `pandas.read_csv` function:

```{python}
#| eval: false
import pandas as pd

# Read in file, argument is the file path
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')
```

Next, we obtain some high-level information about this dataframe: 
```{python}
# Print dataframe's first five rows 
df.head()
```

```{python}
# Print dataframe's column names
df.columns
```

```{python}
# List the data types of each column
df.dtypes
```

```{python}
# Print dataframe's shape: output is a tuple (# rows, # columns)
df.shape
```

## Selecting a single column

Selecting a single column by column name is the simplest case for selecting data in a dataframe. The genereal syntax to do this is:
```python
df['column_name']
```
Notice the column name is given as string inside the square brackets. 
This is an example of **label-based subsetting**, which means we want to select data from our dataframe using the *names* of the columns, *not their position*. When we select rows or column using their position, we are doing **position-based subsetting**. We'll see some methods to do this when we move into selecting rows.

#### Example 
 Suppose we are interested in the number of bird species observed at the Mugu Lagoon in spring. We can access that single column in this way:
```{python}
# Select a single column by using square brackets []
mul_spring = df['MUL_spring']

# Print first five elements in this column
mul_spring.head()
```

Since we only selected a single column, `mul_spring` is a `pandas.Series`:
```{python}
# Check the type of the ouput
print(type(mul_spring))
```
:::{.callout-note}
## `pd.DataFrame` = dictionary of columns
Remember we can think of a `pandas.DataFrame` as a dictionary of its columns? Then we can access a single column using the column name as the key, just like we would do in a dictionary. That is the  we just used: `df['column_name']`.
:::

We can also do label-based subsetting of a single column  using attribute syntax:
```python
df.column_name
```

For example, to see the head of the `MUL_spring` column we would do:
```{python}
df.MUL_spring.head()
```

:::{.callout-caution}
## `df['column_name']` or `df.column_name`?
In general, it is better to use the `df['column_name']` syntax. A couple reasons why are:

- `df['column_name']` can take in any column name, while `df.column_name` only works if the column name has no spaces or special characters
- `df['column_name']` avoids conflicts with `pd.DataFrame` methods and attributes. For example, if `df` has a column named `count`, it's ambiguous whehter `pd.count` is referring to the [`count()` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html) or the `count` column.
:::

## Selecting multiple columns...

### ... using a list of column names

We can select multiple columns in a single call by passing a list with the column names to the square brackets `[]`:

```python
df[['column_1', 'column_10', 'column_245']]
```

Notice there are double square brackets. This is because we are passing the list of names `['column_1', 'column_10', 'column_245']` to the selection brakcets `[]`. 


:::{.callout-tip}
## Check-in
Is this an example of label-based selection or location-based selection?
:::

#### Example
If we want to look at the species in the Tijuana Estuary during winter and fall, then we can select these columns like this:

```{python}
# select columns with names "europe" and "asia"
tje_wf = df[['TJE_winter','TJE_fall']]
```

Notice there are double square brackets. This is because we are passing the list of names `['europe','asia']` to the selection brakcets `[]`. 

:::{.callout-tip}
## Check-in
What is the type and shape of the `tje_wf` output? Verify your answer.

```{python}
#| eval: false 
#| echo: false
# check the type of the resulting selection
print(type(tje_wf))

# check the shape of the selection
print((tje_wf.shape))
```
:::

### ... using a slice

To select a slice of the columns we will use a special case of **`loc` selection** (we'll cover the general one by the end of the lesson). The syntax will be

```python
df.loc[ : , 'column_start':'column_end']
```
where `column_start` and `column_end` are, respectively, the starting point and endpoint of the column slice we want to subset from the dataframe. 

Notice two things:

- the first value passed to `loc` is used for selecting rows, using a colon `:` as the row-selection parameter means "select all the rows"
- the slice of the dataframe we'll obtain includes both endpoints of the slice `'column_start':'column_end'`. In other words we'll get the `column_start` column *and* the `column_end` column. This is different from how slicing works in base Python and NumPy, where the endpoint is not included.

#### Example

Let's select the slice of columns that covers all data from Carpinteria Salt Marsh and Mugu Lagoon. This corresponds to all columns between `CSM_winter` and `MUL_fall`.

```{python}
# Select columns between 'CSM_winter' and 'MUL_fall'
csm_mul = df.loc[:,'CSM_winter':'MUL_fall']
csm_mul.head()
```

### ... using a condition

<!-- TO DO -->