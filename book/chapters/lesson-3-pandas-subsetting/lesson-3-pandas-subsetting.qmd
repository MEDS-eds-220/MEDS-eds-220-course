---
toc-title: In this lesson
---

# 2 Subsetting

In this lesson we will learn different methods to select data from a `pandas.DataFrame`. Like it's often the case when working with the `pandas` package, there are *many* ways in which we can subset a data frame. Here we will review the core methods to do this. 

A summary of the methods covered in this lesson can be found in @fig-summary.

## Learning objectives
By the end of this lesson, students will be able to:

- Choose appropriate methods for selecting rows and columns from a `pandas.DataFrame`
- Construct conditions to subset rows
- Describe the difference between label-based subsetting and position-based subsetting
- Apply best practies when using `iloc` and `loc` selection


## About the data

In this lesson we will use annual estimates of bird species abundance in four coastal wetlands along the California coast. This dataset was derived for education purposes for this course from the [UCSB SONGS Mitigation Monitoring: Wetland Performance Standard - Bird Abundance and Species Richness dataset](https://portal.edirepository.org/nis/mapbrowse?packageid=edi.649.6) @schroeter_ucsb_2024. 
The SONGS dataset was collected as part of the [San Onofre Nuclear Generating Station (SONGS) San Dieguito Wetland Restoration monitoring program](https://marinemitigation.msi.ucsb.edu). 

![San Onofre Nuclear Generating Station in San Diego County, California. Source: Southern California Edison](/book/images/lesson-3/SONGS_aerial.jpg)

The annual bird species abundance estimates is a CSV file with 13 columns and 14 rows. You can see the first three rows below.

```{python}
#| echo: false
import pandas as pd

# Read in file
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')

# See the first five rows
df.head(3)
```

The four wetlands where the bird surveys occured are Carpinteria Salt Marsh (CSM),  Mugu Lagoon (MUL), the San Dieguito Wetland (SDW), and the Tijuana Estuary (TJE). The values from the second column to the last column correspond to the number of different bird species recorded across the survey sites in each wetland during winter, spring, and fall of a given year. For example, the `CSM_fall` column has the number of species recorded in fall at Carpinteria Salt Marsh across years. The `year` column corresponds to the calendar year on which the data was collected. Surveys have happened yearly from 2010 to 2023. 

![Mugu Lagoon in Ventura County, California, seen from the Mugu Peak Trail. Source: USA National Park Service](/book/images/lesson-3/Mugu_Lagoon_from_the_Mugu_Peak_Trail.jpg)

## CSV files

A **CSV (Comma-Separated Values) file** is an open, simple text format for storing tabular data, with rows separated by line breaks and columns by commas. It's widely used in environmental science for sharing datasets like species counts and environmental monitoring data because itâ€™s easy to create, read, and process in different platforms, without the need of proprietary software.

To read in a CSV file into our Python workspace as `pandas.DataFrame` we use the `pandas.read_csv` function:

```{python}
#| eval: false
import pandas as pd

# Read in file, argument is the file path
df = pd.read_csv('data/wetlands_seasonal_bird_diversity.csv')
```

Next, we obtain some high-level information about this data frame: 
```{python}
# Print data frame's first five rows 
df.head()
```

```{python}
# Print data frame's last five rows 
df.tail()
```

```{python}
# Print data frame's column names
df.columns
```

```{python}
# List the data types of each column
df.dtypes
```

```{python}
# Print data frame's shape: output is a tuple (# rows, # columns)
df.shape
```

## Selecting a single column

Selecting a single column by column name is the simplest case for selecting data in a data frame. The genereal syntax to do this is:
```python
df['column_name']
```
Notice the column name is given as string inside the square brackets. 
This is an example of **label-based subsetting**, which means we want to select data from our data frame using the *names* of the columns, *not their position*. When we select rows or column using their position, we are doing **position-based subsetting**. We'll see some methods to do this when we move into selecting rows.

#### Example 
 Suppose we are interested in the number of bird species observed at the Mugu Lagoon in spring. We can access that single column in this way:
```{python}
# Select a single column by using square brackets []
mul_spring = df['MUL_spring']

# Print first five elements in this column
mul_spring.head()
```

Since we only selected a single column, `mul_spring` is a `pandas.Series`:
```{python}
# Check the type of the ouput
print(type(mul_spring))
```
:::{.callout-note}
## `pd.DataFrame` = dictionary of columns
Remember we can think of a `pandas.DataFrame` as a dictionary of its columns? Then we can access a single column using the column name as the key, just like we would do in a dictionary. That is the  we just used: `df['column_name']`.
:::

We can also do label-based subsetting of a single column  using attribute syntax:
```python
df.column_name
```

For example, to see the head of the `MUL_spring` column we would do:
```{python}
df.MUL_spring.head()
```

:::{.callout-caution}
## Favor `df['column_name']` instead of `df.column_name`
In general, it is better to use the `df['column_name']` syntax. A couple reasons why are:

- `df['column_name']` can take in any column name, while `df.column_name` only works if the column name has no spaces or special characters
- `df['column_name']` avoids conflicts with `pd.DataFrame` methods and attributes. For example, if `df` has a column named `count`, it's ambiguous whether `pd.count` is referring to the [`count()` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html) or the `count` column.
:::

## Selecting multiple columns...

### ... using a list of column names

We can select multiple columns in a single call by passing a list with the column names to the square brackets `[]`:

```python
df[['column_1', 'column_10', 'column_245']]
```

Notice there are double square brackets. This is because we are passing the list of names `['column_1', 'column_10', 'column_245']` to the selection brackets `[]`. 


:::{.callout-tip}
## Check-in
Is this an example of label-based selection or location-based selection?
:::

#### Example
If we want to look at the species in the Tijuana Estuary during winter and fall, then we can select these columns like this:

```{python}
# Select columns with names "TJE_winter" and "TJE_fall"
tje_wf = df[['TJE_winter','TJE_fall']]
```

Notice there are double square brackets. This is because we are passing the list of names `['TJE_winter','TJE_fall']` to the selection brakcets `[]`. 

:::{.callout-tip}
## Check-in
What is the type and shape of the `tje_wf` output? Verify your answer.

```{python}
#| eval: false 
#| echo: false
# Check the type of the resulting selection
print(type(tje_wf))

# Check the shape of the selection
print((tje_wf.shape))
```
:::

### ... using a slice

To select a slice of the columns we will use a special case of **`loc` selection** (we'll cover the general one by the end of the lesson). The syntax will be

```python
df.loc[ : , 'column_start':'column_end']
```
where `column_start` and `column_end` are, respectively, the starting point and endpoint of the column slice we want to subset from the data frame. 

Notice two things:

- the first value passed to `loc` is used for selecting rows, using a colon `:` as the row-selection parameter means "select all the rows"
- the slice of the data frame we'll obtain includes both endpoints of the slice `'column_start':'column_end'`. In other words, we'll get the `column_start` column *and* the `column_end` column. This is different from how slicing works in base Python and NumPy, where the endpoint is not included.

#### Example

Let's select the slice of columns that covers all data from Carpinteria Salt Marsh and Mugu Lagoon. This corresponds to all columns between `CSM_winter` and `MUL_fall`.

```{python}
# Select columns between 'CSM_winter' and 'MUL_fall'
csm_mul = df.loc[:,'CSM_winter':'MUL_fall']
csm_mul.head()
```



<!-- TODO 
### ... using a condition
fall_columns = df.filter(like='fall')
-->

## Selecting rows...
Now that we are familiar with some methods for selecting columns, let's move on to selecting rows. 

### ... using a condition
Selecting rows that satisfy a particular condition is one of the most usual kinds of row subsetting. The general syntax for this type of selection is 
```python
df[condition_on_rows]
```
That `condition_of_rows` can be a myriad things, let's see some usual scenarios.

#### Example

Suppose we are intersted in all data after 2020. We can select these rows in this way:

```{python}
# Select all rows with year > 2020
post_2020 = df[df['year']>2020]
post_2020
```

Let's break down what is happening here. The condition for our rows is `df['year']>2020`, this is a `pandas.Series` with boolean values (`True` or `False`) indicating which rows satisfy the condition year>2020:

```{python}
# Check the type of df['year']>1996
print(type(df['year']>2020))

# Print the boolean series
df['year']>2020
```

 When we pass such a series of boolean values to the selection brackets `[]` we keep only the rows that correspond to a `True` value. 

<!-- TO DO: would be nice to add a diagram about selecting rows -->

:::{.callout-tip}
## Check-in
 Get the subset of the data frame on which the San Dieguito Wetland has at least 75 species recorded during spring.
:::

#### Example

Suppose we want to look at data from years 2012 to 2015 (including both years). One way of doing this is to use the `between` operator in our condition:

```{python}
subset = df[df['year'].between(2012, 2015)]
subset
```

Let's break down this code: 

1. `df['year']` is the column with the year values, a `pandas.Series`

2. in `df['year'].between()`, we have that [`between` is a method for the `pandas.Series`](https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html) and we are calling it using the dot `.`

3. `(2012, 2015)` are the parameters for the `between()` method, from the `pandas` documentation we can see this method will subset including both endpoints

4. `df['year'].between(2012, 2015)` is then a `pandas.Series` of boolean values indicating which rows have year equal to 2012, 2013, 2014, or 2015. 

5. when we put `df['year'].between(2012, 2015)` inside the selection brackets `[]` we obtain the rows of the data frame with year equal to 2012, ..., 2015.

:::{.callout-warning}
## Avoid using `loc` for selecting only rows
It is equivalent to write

```python
# Select rows with year<2015
df[df['year']<2015]
```
and
```python
# Select rows with year<2015 using loc
df.loc[ df['year']<2015 , :]
```
In the second one:

- we are using the `df.loc[ row-selection , column-selection]` syntax

- the `row-selection` parameter is the condition `df['year']<2015`

- the `column-selection` parameter is a colon `:`, which indicates we want all columns for the rows we are selecting.

We prefer the first syntax when we are selecting rows and not columns since it is simpler.
:::

### ... using multiple conditions
We can combine multipe conditions to select rows by surrounding each one in parenthesis `()` and using the or operator `|` and the and operator `&`.

#### Example: or 

Let's select rows in which the Carpinteria Salt Marsh has more than 50 species registered in winter *or* fall:

```{python}
df[ (df['CSM_winter']>50) | (df['CSM_fall']>50)]
```

#### Example: and

Let's select rows in which both the Carpinteria Salt Marsh and the San Dieguito Wetland have more than 60 reported bird species during spring:

```{python}
df[ (df['CSM_spring']>60) & (df['SDW_spring']>60)]
```

An empty data frame! That's ok, it just means there are no rows that satisfy the given condition.

### ... by position

All the selections we have done so far have been using labels. Sometimes we may want to select certain rows depending on their *actual position* in the data frame. In other words, using **position-based subsetting**.  To do this, we use **`iloc` selection** with the syntax
```python
 df.iloc[row-indices]
 ```
 `iloc` stands for integer-location based indexing.

#### Example

```{python}
# Select the fifth row (index=4)
df.iloc[4]
```

```{python}
# Select rows 9 through 13, inclduing 13
df.iloc[9:14]
```

Notice that, since we are back to indexing by position, the right endpoint of the slice is not included in the ouput. 

## Selecting rows and columns simultaneously...

Selecting rows and columns simultaneously can be done using `loc` (labels) or `iloc` (positions).

### ...by labels or conditions
When we want to select rows and columns simultaneously by labels (including using conditions) we can use `loc` selection with the syntax 

```python
df.loc[ row-selection , column-selection]
```

specifying both paratmers: `row-selection` and `column-selection`. These parameters can be a condition or a subset of labels from the index or the column names. 

#### Example

Let's select the winter surveys for Mugu Lagoon and the Tijuana Estuary after 2020:

```{python}
df.loc[df['year']>2020, ['MUL_winter','TJE_winter']]
```
Let's break down this code:

- we are using the `df.loc[ row-selection , column-selection]` syntax

- the `row-selection` parameter is the condition `df['year']>2020`, which is a boolean array saying which years are greater than 2020

- the `column-selection` parameter is `['MUL_winter','TJE_winter']`, which is a list with the names of the two columns we are interested in. 


### ... by position

When we want to select rows and columns simultaneously by position we use `iloc` selection with the syntax:
```python
df.iloc[ row-indices , column-indices]
```

#### Example

Suppose we want to select rows 3-7 (including 7) and columns 3 and 4:

```{python}
df.iloc[3:8, [3,4]]
```

Let's break it down:

- we are using the `df.iloc[ row-indices , column-indices]` syntax to select by position

- the `row-indices` parameter is the slice *of integer indices* 3:8. Remember the right endpoint (8) won't be included.

- the `column-indices` parameter is the list of integer indices 3 and 4. This means we are selecting the fourth and fifth column.

## Notes about `loc` and `iloc`

::: {.callout-caution}
## `iloc` vs. `loc`: which one does what?
At the beginning, the difference between `iloc` and `loc` can be confusing. Remember the `i` in `iloc` stands for *integer location*, this reminds us `iloc` only uses integer indexing to retrieve information from the data frames in the same way as indexing for Python lists.

If you want to dive deeper, this is a great discussion about the difference between `iloc` and `loc`: [Stackoverflow - How are iloc and loc different?](https://stackoverflow.com/questions/31593201/how-are-iloc-and-loc-different/31593712#31593712)

And, as always, the documentation will provide you with more information:
[`pandas.DataFrame.loc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) and [`pandas.DataFrame.iloc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html).
:::

<!--
:::{.callout-warning}
## `iloc` for column selection? Avoid it!
We can also access columns by position using `iloc` - but it is best not to if possible.

Suppose we want to access the 10th column in the data frame - then we want to select a column *by position*. In this case the 10th column is the annual sea level rise data and the 10th position corresponds to the index 9. We can select this column by position using the `iloc` selection:

```{python}
# Select column by position using iloc
# The syntax is iloc[row-indices, column-indices]
# [:,9] means "select all rows from the 10th column"
annual_rise_3 = df.iloc[:,9]
annual_rise_3.head()
```

Unless you are *really* looking for information about *the 10th column*, **do not access a column by position**. This is bound to break in many ways:

- it relies on a person correctly counting the position of a column. Even with a small dataset this can be prone to error.

- it is not explicit: if we want information about sea level rise `df.annual_sea_level_rise` or `df['annual_sea_level_rise']` are explicitely telling us we are accessing that information. `df.iloc[:,9]` is obscure and uninformative.

- datastets can get updated. Maybe a new column was added before `annual_sea_level_rise`, this would change the position of the column, which would make any code depending on `df.iloc[:,9]` invalid. 

**Accessing columns by labels helps reproducibility!**
:::

-->

## Summary
:::{.column-page}
![Flow diagram for selecting core methods to subset a `pandas.DataFrame`.](/book/images/lesson-3/pandas-selection-diagram.png){#fig-summary}
:::

## Resources

What is presented in this section is not an  exhaustive list of methods to select data in `pandas.DataFrames`. There are *so many* ways to subset data to get the same result. Some of the content from this lesson is adapted from the following resources and I encourage you to read them to learn more! 

ðŸ“– [Pandas getting started tutorials - How to I select a subset of a
DataFrame](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html) 

ðŸ“– [Pandas documentation - User Guide - Indexing and Selecting Data](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-slicing-with-labels)

ðŸ“– [Python for Data Analysis, 3E - Getting started with pandas](https://wesmckinney.com/book/pandas-basics)