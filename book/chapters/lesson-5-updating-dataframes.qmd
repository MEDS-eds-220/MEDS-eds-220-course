# 4 Updating data frames

In this lesson we will introduce methods for updating a `pandas.DataFrame`, these include adding and removing columns and updating specific values. 

<!--
## Learning objectives

**TODO**

By the end of this lesson students will be able to:
-->

## About the data

For this section we will use the  Palmer Penguins dataset @palmerpenguins developed by Drs. Allison Horst, Alison Hill and Kristen Gorman. This dataset contains size measurements for three penguin species in the Palmer Archipelago, Antarctica  during 2007, 2008, and 2009. 

![The Palmer Archipelago penguins. Artwork by Dr. Allison Horst.](/book/images/lesson-5/penguins-logo.png)

The dataset has 344 rows and 8 columns. We can see the head of the dataset below:

```{python}
#| echo: false

import pandas as pd
import numpy as np

URL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'
penguins = pd.read_csv(URL)

penguins.head()
```

## Adding a single column...

Let us start by importing the packages we will use in this lesson and loading the data:

```{python}
import numpy as np
import pandas as pd
import random  # Used for randomly sampling integers

# Set the seed
random.seed(42)

# Import data
URL = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'
penguins = pd.read_csv(URL)
```

<!--
:::{.callout-caution}
**TODO** Explain seed.
:::
-->

### ... using dictionary-like syntax
The simplest syntax to add a new column to a `pandas.DataFrame` is 

```python
df['new_col_name'] = new_column_values
```
where the `new_column_values` could be: 

- a `pandas.Series` or a `numpy.array` of the same length as the data frame, or
- a single scalar.

If the column name exists, the existing column will be updated.

Remember a `pandas.DataFrame` can be seen as a dictionary of its columns. This syntax for adding a new column to a `pandas.DataFrame` is the same as adding a new key-value pair to a dictionary:
```python
# Add a new key-value pair to a dictionary
dict[new_key] = new_value
```

#### Example

We want to create a new column where the body mass is in kilograms instead of grams, then we need to divide each value in the `body_mass_g` by 1000. 

```{python}
# Add new column body_mass_kg 
penguins['body_mass_kg'] = penguins['body_mass_g']/1000

# Confirm the new column is in the data frame
print("body_mass_kg is in the data frame's columns: ", 'body_mass_kg' in penguins.columns)

# Look at the new column
penguins.head()
```

### ...using the `assign()` method

We can also create or update an existing column using the [`assign()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html) method for `pandas.DataFrames`. The general syntax is:
```python
df = df.assign(new_col_name=new_column_values)
```
Notice the new column names are not strings, we declare them as if we were creating variables.

This way of creating a new column, unlike the dictionary-like syntax, does not modify the data frame in-place. This can be useful for chaining operations:

```{python}
(penguins.assign(bill_length_cm=penguins.bill_length_mm/10)
        .plot(kind='scatter',
              x='bill_length_cm', 
              y='body_mass_g')
    )
```

### ...at a specific location

The new column was added by default at the end of the data frame. If we want to create a new column and insert it at a particular position we can use the data frame method [`insert()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html):
```python
df.insert(loc=integer_index,  # Location of new column
          column='new_col_name', 
          value=new_col_values)
```

#### Example

Let's give each penguin observation a unique identifier as a three digit number and add this column at the beginning of the data frame.

```{python}
# Create random 3-digit codes
codes = random.sample(range(100,1000), len(penguins))  # Sampling w/o replacement

# Insert codes at the front of data frame
penguins.insert(loc=0,  # Index
                column='id_code',
                value=codes)
        
penguins.head()
```

<!--
Moving columns: pop, then insert

df.insert(0, 'name', df.pop('name'))
https://stackoverflow.com/questions/35321812/move-column-in-pandas-dataframe

Inserting at a particular location.
df.columns.get_loc()
-->


## Adding multiple columns

We can also use the [`assign()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html) method to create or update multiple columns in the same call. The general syntax is:
```python
df = df.assign(new_col1_name=new_col1_values, 
               new_col2_name=new_col2_values)
```
Remember this method does not modify the data frame, so you will need to reassign the output to the original data frame to update it.

#### Example

Suppose we want to add these new columns: 

- flipper length converted from mm to cm, and
- a code representing the observer.

We can add these columns to `penguins` using `assign()`:

```{python}
# Create columns with observer codes and flipper length in cm
penguins = penguins.assign(flipper_length_cm=penguins.flipper_length_mm/10, 
                           observer=random.choices(['A','B','C'],  # Sample with replacement
                                                    k=len(penguins))
                          )
# Examine result
penguins.head()
```

## Removing columns

We can remove columns using the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method for `pandas.Data.Frames`, the syntax is:
```python
df = df.drop(columns=col_names)
```
where `col_names` can be a single column name (string) or a list of column names. Notice again that the `drop()` method does not modify the data frame in place, so you need to reassign the output.


#### Example

Now that we updated the units for flipper length and body mass, it makes sense to remove the previous columns to avoid duplicate information. We can do this using `drop()`:

```{python}
# Remove duplicate length and mass measurements
penguins = penguins.drop(columns=['flipper_length_mm','body_mass_g'])

# Confirm result
print(penguins.columns)
```

<!--
## Reordering columns and updating names
-->

<!--
:::{.callout-tip}
## Check-in
**TODO**
:::
-->

## Updating values

Sometimes we want to update a specific value in our data frame. We'll review some methods and best practices to do that in this section. 

### A single value
We can access a single value in a `pandas.DataFrame` using the locators

- [`at[]`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html) to select by labels, or
- [`iat[]`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html) to select by position. 


The syntax for `at[]` is:
```python
df.at[single_index_value, 'column_name']
```
Think of `at[]` as the equivalent to `loc[]` when trying to access a single value.

#### Example
For this example, let's first update the index of the data frame to be the `id_code` column:

```{python}
penguins = penguins.set_index('id_code')
penguins
```

If we want to know what was the bill length of the penguin which has ID number 859, we can directly access that information using `at[]`:

```{python}
# Check bill length of penguin with ID 859
penguins.at[859, 'bill_length_mm']
```

We get this bill length is an NA. Maybe we want to update it to 38.3 mm. We can do this with `at[]` too:
```{python}
# Correct bill length value of penguin with ID 859
penguins.at[859,'bill_length_mm'] = 38.3

# Confirm value was updated
penguins.loc[859]
```

If we want to access or update a single value by position we use the `iat[]` locator. The syntax for `iat[]` is:
```python
df.iat[index_integer_location, column_integer_location]
```
This is the same way you would index entries in a matrix. You may find it useful to think of `iat[]` as the equivalent of `iloc[]` to access a single value in the data frame.

Obtaining the location of a specific column within the column list can be prone to error if we do it 'by hand'. If we need to obtain this index, we can dynamically get the location this way:
```python
penguins.columns.get_loc('column_name')
```

:::{.callout-tip}
## Check-in
a. Obtain the location of the `bill_length_mm` column.

b. Use `iat[]` to access the same bill length value for the penguin with ID 859 and revert it back to an NA. Confirm your update using `iloc[]`.
:::

<!--
```{python}
# Set to NaN using iat
bill_length_index = penguins.columns.get_loc('bill_length_mm')
penguins.iat[3,bill_length_index] = np.nan

# Confirm using iloc
penguins.iloc[3]
```
-->

### Multiple values in a column

What if we want to update multiple values in a column? We'll cover two cases: with a condition on the column values and by selecting a few values to update. 


#### Using a condition 

Often, we need to create a new column where the new values depend on conditions on another column. 

#### Example

We want to classify the Palmer penguins such that :

- penguins with body mass less than 3kg as small, 
- penguins with body mass greater or equal than 3 kg but less than 5 kg as medium, 
- and those with body mass greater or equal than 5 kg as large. 

One way to add this information in a new column is using the [`numpy.select()`](https://numpy.org/doc/stable/reference/generated/numpy.select.html) function:

```{python}
# Create a list with the conditions
conditions = [penguins.body_mass_kg < 3, 
              (3 <= penguins.body_mass_kg) & (penguins.body_mass_kg < 5),
              5 <= penguins.body_mass_kg]

# Create a list with the choices
choices = ["small",
           "medium",
           "large"]

# Add the selections using np.select
penguins['size'] = np.select(conditions, 
                             choices, 
                             default=np.nan) # Value for anything outside conditions

# Display the updated data frame to confirm the new column
penguins.head()
```

<!-- 
https://stackoverflow.com/questions/54653356/case-when-function-from-r-to-python

Add np.where and pd.cut()
-->

#### By selecting values

When we only want to update some values in a column we can do this by selecting this data using `loc` (if selecting by labels) or `iloc` (if selecting by position). The general syntax for updating data with `loc` is:
```python
df.loc[row_selection, column_name] = new_values
```
where 

- `row_selection` is the rows we want to update, this can be any expression that gives us a boolean `pandas.Series`, 
- `col_name` is a single column name, and 
- `new_values` is the new value or values we want. If using multiple values, then `new_values` must be of the same length as the number of rows selected. 

Using `loc[]` in assignment modifies the data frame directly without the need for reassignment.

#### Example

We want to update the "male" values in the sex column to "M".

```{python}
# Select rows with sex=male and simplify values in 'sex' column
penguins.loc[penguins.sex=='male', 'sex'] = 'M'

# Check changes in 'sex' column specifically
print(penguins['sex'].unique())
```


### Best practices

Suppose we want to similarly update the "female" values in the `sex` column to "F". This is an example of another way we might try to do it:

```{python}
# Select rows where 'sex' is 'female' and then attempt to update 'sex' column values
penguins[penguins.sex=='female']['sex'] = 'F' # This raises SettingWithCopyWarning
```

When we select the data we want to update using **chained indexing** (two selection brackets `[][]`) instead of `loc[]` we get a `SettingWithCopyWarning`. With this warning, `pandas` is trying to alert us to a potential bug. In this case, the bug is that we actually did not update our data frame:

```{python}
# Confirm values were updated
print(penguins['sex'].unique())
```

::: {.callout-caution}
## Avoid chained indexing `[][]` and use `.loc[]`
The `SettingWithCopyWarning` often arises from chained indexing:
```python
df[df['col'] == value]['col2'] = new_value
```
In the words of the [`pandas` documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#why-does-assignment-fail-when-using-chained-indexing):

> assigning to the product of chained indexing has inherently unpredictable results.

The best practice is to use `.loc[]` instead:
```python
df.loc[df['col'] == value,'col2'] = new_value
```
`.loc[]` is generally more readable and explicitly modifies the original data frame.

Warnings in Python are intended to be helpful and can prevent unintended data modification errors! 
:::

:::{.callout-tip}
## Check-in
Update the "female" values in the `penguins` data frame to "F". Don't use chained indexing. Confirm that the values in the column were updated.
:::
<!--
```{python}
# no chained indexing in assignment = no warning
penguins.loc[penguins.sex=='female','sex'] = 'F'

# notice the values were updated now
penguins.head()
```
-->

To understand why the `SettingWithCopyWarning` pops up we need to understand that some `pandas` operations return a view to your data, while others return a copy of your data.

- **Views** are actual subsets of the original data, when we update them, we are modifying the original data frame. 

- **Copies** are unique objects, independent of our original data frames. When we update a copy we are not modifying the original data frame. 

<!-- MAKE SOME DIAGRAMS LIKE DATAQUEST https://www.dataquest.io/blog/settingwithcopywarning/ -->

![](/book/images/lesson-5/view-copy.png)

Depending on what we are trying to do we might want to modify the original data frame or we might want to modify a copy. 

![](/book/images/lesson-5/modify-view-copy.png)

Pandas raises the `SettingWithCopyWarning`  because it tries to balance memory efficiency with data integrity. By default, it avoids creating unnecessary copies, but sometimes it’s ambiguous whether a subset should be independent (a copy) or connected (a view).

#### Example

We only want to use data from Biscoe island and, after doing some analyses, we want to add a new column to it:

```{python}
# Select penguins from Biscoe island
biscoe = penguins[penguins.island=='Biscoe']

# ... Other analyses ...

# Add a column
biscoe['sample_col'] = 100  # This raises SettingWithCopyWarning
```

`pandas` is trying to alert you that it is unsure about whether `biscoe` is a view or a copy and it's unclear whether an of our code will modify our dataset or not.

To fix this we can **take control of the copy-view situation and explicitly ask for a copy of the dataset when subsetting the data**. Use the [`copy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html) method to do this:

```{python}
# Make sure you get an independent data frame that won't alter the original
biscoe = penguins[penguins.island=='Biscoe'].copy()

# Add a column, no warning
biscoe['sample_col'] = 100
```

Now we are sure we did not modify our initial data, but rather the `biscoe` data frame:

```{python}
# Confirm the new column is in our subset data
biscoe.head()
```

```{python}
# Confirm that original data was not modified
print('sample_column' in penguins.columns)
```

The `SettingWithCopyWarning` can be tricky, there are also false positives and false negatives. Avoiding chained indexing and making a copy of your data frame subset when needed and possible will save you from the usual pitfalls! 

To learn more about the `SettingWithCopyWarning`, these are some articles that go into more depth:

📖 [`pandas` Documentation -  Returning a view versus a copy](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy)

📖 [Real Python-  SettingWithCopyWarning in pandas: Views vs Copies](https://realpython.com/pandas-settingwithcopywarning/#reader-comments)

📖 [Dataquest - SettingwithCopyWarning: How to Fix This Warning in Pandas](https://www.dataquest.io/blog/settingwithcopywarning/)
